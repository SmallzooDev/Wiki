[{"content":"함수 타입 함수 타입 정의 (T) -\u0026gt; Boolean : Boolean을 반환하는 함수 Predicate (T) -\u0026gt; R : 값 하나를 다른 값으로 변환하는 함수 transfrom (T) -\u0026gt; Unit : Unit을 반환하는 함수 operation 함수 타입 활용 invoke라는 단 하나의 메서드만 제공함, 명시적 invoke호출과 ()연산자로 호출 함수타입 파라미터를 ()? 로 감싸서 널러블함을 표현할 수 있음 (이경우는 명시적 invoke만 가능) named parameter 함수 타입을 정의 할 때 \u0026rsquo;named parameter\u0026rsquo;를 사용 가능 오직 개발 편의를 위한 것 익명 함수 익명함수는 함수 타입 객체를 반환하는 표현식 generic, default parameter는 지원하지 않음 val add2 = fun(a: Int, b: Int) = a + b 익명함수 자체는 요즘 사용하지 않는다고 함 람다가 더 짧고 지원이 더 잘됨 인텔리제이는 람다만 힌트를 제공 그래도 아래와 같은 상황에는 아직 유용 return 범위 명확히 구분하고 싶을 때 타입 명시적 선언 (람다보다 깔끔) return을 명시적으로 사용해야 할 때 고차함수 인자가 2개 이상이고 복잡할 때 람다 표현식 익명함수보다 더 짧은 대안 람다 표현식이 더 많은 기능을 지원 항목 익명 함수 (anonymous function) 람다식 (lambda expression) 작성 방식 fun 키워드 사용 { 파라미터 -\u0026gt; 본문 } 형태 return 동작 로컬 return (해당 함수만 빠져나감) 기본적으로 바깥 함수로 비탈출(non-local return) 가능 타입 추론 명확한 타입 명시 가능 타입 추론 많이 의존 제어문 사용 return, break, continue 자유롭게 사용 가능 제한 있음 (non-local return 조심) ","permalink":"http://localhost:1313/_wiki/kotlin-functional/","summary":"함수 타입 함수 타입 정의 (T) -\u0026gt; Boolean : Boolean을 반환하는 함수 Predicate (T) -\u0026gt; R : 값 하나를 다른 값으로 변환하는 함수 transfrom (T) -\u0026gt; Unit : Unit을 반환하는 함수 operation 함수 타입 활용 invoke라는 단 하나의 메서드만 제공함, 명시적 invoke호출과 ()연산자로 호출 함수타입 파라미터를 ()? 로 감싸서 널러블함을 표현할 수 있음 (이경우는 명시적 invoke만 가능) named parameter 함수 타입을 정의 할 때 \u0026rsquo;named parameter\u0026rsquo;를 사용 가능 오직 개발 편의를 위한 것 익명 함수 익명함수는 함수 타입 객체를 반환하는 표현식 generic, default parameter는 지원하지 않음 val add2 = fun(a: Int, b: Int) = a + b 익명함수 자체는 요즘 사용하지 않는다고 함 람다가 더 짧고 지원이 더 잘됨 인텔리제이는 람다만 힌트를 제공 그래도 아래와 같은 상황에는 아직 유용 return 범위 명확히 구분하고 싶을 때 타입 명시적 선언 (람다보다 깔끔) return을 명시적으로 사용해야 할 때 고차함수 인자가 2개 이상이고 복잡할 때 람다 표현식 익명함수보다 더 짧은 대안 람다 표현식이 더 많은 기능을 지원 항목 익명 함수 (anonymous function) 람다식 (lambda expression) 작성 방식 fun 키워드 사용 { 파라미터 -\u0026gt; 본문 } 형태 return 동작 로컬 return (해당 함수만 빠져나감) 기본적으로 바깥 함수로 비탈출(non-local return) 가능 타입 추론 명확한 타입 명시 가능 타입 추론 많이 의존 제어문 사용 return, break, continue 자유롭게 사용 가능 제한 있음 (non-local return 조심) ","title":"코틀린 함수형 프로그래밍"},{"content":"C++ Grammar and Syntax Guide for Coding Interviews (Algorithms \u0026amp; DS) Core Data Types and Variables Basic Types int x = 5; // Integer long long bigNum = 1LL\u0026lt;\u0026lt;60; // Large integer (note LL suffix) double y = 3.14; // Double precision floating point bool flag = true; // Boolean char c = \u0026#39;A\u0026#39;; // Character string s = \u0026#34;Hello\u0026#34;; // String (requires #include \u0026lt;string\u0026gt;) Type Modifiers unsigned int positiveOnly = 100; // Only non-negative values const int FIXED = 10; // Cannot be modified after initialization Type Aliases typedef long long ll; // Old style type alias using ll = long long; // Modern style type alias (preferred) Auto Type Deduction auto num = 10; // Compiler deduces type (int in this case) auto it = myVector.begin(); // Iterator type automatically deduced Operators and Expressions Arithmetic Operators int a = 5 + 3; // Addition: 8 int b = 5 - 3; // Subtraction: 2 int c = 5 * 3; // Multiplication: 15 int d = 5 / 3; // Integer division: 1 int e = 5 % 3; // Modulo (remainder): 2 double f = 5.0/3; // Floating-point division: 1.6666... Compound Assignment a += 2; // Same as a = a + 2 a -= 2; // Same as a = a - 2 a *= 2; // Same as a = a * 2 a /= 2; // Same as a = a / 2 a %= 2; // Same as a = a % 2 Increment/Decrement int a = 5; int b = ++a; // Pre-increment: a becomes 6, b becomes 6 int c = a++; // Post-increment: c becomes 6, then a becomes 7 int d = --a; // Pre-decrement: a becomes 6, d becomes 6 int e = a--; // Post-decrement: e becomes 6, then a becomes 5 Comparison Operators bool isEqual = (a == b); // Equal to bool isNotEqual = (a != b); // Not equal to bool isGreater = (a \u0026gt; b); // Greater than bool isLess = (a \u0026lt; b); // Less than bool isGreaterEq = (a \u0026gt;= b); // Greater than or equal to bool isLessEq = (a \u0026lt;= b); // Less than or equal to Logical Operators bool andResult = (a \u0026gt; 0 \u0026amp;\u0026amp; b \u0026gt; 0); // Logical AND (short-circuit) bool orResult = (a \u0026gt; 0 || b \u0026gt; 0); // Logical OR (short-circuit) bool notResult = !a; // Logical NOT Bitwise Operators int bitwiseAnd = a \u0026amp; b; // Bitwise AND int bitwiseOr = a | b; // Bitwise OR int bitwiseXor = a ^ b; // Bitwise XOR int bitwiseNot = ~a; // Bitwise NOT int leftShift = a \u0026lt;\u0026lt; 2; // Left shift (multiply by 2^2) int rightShift = a \u0026gt;\u0026gt; 2; // Right shift (divide by 2^2) Ternary Operator int max = (a \u0026gt; b) ? a : b; // If a \u0026gt; b, max = a; otherwise max = b Control Flow Conditionals // If-else statement if (x \u0026gt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Positive\u0026#34;; } else if (x \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Negative\u0026#34;; } else { cout \u0026lt;\u0026lt; \u0026#34;Zero\u0026#34;; } // Switch statement switch (x) { case 1: cout \u0026lt;\u0026lt; \u0026#34;One\u0026#34;; break; case 2: cout \u0026lt;\u0026lt; \u0026#34;Two\u0026#34;; break; default: cout \u0026lt;\u0026lt; \u0026#34;Other\u0026#34;; } Loops // For loop for (int i = 0; i \u0026lt; n; i++) { // Body } // Range-based for loop (C++11) for (auto element : container) { // Process each element } // While loop while (condition) { // Body } // Do-while loop do { // Body } while (condition); Loop Control for (int i = 0; i \u0026lt; n; i++) { if (condition1) continue; // Skip current iteration if (condition2) break; // Exit loop completely } Functions Basic Function // Declaration and definition int add(int a, int b) { return a + b; } // Usage int sum = add(5, 3); // sum = 8 Default Parameters int multiply(int a, int b = 1) { return a * b; } int product1 = multiply(5); // b defaults to 1, result = 5 int product2 = multiply(5, 3); // b is 3, result = 15 Function Overloading int max(int a, int b) { return (a \u0026gt; b) ? a : b; } double max(double a, double b) { return (a \u0026gt; b) ? a : b; } Pass by Reference void swap(int\u0026amp; a, int\u0026amp; b) { int temp = a; a = b; b = temp; } int x = 5, y = 10; swap(x, y); // After this: x = 10, y = 5 Lambda Functions (C++11) // Basic syntax: [capture](parameters) -\u0026gt; returnType { body } auto add = [](int a, int b) -\u0026gt; int { return a + b; }; // Capture by value int multiplier = 2; auto multiply = [multiplier](int x) { return x * multiplier; }; // Capture by reference auto increment = [\u0026amp;multiplier]() { multiplier++; }; // Capture all by value auto lambda1 = [=]() { /* can use all variables by value */ }; // Capture all by reference auto lambda2 = [\u0026amp;]() { /* can use all variables by reference */ }; // Capture specific variables with different methods auto lambda3 = [x, \u0026amp;y]() { /* x by value, y by reference */ }; Function Pointers and std::function #include \u0026lt;functional\u0026gt; // Function pointer int (*funcPtr)(int, int) = add; // std::function object (more versatile) std::function\u0026lt;int(int, int)\u0026gt; func = add; // Can also store lambdas std::function\u0026lt;int(int)\u0026gt; doubler = [](int x) { return x * 2; }; Arrays and Strings Arrays // Declaration and initialization int arr1[5]; // Uninitialized array of 5 integers int arr2[5] = {1, 2, 3, 4, 5}; // Initialized array int arr3[] = {1, 2, 3, 4, 5}; // Size deduced from initializer int arr4[5] = {1, 2}; // Partial initialization (rest are 0) // Multidimensional arrays int matrix[3][4]; // 3×4 matrix (3 rows, 4 columns) int cube[3][3][3]; // 3D array // Accessing elements int first = arr2[0]; // First element (1-based indexing) int last = arr2[4]; // Last element // Common error: arrays don\u0026#39;t track their size int size = sizeof(arr2) / sizeof(arr2[0]); // Calculate array size C-style Strings char str1[] = \u0026#34;Hello\u0026#34;; // Null-terminated character array char str2[10] = \u0026#34;Hello\u0026#34;; // With explicit size const char* str3 = \u0026#34;Hello\u0026#34;; // String literal (read-only) // String operations (require \u0026lt;cstring\u0026gt;) #include \u0026lt;cstring\u0026gt; size_t len = strlen(str1); // Length: 5 char concat[20]; strcpy(concat, str1); // Copy str1 to concat strcat(concat, \u0026#34; World\u0026#34;); // Append to concat int comp = strcmp(str1, str2); // Compare strings C++ Strings #include \u0026lt;string\u0026gt; // Declaration and initialization string s1; // Empty string string s2 = \u0026#34;Hello\u0026#34;; // From string literal string s3(5, \u0026#39;a\u0026#39;); // String of 5 \u0026#39;a\u0026#39;s: \u0026#34;aaaaa\u0026#34; string s4 = s2; // Copy of s2 // Operations int length = s2.length(); // or s2.size() char first = s2[0]; // Access character (no bounds checking) char safe = s2.at(0); // Access with bounds checking string concat = s2 + \u0026#34; World\u0026#34;; // String concatenation s2 += \u0026#34; World\u0026#34;; // Append to s2 string sub = s2.substr(0, 5); // Substring (starting at 0, length 5) // Searching size_t pos = s2.find(\u0026#34;llo\u0026#34;); // Find substring (returns position or string::npos) bool contains = s2.find(\u0026#34;llo\u0026#34;) != string::npos; // Check if contains substring // Comparison bool isEqual = (s2 == s3); // String comparison bool isLess = (s2 \u0026lt; s3); // Lexicographical comparison // Modification s2.replace(0, 1, \u0026#34;J\u0026#34;); // Replace \u0026#34;H\u0026#34; with \u0026#34;J\u0026#34; s2.erase(0, 1); // Remove first character s2.insert(0, \u0026#34;H\u0026#34;); // Insert at position 0 s2.clear(); // Empty the string bool isEmpty = s2.empty(); // Check if empty STL Containers Vector #include \u0026lt;vector\u0026gt; // Declaration and initialization vector\u0026lt;int\u0026gt; v1; // Empty vector vector\u0026lt;int\u0026gt; v2(5); // Vector of 5 zeros vector\u0026lt;int\u0026gt; v3(5, 10); // Vector of five 10s vector\u0026lt;int\u0026gt; v4 = {1, 2, 3, 4, 5}; // Using initializer list vector\u0026lt;int\u0026gt; v5(v4); // Copy of v4 vector\u0026lt;int\u0026gt; v6(v4.begin(), v4.begin()+3); // First 3 elements of v4 // Size operations int size = v4.size(); // Number of elements bool isEmpty = v4.empty(); // Check if empty v4.resize(10); // Resize to 10 elements v4.resize(12, 7); // Add 2 more elements with value 7 int capacity = v4.capacity(); // Current capacity v4.reserve(20); // Reserve space for 20 elements v4.shrink_to_fit(); // Reduce capacity to match size // Element access int first = v4[0]; // First element (no bounds checking) int safe = v4.at(0); // With bounds checking int front = v4.front(); // First element int back = v4.back(); // Last element int* data = v4.data(); // Pointer to underlying array // Modifiers v4.push_back(6); // Add element to end v4.pop_back(); // Remove last element v4.insert(v4.begin() + 2, 10); // Insert 10 at position 2 v4.insert(v4.begin() + 2, 3, 10); // Insert 3 copies of 10 v4.insert(v4.begin() + 2, {7, 8, 9}); // Insert multiple elements v4.erase(v4.begin() + 2); // Remove element at position 2 v4.erase(v4.begin(), v4.begin() + 3); // Remove range of elements v4.clear(); // Remove all elements vector\u0026lt;int\u0026gt;().swap(v4); // Clear and deallocate memory // Iterating for (auto it = v4.begin(); it != v4.end(); ++it) { cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } // Range-based loop (C++11) for (int x : v4) { cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } // Algorithm example (sort) #include \u0026lt;algorithm\u0026gt; sort(v4.begin(), v4.end()); // Sort in ascending order sort(v4.begin(), v4.end(), greater\u0026lt;int\u0026gt;()); // Sort in descending order // 2D vector vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; matrix(3, vector\u0026lt;int\u0026gt;(4, 0)); // 3×4 matrix of zeros int val = matrix[1][2]; // Access element Pair and Tuple #include \u0026lt;utility\u0026gt; // For pair #include \u0026lt;tuple\u0026gt; // For tuple // Pair pair\u0026lt;int, string\u0026gt; p1 = {1, \u0026#34;one\u0026#34;}; // Create pair pair\u0026lt;int, string\u0026gt; p2 = make_pair(2, \u0026#34;two\u0026#34;); // Alternative creation int first = p1.first; // Access first element string second = p1.second; // Access second element bool isLess = (p1 \u0026lt; p2); // Lexicographical comparison // Tuple tuple\u0026lt;int, string, double\u0026gt; t1 = {1, \u0026#34;one\u0026#34;, 1.1}; // Create tuple tuple\u0026lt;int, string, double\u0026gt; t2 = make_tuple(2, \u0026#34;two\u0026#34;, 2.2); int tFirst = get\u0026lt;0\u0026gt;(t1); // Access elements by index string tSecond = get\u0026lt;1\u0026gt;(t1); double tThird = get\u0026lt;2\u0026gt;(t1); Set and Multiset #include \u0026lt;set\u0026gt; // Set (sorted, no duplicates) set\u0026lt;int\u0026gt; s1; // Empty set set\u0026lt;int\u0026gt; s2 = {1, 2, 3, 4, 5}; // Using initializer list set\u0026lt;int, greater\u0026lt;int\u0026gt;\u0026gt; s3; // Custom comparison (descending) // Size operations int size = s2.size(); // Number of elements bool isEmpty = s2.empty(); // Check if empty // Modifiers s2.insert(6); // Insert element auto result = s2.insert(6); // Returns pair\u0026lt;iterator, bool\u0026gt; bool wasInserted = result.second; // Check if inserted s2.erase(3); // Remove element by value s2.erase(s2.begin()); // Remove element by iterator s2.erase(s2.begin(), s2.find(4)); // Remove range s2.clear(); // Remove all elements // Lookup auto it = s2.find(3); // Find element bool contains = (it != s2.end()); // Check if found int count = s2.count(3); // Count occurrences (0 or 1) auto lower = s2.lower_bound(3); // First element \u0026gt;= 3 auto upper = s2.upper_bound(3); // First element \u0026gt; 3 auto range = s2.equal_range(3); // Both bounds as pair // Multiset (sorted, allows duplicates) multiset\u0026lt;int\u0026gt; ms = {1, 2, 2, 3, 3, 3}; // Create multiset ms.insert(3); // Insert another 3 int count3 = ms.count(3); // Count of 3s (now 4) Map and Multimap #include \u0026lt;map\u0026gt; // Map (sorted key-value pairs, unique keys) map\u0026lt;string, int\u0026gt; m1; // Empty map map\u0026lt;string, int\u0026gt; m2 = {{\u0026#34;one\u0026#34;, 1}, {\u0026#34;two\u0026#34;, 2}}; // Using initializer list map\u0026lt;string, int, greater\u0026lt;string\u0026gt;\u0026gt; m3; // Custom key comparison // Element access int value = m2[\u0026#34;one\u0026#34;]; // Access by key (inserts if not found) int valueOrDefault = m2.value_or(\u0026#34;three\u0026#34;, 0); // Value or default if not found // Size operations int size = m2.size(); // Number of elements bool isEmpty = m2.empty(); // Check if empty // Modifiers m2[\u0026#34;three\u0026#34;] = 3; // Insert or update m2.insert({\u0026#34;four\u0026#34;, 4}); // Insert only m2.insert(make_pair(\u0026#34;five\u0026#34;, 5)); // Alternative insertion auto result = m2.insert({\u0026#34;one\u0026#34;, 10}); // Won\u0026#39;t insert if key exists bool wasInserted = result.second; // Check if inserted m2.erase(\u0026#34;one\u0026#34;); // Remove by key m2.erase(m2.begin()); // Remove by iterator m2.erase(m2.begin(), m2.find(\u0026#34;three\u0026#34;)); // Remove range m2.clear(); // Remove all elements // Lookup auto it = m2.find(\u0026#34;one\u0026#34;); // Find element bool contains = (it != m2.end()); // Check if found int count = m2.count(\u0026#34;one\u0026#34;); // Count occurrences (0 or 1) auto lower = m2.lower_bound(\u0026#34;one\u0026#34;); // First key \u0026gt;= \u0026#34;one\u0026#34; auto upper = m2.upper_bound(\u0026#34;one\u0026#34;); // First key \u0026gt; \u0026#34;one\u0026#34; auto range = m2.equal_range(\u0026#34;one\u0026#34;); // Both bounds as pair // Iterating for (const auto\u0026amp; pair : m2) { cout \u0026lt;\u0026lt; pair.first \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; pair.second \u0026lt;\u0026lt; endl; } // Multimap (sorted key-value pairs, allows duplicate keys) multimap\u0026lt;string, int\u0026gt; mm = {{\u0026#34;one\u0026#34;, 1}, {\u0026#34;two\u0026#34;, 2}, {\u0026#34;one\u0026#34;, 10}}; int countOne = mm.count(\u0026#34;one\u0026#34;); // Count of \u0026#34;one\u0026#34; keys (2) Unordered Containers #include \u0026lt;unordered_set\u0026gt; #include \u0026lt;unordered_map\u0026gt; // Unordered set (hash-based, no duplicates) unordered_set\u0026lt;int\u0026gt; us = {1, 2, 3, 4, 5}; us.insert(6); // O(1) average insertion bool contains = (us.find(3) != us.end()); // O(1) average lookup // Unordered map (hash-based key-value pairs, unique keys) unordered_map\u0026lt;string, int\u0026gt; um = {{\u0026#34;one\u0026#34;, 1}, {\u0026#34;two\u0026#34;, 2}}; um[\u0026#34;three\u0026#34;] = 3; // O(1) average insertion int value = um[\u0026#34;one\u0026#34;]; // O(1) average lookup // Hash table properties float loadFactor = us.load_factor(); // Current load factor float maxLoadFactor = us.max_load_factor(); // Max load factor us.max_load_factor(0.7f); // Set max load factor us.rehash(20); // Set minimum bucket count us.reserve(15); // Reserve space for elements Stack #include \u0026lt;stack\u0026gt; // Declaration and initialization stack\u0026lt;int\u0026gt; st; // Empty stack // Operations st.push(1); // Add element to top st.push(2); // Add another element int top = st.top(); // Access top element (2) st.pop(); // Remove top element bool isEmpty = st.empty(); // Check if empty int size = st.size(); // Number of elements Queue #include \u0026lt;queue\u0026gt; // Declaration and initialization queue\u0026lt;int\u0026gt; q; // Empty queue // Operations q.push(1); // Add element to back q.push(2); // Add another element int front = q.front(); // Access front element (1) int back = q.back(); // Access back element (2) q.pop(); // Remove front element bool isEmpty = q.empty(); // Check if empty int size = q.size(); // Number of elements Priority Queue #include \u0026lt;queue\u0026gt; // Declaration and initialization (max heap by default) priority_queue\u0026lt;int\u0026gt; pq; // Empty priority queue (max-heap) priority_queue\u0026lt;int, vector\u0026lt;int\u0026gt;, greater\u0026lt;int\u0026gt;\u0026gt; minpq; // Min-heap // Operations pq.push(3); // Add element pq.push(1); // Add element pq.push(4); // Add element int top = pq.top(); // Access top element (largest: 4) pq.pop(); // Remove top element bool isEmpty = pq.empty(); // Check if empty int size = pq.size(); // Number of elements // Custom comparison struct Compare { bool operator()(const pair\u0026lt;int, int\u0026gt;\u0026amp; a, const pair\u0026lt;int, int\u0026gt;\u0026amp; b) { return a.first \u0026gt; b.first; // Min-heap based on first element } }; priority_queue\u0026lt;pair\u0026lt;int, int\u0026gt;, vector\u0026lt;pair\u0026lt;int, int\u0026gt;\u0026gt;, Compare\u0026gt; customPQ; Deque #include \u0026lt;deque\u0026gt; // Declaration and initialization deque\u0026lt;int\u0026gt; dq; // Empty deque deque\u0026lt;int\u0026gt; dq2 = {1, 2, 3, 4, 5}; // Using initializer list // Operations (all operations at both ends are efficient) dq.push_back(6); // Add to back dq.push_front(0); // Add to front dq.pop_back(); // Remove from back dq.pop_front(); // Remove from front int front = dq.front(); // Access front element int back = dq.back(); // Access back element int element = dq[2]; // Random access bool isEmpty = dq.empty(); // Check if empty int size = dq.size(); // Number of elements STL Algorithms Important Headers #include \u0026lt;algorithm\u0026gt; // Most algorithms #include \u0026lt;numeric\u0026gt; // Numeric algorithms like accumulate #include \u0026lt;functional\u0026gt; // Function objects Non-modifying Sequence Operations // Find auto it = find(v.begin(), v.end(), value); // Find value auto it = find_if(v.begin(), v.end(), // Find using predicate [](int x) { return x \u0026gt; 10; }); int count = count(v.begin(), v.end(), value); // Count occurrences int count = count_if(v.begin(), v.end(), // Count using predicate [](int x) { return x % 2 == 0; }); // Comparison bool allEven = all_of(v.begin(), v.end(), // Check if all meet condition [](int x) { return x % 2 == 0; }); bool anyEven = any_of(v.begin(), v.end(), // Check if any meets condition [](int x) { return x % 2 == 0; }); bool noneEven = none_of(v.begin(), v.end(), // Check if none meet condition [](int x) { return x % 2 == 0; }); // Search auto it = search(v1.begin(), v1.end(), // Find subsequence v2.begin(), v2.end()); // Min/Max auto minElement = min_element(v.begin(), v.end()); // Iterator to minimum auto maxElement = max_element(v.begin(), v.end()); // Iterator to maximum auto [minIt, maxIt] = minmax_element(v.begin(), v.end()); // Both at once Modifying Sequence Operations // Copy copy(src.begin(), src.end(), dest.begin()); // Copy range to destination copy_if(src.begin(), src.end(), dest.begin(), // Copy with condition [](int x) { return x \u0026gt; 0; }); copy_n(src.begin(), 5, dest.begin()); // Copy first n elements // Transform transform(src.begin(), src.end(), dest.begin(), // Apply function to each element [](int x) { return x * 2; }); transform(src1.begin(), src1.end(), // Apply binary function src2.begin(), dest.begin(), [](int x, int y) { return x + y; }); // Generate and Fill fill(v.begin(), v.end(), value); // Fill range with value fill_n(v.begin(), 5, value); // Fill first n elements generate(v.begin(), v.end(), // Generate values with function []() { return rand() % 100; }); iota(v.begin(), v.end(), 0); // Fill with increasing values // Remove auto newEnd = remove(v.begin(), v.end(), value); // Remove value (doesn\u0026#39;t resize) v.erase(newEnd, v.end()); // Actually erase removed elements auto newEnd = remove_if(v.begin(), v.end(), // Remove with condition [](int x) { return x \u0026lt; 0; }); // Replace replace(v.begin(), v.end(), oldValue, newValue); // Replace value replace_if(v.begin(), v.end(), // Replace with condition [](int x) { return x \u0026lt; 0; }, 0); // Reverse and Rotate reverse(v.begin(), v.end()); // Reverse range rotate(v.begin(), v.begin() + 3, v.end()); // Rotate elements Sorting and Related Operations // Sorting sort(v.begin(), v.end()); // Sort in ascending order sort(v.begin(), v.end(), greater\u0026lt;int\u0026gt;()); // Sort in descending order sort(v.begin(), v.end(), // Sort with custom comparator [](int a, int b) { return abs(a) \u0026lt; abs(b); }); partial_sort(v.begin(), v.begin() + 5, v.end()); // Sort just first 5 elements stable_sort(v.begin(), v.end()); // Stable sort // Binary search (on sorted ranges) bool found = binary_search(v.begin(), v.end(), value); // Check if exists auto it = lower_bound(v.begin(), v.end(), value); // First element \u0026gt;= value auto it = upper_bound(v.begin(), v.end(), value); // First element \u0026gt; value auto [first, last] = equal_range(v.begin(), v.end(), value); // Both bounds // Partitioning auto it = partition(v.begin(), v.end(), // Partition by condition [](int x) { return x % 2 == 0; }); bool isPartitioned = is_partitioned(v.begin(), v.end(), // Check if partitioned [](int x) { return x % 2 == 0; }); // Nth element nth_element(v.begin(), v.begin() + n, v.end()); // Nth element in sorted position Numeric Operations #include \u0026lt;numeric\u0026gt; // Basic operations int sum = accumulate(v.begin(), v.end(), 0); // Sum of elements int product = accumulate(v.begin(), v.end(), 1, // Product of elements multiplies\u0026lt;int\u0026gt;()); int sum = reduce(v.begin(), v.end()); // C++17 parallel-friendly sum // Adjacent element operations vector\u0026lt;int\u0026gt; differences(v.size() - 1); adjacent_difference(v.begin(), v.end(), // Differences of adjacent elements differences.begin()); vector\u0026lt;int\u0026gt; sums(v.size() - 1); adjacent_find(v.begin(), v.end(), // Find equal adjacent elements sums.begin()); // Prefix sums vector\u0026lt;int\u0026gt; prefixSums(v.size()); partial_sum(v.begin(), v.end(), prefixSums.begin()); // Cumulative sum // Inner product int dotProduct = inner_product(v1.begin(), v1.end(), // Dot product v2.begin(), 0); Heap Operations // Create heap make_heap(v.begin(), v.end()); // Create max-heap make_heap(v.begin(), v.end(), greater\u0026lt;int\u0026gt;()); // Create min-heap // Heap operations v.push_back(value); // Add element to end push_heap(v.begin(), v.end()); // Fix heap after push_back pop_heap(v.begin(), v.end()); // Move largest to end v.pop_back(); // Remove element now at end // Heap properties bool isHeap = is_heap(v.begin(), v.end()); // Check if is a heap auto it = is_heap_until(v.begin(), v.end()); // Iterator to first non-heap element Set Operations (on sorted ranges) // Difference, union, intersection set_difference(v1.begin(), v1.end(), // Elements in v1 but not in v2 v2.begin(), v2.end(), result.begin()); set_union(v1.begin(), v1.end(), // Elements in either v1 or v2 v2.begin(), v2.end(), result.begin()); set_intersection(v1.begin(), v1.end(), // Elements in both v1 and v2 v2.begin(), v2.end(), result.begin()); set_symmetric_difference(v1.begin(), v1.end(), // Elements in either but not both v2.begin(), v2.end(), result.begin()); // Set membership bool isSubset = includes(v1.begin(), v1.end(), // Check if v2 is subset of v1 v2.begin(), v2.end()); Common Algorithm Patterns Binary Search Implementation // Binary search on sorted array bool binarySearch(const vector\u0026lt;int\u0026gt;\u0026amp; arr, int target) { int left = 0; int right = arr.size() - 1; while (left \u0026lt;= right) { int mid = left + (right - left) / 2; // Avoid overflow if (arr[mid] == target) return true; else if (arr[mid] \u0026lt; target) left = mid + 1; else right = mid - 1; } return false; } // Find first position greater than or equal to target int lowerBound(const vector\u0026lt;int\u0026gt;\u0026amp; arr, int target) { int left = 0; int right = arr.size(); while (left \u0026lt; right) { int mid = left + (right - left) / 2; if (arr[mid] \u0026lt; target) left = mid + 1; else right = mid; } return left; } // Find first position greater than target int upperBound(const vector\u0026lt;int\u0026gt;\u0026amp; arr, int target) { int left = 0; int right = arr.size(); while (left \u0026lt; right) { int mid = left + (right - left) / 2; if (arr[mid] \u0026lt;= target) left = mid + 1; else right = mid; } return left; } Two Pointers Technique // Find pair with given sum in sorted array bool findPair(const vector\u0026lt;int\u0026gt;\u0026amp; arr, int target) { int left = 0; int right = arr.size() - 1; while (left \u0026lt; right) { int currentSum = arr[left] + arr[right]; if (currentSum == target) return true; else if (currentSum \u0026lt; target) left++; else right--; } return false; } // Remove duplicates from sorted array in-place int removeDuplicates(vector\u0026lt;int\u0026gt;\u0026amp; nums) { if (nums.empty()) return 0; int writeIndex = 1; for (int readIndex = 1; readIndex \u0026lt; nums.size(); readIndex++) { if (nums[readIndex] != nums[readIndex - 1]) { nums[writeIndex++] = nums[readIndex]; } } return writeIndex; } // Find maximum water container (container with most water problem) int maxArea(const vector\u0026lt;int\u0026gt;\u0026amp; height) { int left = 0; int right = height.size() - 1; int maxWater = 0; while (left \u0026lt; right) { int h = min(height[left], height[right]); int w = right - left; maxWater = max(maxWater, h * w); if (height[left] \u0026lt; height[right]) left++; else right--; } return maxWater; } // Three-sum problem vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; threeSum(vector\u0026lt;int\u0026gt;\u0026amp; nums) { vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; result; if (nums.size() \u0026lt; 3) return result; sort(nums.begin(), nums.end()); for (int i = 0; i \u0026lt; nums.size() - 2; i++) { // Skip duplicates if (i \u0026gt; 0 \u0026amp;\u0026amp; nums[i] == nums[i-1]) continue; int left = i + 1; int right = nums.size() - 1; int target = -nums[i]; while (left \u0026lt; right) { int sum = nums[left] + nums[right]; if (sum == target) { result.push_back({nums[i], nums[left], nums[right]}); // Skip duplicates while (left \u0026lt; right \u0026amp;\u0026amp; nums[left] == nums[left+1]) left++; while (left \u0026lt; right \u0026amp;\u0026amp; nums[right] == nums[right-1]) right--; left++; right--; } else if (sum \u0026lt; target) { left++; } else { right--; } } } return result; } ","permalink":"http://localhost:1313/_wiki/cpp-ps-basic/","summary":"C++ Grammar and Syntax Guide for Coding Interviews (Algorithms \u0026amp; DS) Core Data Types and Variables Basic Types int x = 5; // Integer long long bigNum = 1LL\u0026lt;\u0026lt;60; // Large integer (note LL suffix) double y = 3.14; // Double precision floating point bool flag = true; // Boolean char c = \u0026#39;A\u0026#39;; // Character string s = \u0026#34;Hello\u0026#34;; // String (requires #include \u0026lt;string\u0026gt;) Type Modifiers unsigned int positiveOnly = 100; // Only non-negative values const int FIXED = 10; // Cannot be modified after initialization Type Aliases typedef long long ll; // Old style type alias using ll = long long; // Modern style type alias (preferred) Auto Type Deduction auto num = 10; // Compiler deduces type (int in this case) auto it = myVector.","title":"cpp ps용 기본 문법 리마인드 💡"},{"content":"1~3장 기본 문법 진짜 간단하게 문법을 훑는다.\n3장 프로그램 구조와 제어 흐름 예외 처리에 대한 조언 코드의 특정 위치에서 처리할 수 없는 예외는 잡지 않는다. def read_data(filename): with open(filename, \u0026#39;rt\u0026#39;) as file: rows = [] for line in file: row = line.split() rows.append((row[0], int(row[1]), float(row[2]))) return rows 위의 경우 함수의 사용자가 잘못된 파일명을 처리할 기회가 사라짐 예외를 호출자한테 전달하는게 바람직하다고함 파이썬은 매번 에러 확인하지 말고, 실패하도록 내버려두라는 철학을 가짐. 예외는 프로그램 흐름을 위로 “전파”시켜서, 상위 책임 코드에서 처리하는 게 자연스럽다는 접근 흠..\n특정 위치에서 복구가 필요한 경우 def read_data(filename): with open(filename, \u0026#39;rt\u0026#39;) as file: rows = [] for line in file: row = line.split() try: rows.append((row[0], int(row[1]), float(row[2]))) except ValueError as e: print(\u0026#39;Bad rows: \u0026#39;, row) print(\u0026#39;Reason: \u0026#39;, e) return rows 잡는 에러의 영역을 가능한 narrow하게 만들것 컨텍스트 관리와 with 문 with open(\u0026#39;debuglog\u0026#39;, \u0026#39;wt\u0026#39;) as file: file.write(\u0026#39;Debugging\\n\u0026#39;) # statements file.write(\u0026#39;Done\\n\u0026#39;) import threading lock = threading.lock() with lock: # 임계구역 # statements # 임계구역 종료 with obj문은 제어 흐름이 이어서 나오는 블록에 진입하고 빠져나올때 일어나는 일을 객체 obj가 관리하게 한다. with obj문이 실행되면 새로운 컨텍스트에 진입한다는 신호로 obj.__enter__()가 호출된다. 컨텍스트를 벗어날때는 obj.__exit__(type, value, traceback)이 호출된다. (발생한 예외가 없다면 세 args모두 None으로) __exit__이 False, None을 반환하는 경우는 예외가 컨텍스트 밖으로 전달된다. 여러가지 decorator 로직을 프록시 없이 작성 할 수 있을 것 같다. 뭔가 js의 프로토콜 기반 방법론과 비슷한 방식인것같다. (protocol을 구현하는 객체에 대해서 특정 예약어를 쓸 수 있게 해주는)\nclass ListTransaction: def __init__(self, theList): self.theList = theList def __enter__(self): self.workingcopy = list(self.theList) return self.workingcopy def __exit__(self, type, value, tb): if type is None: self.theList[:] = self.workingcopy return False items = [1,2,3] with ListTransaction(items) as working: working.append(4) working.append(5) print(items) # [1,2,3,4,5] try: with ListTransaction(items) as working: working.append(6) working.append(7) raise RuntimeError(\u0026#34;We\u0026#39;re hosed!\u0026#34;) except RuntimeError: pass print(items) # [1,2,3,4,5] 실제로 위와 같은 트랜잭션도 구현이 손쉽게 가능하다. exit의 리턴값은 오직 예외 전파여부만 관리함, 헷갈리지 말것\n단언과 debug assert file, \u0026#39;write_data: file not defined!\u0026#39; file 자리는 T/F로 평가되는 expression 최적화 모드로 파이썬을 실행시키면 assert실행 안함 주의 사용자 입력이나, 주요 연산의 성공여부를 체크하기위해 사용한다 -\u0026gt; (X) 항상 참이어야 하는 불변성을 검사할 때 사용한다 -\u0026gt; (O) 내부 프로그램의 일관성을 확인하려는 것\n파이써닉한 파이썬 기본 모델은 명령형 프로그래밍이라고 한다. 모호함과 적절하지 않은 예외를 가장 파이써닉하지 않다고 생각하는 것 같다. 객체, 타입, 프로토콜 파이썬 객체 모델과 메커니즘을 설명하고, 다양한 객체의 핵심 동작을 정의하는 \u0026lsquo;프로토콜\u0026rsquo;을 특별히 주의해서 살펴보겠다.\n객체의 고윳값과 타입 id() : 보통 객체의 메모리 내 위치 is, is not은 고윳값을 비교 그 외 isinstance()같은 것들이 있기는 하지만, 오버헤드가 있고 유사성 검사에 약한 부분이 있어 지양하는게 좋다고 한다. 가비지 컬렉션 객체의 참조 횟수는 del 문이 사용되거나, 참조가 유효 범위를 벗어나거나, 재할당 될 경우 감소한다. 참조횟수가 0이되면 가비지 컬렉션의 대상이 됨 sys.getrefcount() 로 참조 횟수를 확인 할 수 있음 a = {} b = {} a[\u0026#39;b\u0026#39;] = b b[\u0026#39;a\u0026#39;] = a del a del b 이런경우 순환 가비지 컬렉터의 실행이 되기 전까지는 가비지컬렉션되지는 않음 참조와 복사 보통은 얕은 복사 별개의 리스트를 생성하는 것처럼 동작해도 요소는 공유되기때문에 변경을 일으킴 copy.deepcopy()를 사용할 수 있기는 한데, 권장하지는 않음 흠\u0026hellip;\n1급 객체 파이썬에서 객체는 모두 1급 line = \u0026#39;ACME,100,490.10\u0026#39; column_types = [str, int, float] # 이런거 row = [ty(val) for ty, val in zip(column_types, line.split(\u0026#39;,\u0026#39;))] print(row) _formats = { \u0026#39;text\u0026#39; : TextFormatter, \u0026#39;csv\u0026#39; : CSVFormatter, \u0026#39;html\u0026#39; : HTMLFormatter } if format in _formats: formatter = _formats[format]() else: raise RuntimeError(\u0026#39;Unsupported format!\u0026#39;) 이런 것들이 가능해진다. (아래는 정말 js스럽다) 최신 언어들의 표현력도 많이 올라가서 이게 장점이라거나 단점이라는 생각이 잘 들지는 않는 것 같다.\nNone 싱글턴 인스턴스이다. is None을 쓸 수 있다. == None은 린트에 잡힌다. 객체 프로토콜과 데이터 추상화 대부분 프로토콜로 정의되어 있다는 것이 파이썬의 특징 정적 언어용 컴파일러와 달리 파이썬은 프로그램이 올바르게 동작할지 사전에 확인하지 않는다. 대신, 객체의 동작 방식은 ‘스페셜’ 또는 ‘마법’의 메서드라 부르는 디스패치(dispatch, 동적으로 실행되는 메서드)를 포함하는 동적 프로세스가 결정한다. 이러한 스페셜 메서드의 앞뒤에는 언제나 이중 밑줄이 온다.\n디스패치는 실행 과정에서 호출 시 어떤 다형성 구현을 선택할지 결정하는 프로세스이다. 메서드명 시그니처 설명 new def new(cls, *args, **kwargs) -\u0026gt; object 인스턴스 생성 (클래스 메서드) init def init(self, *args, **kwargs) -\u0026gt; None 생성된 인스턴스 초기화 del def del(self) -\u0026gt; None 인스턴스가 삭제될 때 호출 repr def repr(self) -\u0026gt; str 객체의 표현 문자열 반환 숫자 프로토콜 특수한건 따로 없음 하위타입 때문에 피연산대상을 바꿔서 넣어줘야 하는 경우가 있는데 이런 경우도 알아서 NotImplemented를 보고 해줌 비교 프로토콜 is는 프로토콜 포함이 아닌 인스턴스 고유값 비교 (재정의 불가) 그 외에는 comparator와(lt, gt), hash등 큰 차이 없는 것 같다. functools 모듈의 클래스 데코레이터를 추천한다. 변환 프로토콜 str, bytes, bool, int 등 내장함수 사용을 위해 사용 할 수 있는 프로토콜 메서드들이 있다. 컨테이너 프로토콜 마찬가지로 내장함수와 특정 키워드들을 사용할 수 있게 해주는 프로토콜 (len, getitem, setitem, delitem, contains 등) 이터레이터 프로토콜 js와 거의 동일 s = \u0026#39;Hello world\u0026#39; _iter = s.__iter__() while True: try: x = _iter.__next__() except StopIteration: break # for loop block의 내용들 실행 class FRange: def __init__(self, start, stop, step): self.start = start self.stop = stop self.step = step def __iter__(self): x = self.start while x \u0026lt; self.stop: yield x x += self.step nums = FRange(0.0, 1.0, 0.1) for x in nums: print(x) 이런 부분들도 잘 됨 속성(attribute) 프로토콜 보일러 플레이트 용, 정확히 뭘 할지는 나중에 다시 나온다고 한다. 함수 프로토콜 그냥 ()연산자가 call()을 호출하기에 따라 할 수 있다 정도 컨텍스트 관리자 프로토콜 with 관련 프로토콜이고, 위에서 정리된게 전부이다. 파이써닉한 파이썬이라는것은.. 결국 위와 같은 프로토콜을 잘 활용하는것? 구체적으로는 repl 잘 만들어두기 iterator protocol은 구현해두면 좋음 with를 잘 활용하기 정도를 거론한다. 함수 이런게 가능하다 def func(*args, **kargs): # args 는 위치 인수 튜플 # kargs는 위치 인수 튜플 return 이렇게 해야 할 때도 있다.. import time def after(seconds, func, /, *args, **kargs): time.sleep(seconds) return func(*args, **kargs) def duration(*, seconds, minutes, hours): return seconds + 60 * minutes + 3600 * hours after(5, duration, seconds=20, minutes=3, hours=2) 스타일상 부작용이 있는 함수는 결과로 None을 반환하는것이 일반적이다. 중첩 함수 내의 변수 이름은 렉시컬 스코프에 묶이고, 체이닝도 한다. (지금 스코프부터 하나씩 밖으로 나가며 체이닝) nonlocal, global같은 변수 키워드로 다른 스코프 변수를 건들 수 있긴 하다. 람다 # lamda args: expression a = lamda x, y: x + y r = a(2, 3) 클로저 주의, 함수 호출 시점의 환경을 바인딩함 (lazy binding) x = 2 f = lamda y: x * y x = 3 g = lamda x: x * y print(f(10)) # 30 print(g(10)) # 30 # 이렇게 해야함 # f = lambda y, x=x: x * y # g = lambda y, x=x: x * y def make_greeting(names): funcs = [] for name in names: funcs.append(lambda: print(\u0026#39;Hello\u0026#39;, name)) return funcs a, b, c = make_greeting([\u0026#39;Guido\u0026#39;, \u0026#34;Ada\u0026#34;, \u0026#39;Margaret\u0026#39;]) # return funcs 시점의 name의 값이 바인딩 a() # Hello Margaret b() # Hello Margaret c() # Hello Margaret def make_greeting_correct(names): funcs = [] for name in names: funcs.append(lambda name=name: print(\u0026#39;Hello\u0026#39;, name)) return funcs a2, b2, c2 = make_greeting_correct([\u0026#39;Guido\u0026#39;, \u0026#34;Ada\u0026#34;, \u0026#39;Margaret\u0026#39;]) # 직접 바인딩 a2() b2() c2() 콜백 함수에서 인수 전달 import time def add(x, y): return x + y def after(seconds, func): time.sleep(seconds) func() # after(10, add(2,3)) 안됨, 호출 시점에 호출됨 # 람다 thunk 사용 after(10, lambda: add(2,3)) # partial 사용 from functools import partial after(10, partial(add, 2, 3)) # partial은 아래와 같은 것들도 가능 def func(a,b,c,d): print(a,b,c,d) f = partial(func, 1, 2) f(3,4) # func(1,2,3,4) f(10, 20) # func(1,2,10,20) # partial과 lamda의 차이 def func2(a,b): return a + b a = 2 b = 3 f2 = lambda: func2(a,b) g2 = partial(func2, a,b) a = 10 b = 20 f2() # 30, 호출 시점의 a, b 바인딩 g2() # 5 partial 정의 시점의 a, b 바인딩 추가적으로 partial로 생성한 객체는 바이트로 직렬화도 가능하다. (lamda는 불가능) 데코레이터 def trace(func): def call(*args, **kargs): print(\u0026#39;Calling\u0026#39;, func.__name__) return func(*args, **kargs) return call @trace def square(x): return x+x square(3) square(4) square(5) square(6) # trace(func) from functools import wraps def trace(func): @wraps(func) def call(*args, **kargs): print(\u0026#39;Calling\u0026#39;, func.__name__) return func(*args, **kargs) return call wraps를 쓰면 더 편리, 함수의 메타데이터를 대체 함수에 복사, 이 경우 제공된 함수 func()의 메타데이터는 반환된 래퍼함수 call()에 복사된다. 데코레이터의 나열 순서는 중요하다. @classmethod, @staticmethod와 같은 데코레이터는 가장 바깥쪽에 위치해야 한다. from functools import wraps def trace(message): def decorate(func): @wraps(func) def wrapper(*args, **kargs): print(message.format(func=func)) return func(*args, **kargs) return wrapper return decorate @trace(\u0026#39;Hello {func.__name__}\u0026#39;) def func1(): pass @trace(\u0026#39;Hello {func.__name__}\u0026#39;) def func2(): pass func1() func2() logged = trace(\u0026#39;Simplified with logged {func.__name__}\u0026#39;) @logged def func3(): pass @logged def func4(): pass func3() func4() 파이써닉한 파이썬: 함수와 조합에 대한 생각 시스템은 모두 구성 요소의 조합으로 구축됨 그리고 그 구성요소의 근본은 함수임 함수의 입력은 어떻게 되는가? 출력은 어떻게 처리되는가? 에러는 어떻게 보고되는가? 이 모든것을 어떻게 컨트롤하고 더 잘 이해할 수 있을까? 제너레이터 제너레이터는 파이썬에서 매우 흥미로우면서도 강력한 기능의 하나다. 제너레이터는 새로운 형태의 반복 패턴을 정의하는 편리한 방법으로 소개되고 있지만, 그것보다 훨씬 더 많은 기능들이 있다. 제너레이터는 함수의 전체 실행 모델을 근본적으로 변경할 수 있다.\n제너레이터와 yield 함수에서 yield 키워드를 사용하면 제너레이터 객체를 정의하게 된다. 제너레이터의 주된 기능은 반복에 사용할 값을 생성하는 것이다. def countdown(n): print(\u0026#39;Counting down from\u0026#39;, n) while n \u0026gt; 0: yield n n -= 1 c = countdown(10) print(c) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) print(next(c)) for x in countdown(10): print(\u0026#39;T-minus\u0026#39;, x) \u0026lt;generator object countdown at 0x100e88190\u0026gt; Counting down from 10, 10 9 8 7 6 5 4 3 2 1 Counting down from 10 T-minus 10 T-minus 9 T-minus 8 T-minus 7 T-minus 6 T-minus 5 T-minus 4 T-minus 3 T-minus 2 T-minus 1 제너레이터 객체는 반복을 시작할 때만 함수를 실행한다. 제너레이터 객체를 수행하는 방법은 다음과 같이 next()를 호출하는것이다. next()를 호출하면 처음에는 yield전까지 문을 실행하며, 결과를 반환하고 다음 next()가 호출될 때 까지 함수 실행을 일시적으로 중단한다. 중단동안 함수는 지역 변수와 실행 환경을 모두 유지한다. 제너레이터는 한번만 반복할 수 있고 여러번 반복하고싶다면 아래처럼 만들어두는것이 좋다. class countdown: def __init__(self, start): self.start = start def __iter__(self): n = self.start while n \u0026gt; 0: yield n n-= 1 count = countdown(10) for n in count: print(n) for n in count: print(n) 제너레이터 위임 yield를 포함하는 함수는 스스로 실행되지 않는다는 점이 제네레이터의 중요한 특징이다. 별도의 next()호출에 의해서만 함수 실행 흐름이 관리된다. 그래서 yield from이라는 문이 있다. def countup(stop): n = 1 while n \u0026lt;= stop: yield n n += 1 def countdown(start): n = start while n \u0026gt; 0: yield n n-= 1 def up_and_down(n): yield from countup(n) yield from countdown(n) for x in up_and_down(5): print(x, end=\u0026#39; \u0026#39;) # 원래면 아래처럼 했어야 함 def up_and_down_without_yield(n): for x in countup(n): yield x for x in countdown(n): yield x # 이런 경우에 유용 def flatten(items): for i in items: if isinstance(i, list): yield from flatten(i) else: yield i 위와같이 중첩된 것들도 지연평가 + 분리된 코드로 잘 작성 할 수 있다. import pathlib import re for path in pathlib.Path(\u0026#39;.\u0026#39;).rglob(\u0026#39;*.py\u0026#39;): if path.exists(): with path.open(\u0026#39;rt\u0026#39;, encoding=\u0026#39;latin-1\u0026#39;) as file: for line in file: m = re.match(\u0026#39;.*(#.*)$\u0026#39;, line) if m: comment = m.group(1) if \u0026#39;spam\u0026#39; in comment: print(comment) def get_paths(todir, pattern): for path in pathlib.Path(todir).rglob(pattern): if path.exists(): yield path def get_files(paths): for path in paths: with path.open(\u0026#39;rt\u0026#39;, encoding=\u0026#39;latin-1\u0026#39;) as file yield file def get_lines(files): for file in files: yield from file def get_comments(lines): for line in lines: m = re.match(\u0026#39;.*(#.*)$\u0026#39;, line) if m: yield m.group(1) def print_matching(lines, substring): for line in lines: if substring in line: print(substring) paths = get_paths(\u0026#39;.\u0026#39;, \u0026#39;*py\u0026#39;) files = get_files(paths) lines = get_lines(files) comments = get_comments(lines) print_matching(comments, \u0026#39;spam\u0026#39;) yield를 응용하여, flatten을 개선한 예재 def flatten(items): stack = [ iter(items) ] print(stack) while stack: try: item = next(stack[-1]) if isinstance(item, list): stack.append(iter(item)) print(\u0026#39;stack appended\u0026#39;) print(stack) else: yield item except StopIteration: stack.pop() 향상된 generator (코루틴 개념 포함) yield를 할당문 우측에 두어, 외부에서 값을 전달받을 수 있다. → 예: value = yield 형태로 사용하면, send()를 통해 전달된 값이 value에 들어간다. 제너레이터 객체에 값을 외부에서 넣어줄 수 있는 메서드인 send() 를 활용해 양방향 통신이 가능하다. contextlib.contextmanager는 제너레이터의 __enter__ / __exit__ 프로토콜을 활용해 컨텍스트 관리자를 간결하게 구현할 수 있게 해준다. async def / await 구문은 내부적으로 제너레이터 기반의 코루틴 프레임워크에서 발전된 구조다. → 초창기에는 yield from 기반의 async 구현(asyncio.coroutine)이었고, 이후에 await가 명시적으로 추가되었다. I/O 작업은 보통 지연이 발생하므로, yield나 await로 중단점(pause point)을 만든 후, 결과가 준비되었을 때 다시 실행을 재개하는 구조로 동작한다.\n실제로는\n실행을 중단(pause) 하며 Future 객체를 반환 이벤트 루프가 Future의 완료를 감지하면 해당 제너레이터에 다시 send()로 값 주입, 실행 재개 ","permalink":"http://localhost:1313/_wiki/python_distilled/","summary":"1~3장 기본 문법 진짜 간단하게 문법을 훑는다.\n3장 프로그램 구조와 제어 흐름 예외 처리에 대한 조언 코드의 특정 위치에서 처리할 수 없는 예외는 잡지 않는다. def read_data(filename): with open(filename, \u0026#39;rt\u0026#39;) as file: rows = [] for line in file: row = line.split() rows.append((row[0], int(row[1]), float(row[2]))) return rows 위의 경우 함수의 사용자가 잘못된 파일명을 처리할 기회가 사라짐 예외를 호출자한테 전달하는게 바람직하다고함 파이썬은 매번 에러 확인하지 말고, 실패하도록 내버려두라는 철학을 가짐. 예외는 프로그램 흐름을 위로 “전파”시켜서, 상위 책임 코드에서 처리하는 게 자연스럽다는 접근 흠.","title":"파이써닉 파이썬"},{"content":"Basic [[Python_Distilled]] ","permalink":"http://localhost:1313/_wiki/python/","summary":"Basic [[Python_Distilled]] ","title":"Python 관련 내용 정리"},{"content":"망쳐버린 소프트웨어 프로젝트와 무용담 \u0026ldquo;우리가 만든 소프트웨어는 정말 좋았는데, 시장이 무르익지 않았어\u0026rdquo; -\u0026gt; 소비자 요구를 파악하지 못했다.\n\u0026ldquo;소프트웨어는 잘 만들었는데 영업 판매가 잘 되지 않았어\u0026rdquo; -\u0026gt; 아무도 그런 소프트웨어를 원하지 않았다.\n\u0026ldquo;제품은 끝내줬는데 제대로 좀 해보려는 마당에 윗선에서 잘렸어\u0026rdquo; -\u0026gt; 수익을 창출하기까지 너무 오래걸렸다.\n\u0026ldquo;좋은 소프트웨어란 그 소프트웨어가 성숙도 사이클에서 어디에 있는지, 어떤 사용자를 대상으로 하는지, 어떻게 진화하고 성장하기를 원하는지 등에 따라 매우 다를 수 있다. 소프트웨어에서 고객이 진정 무엇을 필요로 할지, 그리고 제각자와 고객이 모두 제품 성숙도 사이클과 리스크 허용도 면에서 어떤 위치에 있는지에 대해 진지하게 고민을 시작해 보면 더 나은 전략 결정을 내릴 수 있고, 시장에 진정 훌륭한 소프트웨어를 내놓을 수 있다.\u0026rdquo;\n마리사 메이어 당신에게 투자하는 사람과 당신에게 도전거리를 안겨주는 사람을 위해 일하세요.\n언제나 아직 준비되지 않은 일을 하세요. 약간 두려운 느낌이 드는 일을 하다는 것은 한 발 앞으로 나갈 수 있다는 것\n존 벤틀리 성공을 Favorable Termination of an Attemps 라고 생각해요\n비야네 스트롭스트룹 대학원은 지금 당장은 별로 쓸모없어 보이는 것에 대해 생각하고 실험하고 배울 수 있는 몇 안 남은 장소 가운데 하나죠\n소프트웨어는 관성이 매우 크기 때문에 앞으로도 포트란, 코볼, c코드는 볼 수 있을 거에요\n피터 노빅 \u0026ldquo;나가서 문제를 해결해 보세요\u0026rdquo;\n\u0026ldquo;중요한 일을 하세요\u0026rdquo;\n대책 없이 불평만 하는 사람이 되지 않기 위해 문제점을 지적할때는 해결책이 적어도 하나쯤은 있어야 한다. 둘때, 해결책과 관련한 실천사항을 이행하는데, 스스로 나서서 도와줄 준비가 되어 있어야 한다.\n시간을 잘 관리하는법 시간 사분면, 그리고 그 중에서도 중요하고 급한일과 중요하지만 급하진 않은일에 시간을 잘 분배하기\n","permalink":"http://localhost:1313/_wiki/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EB%A1%9C-%EC%82%AC%EB%8A%94%EB%B2%95/","summary":"망쳐버린 소프트웨어 프로젝트와 무용담 \u0026ldquo;우리가 만든 소프트웨어는 정말 좋았는데, 시장이 무르익지 않았어\u0026rdquo; -\u0026gt; 소비자 요구를 파악하지 못했다.\n\u0026ldquo;소프트웨어는 잘 만들었는데 영업 판매가 잘 되지 않았어\u0026rdquo; -\u0026gt; 아무도 그런 소프트웨어를 원하지 않았다.\n\u0026ldquo;제품은 끝내줬는데 제대로 좀 해보려는 마당에 윗선에서 잘렸어\u0026rdquo; -\u0026gt; 수익을 창출하기까지 너무 오래걸렸다.\n\u0026ldquo;좋은 소프트웨어란 그 소프트웨어가 성숙도 사이클에서 어디에 있는지, 어떤 사용자를 대상으로 하는지, 어떻게 진화하고 성장하기를 원하는지 등에 따라 매우 다를 수 있다. 소프트웨어에서 고객이 진정 무엇을 필요로 할지, 그리고 제각자와 고객이 모두 제품 성숙도 사이클과 리스크 허용도 면에서 어떤 위치에 있는지에 대해 진지하게 고민을 시작해 보면 더 나은 전략 결정을 내릴 수 있고, 시장에 진정 훌륭한 소프트웨어를 내놓을 수 있다.","title":"프로그래머로 사는법 간략한 인용과 후기 👨‍💻"},{"content":"트랜잭션 관리 스프링의 빈은 기본적으로 싱글톤이다. 즉, 하나의 서비스 객체 인스턴스가 여러 스레드에서 공유되어 사용된다. 하지만 트랜잭션은 스레드마다 독립적으로 관리되어야 한다. 그래서 ThreadLocal로 관리한다.\nTransactionSynchronizationManager 스프링은 TransactionSynchronizationManager 클래스를 통해 트랜잭션 리소스와 상태를 관리한다. 이 클래스는 ThreadLocal 변수를 사용하여 각 스레드별로 독립적인 트랜잭션 컨텍스트를 유지한다.\n// TransactionSynchronizationManager의 일부 (간략화됨) public abstract class TransactionSynchronizationManager { // 리소스를 스레드별로 저장하는 ThreadLocal 맵 private static final ThreadLocal\u0026lt;Map\u0026lt;Object, Object\u0026gt;\u0026gt; resources = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Transactional resources\u0026#34;); // 트랜잭션 동기화 활성화 상태 private static final ThreadLocal\u0026lt;Boolean\u0026gt; actualTransactionActive = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Actual transaction active\u0026#34;); // 현재 트랜잭션 이름 private static final ThreadLocal\u0026lt;String\u0026gt; currentTransactionName = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction name\u0026#34;); // 읽기 전용 플래그 private static final ThreadLocal\u0026lt;Boolean\u0026gt; currentTransactionReadOnly = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction read-only status\u0026#34;); // 격리 수준 private static final ThreadLocal\u0026lt;Integer\u0026gt; currentTransactionIsolationLevel = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction isolation level\u0026#34;); // 트랜잭션 동기화 콜백 객체 private static final ThreadLocal\u0026lt;List\u0026lt;TransactionSynchronization\u0026gt;\u0026gt; synchronizations = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Transaction synchronizations\u0026#34;); // 리소스 바인딩 메서드 public static void bindResource(Object key, Object value) { Map\u0026lt;Object, Object\u0026gt; map = resources.get(); if (map == null) { map = new HashMap\u0026lt;\u0026gt;(); resources.set(map); } map.put(key, value); } // 리소스 조회 메서드 public static Object getResource(Object key) { Map\u0026lt;Object, Object\u0026gt; map = resources.get(); if (map == null) { return null; } return map.get(key); } // 리소스 제거 메서드 public static Object unbindResource(Object key) { Map\u0026lt;Object, Object\u0026gt; map = resources.get(); if (map == null) { return null; } Object value = map.remove(key); if (map.isEmpty()) { resources.remove(); } return value; } // 기타 메서드들... } 실제 동작 흐름 트랜잭션 시작:\n// DataSourceTransactionManager의 doBegin 메서드 (간략화됨) @Override protected void doBegin(Object transaction, TransactionDefinition definition) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; Connection con = null; try { // 데이터소스에서 연결 획득 con = obtainDataSourceConnection(); // 자동 커밋 해제 (트랜잭션 시작) con.setAutoCommit(false); // 트랜잭션 격리 수준 설정 Integer previousIsolationLevel = DataSourceUtils.prepareConnectionForTransaction(con, definition); txObject.setPreviousIsolationLevel(previousIsolationLevel); // 연결을 트랜잭션 리소스로 ThreadLocal에 바인딩 TransactionSynchronizationManager.bindResource(getDataSource(), txObject.getConnectionHolder()); // 기타 트랜잭션 속성 설정... TransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly()); TransactionSynchronizationManager.setCurrentTransactionName(definition.getName()); TransactionSynchronizationManager.setCurrentTransactionIsolationLevel(definition.getIsolationLevel()); TransactionSynchronizationManager.initSynchronization(); } catch (Throwable ex) { // 실패시 정리 로직... } } 트랜잭션 중 리소스 활용:\n// JdbcTemplate 같은 데이터 액세스 기술은 현재 스레드에 바인딩된 커넥션을 사용 // DataSourceUtils.getConnection의 일부 (간략화됨) public static Connection getConnection(DataSource dataSource) throws CannotGetJdbcConnectionException { ConnectionHolder conHolder = (ConnectionHolder) TransactionSynchronizationManager.getResource(dataSource); if (conHolder != null \u0026amp;\u0026amp; conHolder.hasConnection()) { // ThreadLocal에서 현재 트랜잭션 커넥션을 가져옴 return conHolder.getConnection(); } else { // 트랜잭션 없으면 새 커넥션 획득 Connection con = fetchConnection(dataSource); // ... return con; } } 트랜잭션 커밋/롤백:\n// DataSourceTransactionManager의 doCommit 메서드 (간략화됨) @Override protected void doCommit(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try { con.commit(); } catch (SQLException ex) { throw new TransactionSystemException(\u0026#34;Could not commit JDBC transaction\u0026#34;, ex); } } // DataSourceTransactionManager의 doRollback 메서드 (간략화됨) @Override protected void doRollback(DefaultTransactionStatus status) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) status.getTransaction(); Connection con = txObject.getConnectionHolder().getConnection(); try { con.rollback(); } catch (SQLException ex) { throw new TransactionSystemException(\u0026#34;Could not roll back JDBC transaction\u0026#34;, ex); } } 트랜잭션 종료 후 정리:\n// DataSourceTransactionManager의 doCleanupAfterCompletion 메서드 (간략화됨) @Override protected void doCleanupAfterCompletion(Object transaction) { DataSourceTransactionObject txObject = (DataSourceTransactionObject) transaction; // ThreadLocal에서 리소스 언바인딩 TransactionSynchronizationManager.unbindResource(getDataSource()); // 동기화 리소스 정리 TransactionSynchronizationManager.clearSynchronization(); // 커넥션 정리 (원래 상태로 복원) Connection con = txObject.getConnectionHolder().getConnection(); try { // 자동 커밋 원복 con.setAutoCommit(true); // 격리 수준 원복 DataSourceUtils.resetConnectionAfterTransaction(con, txObject.getPreviousIsolationLevel()); // 커넥션 반환 DataSourceUtils.releaseConnection(con, getDataSource()); } catch (Throwable ex) { // 예외 처리... } } TL;DR ThreadLocal 저장소: TransactionSynchronizationManager는 ThreadLocal을 사용하여 각 스레드별로 독립적인 트랜잭션 컨텍스트와 리소스를 관리한다. 이를 통해 싱글톤 서비스 객체가 동시에 여러 트랜잭션을 처리할 수 있다.\n리소스 바인딩: 트랜잭션 매니저는 트랜잭션 시작 시 데이터베이스 커넥션 같은 리소스를 ThreadLocal에 바인딩한다.\n리소스 참조: 트랜잭션 내에서 데이터 액세스 코드는 ThreadLocal에서 바인딩된 리소스를 가져와 사용한다.\n리소스 정리: 트랜잭션 완료 후 ThreadLocal에서 리소스를 제거하고 원래 상태로 복원한다.\n이러한 메커니즘을 통해 스프링은 싱글톤 빈을 사용하면서도 트랜잭션 관리를 각 요청마다 독립적으로 수행할 수 있다. 또한 이 방식은 트랜잭션 전파 속성을 구현하는 데도 필수적이며, 하나의 스레드 내에서 여러 트랜잭션 메서드 호출 간의 관계를 관리하는 데 사용된다.\n트랜잭션 전파 속성 트랜잭션 전파 속성(Transaction Propagation)은 이미 진행 중인 트랜잭션이 있을 때 또는 없을 때 새로운 트랜잭션 메서드가 호출되었을 때 어떻게 동작할지를 결정하는 정책. @Transactional 애노테이션의 propagation 값으로 지정\nREQUIRED (기본값)\n현재 트랜잭션이 있으면 그 트랜잭션을 사용한다. 없으면 새 트랜잭션을 생성한다. @Transactional(propagation = Propagation.REQUIRED) public void serviceMethod() { ... } REQUIRES_NEW\n항상 새로운 트랜잭션을 생성한다. 기존 트랜잭션이 있으면 일시 중단시키고 새 트랜잭션을 실행한 후 기존 트랜잭션을 계속한다. @Transactional(propagation = Propagation.REQUIRES_NEW) public void mustHaveNewTransaction() { ... } SUPPORTS\n현재 트랜잭션이 있으면 그 트랜잭션을 사용한다. 없으면 트랜잭션 없이 실행한다. @Transactional(propagation = Propagation.SUPPORTS) public void canWorkWithOrWithoutTx() { ... } NOT_SUPPORTED\n트랜잭션 없이 실행한다. 현재 트랜잭션이 있으면 일시 중단시킨다. @Transactional(propagation = Propagation.NOT_SUPPORTED) public void mustRunWithoutTransaction() { ... } MANDATORY\n현재 트랜잭션이 있어야만 실행한다. 없으면 예외를 발생시킨다. @Transactional(propagation = Propagation.MANDATORY) public void mustRunInExistingTransaction() { ... } NEVER\n트랜잭션 없이 실행한다. 현재 트랜잭션이 있으면 예외를 발생시킨다. @Transactional(propagation = Propagation.NEVER) public void mustNeverRunInTransaction() { ... } NESTED\n현재 트랜잭션이 있으면 중첩 트랜잭션을 생성한다. 중첩 트랜잭션은 부모 트랜잭션의 일부로 커밋되지만, 독립적으로 롤백될 수 있다. 없으면 REQUIRED처럼 새 트랜잭션을 생성한다. @Transactional(propagation = Propagation.NESTED) public void runInNestedTransaction() { ... } TL;DR 이러한 전파 속성을 통해 복잡한 트랜잭션 시나리오를 선언적으로 처리할 수 있음. 예를 들어, 하나의 서비스 메서드가 여러 다른 트랜잭션 메서드를 호출할 때 각 메서드의 트랜잭션 동작을 세밀하게 제어할 수 있다\n","permalink":"http://localhost:1313/_wiki/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EC%A0%95%EB%A6%AC/","summary":"트랜잭션 관리 스프링의 빈은 기본적으로 싱글톤이다. 즉, 하나의 서비스 객체 인스턴스가 여러 스레드에서 공유되어 사용된다. 하지만 트랜잭션은 스레드마다 독립적으로 관리되어야 한다. 그래서 ThreadLocal로 관리한다.\nTransactionSynchronizationManager 스프링은 TransactionSynchronizationManager 클래스를 통해 트랜잭션 리소스와 상태를 관리한다. 이 클래스는 ThreadLocal 변수를 사용하여 각 스레드별로 독립적인 트랜잭션 컨텍스트를 유지한다.\n// TransactionSynchronizationManager의 일부 (간략화됨) public abstract class TransactionSynchronizationManager { // 리소스를 스레드별로 저장하는 ThreadLocal 맵 private static final ThreadLocal\u0026lt;Map\u0026lt;Object, Object\u0026gt;\u0026gt; resources = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Transactional resources\u0026#34;); // 트랜잭션 동기화 활성화 상태 private static final ThreadLocal\u0026lt;Boolean\u0026gt; actualTransactionActive = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Actual transaction active\u0026#34;); // 현재 트랜잭션 이름 private static final ThreadLocal\u0026lt;String\u0026gt; currentTransactionName = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction name\u0026#34;); // 읽기 전용 플래그 private static final ThreadLocal\u0026lt;Boolean\u0026gt; currentTransactionReadOnly = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction read-only status\u0026#34;); // 격리 수준 private static final ThreadLocal\u0026lt;Integer\u0026gt; currentTransactionIsolationLevel = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Current transaction isolation level\u0026#34;); // 트랜잭션 동기화 콜백 객체 private static final ThreadLocal\u0026lt;List\u0026lt;TransactionSynchronization\u0026gt;\u0026gt; synchronizations = new NamedThreadLocal\u0026lt;\u0026gt;(\u0026#34;Transaction synchronizations\u0026#34;); // 리소스 바인딩 메서드 public static void bindResource(Object key, Object value) { Map\u0026lt;Object, Object\u0026gt; map = resources.","title":"스프링 트랜잭션 전파 속성"},{"content":" 사실 객체의 참조과 서로 있는 객체라면 발생하지, JPA와 직접적인 연관은 없다.\n양방향 참조 1. toString() 메서드 구현 시 무한루프 @Entity public class Parent { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;parent\u0026#34;) private List\u0026lt;Child\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); @Override public String toString() { return \u0026#34;Parent{id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, children=\u0026#34; + children + \u0026#34;}\u0026#34;; } } @Entity public class Child { @Id @GeneratedValue private Long id; private String name; @ManyToOne private Parent parent; @Override public String toString() { return \u0026#34;Child{id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, parent=\u0026#34; + parent + \u0026#34;}\u0026#34;; } } 이 경우 Parent의 toString()이 Child의 toString()을 호출하고, Child의 toString()이 다시 Parent의 toString()을 호출하는 무한루프가 발생합니다.\n2. equals()와 hashCode() 구현 시 무한루프 @Entity public class User { @Id @GeneratedValue private Long id; @OneToMany(mappedBy = \u0026#34;user\u0026#34;) private Set\u0026lt;Post\u0026gt; posts = new HashSet\u0026lt;\u0026gt;(); @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; User user = (User) o; return Objects.equals(id, user.id) \u0026amp;\u0026amp; Objects.equals(posts, user.posts); } @Override public int hashCode() { return Objects.hash(id, posts); } } @Entity public class Post { @Id @GeneratedValue private Long id; @ManyToOne private User user; @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Post post = (Post) o; return Objects.equals(id, post.id) \u0026amp;\u0026amp; Objects.equals(user, post.user); } @Override public int hashCode() { return Objects.hash(id, user); } } User의 equals() 메서드가 Post의 equals()를 호출하고, Post의 equals()가 다시 User의 equals()를 호출하는 무한루프가 발생합니다.\n3. JSON 직렬화 시 무한루프 @Entity public class Team { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;team\u0026#34;) private List\u0026lt;Member\u0026gt; members = new ArrayList\u0026lt;\u0026gt;(); } @Entity public class Member { @Id @GeneratedValue private Long id; private String name; @ManyToOne private Team team; } 위 엔티티들을 Jackson 같은 JSON 라이브러리로 직렬화할 때 Team → Members → Team → \u0026hellip; 무한루프가 발생합니다.\n4. DTO 변환 과정에서의 무한루프 public TeamDTO convertToDTO(Team team) { TeamDTO dto = new TeamDTO(); dto.setId(team.getId()); dto.setName(team.getName()); dto.setMembers(team.getMembers().stream() .map(this::convertToMemberDTO) .collect(Collectors.toList())); return dto; } public MemberDTO convertToMemberDTO(Member member) { MemberDTO dto = new MemberDTO(); dto.setId(member.getId()); dto.setName(member.getName()); dto.setTeam(convertToDTO(member.getTeam())); // 무한루프 발생 return dto; } 팀을 DTO로 변환하면서 멤버를 변환하고, 멤버를 변환하면서 다시 팀을 변환하는 무한루프가 발생합니다.\n5. 엔티티 복사/클론 과정에서의 무한루프 public Order cloneOrder(Order original) { Order clone = new Order(); clone.setId(original.getId()); // 다른 속성들 복사 // 고객 정보 복사 if (original.getCustomer() != null) { clone.setCustomer(cloneCustomer(original.getCustomer())); } return clone; } public Customer cloneCustomer(Customer original) { Customer clone = new Customer(); clone.setId(original.getId()); // 다른 속성들 복사 // 주문 정보 복사 if (original.getOrders() != null) { for (Order order : original.getOrders()) { clone.addOrder(cloneOrder(order)); // 무한루프 발생 } } return clone; } Order를 복제하면서 Customer를 복제하고, Customer를 복제하면서 다시 Order를 복제하는 무한루프가 발생합니다.\n6. 재귀적 연관관계에서의 무한루프 @Entity public class Comment { @Id @GeneratedValue private Long id; private String content; @ManyToOne private Comment parent; @OneToMany(mappedBy = \u0026#34;parent\u0026#34;) private List\u0026lt;Comment\u0026gt; replies = new ArrayList\u0026lt;\u0026gt;(); } 위와 같은 자기참조 구조에서 toString(), equals(), hashCode(), JSON 직렬화 등을 구현할 때 모두 무한루프가 발생할 수 있습니다.\n7. Fetch Join과 같은 JPQL 쿼리에서의 무한루프 // 무한 순환 참조 가능성이 있는 JPQL @Query(\u0026#34;SELECT p FROM Parent p JOIN FETCH p.children c JOIN FETCH c.parent\u0026#34;) List\u0026lt;Parent\u0026gt; findAllWithChildrenAndTheirParents(); 이러한 쿼리는 JPA에서 직접적인 무한루프를 유발하지는 않지만, 결과를 처리하는 과정에서 위에서 언급한 다른 상황들과 결합하여 무한루프가 발생할 수 있습니다.\n8. 양방향 연관관계에서 캐스케이드 작업 시 무한루프 영속성 전이(cascade)와 함께 양방향 연관관계를 사용할 때, 엔티티 저장이나 삭제 과정에서 상호 참조로 인한 무한루프가 발생할 수 있습니다.\n해결책 1. JSON 직렬화 시 Jackson 어노테이션 사용 방법 1: @JsonIgnore 사용 @Entity public class Team { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;team\u0026#34;) private List\u0026lt;Member\u0026gt; members = new ArrayList\u0026lt;\u0026gt;(); // getter와 setter } @Entity public class Member { @Id @GeneratedValue private Long id; private String name; @ManyToOne @JsonIgnore // 이 속성은 JSON 직렬화에서 제외됨 private Team team; // getter와 setter } 방법 2: @JsonManagedReference와 @JsonBackReference 사용 @Entity public class Team { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;team\u0026#34;) @JsonManagedReference // 부모 쪽에서는 정상적으로 직렬화 private List\u0026lt;Member\u0026gt; members = new ArrayList\u0026lt;\u0026gt;(); // getter와 setter } @Entity public class Member { @Id @GeneratedValue private Long id; private String name; @ManyToOne @JsonBackReference // 자식 쪽에서는 직렬화에서 제외 private Team team; // getter와 setter } 방법 3: @JsonIdentityInfo 사용 @Entity @JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34; ) public class Team { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;team\u0026#34;) private List\u0026lt;Member\u0026gt; members = new ArrayList\u0026lt;\u0026gt;(); // getter와 setter } @Entity @JsonIdentityInfo( generator = ObjectIdGenerators.PropertyGenerator.class, property = \u0026#34;id\u0026#34; ) public class Member { @Id @GeneratedValue private Long id; private String name; @ManyToOne private Team team; // getter와 setter } 2. DTO 변환 시 순환 참조 끊기 // DTO 클래스들 public class TeamDTO { private Long id; private String name; private List\u0026lt;MemberDTO\u0026gt; members; // getter와 setter } public class MemberDTO { private Long id; private String name; private Long teamId; // 팀 객체 대신 ID만 포함 private String teamName; // 필요한 팀 정보만 포함 // getter와 setter } // 변환 로직 public class EntityToDTOConverter { public TeamDTO convertTeamToDTO(Team team) { TeamDTO dto = new TeamDTO(); dto.setId(team.getId()); dto.setName(team.getName()); if (team.getMembers() != null) { // 멤버를 변환할 때 팀 정보를 다시 포함하지 않음 dto.setMembers(team.getMembers().stream() .map(this::convertMemberToDTOWithoutTeam) .collect(Collectors.toList())); } return dto; } // 팀 정보 없이 멤버만 변환 private MemberDTO convertMemberToDTOWithoutTeam(Member member) { MemberDTO dto = new MemberDTO(); dto.setId(member.getId()); dto.setName(member.getName()); // 팀 전체 객체 대신 필요한 정보만 포함 if (member.getTeam() != null) { dto.setTeamId(member.getTeam().getId()); dto.setTeamName(member.getTeam().getName()); } return dto; } public MemberDTO convertMemberToDTO(Member member) { MemberDTO dto = new MemberDTO(); dto.setId(member.getId()); dto.setName(member.getName()); // 팀 전체 객체 대신 필요한 정보만 포함 if (member.getTeam() != null) { dto.setTeamId(member.getTeam().getId()); dto.setTeamName(member.getTeam().getName()); } return dto; } } 해결 방법들의 장점 Jackson 어노테이션 방식: @JsonIgnore: 가장 간단하지만 한쪽 방향의 정보만 직렬화됨 @JsonManagedReference/@JsonBackReference: 부모-자식 관계를 명확히 표현하며 양방향 참조 문제 해결 @JsonIdentityInfo: 객체를 처음에는 완전히 직렬화하고, 이후 참조 시에는 ID만 사용하여 순환 참조 방지 DTO 변환 방식: 더 세밀한 제어 가능 필요한 정보만 선택적으로 포함 가능 순환 참조 문제를 근본적으로 해결 API 응답 구조를 엔티티 구조와 분리 가능 두 방식은 상황에 따라 함께 사용할 수도 있습니다. 간단한 경우에는 Jackson 어노테이션이 편리하고, 복잡한 데이터 변환이 필요한 경우에는 DTO 패턴이 더 적합합니다.\n","permalink":"http://localhost:1313/_wiki/%EC%96%91%EB%B0%A9%ED%96%A5-%EC%88%9C%ED%99%98%EC%B0%B8%EC%A1%B0/","summary":"사실 객체의 참조과 서로 있는 객체라면 발생하지, JPA와 직접적인 연관은 없다.\n양방향 참조 1. toString() 메서드 구현 시 무한루프 @Entity public class Parent { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;parent\u0026#34;) private List\u0026lt;Child\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); @Override public String toString() { return \u0026#34;Parent{id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, children=\u0026#34; + children + \u0026#34;}\u0026#34;; } } @Entity public class Child { @Id @GeneratedValue private Long id; private String name; @ManyToOne private Parent parent; @Override public String toString() { return \u0026#34;Child{id=\u0026#34; + id + \u0026#34;, name=\u0026#39;\u0026#34; + name + \u0026#34;\u0026#39;, parent=\u0026#34; + parent + \u0026#34;}\u0026#34;; } } 이 경우 Parent의 toString()이 Child의 toString()을 호출하고, Child의 toString()이 다시 Parent의 toString()을 호출하는 무한루프가 발생합니다.","title":"양방향 순환참조 정리"},{"content":" 책의 내용을 일부 \u0026lsquo;발췌\u0026rsquo;해서 정리 각 장별 간단한 개요는 작성하지만, 실질적으로는 내가 조금 더 기억하고 싶은 내용만 일부 발췌해서 기록\n1장 사용자 수에 따른 규모 확장성 개요 기본적인 어플리케이션 설게와 매우 자주 사용되는 컴포넌트 혹은 구현해야하는 요구사항에 대해서 소개해 주는장 예를들어 아래와 같은 것들을 개념을 개략적으로 설명해준다. 데이터 저장소 수직적 확장,수평적 확장 다중화 캐시 안정성과, 가용성과같은 시스템을 측정할 수 있는 요소들도 설명해준다. 내용 캐시 사용시 유의 할 점 어떤 상황에 바람직한지 생각하기 어떤 데이터를 캐시할지 생각하지 만료기한을 잘 설정하기 일관성을 유지 할 수 있도록 생각하기 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우? 캐시가 단일 장애 지점이 되지 않도록 설계하기 캐시 메모리의 용량과 방출 정책에 대해서 설계하기 샤딩 \u0026ldquo;같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다.\u0026rdquo; 쓰기와 읽기 모든 부하에 대한 분산이 가장 큰 장점 데이터 베이스의 수평적 확장(샤딩) 이후에 생겨나는 문제점 데이터의 재 샤딩이 필요해짐 (샤드 소진) 유명인사 문제 : 특정 샤드에 질의가 집중되는 문제 조인과 비정규화 정리 웹 계층은 무상태 계층으로 모든 계층에 다중화 도입 가능한 한 많은 데이터를 캐시할 것 여러 데이터 센터를 지원할 것 정적 콘텐츠는 CDN을 통해 서비스할 것 데이터 계층은 샤딩을 통해 그 규모를 확장할 것 각 계층은 독립적 서비스로 분할할 것 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것 2장 개략적인 규모 추정 개요 이후에 설명할 내용이나, 설계에 있어 근거가 되는 \u0026lsquo;단위\u0026rsquo;를 설명해주는 장 데이터의 단위나 속도등을 알려준다. 제프딘의 응답 지연시간\n작업 소요 시간 L1 캐시 참조 0.5 ns 분기 예측 오류 5 ns L2 캐시 참조 7 ns 뮤텍스 락/언락 100 ns 메인 메모리 참조 100 ns 압축(Zippy)로 1KB 압축 10,000 ns (10 μs) SSD에서 4K 읽기 16,000 ns (16 μs) 메모리에서 1MB 순차적 읽기 250,000 ns (250 μs) SSD에서 1MB 순차적 읽기 1,000,000 ns (1 ms) 하드 디스크 탐색 10,000,000 ns (10 ms) 하드 디스크에서 1MB 순차적 읽기 20,000,000 ns (20 ms) 같은 데이터센터 내 서버 간 왕복 500,000 ns (0.5 ms) 미국 해안 간 왕복 지연시간 30,000,000 ns (30 ms) TCP 패킷 재전송 1-3 초 (1,000,000,000-3,000,000,000 ns) 디스크 드라이브 MTBF(평균 고장 간격) 수개월 (10^15 ns) 가용성 관련 : 99%가 연간 3.65일의 downtime을 허용한다. qps : qury per second 추정치 mau x 매일 사용하는 사용자 비율 x 각사용자의 평균 트윗을 올리는 건수 : 이런식으로 계산 즉 mau가 얼마인지, 실제 사용 비율을 얼마로 추정하는지, 미디어를 포함한 요청이 얼마나될지 미디어 데이터터 평균값은 얼마나 될지 데이터 보존 기한은 얼마일지 위와 같은 질문과 함께 따져봐야한다. 3장 시스템 설계 면접 공략법 개요 설계 면접과 관련한 실질적인 팁 너무 부담가지지 말것 완벽한 설계를 보려는게 아님 설계 기술의 시연과 과정에서 내린 결정들에 대한 방어 능력을 보이는자리 부정적 신호에만 유의할것 설계의 순수성에 집착하지 말고 tradeoff를 잘 고려할 것 효과적인 면접을 위한 4단계 접근법 1단계 문제 이해 및 설계 범위 확정 요구사항을 완전히 이해하지 않고 생각 없이 답내지 않기 (속도를 늦춰라) 요구사항을 정확하게 이해하는데 \u0026lsquo;필요한\u0026rsquo; 질문을 하라. 아래는 도움이 될 질문 예시 구체적으로 어떤 기능들을 만들어야 하나? 제품 사용자 수는 얼마나 되나? 회사의 규모는 얼마나 빨리 커지리라 예상하나? 석 달, 여섯 달, 일년 뒤의 규모는 얼마가 되리라 예상하는가? 회사가 주로 사용하는 기술 스택(technology stack)은 무엇인가? 설계를 단순화하기 위해 활용할 수 있는 기존 서비스로는 어떤 것들이 있는가? 2단계 개략적인 설계안 제시 및 동의 구하기 3단계 상세 설계 4단계 마무리 개선점, 병목, 혹은 더 개선하능한 구간을 질문받으면 같이 고민해본다. 요약을 제시한다. 오류가 발생하면 무슨일이 생기는지 땁져본다. 운영이슈도 논의해본다. 미래에 닥칠 규모 확장 요구에 어떻게 대처할 것인지 생각해본다. 4장 처리율 제한 장치의 설계 개요 처리율 제한 장치 설계 예시를 통한 면접 가이드 사실 처리율 제한 장치를 이해하는데도 큰 도움이 되는 장 처리율 제한 장치에 대한 이해 클라이언트 혹은 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치 임계치에 도달하면 추가로 도달한 모든 호출은 처리가 중단 되어야 한다. 장점 ddos와 같은 공격에 의한 자원 고갈을 방지 비용을 절감 과부하를 막아준다. 1단계 문제 이해 및 설계 범위 확정 서버측 api 처리율을 제한하기 위한 장치를 설계해야함 다양한 제어 규칙을 정의 할 수 있어야함. 대규모 요청을 처리해야함 분산 환경에 동작해야함. 독립된 서비스여도 상관 없고, 애플리케이션 코드에 포함되어도 상관 없음. 사용자에게 전달되는 에러처리를 해야함 2단계 개략적 설계안 제시 및 동의 구하기 클라이언트를 배제하면 두가지가 있다. (위변조가능, 통제어려움) 서버측 처리율 제한 미들웨어 : 보통 msa환경에서는 api 게이트웨이에 많이 둔다. 개인적인 의견으로는 관리포인트가 늘어나지 않는게 낫다는 관점에서 게이트웨이가 좋은 것 같다. 추후 상용 게이트웨이를 쓰거나 할 니즈가 생기는경우도 생각해보기 쉽다.\n처리율 제한 알고리즘 토큰 버킷 알고리즘 간단하고, 이해도도 높고, 많이쓰인다. 간단하게 요청이 도착하면, 토큰 버킷을 검사해서 토큰이 남아있는지 확인하고 없으면 요청을 버린다. 버킷에 토큰을 공급하는 공급률을 조정한다. 버킷크기와 토큰 공급률을 인자로 한다. 통상적으로 api endpoint별로 별도의 버킷을 둔다. 메모리 효율적이고, 구현이 쉽고, 짧은 시간에 집중되는 (burst)트래픽도 처리 가능하다. 누출 버킷 알고리즘 (leaky bucket) 버킷을 큐로 구현하면 아이디어가 비슷하다. 토큰의 공급이 아닌, 큐의 빈자리를 기준으로 요청을 버린다. 큐의 크기가 제한되어 마찬가지로 메모리 효율적이다. 고정된 처리율을 가지고 있어 안정적 출력이 필요한 경우 적합하다. 단기간 트래픽을 제때 처리 못하면, 최신 요청들이 버려진다. 고정 윈도 카운터 알고리즘 이후 사용될 이 아이디어를 기반으로한 다른 개선버전이 실질적으로 쓰인다. 타임라인을 고정된 간격의 윈도우로 나누고 그 윈도우마다 카운터를 붙인다. 윈도우 내에 카운터만큼의 요청이 가득차면 다음 윈도우가 열릴때까지 버린다. 경계구간에 몰리면 허용한도 이상의 요청을 받게 될 수 있다. 이동 윈도 로깅 알고리즘 요청의 타임스탬프를 추적한다. 타임스탬프를 sorted set 같은것에 보관한다. 새 요청이 오면 만료된 타임스탬프는 제거된다. (현재 윈도우의 시작 지점보다 오래된 타임스탬프) 새요청의 타임스탬프를 로그에 추가한다. 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 아니면 버린다. 이게 이해가 조금 힘들었는데, 타임스탬프가 새로운 요청 기준으로 판별된다는 점을 추가하면 이해가 쉽다. 즉 새로운 요청이 왔을 때, 그 시점으로 윈도우시간 이전의 로그 카운트를 검사한다.\n위의 하나를 골라서 상세 설계에 들어간다. 3단계 상세 설계 처리율 제한 규칙을 고려한다. 처리율 한도 초과 트래픽의 처리 : 적절한 헤더 응답과 함께 내보내준다. 5장 안정 해시 설계 개요 수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다. 해시 키 재배치 문제 일반적으로 모듈러연산을 기준으로 해시한 상황을 가정하면, 서버풀의 크기가 고정되어 있을 때, 그리고 데이터 분포가 균등할때는 잘 동작한다. 하지만 서버가 추가되거나 기존 서버가 삭제되면 문제가 생긴다. 예를 들어 n번 서버가 장애를 일으켜 동작을 중단하면 서버풀이 n-1개가 되는데 그 결과로 해시값은 변하지 않지만 나버지 연사을 적용하여 계산한 서버 인덱스 값은 달라질 것이다. 문제는 이러면 죽은 서버 뿐만이 아니라 다른 서버의 키도 재분배가 이루어져아 한다. 안정해시 안정해시는 해시 테이블의 크기가 조정될 때 오직 k/n개의 키만 재배치하는 해시 기술이라고 한다. 여기서 k는 키의 갯수이고 n이 슬롯의 갯수이다. 원리는 해시 함수를 기반으로 해시 공간(해시함수의 y값 공간)을 두고, 순환 구조를 만든다. x0 ~ xn 까지의 해시공간이 있을 때 xn다음이 x0가 되는 구조 그 키의 링(ring) 위에 서버와 키들을 배치하고, 특장 방향으로 돌면서 특정 키값마다 저장할 서버를 찾는구조 균등분포와 파티션 크기를 일정하게 유지하기 어렵다는것이 단점이었다. 어차피 논리적인 공간이므로, 가상노드를 여러개를 두어 해결한다. 6장 키-값 저장소 설계 1단계 문제 이해 및 설계 범위 확정 키값 쌍의 크기는 10kb이하. 큰 데이터를 저장 할 수 있어야 한다. 높은 가용성을 제공해야한다. 높은 규모의 확장성을 제공해야한다. 데이터 일관성 수준은 조정이 가능해야 한다. 응답 지연시간이 짧아야 한다. 분산 키-값 저장소 분산 해시테이블 분산 시스템을 설계할때는 CAP정리를 이해하고 있어야 한다. Consitency vs Availability vs Partition toleration Consitency : 일관성, 즉 모든 클라이언트는 어떤 노드에 접근하든 \u0026lsquo;같은\u0026rsquo; 데이터를 봐야한다. Availability : 가용성, 즉 모든 클라이언트는 일부 노드에 장애가 발생해도 \u0026lsquo;항상\u0026rsquo; 응답을 받아야 한다. Partition toleration : 파티션 감내, 즉 두 노드의 네트워크 파티션이 생기더라도 시스템은 계속 동작해야 한다. 요점은 이 세가지중에 두가지를 충족하려면 나머지 하나는 버려야한다.\nCP 시스템 : 일관성과 파티션 감내를 충족한다. 즉 가용성을 버린다. Two Phase Commit에서 네트워크 분할 발생 시, 트랜잭션 조정자가 모든 참여 노드로부터 응답을 받지 못하면 전체 트랜잭션을 중단한다. 이 과정에서 일부 노드가 사용 불가능해지더라도 데이터 일관성을 유지한다. Mongodb 예시 예를들어 네트워크 분할 발생시 슬레이브 노드는 통신이 끊기면 그냥 읽기요청을 처리안해버림 AP 시스템 : 가용성과 파티션 감내를 충족한다. 즉 일관성을 버린다. 네트워크 분할에도, 쓰기와 읽기 작업을 계속 처리한다. 최종적 일관성을 제공하기위해서 보완수단을 쓴다. (즉각적인 일관성을 희생) CA 시스템 : 가용성과 일관성을 충족하지만, 네트워크 파티션을 희생한다. 단일 노드로 구성할경우 (말장난 같지만) 실질적으로는 없고, 사용도 안하는 구조 결론적으로는 CP냐 AP냐의 트레이드 오프 사이에서 결정하는 경우가 압도적 대다수\n다시 분산 키-값 저장소에서 달성해야 할 목표들 데이터 파티션 : 안정해시를 이용해서 파티션한다. 데이터 다중화 : 안정해시 위에서 저장될 파티션을 정하는 로직에서 추가적으로 n개의 노드를 더 탐색해서 다중화한다. 데이터 일관성 : 정족수 합의 프로토콜을 이용한다. 정족수 합의 프로토콜 일단 기본적으로 다음과 같은 변수를 사용한다. N = 사본의 갯수 W = 쓰기 연산 정족수, 즉 쓰기 연산이 성공한것으로 간주되려면, W개의 서버로부터 응답을 받아야 한다. R = 읽기 연산 정족수, 마찬가지로 R개의 서버로부터 동일한 값을 응답받아야 정상적인 읽기로 간주한다. 보통 많이 사용하는 구성 R = 1, W = N : 빠른 읽기 연산에 최적화 W = 1, R = N : 빠른 쓰기 연산에 최적화 W + R \u0026gt; N : 강한 일관성 (보통 N = 3, W = R = 2 의 비율) W + R \u0026lt;= N : 강산 일관성이 보장되지 않음 일관성 모델 : 강한 일관성 : 클라이언트는 절대 낡은 데이터를 보지 못하게 한다. 약한 일관성 : 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수 있다. 최종 일관성 : 약한 일관성이지만, 최종적으로는 동기화 된다. 보통 강한 일관성은 분산환경에서는 맞지 않다. 읽기 락까지 걸어버리기 때문에 비 일관성 모델 : versionning과 vector clock을 주로 많이 사용한다. 충돌 감지 및 해소 과정 초기 설정 시스템의 각 노드는 자신만의 벡터 시계를 유지한다. 벡터 시계는 [node1: count1, node2: count2, ...] 형태로 표현한다. 초기값은 모든 노드에 대해 0으로 설정한다. 데이터 변경 시 노드가 데이터를 변경할 때마다 자신의 카운터를 증가시킨다. 변경된 데이터는 현재 벡터 시계 값과 함께 저장한다. 데이터 동기화 과정 노드 간에 데이터를 동기화할 때, 데이터와 함께 벡터 시계를 전송한다. 수신 노드는 자신의 벡터 시계와 수신된 벡터 시계를 비교한다. 충돌 감지 벡터 시계 간의 관계는 세 가지로 분류한다.: 동일(Equal): 두 벡터의 모든 값이 같은 경우. 선행(Happens-before): 벡터 A의 모든 값이 벡터 B의 값보다 작거나 같고, 적어도 하나는 작은 경우. 동시성(Concurrent): 위 두 관계가 성립하지 않는 경우. (일부 값은 더 크고, 일부 값은 더 작음) 충돌은 두 벡터 시계가 동시성 관계일 때 감지. 이는 두 노드가 서로의 변경사항을 모른 채 동일한 데이터를 변경했음을 의미하기 때문. 충돌 해소 방법 자동 해소: 타임스탬프 기반: 가장 최근 타임스탬프를 가진 버전을 선택. 우선순위 기반: 미리 정의된 노드 우선순위에 따라 선택. 사용자 개입: 충돌 발생 시 사용자에게 알리고 수동 병합을 요청. 두 버전의 차이점을 표시하여 사용자가 선택하도록. 병합 전략: 필드별 병합: 객체의 각 필드를 독립적으로 처리. 의미적 병합: 애플리케이션 로직에 기반한 병합 규칙을 적용. 벡터 시계 업데이트 충돌이 해소된 후, 노드는 자신의 벡터 시계를 업데이트: 자신의 카운터를 증가. 다른 노드의 카운터는 수신된 벡터 시계와 자신의 벡터 시계 중 더 큰 값을 취함. 장애 감지 : 멀티캐스팅은 서버가 많으면 비효율적임 그래서 가십 프로토콜같은 솔루션을 사용 각자 노드가 테이블을 가지고 있으며 무작위로 하트비트를 전송/기록 특정 노드의 하트비트 시간이 지연되었으면 다른노드로 전달 다른 노드에서도 오랫동안 증가가 안되어있으면 장애 노드로 파악 일시적 장애 처리 : 엄격한 정족수에서는 그냥 연산금지로 끝남 느슨한 정족수는 해시링을 이용해서 대응할 서버를 이동시킴 그동안의 변경사항을 일괄 반영하는 장치를 만들어둬야함 영구 장애 처리 : 반 앤트로피 프로토콜을 구현해서 사본을 동기화해야함 머클트리를 이용한다고 함 7장 분산 시스템을 위한 유일 id 생성기 설계 1단계 문제 이해 및 설계 범위 확정 유일, 정렬가능 숫자로만 구성 64bit로 표현가능 발급 날짜에 따라 정렬되어야함 초당 10,000개를 만들 수 있어야 함 2단계 개략적 설계안 제시 및 동의 구하기 multi master replication uuid ticket server snowflake multi master replication db마다 autoincrement를 db 숫자만큼 하기 단점이 너무 많다 대표적으로 확장성 uuid 충돌 가능성이 낮다 중복이 발생할 기댓값이 50%가 되려면 초당 10억개씩 100년동안 생성.. 서버간 조율이 전혀 필요없음 근데, 128비트에 문자열도 포함되고 시간순 정렬이 불가능하다. ticket server 하나의 auto increment 서버를 둔다. 유일성이 보장되는데 구현도 쉽다. SPOF snowflake 트위터에서 만들었다고 함 사인, 타임스탬프, 데이터센터 id, 서버 id, 일련번호 기본적으로 타임스탬프 포함이라 정렬이됨 용량이 적음 같은 노드에서 시간이 겹치는 경우에만 일련번호로 분리 8장 URL 단축기 설계 1단계 문제 이해 및 설계 범위 확정 쓰기연산 : 매일 1억개 초당쓰기 : 1160개 읽기연산 : 비율을 10:1로 가정 초당 11600개 10년운영시 레코드 : 3650억개 보통 36.5tb 2단계 개략적 설계안 제시 및 동의 구하기 기본적으로 예상 가능한 구조 리다이렉션은 301, 302를 고려해야함 301은 영원히 리다이렉트를 함 (브라우저에서) 302는 계속 우리서버를 프록시할것 특정 메타데이터를 이용할 서비스를 고려중이라면 302 URL 단축 로직 해시로직이 필요함 해시 후 충돌 해소 처음 7개 글자만 이용 당연히 발생할 충돌은 특정 문자를 더 붙이고 다시 검사 충돌이 많은 상황이라면 db조회가 많아질 수 있음 base-62 변환 캐시로 최적화 9장 웹 크롤러 설계 는 정리는 생략.. 10장 알림 시스템 설계 푸시, sms, 이메일 지원 soft real-time 시스템 (가능한 빨리, 부하시 약간의 지연을 허용) ios, android, 랩톱/데스크톱 알림은 클라이언트앱쪽에서, 혹은 스케줄링 서버를 통해 알림을 안받는 설정도 가능하도록 하루에 천만건의 모바일 푸시 알림, 백만건의 sms, 500만건의 이메일 알림 유형별 지원 방안 ios apns가 있음 device token, payload를 저기에 보내면 됨 android 마찬가지 sms 상용 서비스 이용 필요 이메일 마찬가지로 벤더를 끼고 함 2단계 계락적 설계안 제시 후 동의 구하기 기본적으로 병목을 고려해야하고 spof가 안되도록 해야함 규모확장성을 갖춰야함 위의 것들을 고려하면 큐를 이용한 서버를 생각하게됨 다중화 가능한 알림서버와 데이터베이스 각 서비스별 큐를 두고 작업서버를 연동 3단계 상세 설계 안정성 데이터 손실 방지 : 재시도 매커니즘을 구현하기 위해 알림 로그 데이터베이스를 유지 알림 중복 전송 방지 : 중복 전송을 100퍼센트 막는것은 사실상 불가능하다. 추가로 필요한 컴포넌트 및 고려사항 알림 템플릿 알림 설정 : 사용자별로 알림 설정 전송률 제한 재시도 방법 푸시알림과 보안 큐 모니터링 이벤트 추적 11장 뉴스 피드 시스템 설계 이건 데이터 중심 애플리케이션 설계에서 다룬 내용이 주 맥락이다.\n기본적으로 뉴스피드 캐시를 사용자마다 두는 구조로 개발을 하는데,\n쓰기 대비 읽기 트래픽이 압도적인 뉴스피드 특성상,\n읽기 최적화를 위해서 쓰기 시점 팬아웃을 한다.\n즉 내가 포스팅을 하면 나랑 친구 혹은 follow하는 사용자들의 피드 캐시에 쓰기가 된다는것.\n그러면 그 캐시를 받아서 읽기 성능이 비약적으로 상승한다.\nqps분석 결과 읽기 트래픽이 압도적으로 많아 쓰기 성능이 떨어지는것을 감내하고 의사결정을 한것\n그러나 호날두가 등장한다!\n호날두는 팔로워가 몇억명인데\n호날두의 쓰기속도가 매우 줄어든다.\n그래서 하이브리드로 특정 팔로워 이상은 쓰기 팬아웃을 안한다는 것\n추가적으로 책에서 언급된건\n쓰기 시점의 팬아웃은 서비스를 자주 이용하지 않는 사용자도 갱신하는것 그로인해 비활성화된 사용자가 많다면 읽기시점에 팬아웃하는 모델이 유리할수 있따는것 그리고 캐시와 관련된 전략이 나와있다.\n12장 채팅 시스템 설계 1단계 문제 이해 및 설계 범위 확정 응답 지연이 낮은 일대일 채팅 최대 100명까지 그룹채팅 사용자의 접속상태 표시 기능 다양한단말지원 푸시알림 2단계 개략적 설계안 제시 및 동의 구하기 중간에 서버를 둔다는것을 이해해야 한다.(클라이언트간 통신이 아님) 결론적으로 우리 서버는 클라이언트들로부터 메시지 수신 메시지 수신자 결정 및 전달 수신자가 접속상태가 아닌경우 접속할 때 까지 메시지 보관 폴링 클라이언트가 주기적으로 서버에 데이터를 요청하는것 롱 폴링 : 폴링의 비효율을 일부 해소한 것. 폴링중 세 메세지가 없는경우 타임아웃만큼만 대기한다. 서버측에서 마찬가지로 연결 여부를 체크할 방법이 없다. 웹소켓 서버가 클라이언트에게 비동기 메세지를 보낼때 사용 http 핸드쉐이크 이후 웹소켓으로 업그레이드함 서버 입장에서 관리만 효율적으로 해주면 됨 2단계 계략적 설계안 제시 및 동의 구하기 일단 기본적으로 무상태로 설계하지만, 채팅서비스는 무상태로 설계할 수 없음 규모 확장성 : 간단한 계산 (메모리 정도) 이후 양해구해서 넘어가기 ","permalink":"http://localhost:1313/_wiki/system-design-interview/","summary":"책의 내용을 일부 \u0026lsquo;발췌\u0026rsquo;해서 정리 각 장별 간단한 개요는 작성하지만, 실질적으로는 내가 조금 더 기억하고 싶은 내용만 일부 발췌해서 기록\n1장 사용자 수에 따른 규모 확장성 개요 기본적인 어플리케이션 설게와 매우 자주 사용되는 컴포넌트 혹은 구현해야하는 요구사항에 대해서 소개해 주는장 예를들어 아래와 같은 것들을 개념을 개략적으로 설명해준다. 데이터 저장소 수직적 확장,수평적 확장 다중화 캐시 안정성과, 가용성과같은 시스템을 측정할 수 있는 요소들도 설명해준다. 내용 캐시 사용시 유의 할 점 어떤 상황에 바람직한지 생각하기 어떤 데이터를 캐시할지 생각하지 만료기한을 잘 설정하기 일관성을 유지 할 수 있도록 생각하기 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우?","title":"가상 면접 사례로 배우는 대규모 시스템 설계"},{"content":"JVM JVM 구성요소 유저모드 어플리케이션 프로세스, 가상 메모리 공간을 활용, 머신으로서 연산, os의 일부기능 jvm 구성요소 클래스 로더(Class Loader) 자바 클래스 파일(.class)을 로드하고 링크하는 역할 로딩, 링킹, 초기화 단계로 구성됨 부트스트랩 클래스 로더, 확장 클래스 로더, 애플리케이션 클래스 로더로 구성 클래스 로딩 링킹등이 런타임에 일어날 수 있다. 런타임 데이터 영역(Runtime Data Area) 메서드 영역(Method Area): 클래스 구조, 메서드 데이터, 상수, 정적 변수 등 저장 힙(Heap): 객체와 인스턴스 변수가 저장되는 공간 스택(Stack): 스레드마다 별도로 존재하며 지역 변수, 매개변수, 리턴 값 등 저장 PC 레지스터(Program Counter Register): 현재 실행 중인 명령어 주소 저장 네이티브 메서드 스택(Native Method Stack): 네이티브 코드를 위한 스택 실행 엔진(Execution Engine) 인터프리터(Interpreter): 바이트코드를 한 줄씩 해석하고 실행 JIT 컴파일러(Just-In-Time Compiler): 자주 사용되는 코드를 네이티브 코드로 컴파일하여 성능 향상 가비지 컬렉터(Garbage Collector): 더 이상 사용되지 않는 메모리 자동 정리 네이티브 메서드 인터페이스(JNI, Java Native Interface) 자바 코드가 네이티브 애플리케이션이나 C, C++ 등의 라이브러리와 상호작용할 수 있게 함 네이티브 메서드 라이브러리(Native Method Libraries) C, C++ 등으로 작성된 라이브러리 모음 클래스로더 .class file(실행 바이너리)\nClassFile { u4 magic; // 매직넘버(0xCAFEBABE), JVM이 유효한 클래스 파일인지 식별 u2 minor_version; // 클래스 파일 포맷의 마이너 버전 u2 major_version; // 클래스 파일 포맷의 메이저 버전 u2 constant_pool_count; // 상수 풀 항목 수 + 1 cp_info constant_pool[constant_pool_count-1]; // 상수 풀 테이블 u2 access_flags; // 클래스의 접근 제어자 u2 this_class; // 현재 클래스를 나타내는 상수 풀 인덱스 u2 super_class; // 부모 클래스를 나타내는 상수 풀 인덱스 u2 interfaces_count; // 구현된 인터페이스 수 u2 interfaces[interfaces_count]; // 구현된 인터페이스들의 상수 풀 인덱스 u2 fields_count; // 필드 수 field_info fields[fields_count]; // 필드 정보 u2 methods_count; // 메서드 수 method_info methods[methods_count]; // 메서드 정보 u2 attributes_count; // 속성 수 attribute_info attributes[attributes_count]; // 클래스의 추가 속성 정보 } 추가적으로 .class를 보고 실제 네이티브 머신코드로 interprete, 반복되는 애들을 미리 번역해놓는(컴파일) 애들이 jit compiler 이름을 알고 있는 특정 클래스에 대한 정의(byte stream)을 가져오는 역할을 수행 가져온다는 것은 네트워크를 통해 가져오는것을 포함 부트스트랩 클래스 로더 (비유하자만, 실제 cpu의 부트로더가 필요한일을 마치고, os코드의 진입지점을 실행시키고 종료되는데 마찬가지) jvm에서 라이브러리로 취급되는것들(rt.jar, tools.jar)을 로드 플랫폼 클래스 로더 (기존 확장 클래스 로더) 클래스 라이브러리 로드 어플리케이션 클래스 로더 Java 클래스 로딩 java는 실행과정에 링킹 과정이 포함되어있음 기존의 컴파일 - 링크 - 런타임보다는 실제 바이트코드를 로딩하고, 링크 런타임이 실행단계에 분류되어있음 실질적으로는 Loading -\u0026gt; Linking -\u0026gt; Using -\u0026gt; Unloading(GC) 해석 (Resolution)단계는 동적 바인딩(혹은 lazy binding)을 지원할 목적으로 초기화 후로 지연될 수있음 클래스 로더가 하는 일 클래스 검증 규칙과 제약을 만족하는지 파일형식 메타데이터 바이트코드 심벌참조 보안위협에 대한 검증 포함 준비 및 해석 java.lang.Class 인스턴스(메타데이터)가 힙 영역에 생성, 클래스 변수 메모리를 0으로 초기화 로드되는 클래스의 인스턴스는 Using단계에서 힙사용 final선언된 변수 정리 생성자 호출 전 상태 필드 초깃값은 생성자 호출시 정의 정적필드에 초기값 할당 해석은 상수풀의 심벌 참조를 직접 참조로 대체하는 과정 Heap 영역에 객체 생성 jvm은 객체 저장을 위한 메모리 공간을 확보 후 0으로 초기화 (객체 헤더 제외) 객체 초기화를 위한 구성설정 실시 기본적으로 object header, instance data, padding으로 되어있음 object header(의 klass word)를 통해 아까 로드한 metadata에 접근 클래스 이름 및 메타 정보 확인 방법 객체에 대한 해시코드 GC세대 나이 생성자 호출 런타임 데이터 영역 프로그램 카운터\n프로그램 카운터 레지스터는 작은 메모리 영역으로 현재 실행중인 스레드의 \u0026lsquo;바이트 코드 줄 번호 표시기\u0026rsquo;라고 생각하면 쉽다. 바이트코드 인터피르터는 이 카운터 값을 바꿔 다음에 실행할 바이트코드 명령어를 선택하는식으로 동작 프로그램의 제어 흐름, 분기, 순환, 점프등을 표현 예외처리나 스레드복원같은 기능이 이 표시기를 활용해 동작 jvm의 멀티스레딩은 cpu코어를 여러 스레드가 교대로 사용하는 방식으로 구현되기 때문에, 특정 시각에 한 코어는 한 스레드의 명령어만 실행하게 된다. 따라서 스레드 전환 후 이전에 실행하다 멈춘 지점을 정확하게 복원하려면 스레드 각각에는 고유한 프로그램 카운터가 필요하다. 따라서 각 스레드의 카운터는 서로 영향을 주지 않는 독립된 영역에 저장된다. 이 메모리 영역을 프라이빗 메모리라고 한다. 스레드가 자바 메서드를 실행중일 때는 실행중인 바이트코드 명령어의 주소가 프로그램 카운터에 기록된다. 한 편 스레드가 네이티브 메서드를 실행중일 때 프로그램 카운터 값은 undefined다 프로그램 카운터 메모리 영역은 oom 조건이 명시되지 않은 유일한 영역이기도 하다. 자바 가상 머신 스택\n마찬가지로 스레드 프라이빗하며, 스레드와 수명주기가 같다. 가상머신스택은 메서드를 실행하는 스레드의 메모리 모델을 설명해준다. 메서드 호출시 스택프레임만들고, 지역변수 테이블, 피연산자 스택, 동적 링크, 메서드 반환값등의 정보를 저장한다. 그다음 스택프레임을 가상머신 스택에 푸시하고, 메서드가 끝나면 팝하는일을 반복한다. 지역 변수 테이블에는 jvm이 컴파일타임에 알수있는 다양한 기본데이터타입, 객체 참조, 반환주소 타입을 저장한다. 이걸 저장하는 공간을 지역 변수 슬롯이라 하고 슬롯의 크기는 일반적으로 32비트이다. 지역 변수 테이블을 구성하는데 필요한 데이터 공간은 컴파일 과정에 할당된다. 자바 메서드는 스택프레임에서 지역변수용으로 할당받아야 할 공간의 크기가 이미 완벽하게 결정되어있다. 네이티브 메서드 스택\njvm 스택과 비슷! 네이티브 메서드를 사용할때 실행된다. (보통 다른 언어로 작성된 메서드, jni를 통해 호출됨, 즉 jvm이 직섭 실행할수없는 네이티브 코드를 실행하기 위한 메서드) 자바 힙\n모든 스레드 공유 다른 언어의 힙과 동일 거의 모든(사실상 모든)객체가 힙에 저장됨. gc가 관리하는 메모리 영역이기에, gc힙이라고 함 객체 할당 효율을 높이고자 스레드 로컬 할당 버퍼 여러개로 나뉜다. (그래도 모든 객체가 힙에 저장된다는 사실은 마찬가지, 일부 메모리회수와 할당을 조금 더 빠르게 하기위해 일정한 세부영역이 있을 뿐) 힙은 물리적으로 떨어진 메모리에 위치해도 상관없으나 논리적으로는 연속되어야 한다. 메서드 영역\n모든 스레드가 공유하는 영역으로, JVM이 시작될 때 생성됨 런타임 상수 풀, 필드와 메서드 데이터, 메서드와 생성자 코드, 클래스와 인터페이스 초기화에 사용되는 코드 등을 포함 클래스 로더가 클래스 파일을 로드할 때, 해당 클래스의 메타데이터를 이 영역에 저장 JDK 8까지는 이 영역을 \u0026ldquo;영구 생성(Permanent Generation)\u0026rdquo; 또는 \u0026ldquo;PermGen\u0026quot;이라고 불렀음 JDK 8 이후에는 메서드 영역의 구현이 \u0026ldquo;메타스페이스(Metaspace)\u0026ldquo;로 변경됨 메타스페이스는 기존 PermGen과 달리 OS가 관리하는 네이티브 메모리 영역을 사용하므로 더 이상 JVM 힙 메모리의 일부가 아님 이 변경으로 OutOfMemoryError: PermGen Space 오류가 발생하지 않게 됨 클래스 메타데이터, 메서드의 바이트코드, static 변수와 상수 정보 등이 저장됨 런타임 상수 풀은 리터럴 상수, 필드 참조, 메서드 참조 등을 포함하며 심볼릭 참조를 실제 참조로 변환하는 데 사용됨 클래스의 정적 변수는 여기에 저장되지만, Java 8 이후에는 static 변수의 실제 데이터는 힙에 저장됨 JIT컴파일러가 컴파일한 코드를 캐싱한다. 런타임 상수 풀\n클래스 버전, 필드, 메서드, 인터페이스등 클래스파일에 포함된 정보 및 리터럴, 심볼참조가 저장되는 영역 클래스로더가 클래스 로드시 상기 정보를 저장 동적으로 운영되며 런타임에 새로운 상수가 추가될 수 있음 JVM 스택 구조 지역변수 테이블, 피연산자 스택, 메서드 반환값등을 저장 보통 지역변수 테이블을 스택으로 지칭 지역변수 테이블은 슬롯으로 이루어지며, 기본형 변수 하나가 슬롯한개를 사용 java 스택의 크기는 메모리 용량이 아닌 슬롯의 개수 jvm이 허용하는 스택의 크기를 초과할경우 stackoverflow 스택 프레임 구조\n구성 요소 설명 지역 변수 배열(Local Variable Array) • 메서드의 지역 변수 저장\n• 메서드 파라미터도 여기 저장\n• 인덱스 0부터 시작\n• 인스턴스 메서드의 경우 인덱스 0은 \u0026rsquo;this\u0026rsquo; 참조\n• 각 슬롯은 32비트 크기\n• long, double은 두 슬롯 차지 피연산자 스택(Operand Stack) • 메서드 실행 중 임시 작업 공간\n• 바이트코드 명령어의 피연산자를 push/pop\n• 메서드 호출 시 인자값 전달에 사용\n• JVM은 스택 기반 해석기 동적 링크(Dynamic Linking) • 상수 풀의 심볼릭 참조를 실제 참조로 변환\n• 실행 시 메서드나 필드 참조 해결\n• 런타임에 클래스 간 연결 설정 반환 주소(Return Address) • 메서드 호출 완료 후 돌아갈 주소\n• 호출자의 스택 프레임 위치 정보\n• 호출된 메서드가 정상/예외적으로 종료된 뒤 사용 부가 정보(Additional Information) • 예외 처리 정보\n• 디버깅 정보\n• JVM 구현에 따라 추가 정보 포함 가능 JVM 힙 구조 GC가 관리하는 메모리 영역 객체의 인스턴스 및 배열이 저장되는 공간 설정에따라 크기 변경 고정 가능 세대별 컬렉션 이론 (Generational collection thory)을 기반으로 설계 및 운영 Eden, Survivor New/Old Generation 영구 세대 (Metaspace) JVM GC Heap영역에서 참조되지 않는 개체를 수집 및 제거해 메모리 회수 Minor/Major(Full) GC GC수행시 프로그램 일시 정지 stop-the-world GC 속도 Minor GC 보통 1초이내 Full GC 1초이상 지연되기도 함 -\u0026gt; 문제는 db커넥션이 끊기거나 하는 운영문제가 생길 수 있음 GC가 처리해야할 문제의 핵심 3요소\n회수 대상을 판단하는 것 메모리를 회수하는 시점 메모리 회수 방법 세대 단위 컬렉션 이론 바탕이 되는 가설 대다수 객체는 일찍 사라짐(약한 세대 가설) gc과정에서 살아남은 횟수가 늘어날수록 (앞으로도) 생존 가능성이 높아짐(강한세대 가설) 다른세대에 속한 객체간 참조는 같은세대에 속한 객체간 참조보다 훨씬 적음 (세대 간 참조 가설) 핫스팟 vm에서 에덴과 생존자 공간비율은 보통 8:1 IBM 연구에 따르면 보통 첫 GC에 대략 98% 객체가 소멸 10% 메모리 파편화 방지를 위해 활용 (Overhead) jvm heap 영역 세대별 space 출처 : https://medium.com/@khurshidbek-bakhromjonov/java-memory-management-understanding-the-jvm-heap-method-area-stack-24a4d4fa2363\nYoung generation eden 객체 생성직후 저장되는 영역 Minor GC 발생시 Survivor 영역으로 이동 Copy \u0026amp; Scavenge 알고리즘 Survivor 0,1 Minor GC 발생시 Eden, S0에서 살아남은 객체는 S1 (S0, S1 서로 교대) S1에서 살아남은 객체는 Old로 age bit 사용 (참조 계수) Old generation Young generation 영역에서 소멸하지 않고 남은 개체들이 사용하는 영역 Full GC 발생시 개체 회수 (비용이 크고 디테일함, 실제로 정말 사용되는지 찾음) Mark \u0026amp; Compact 알고리즘 Permanent Metaspace 로드되는 클래스, 메소드 등에 관한 메타 정보 저장 java heap이 아닌 native메모리 영역사용 리플렉션 클래스 로드시 사용 GC 알고리즘 Mark and sweep\n1단계 마크(회수대상 판단) 2단계 회수 단점 효율이 일정하지 않음 (힙이 많이 채워져있을경우 특히) 메모리 파편화 발생 Mark and copy\n가용 메모리 공간을 둘로 나눈후 한쪽만 사용 (S0, S1) 살아남은 인스턴스를 옮길때 옮김 (Copy) 즉 살아남은 인스턴스를 다른 영역으로 복사하고 사용했던 공간을 모두 비운다. 단점 가용메모리 공간이 절반으로 줄어듦 Andrew Appen의 제안으로 개선 (위의 연구) Mark and compact\n생존한 객체를 모음 (copy 과정에서 compact) 단점 살아남은 객체가 많을수록 부담이 크게 증가 (사실상 모든 알고리즘 공통) 인스턴스 이동 과정에서 응용프로그램의 연산이 일시정지 (Stop the world!) (사실상 모든 알고리즘 공통) 도달 가능성 분석 도달 가능성 분석 알고리즘에 기초해 회수 대상 인스턴스를 판단 GC 루트 객체들을 기점으로 참조하는 다른 객체들을 탐색하는 방식 GC 루트 객체가 될 수 있는 것들\njvm stack frame 지역변수 테이블에서 참조하는 객체 Synchronized 키워드로 잠겨있는 객체 JNI가 참조하는 객체 메서드 영역에서 클래스 정적 필드로 참조하는 객체 메서드 영역에서 상수로 참조되는 객체 JVM 내부에서 사용되는 참조 Garbage First GC 클래식 GC 종류 일부\nSerial 단일 스레드로 작동, 회수가 끝낼때까지 모두 멈춤 간단하고 효율적이며 알고리즘 수준에서 리소스 사용량 적음 ParNew 시리얼 컬렉터를 병렬처리 Parallel scavenge 사용자 코드 처리 실행 효율 극대화를 목표로 설계 CMS GC java 14까지 사용되었음 G1 GC 4gb 이상 대용량 heap 메모리를 사용하는 멀티스레드 기반 응용 프로그램에 특화된 GC Heap을 영역 (1~32mb)단위로 분할한 후 멀티스레드 스캔 G1 GC jdk 9부터 서버용 응용 프로그램에 집중한 GC JVM 힙을 세대단위가 아닌 독립 영역으로 구분했음 힙의 모든 영역을 회수 집합 (Collection set)에 포함시켜 영역단위 처리 가장 쓰레기가 많은 영역을 파악 회수시 가장 득이 되는 영역 파악 객체 메모리 레이아웃과 해시코드 Object Header klass word : 메타스페이스에 있는 클래스 정보에 대한 참조자 Mark word Hashcode는 Object.hashCode() 함수가 호출되는 시점에 계산 자바는 메모리 접근을 못하니까 사용 같은 인스턴스인지 식별 등 age는 GC에서 살아남은 횟수 Lock flag는 객체를 중심으로 멀티스레드 환경에서 경쟁조건이 발생하는 문제를 해결하기 위해서 상태 설명 Unlocked 객체가 잠금되지 않은 상태 (Mark Word에 객체 해시 코드 저장) Lightweight Lock (Thin Lock) spinlock, 경량 락이 적용된 상태 (스레드가 Mark Word를 자신의 Lock Record로 변경) Inflated Lock (Fat Lock) 중간 이상의 경쟁이 발생해 OS의 모니터(lock)로 관리되는 상태 Biased Lock 편향 락이 활성화된 상태 (특정 스레드가 반복적으로 객체를 사용하는 경우) Heavyweight Lock 뮤텍스 동기화 Monitor Locked OS 기반 모니터 락을 사용하여 객체를 보호하는 상태 Instance Data Padding Object 클래스 java의 모든 클래스는 object의 파생형식 equals() 매개변수로 전달된 참조자와 this가 가리키는 대상이 같은 값인지 값만 비교 즉 동등성 비교 hashCode() 객체 식별을 위한 고유 해시결과 값(Unique) jvm의 힙영역에서 주소가 계속 달라지기때문에, 주소값이 아닌 hashCode로 인스턴스 식별 동일성 비교에 사용 toString() 클래스명@해시코드 getClass() JVM Concurrent JVM과 스레드 스레드의종류를 아래처럼 나눌수 있음 플랫폼 스레드 커널 스레드 가상 스레드 기본적으로 네이티브 언어는 굳이 고려할 필요가 없는데, jvm은 실제 플랫폼 스레드와 커널스레드관련해서 볼 것들이 있음 스택 메모리는 스레드마다 할당 예를들어 오버헤드를 볼때 tcb를 저장/복원하는 오버헤드와 java thread를 jvm관련 비용들도 같이 봐야함 객체 메모리 레이아웃과 해시코드 object header중 lock flag를 다시 볼 시간 lock flag는 누가 선정하는가? 경쟁 상황시 락을 획들 못하면 해당값이 변하고 다른 스레드들이 blocked됨 JVM 메인 메모리와 작업메모리(working memory) 작업메모리는 스레드가 사용하는 변수의 사본이 저장되며\n스레드 내부에 연산은 작업 메모리에만 반영\n스레드는 jvm 메인 메모리에 직접 접근 불가\n읽기 메인 메모리에서 변수의 값을 읽어 작업 메모리로 전송\n적재 메인 메모리가 전송한 값을 작업메모리에 저장\n저장 작업 메모리 변수의 값을 메인 메모리로 전송\n쓰기 작업메모리의 값을 메인메모리에 씀\n일반 변수의 동기화 시점\n명시적 (synchronized, volatile) Thread.start(), join() Lock, Atomic class 클래스 로딩 과정에서 정적 변수 초기화시 기타 jvm이 정한 최적화, 동기화 기준을 충족 시 volatile\n멑티스레드 환경에서 여러 스레드가 접근하는 변수에 대해 가시성을 제공 (메인 메모리 동기화) 가상 스레드 실제로 한 (커널)스레드에서 분리된 여러 단위코드로 실행하는 개념 스위칭 오버헤드를 줄이기 위함 마치 각각이 개별 스레드로 보이지만, 사실 하나의 스레드로 처리되도록 상호 의존성이 전혀 없는 코드여야함 동기화를 위한 OS수준 커널 객체 커널 객체를 이용함 (동기화 객체) event mutex semaphore 포인터 혹은 카운터로 사용되는 메모리로 생각할수있음 커널 객체는 생성할 수 있는 갯수가 제한적이며 spinlock에 비해 무거움 (위의것들) 동기화 메서드 임계영역 기반 동기화 기법으로 메서드 코드 전체를 임계영역으로 설정 여러 스레드에서 호출하더라도 동시 실행이 허용되지 않음 모니터락 동작 순서 스레드가 synchronized 메서드 호출시 모니터락을 요청 타 스레드가 모니터락을 이미 점유하고 있으면 스레드 상태를 blocked상태로 전환 기존 모니터 락 점유 스레드가 구간을 벗어나(임계영역을)면 모니터락을 해제하고 blocked상태로 대기중인 스레드중 하나가 락을 얻고 동기화 구간에 진입 ","permalink":"http://localhost:1313/_wiki/java-jvm/","summary":"JVM JVM 구성요소 유저모드 어플리케이션 프로세스, 가상 메모리 공간을 활용, 머신으로서 연산, os의 일부기능 jvm 구성요소 클래스 로더(Class Loader) 자바 클래스 파일(.class)을 로드하고 링크하는 역할 로딩, 링킹, 초기화 단계로 구성됨 부트스트랩 클래스 로더, 확장 클래스 로더, 애플리케이션 클래스 로더로 구성 클래스 로딩 링킹등이 런타임에 일어날 수 있다. 런타임 데이터 영역(Runtime Data Area) 메서드 영역(Method Area): 클래스 구조, 메서드 데이터, 상수, 정적 변수 등 저장 힙(Heap): 객체와 인스턴스 변수가 저장되는 공간 스택(Stack): 스레드마다 별도로 존재하며 지역 변수, 매개변수, 리턴 값 등 저장 PC 레지스터(Program Counter Register): 현재 실행 중인 명령어 주소 저장 네이티브 메서드 스택(Native Method Stack): 네이티브 코드를 위한 스택 실행 엔진(Execution Engine) 인터프리터(Interpreter): 바이트코드를 한 줄씩 해석하고 실행 JIT 컴파일러(Just-In-Time Compiler): 자주 사용되는 코드를 네이티브 코드로 컴파일하여 성능 향상 가비지 컬렉터(Garbage Collector): 더 이상 사용되지 않는 메모리 자동 정리 네이티브 메서드 인터페이스(JNI, Java Native Interface) 자바 코드가 네이티브 애플리케이션이나 C, C++ 등의 라이브러리와 상호작용할 수 있게 함 네이티브 메서드 라이브러리(Native Method Libraries) C, C++ 등으로 작성된 라이브러리 모음 클래스로더 .","title":"java, jvm"},{"content":" JVM 밑바닥부터 파해치기책을 정리한 내용이며, 모든 내용은 해당 도서 기반입니다.\n1부 자바와 친해지기 1장 자바 기술 시스템 소개 1.1 들어가며 하드웨어 플랫폼 족쇄 제거 안전한 메모리 관리 시스템 런타임 핫코드 감지, 컴파일 최적화하며 최상의 성능 도움 표준 api도 풍부하고 서드파티 라이브러리도 많다. 이번 장에는 자바 시스템의 구성요소, 역사, 자바의 현재와 미래를 다룬다.\n1.2 자바 기술 시스템 크게는 아래를 포괄한다 자바 프로그래밍 언어 가상 머신 구현 클래스 파일 포맷 클래스 라이브러리 api (표준 api) 오픈소스 클래스 라이브러리 언어, vm, 클래스 라이브러리를 묶어 jdk라고 한다, 또한 java se api, vm, 배포기술까지를 묶으면 jre라고한다. 1.3 자바의 과거 와 현재 방대한 역사속에 다양한 jvm구현체들과 소송들을 소개하고 미래를 향한 움직임도 소개한다. 재미있게 읽었고, 다시 알아야한다면 다시 보면 될 내용이라 정리하지는 않았다. 그중 기억나는 일부만 정리한다.\nHello World 실행에도 100mb가 넘는 jre 마이크로 서비스에 맞지 않는 언어 구동시간이 길고 최고성능을 내기까지 예열이 필요 (잦은 배포와, 고가용성 서비스에 불리) 서버리스 아키텍처에서 이런 모순이 두드러짐 2부 자동 메모리 관리 2장 자바 메모리 영역과 메모리 오버플로 2.2 런타임 데이터 영역 2.2.1 프로그램 카운터 프로그램 카운터 레지스터는 작은 메모리 영역으로 현재 실행중인 스레드의 \u0026lsquo;바이트 코드 줄 번호 표시기\u0026rsquo;라고 생각하면 쉽다. 바이트코드 인터피르터는 이 카운터 값을 바꿔 다음에 실행할 바이트코드 명령어를 선택하는식으로 동작 프로그램의 제어 흐름, 분기, 순환, 점프등을 표현 예외처리나 스레드복원같은 기능이 이 표시기를 활용해 동작 jvm의 멀티스레딩은 cpu코어를 여러 스레드가 교대로 사용하는 방식으로 구현되기 때문에, 특정 시각에 한 코어는 한 스레드의 명령어만 실행하게 된다. 따라서 스레드 전환 후 이전에 실행하다 멈춘 지점을 정확하게 복원하려면 스레드 각각에는 고유한 프로그램 카운터가 필요하다. 따라서 각 스레드의 카운터는 서로 영향을 주지 않는 독립된 영역에 저장된다. 이 메모리 영역을 프라이빗 메모리라고 한다. 스레드가 자바 메서드를 실행중일 때는 실행중인 바이트코드 명령어의 주소가 프로그램 카운터에 기록된다. 한 편 스레드가 네이티브 메서드를 실행중일 때 프로그램 카운터 값은 undefined다 프로그램 카운터 메모리 영역은 oom 조건이 명시되지 않은 유일한 영역이기도 하다. 2.2.2 자바 가상 머신 스택 마찬가지로 스레드 프라이빗하며, 스레드와 수명주기가 같다. 가상머신스택은 메서드를 실행하는 스레드의 메모리 모델을 설명해준다. 메서드 호출시 스택프레임만들고, 지역변수 테이블, 피연산자 스택, 동적 링크, 메서드 반환값등의 정보를 저장한다. 그다음 스택프레임을 가상머신 스택에 푸시하고, 메서드가 끝나면 팝하는일을 반복한다. 지역 변수 테이블에는 jvm이 컴파일타임에 알수있는 다양한 기본데이터타입, 객체 참조, 반환주소 타입을 저장한다. 이걸 저장하는 공간을 지역 변수 슬롯이라 하고 슬롯의 크기는 일반적으로 32비트이다. 지역 변수 테이블을 구성하는데 필요한 데이터 공간은 컴파일 과정에 할당된다. 자바 메서드는 스택프레임에서 지역변수용으로 할당받아야 할 공간의 크기가 이미 완벽하게 결정되어있다. 2.2.3 네이티브 메서드 스택 jvm 스택과 비슷! 네이티브 메서드를 사용할때 실행된다. (보통 다른 언어로 작성된 메서드, jni를 통해 호출됨, 즉 jvm이 직섭 실행할수없는 네이티브 코드를 실행하기 위한 메서드) 2.2.4 자바 힙 모든 스레드 공유 다른 언어의 힙과 동일 거의 모든(사실상 모든)객체가 힙에 저장됨. gc가 관리하는 메모리 영역이기에, gc힙이라고 함 객체 할당 효율을 높이고자 스레드 로컬 할당 버퍼 여러개로 나뉜다. (그래도 모든 객체가 힙에 저장된다는 사실은 마찬가지, 일부 메모리회수와 할당을 조금 더 빠르게 하기위해 일정한 세부영역이 있을 뿐) 힙은 물리적으로 떨어진 메모리에 위치해도 상관없으나 논리적으로는 연속되어야 한다. 2.2.5 메서드 영역 ","permalink":"http://localhost:1313/_wiki/jvm-%EB%B0%91%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%ED%8C%8C%ED%95%B4%EC%B9%98%EA%B8%B0/","summary":"JVM 밑바닥부터 파해치기책을 정리한 내용이며, 모든 내용은 해당 도서 기반입니다.\n1부 자바와 친해지기 1장 자바 기술 시스템 소개 1.1 들어가며 하드웨어 플랫폼 족쇄 제거 안전한 메모리 관리 시스템 런타임 핫코드 감지, 컴파일 최적화하며 최상의 성능 도움 표준 api도 풍부하고 서드파티 라이브러리도 많다. 이번 장에는 자바 시스템의 구성요소, 역사, 자바의 현재와 미래를 다룬다.\n1.2 자바 기술 시스템 크게는 아래를 포괄한다 자바 프로그래밍 언어 가상 머신 구현 클래스 파일 포맷 클래스 라이브러리 api (표준 api) 오픈소스 클래스 라이브러리 언어, vm, 클래스 라이브러리를 묶어 jdk라고 한다, 또한 java se api, vm, 배포기술까지를 묶으면 jre라고한다.","title":"JVM-밑바닥부터-파해치기"},{"content":"25 병행성에 관한 대화 여러사람이 동시에 복숭아를 집을 수 있도록 했을때는 빨랐어요, 반면에 제 방법은 한번에 한명씩 집기 때문에 정확하겠지만 꽤 느리겠군요.\n멀티 쓰레드 프로그램이라고 불리는 프로그램들이 있네, 각 쓰레드는 독립된 객체로서 프로그램 내에서 프로그램을 대신하여 일으 하지, 이 쓰레드들은 메모리에 접근하는데, 쓰레드 입장에서 보면 메모리는 아까 이야기했던 복숭아와 같은 거야\n동시성을 운영체제에서 다뤄야 할 몇 가지 이유가 있지. 운영체제는 락과 컨디션 변수와 같은 기본 동적으로 멀티쓰레드 프로그램을 지원해야 한다네. 둘째로 운영체제는 그 자체로 최초의 동시 프로그램이기 때문이야\n26 병행성: 개요 프로그램에서 한 순간에 하나의 명령어만을 실행하는 (단일 PC값) 고전적인 관점에서 벗어나 멀티 쓰레드 프로그램은 하나 이상의 실행 지점을 가지고 있다(독립적으로 불러 들여지고 실행될 수 있는 여러개의 PC값). 멀티 쓰레드를 이해하는 다른 방법은 각 쓰레드가 프로세스와 매우 유사하지만, 차이가 있다면 쓰레드들은 주소공간을 공유하기 때문에 동일한 값에 접근할 수있다는 것이다. 하나의 스레드의 상태는 프로세스의 상태와 매우 유사하다. 스레드는 어디서 명령어를 불러들일지 추적하는 프로그램 카운터와 연산을 위한 레지스터들을 가지고 있다. 만약 두개의 스레드가 하나의 프로세서에서 실행중이라면 실행하고자 하는 스레드는 반드시 context switch을 통해서 실행중이 스레드와 교체되어야 한다. 스레드의 문맥교환은 t1이 사용하던 레지스터들을 저장하고 t2가 사용하던 레지스터의 내용으로 복원한다는 점에서 프로세스의 문맥 교환과 유사하다. 프로세스가 문맥 교환을 핼 때에 프로세스의 상태를 프로세스 제어 블럭에 저장하듯이 스레드는 스레드 제어 블럭이 필요하다. 가장 큰 차이중 하나는 프로세스의 경우오 달리 스레드간의 문맥 교환에서는 주소공간을 그대로 사용한다는 것이다. 스레드와 프로세스의 또 다는 차이는 스택에 있다. 고전적 프로세스 주소공간과 같은 간단한 모델에서는 스택이 하나만 존재한다.(주로 주소 공간의 하부에) 반면에 멀티스레드 프로세스의 경우에는 각 스레드가 독립적으로 실행되며 주소공간에는 하나의 스택이 아니라 스레드마다 스택이 할당되어 있다. 26.1 왜 스레드를 사용하는가? 우리는 멀티스레드를 사용하면서 발생하는 문제를 배울것이기 때문에 그 전에 왜 사용하는지의 효용에 대해서 알아볼것이다. 주요하게는 두가지 이유가 있다. 병렬처리 (parallelism) : 예를 들어 두개의 큰 배열을 더하거나, 배열의 각 원소 값을 증가시키는 것과 같이 매우 큰 배열을 대상으로 연산을 수행하는 프로그램을 작성하고 있따고 가정해보자. 단일프로세스는 간단하다 - 각 작업을 하나씩 수행 후 완료 그러나 멀티프로세스시스템에서는 각 프로세서가 작업의 일부분을 수행하게 함으로써 실행속도를 높일수 있다. 표준 단일 스레드 프로그램을 멀티프로세서상에서 같은 작업을 하는 프로그램으로 변환하는 작업을 병려화라고 한다. 두번째는 약간 미묘한데, 느린 I/O로 인해 프로그램 실행이 멈추지 않도록 하기 위해서 스레드를 이용한다. 프로그램중 하나의 스레드가 대기하는동안 스케줄러는 다른 스레드로 전환할 수 있고 이 스레드는 준비 상태이며 유용한 작업을 수행한다. 26.2 예제: 스레드 생성 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026#34;common.h\u0026#34; #include \u0026#34;common_threads.h\u0026#34; void *mythread(void *arg) { printf(\u0026#34;%s\\n\u0026#34;, (char *) arg); return NULL; } int main(int argc, char *argv[]) { pthread_t p1, p2; int rc; printf(\u0026#34;main: begin\\n\u0026#34;); Pthread_create(\u0026amp;p1, NULL, mythread, \u0026#34;A\u0026#34;); Pthread_create(\u0026amp;p2, NULL, mythread, \u0026#34;B\u0026#34;); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(\u0026#34;main: end\\n\u0026#34;); return 0; } 함수 호출처럼 스레드를 생성하기도 한다. 함수호출에서는 함수실행후에 호출자에게 리턴하는 반면에 스레드의 생성에서는 실행할 명령어들을 갖고있는 새로운 스레드가 생성되고 생성된 스레드는 호출자와는 별개로 실행된다. 스레드 생성함수가 리턴되기 전에 스레드가 실행 될 수 도 있고, 그보다 이후에 실행 될 수 있다. 다음에 실행될 스레드는 스케줄러에 의해 결정된다. 이 예제에서 알 수 있듯 스레드는 일을 복잡하게 만든다. 26.3 훨씬 더 어려운 이유: 데이터 공유 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026#34;common.h\u0026#34; #include \u0026#34;common_threads.h\u0026#34; static volatile int counter = 0; // mythread() // Simply adds 1 to counter repeatedly, in a loop // No, this is not how you would add 10,000,000 to // a counter, but it shows the problem nicely. void *mythread(void *arg) { printf(\u0026#34;%s: begin\\n\u0026#34;, (char *) arg); int i; for (i = 0; i \u0026lt; 1e7; i++) { counter = counter + 1; } printf(\u0026#34;%s: done\\n\u0026#34;, (char *) arg); return NULL; } // main() // Just launches two threads (pthread_create) // and then waits for them (pthread_join) int main(int argc, char *argv[]) { pthread_t p1, p2; printf(\u0026#34;main: begin (counter = %d)\\n\u0026#34;, counter); Pthread_create(\u0026amp;p1, NULL, mythread, \u0026#34;A\u0026#34;); Pthread_create(\u0026amp;p2, NULL, mythread, \u0026#34;B\u0026#34;); // join waits for the threads to finish Pthread_join(p1, NULL); Pthread_join(p2, NULL); printf(\u0026#34;main: done with both (counter = %d)\\n\u0026#34;, counter); return 0; } 이 프로그램은 단일 프로세서더라도 기대한대로 결과가 출력되지 않는다. 26.4 문제의 핵심: 제어 없는 스케줄링 요약하면 t1이 값을 읽고, 저장하기 직전에 인터럽트, t2로 전환, 51로 정상 수행, 인터럽트, t1이 작업을 이어서하다보니 51을 다시 반영.. 이러한 상황 즉 명령어의 실행 순서에 따라 결과가 달라지는 상황을 경쟁조건이라고 한다. (race condition, data race) 이러한 경우 비결정적인 결과가 발생한다 (indeterminate) 그리고 멀티스레드와 같은 코드를 실행할때 경쟁조건이 발생하기 때문에 이러한 코드 부분을 임계 영역(critical section)이라고 한다. 공유 변수/자원을 접근하고 하나 이상의 스레드에서 동시에 실행되면 안되는 코드 이러한 코드에서 필요한것은 상호 배제이다. 이 속성은 하나의 스레드가 임계 영역 내의 코드를 실행중일 때는 다른스레드가 실행할 수 없도록 보장해준다. 그리고 원자성이라는 것은 전부 아니면 전무 즉 모두 실행되거나, 중간 상태가 없도록 모두 실행되지 않아야 한다는 의미이다. (atomic) 26.5 원자성에 대한 바람 임계 영역 문제에 대한 해결 방법중 하나로 강력한 명령어 한 개로 의도한 동작을 수행하여, 인터럽트 발생 가능성을 원천적으로 차단하는 것이다. mov 0x8049alc, % e a x add $0x1, \u0026amp;eax mov seax, 0x8049alc 위의 일련의 명령어를 이러한 memory-add 0x8049alc, $0x1 하나의 문장으로 구분해서 원자성을 띄게 한다면 가능하기는 하다. 하지만 현실적으로 어려운 부분이 많다. 예를들어 병행성을 가지는 B-tree를 만드는 중이라고 했을 때, 원자적으로 B-tree를 갱신하는 어셈블리어를 원해야 할까? 그러면 어셈블리어는 전혀 일반적이지 않게 된다. 따라서 우리가 해야 할 일은 하드웨어에 동기화 함수 (synchronization primitives)구현에 필요한 몇가지 유용한 명령어를 원하면 된다. 이 하드웨어 지원을 사용하고 운영체제의 도움을 받아 한 번에 하나의 스레드만 임계영역에서 실행하도록 구성된 멀티스레드 프로그램을 만들 수 있다. 26.6 또 다른 문제: 상대 기다리기 더 복잡해지는 것중에 하나는 스레드간의 순서도 생길수 있다. 예를들어 하나의스레드가 다른 스레드가 어떤 동작을 끝낼 때 까지 대기해야 하는 상황도 빈번하게 발생한다. 프로세스가 디스크 i/o를 요청하고 응답이 올 때 까지 잠든 경우가 좋은 예이다. 참고로 이 장은 멀티스레드의 문제에 대한 정의와 용어정리가 정부인데, 용어정리를 원문과 함께 다시하면 좋을 것 같아서 아래의 인용문을 가져왔다, 거의 모든 용어는 다익스트라가 정의했다고 한다.\nThese four terms are so central to concurrent code that we thought it worth while to call them out explicitly. See some of Dijkstra’s early work [D65,D68] for more details. • A critical section is a piece of code that accesses a shared resource, usually a variable or data structure. • A race condition (or data race [NM92]) arises if multiple threads of execution enter the critical section at roughly the same time; both attempt to update the shared data structure, leading to a surprising (and perhaps undesirable) outcome. • An indeterminate program consists of one or more race conditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. • To avoid these problems, threads should use some kind of mutual exclusion primitives; doing so guarantees that only a single thread ever enters a critical section, thus avoiding races, and resulting in deterministic program outputs 27 막간: 스레드 api 핵심 질문 : 스레드를 생성하고 제어하는 방법 운영체제가 스레드를 생성하고 제어하는 데 어떤 인터페이스를 제공해야 할까? 어떻게 이 인터페이스를 설계해야 쉽고 유용하게 사용할 수 있을까?\n27.1 스레드 생성 #include \u0026lt;pthread.h\u0026gt; int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine)(void *), void *arg); thread : pthread_t 타입 구조체의 포인터. 이 구조가 스레드와 상호작용하는데 쓰이기때문에 초기화시 전달. attr : 스레드의 속성 지정, 스택 크기와 스레드의 스케줄링 우선순위와 같은 정보들 *(*start_routine)(void *) : 이 스레드가 실행할 함수, 예시에서는 void 함수를 전달 *arg : 실행할 함수에게 전달한 인자. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t *) arg; printf(\u0026#34;%d %d\\n\u0026#34;, args-\u0026gt;a, args-\u0026gt;b); return NULL; } int main(int argc, char *argv[]) { pthread_t p; myarg_t args = {10, 20}; int rc = pthread_create(\u0026amp;p, NULL, mythread, \u0026amp;args); if (rc != 0) { fprintf(stderr, \u0026#34;Error creating thread\\n\u0026#34;); return 1; } ... } 27.2 스레드 종료 int pthread_join (pthread_t thread, void **value_ptr); thread : 기다릴 스레드 **value_ptr : 반환값의 포인터 typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-\u0026gt;x = 1; rvals-\u0026gt;y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026amp;p, NULL, mythread, \u0026amp;args); Pthread_join(p, (void **) \u0026amp;rvals); printf(\u0026#34;returned %d %d\\n\u0026#34;, rvals-\u0026gt;x, rvals-\u0026gt;y); free(rvals); return 0; } 특히 주의해야할것은 스레드의 반환값에 스레드 콜스택의 포인터를 절대 반환하지 말라는 것이다. 사실 위의 예시들은 그냥 프로시저 호출을 쓰는게 낫다. 굳이 저렇게 할 이유가 없다\n보통 웹서버는 그냥 join을 거의 안쓰고 메인스레드를 이용해서 사용자 요청을 받아 작업자에게 전달하는 작업을 무한히 할 것 또는 실제 병렬적으로 처리하는경우는 이렇게 하나두개의 일만 하지 않기 때문에 그냥 예시코드라 하는것 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; void *mythread(void *arg) { int id = *(int *)arg; printf(\u0026#34;Thread %d is running\\n\u0026#34;, id); return NULL; } int main() { pthread_t threads[3]; int ids[3] = {1, 2, 3}; // 여러 개의 쓰레드 생성 for (int i = 0; i \u0026lt; 3; i++) { pthread_create(\u0026amp;threads[i], NULL, mythread, \u0026amp;ids[i]); } // 모든 쓰레드가 종료될 때까지 기다림 for (int i = 0; i \u0026lt; 3; i++) { pthread_join(threads[i], NULL); } printf(\u0026#34;All threads finished\\n\u0026#34;); return 0; } 27.3 락 POSIX 스레드 라이브러리에서는 아래처럼 제공된다. int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 뭔가 아래처럼 생긴 코드를 생각하겠지만 일부 틀린점이 있다. 다만 기본적으로 pthread_mutex_lock()이 호출되었을때 다른 어떤 스레드도 락을 가지고 있지 않다면 이 스레드가 락을 얻어 임계 영역에 진입한다. 락 획득을 시도하는 스레드는 락을 얻을 때까지 호출에서 리턴하지 않는다. 락을 획득한 스레드만 언락을 호출해야한다. pthread_mutex_t lock; pthread_mutex_lock(\u0026amp;lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026amp;lock); 이코드가 동작하지않는 이유는 두가지이지다. 첫번째로는 초기화를 하지 않았다. 두번째 문제는 락과 언락을 호출 할 때 에러코드를 확인하지 않았다는 것이다. 만약 조용히 실패하는경우 여러스레드가 임계영역에 동시 진입이 가능하다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; pthread_mutex_t lock; int x = 0; // 공유 자원 (임계 영역 보호 필요) void *mythread(void *arg) { if (pthread_mutex_lock(\u0026amp;lock) != 0) { // 락 획득 실패 시 오류 처리 perror(\u0026#34;pthread_mutex_lock failed\u0026#34;); return NULL; } // 임계 영역 (Critical Section) x = x + 1; printf(\u0026#34;Thread %ld: x = %d\\n\u0026#34;, pthread_self(), x); if (pthread_mutex_unlock(\u0026amp;lock) != 0) { // 언락 실패 시 오류 처리 perror(\u0026#34;pthread_mutex_unlock failed\u0026#34;); return NULL; } return NULL; } int main() { pthread_t t1, t2; // 뮤텍스 초기화 (반환값 체크) if (pthread_mutex_init(\u0026amp;lock, NULL) != 0) { perror(\u0026#34;pthread_mutex_init failed\u0026#34;); return 1; } // 두 개의 스레드 생성 pthread_create(\u0026amp;t1, NULL, mythread, NULL); pthread_create(\u0026amp;t2, NULL, mythread, NULL); // 스레드 종료 대기 pthread_join(t1, NULL); pthread_join(t2, NULL); // 뮤텍스 제거 pthread_mutex_destroy(\u0026amp;lock); return 0; } 아예 코드를 아래처럼 깔끔하게 유지하도록! // Keeps code clean; only use if exit() OK upon failure void Pthread_mutex_lock(pthread_mutex_t *mutex) { int rc = pthread_mutex_lock(mutex); assert(rc == 0); } 아래 두 루틴도 있지만 사용하지 않는 편이 낫다. int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_timedlock(pthread_mutex_t *mutex, struct timespec *abs_timeout); 27.4 컨디션 변수 int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); int pthread_cond_signal(pthread_cond_t *cond); 한 스레드가 계속 진행하기 전에 다른 스레드가 무엇인가를 해야 하는 경우 pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t cond = PTHREAD_COND_INITIALIZER; Pthread_mutex_lock(\u0026amp;lock); while (ready == 0) Pthread_cond_wait(\u0026amp;cond, \u0026amp;lock); Pthread_mutex_unlock(\u0026amp;lock); 28 락 28.1 기본 개념 프로그래머들은 소스코드의 임계영역을 락으로 둘러서 그 임계영역이 마치 하나의 원자 단위 명령어인것처럼 실행되도록 한다. lock_t mutex; // some globally-allocated lock \u0026#39;mutex\u0026#39; lock(\u0026amp;mutex); balance = balance + 1; unlock(\u0026amp;mutex); 락은 일종의 변수이며, 락변수는 둘중 하나의 상태를 갖는다 사용가능 (available, unlocked, free) 사용중 (acquired) 그리고 임계 영역에서는 정확히 하나의 스레드가 락을 획득한 상태이다 락 소유자의 unlcok()으로 락은 사용 가능으로 되돌아간다. 락은 프로그래머에게 스케줄링에 대한 최소한의 제어권을 제공한다. 프로그래머가 스레드를 생성하고 운영체제가 제어한다. 락은 스레드에 대한 제어권을 일부 이양 받을 수 있게 해준다. 28.2 Pthread 락 스레드간의 상호 배제 (mutual exclusion)을 제공하기 때문에 posix 라이브러리는 락을 mutex라고 부른다. 28.3 락의 구현 락의 동작 방식은 이해하기가 쉬워 대략적으로 이해했을 것이다 그렇다면 어떻게 락을 만들어야 하는가? 핵심질문 : 락은 어떻게 만들까? 효율적인 락은 어떻게 만들어야할까? 효율적인 락은 낮은 비용으로 상호 배제 기법을 제공하고, 다음에 다룰 몇가지 속성들을 추가로 가져야 한다. 어떤 하드웨어 지원 혹은 운영체제 지원이 필요할까?\n28.4 락의 평가 다음과 같은 것들이 락의 평가요인이다. 상호 배제 (mutual exclusion)을 제대로 지원하는가? 공정성 (fairness)는 스레드들이 락획득에 대한 공정한 기회가 주어지는가? 반대로 starve상태가 일어나지는 않는가? 성능 (performance)는 락 사용 시간적 오버헤드를 평가해야한다. 이건 여러스레드, 혹은 멀티 cpu간에서도 평가를 각각 해야한다. 28.5 인터럽트 제어 초창기 단일 프로세스 시스템에서는 상호 배제 지원을 위해 임계영역 내에서는 인터럽트를 비활성하는 방식을 사용했다. void lock() { DisableInterrupts(); } void unlock() { EnableInterrupts(); } 단순하다, 그리고 이해하기 쉽다. 노력하지 않아도 잘 동작할것을 짐작할 수 있다. 임계영역내의 동작이 진행되는 동안 인터럽트를 무시할 수 있다면, 임계영역내의 동작이 원자적으로 시행될것을 보장할 수 있다. 단점이 많다. 첫 번째는, 이 요청을 하는 스레드가 인터럽트를 활성/비활성하는 priviledged 연산을 실행 할 수 있도록 허가해야 한다. 그리고 이 priviledged 권한을 통해 다른 것을 하지 않는다는것을 신뢰 할 수 있어야 한다. 예를들어 lock을 얻고 무한루프 혹은 나쁜짓을 해도 lde에서는 제어권을 다시 가져올 수 없다. 두 번째는, 멀티프로세서에서는 적용을 할 수 없다는 것이다. 여러 스레드가 여러 cpu에서 실행중이라면 각 스레드가 동일한 임계 영역을 진입하려고 시도할 수 있다. 특정 프로세서에서의 인터럽트 비활성화는 다른 프로세스에서 실행중인 프로그램에는 영향이 없다. 세 번째는, 장시간동안 인터럽트를 중시지시키는 것은 중요한 인터럽트의 시점을 놓칠 수 있다는 것이다. 예를 들어 cpu가 저장 장치에서 읽기 요청을 마친 사실을 모르고 지나갔다고 해보자. 운영체제가 읽기 결과를 기다리는 프로세스를 어떻게 깨울까? 마지막은, 이 방법은 비효율적이라는 것이다. (최신 cpu에서는 매우 느리게 동작한다.) 28.6 실패한 시도: 오직 load/store 명령어만 사용하기 typedef struct __lock_t { int flag; } lock_t; void init(lock_t *mutex) { // 0 -\u0026gt; lock is available, 1 -\u0026gt; held mutex-\u0026gt;flag = 0; } void lock(lock_t *mutex) { while (mutex-\u0026gt;flag == 1) // 만약 사용중이면 기다린다. ; // spin-wait (do nothing) mutex-\u0026gt;flag = 1; // now SET it! } void unlock(lock_t *mutex) { mutex-\u0026gt;flag = 0; } 위의 코드는 두가지 문제가 있다. 먼저 제대로 동작하는지 여부이다. 두개의 스레드가 flag 0을 보고 같이 진입하는게 가능하다 두번째는 성능이다. 락을 기다리는동안 spin-wait을 하는게 락을 해제할 때 까지 시간을 낭비한다. 단일프로세서에서는 특히 매우 손해가 크다. 락을 소유한 스레드조차도 실행할 수 없기 때문이다. 이건 lock을 호출한 스레드가 기다리기때문에, 소유한 스레드도 컨텍스트 스위치 전까지는 뭘 할 수 가 읎음 28.7 Test-And-Set을 사용하여 작동하는 스핀 락 구현하기 원자적 교체라고도 알려진 명령어이다. int TestAndSet(int *old_ptr, int new) { int old = *old_ptr; // fetch old value at old_ptr *old_ptr = new; // store \u0026#39;new\u0026#39; into old_ptr return old; // return the old value } 위 코드와 동일한 동작을 하는 하드웨어 명령어를 지원받는것 (실제 c코드가 아닌) typedef struct __lock_t { int flag; } lock_t; void init(lock_t *lock) { // 0: lock is available, 1: lock is held lock-\u0026gt;flag = 0; } void lock(lock_t *lock) { while (TestAndSet(\u0026amp;lock-\u0026gt;flag, 1) == 1) ; // spin-wait (do nothing) } void unlock(lock_t *lock) { lock-\u0026gt;flag = 0; } 첫번째로 처음 스레드가 lock()을 호출하고 다른 어떤 스레드도 락을 보유하지 않는다면 현재의 flag =0이라면, 이 스레드가 TestAndSet(flag, 1)을 호출하면 이 루틴은 flag의 이전 값인 0을 반환한다. flag값을 검사한 스레드는 while문에서 회전하지 않고 락을 획득한다. 두 번째는 처음 스레드가 락을 획득하여 flag값이 1인상태이다. 두번째 스레드가 lock을 호출하면 첫 스레드가 반환할때까지 while문을 반복한다. 주의할점은 선점형 스케줄러를 사용해야 한다는 것이다.(preemptive scheduler) 그렇지 않으면 spin while loop가 영원히 독점할수 있기 때문이다.\n28.8 스핀 락 평가 단일 cpu의 경우는 오버헤드가 상당히 크다. 임계영역내에서 락을 갖고있던 스레드가 선점된 경우, N-1개의 다른 스레드가 있다고 가정 할 때 스케줄러가 락을 획득하려는 다르 스레드를 깨우고 대기하면서 시간을 낭비 할 수 있다. 반면에 cpu가 여러개인 경우 스핀락은 꽤 합리적으로 동작한다. 물론 대기는 있지만, 락을 점유한 cpu의 작업이 끊기지 않을 것 이기 때문에 금방금방 락이 넘어갈것이다. 28.9 Compare-And-Swap int CompareAndSwap(int *ptr, int expected, int new) { int original = *ptr; if (original == expected) *ptr = new; return original; } ptr이 가리키고 있는 주소의 값이 expected와 일치하는지 검사하는것이다. 일치한다면 주소의 값을 새로운 값으로 변경한다. 만약 불일치한다면 아무것도 하지 않는다. 원래의 메모리 값을 반환하여 호출한 코드의 락 획득 여부를 알 수 있도록한다. 28.11 Fetch-And-Add int FetchAndAdd(int *ptr) { int old = *ptr; *ptr = old + 1; return old; } typedef struct __lock_t { int ticket; int turn; } lock_t; void lock_init(lock_t *lock) { lock-\u0026gt;ticket = 0; lock-\u0026gt;turn = 0; } void lock(lock_t *lock) { int myturn = FetchAndAdd(\u0026amp;lock-\u0026gt;ticket); while (lock-\u0026gt;turn != myturn) ; // spin } void unlock(lock_t *lock) { lock-\u0026gt;turn = lock-\u0026gt;turn + 1; } 스케줄링이 가능하도록 한 방법 28.12 요약: 과도한 스핀 핵심질문: 회전은 낭비이다. 회전을 피하는 방법이 무엇이 있을까?\n28.13 간단한 접근법: 조건 없는 양보! void init() { flag = 0; } void lock() { while (TestAndSet(\u0026amp;flag, 1) == 1) yield(); // give up the CPU } void unlock() { flag = 0; } 간단하고 좋은 접근방식이지만, 컨텍스트 스위치 비용도 상당하다. 28.14 큐의 사용: 스핀 대신 잠자기 위의 접근법들은 지나치게 운에 의존하고 있다. 이번에는 큐를 사용할것이다. typedef struct __lock_t { int flag; int guard; queue_t *q; } lock_t; void lock_init(lock_t *m) { m-\u0026gt;flag = 0; m-\u0026gt;guard = 0; queue_init(m-\u0026gt;q); } void lock(lock_t *m) { while (TestAndSet(\u0026amp;m-\u0026gt;guard, 1) == 1) ; // acquire guard lock by spinning if (m-\u0026gt;flag == 0) { m-\u0026gt;flag = 1; // lock is acquired m-\u0026gt;guard = 0; } else { queue_add(m-\u0026gt;q, gettid()); m-\u0026gt;guard = 0; park(); } } void unlock(lock_t *m) { while (TestAndSet(\u0026amp;m-\u0026gt;guard, 1) == 1) ; // acquire guard lock by spinning if (queue_empty(m-\u0026gt;q)) m-\u0026gt;flag = 0; // let go of lock; no one wants it else unpark(queue_remove(m-\u0026gt;q)); // hold lock (for next thread!) m-\u0026gt;guard = 0; } park(),unpark(thread)는 각각 호출한 스레드 혹은, 아규먼트로 넘긴 스레드를 재우고 깨우는 함수이다. 경쟁발생 획득한애들 빼고 다 큐에넣고, 그동안 락 획득여부를 누군가 획득했다고 설정해놓고, 큐가 비워지고 언락해야하는 누군가가 그재서야 flag를 0으로 되돌린다 문제는 여기도 경쟁조건이 있다는건데 (park()를 호출하기 직전 vs 점유중인 락을 해제하는경우) 이러면 락은 해제됐고 점유한 스레드가없어서 깨워줄 방법이 없다. Solaris는 이 문제를 setPark()를 통해서 해결했는데 이 루틴은 스레드가 현재 park()호출 직전이라는것으 표시한다. 만약 그때 인터럽트가 실행되어 park()가 호출되기 전에 다른 스레드가 unpark()를 먼저 호출한다면 블럭되는대신 바로 리턴된다. } else { queue_add(m-\u0026gt;q, gettid()); setpark(); // 요기 m-\u0026gt;guard = 0; park(); } 29 락 기반의 병행 자료 구조 범용 자료 구조에서 락을 사용하는 방법을 살펴본다. 자료 구조에 락을 추가하면 해당 자료 구조를 경쟁조건으로부터 thread safe한 자료구조로 만들 수 있다.\n핵심 질문: 지료구조에 락을 추가하는 방법 특정 자료구조가 주어졌을 때, 어떤 방식으로 락을 추가해야 그 자료구조가 정확하게 동작하게 만들 수 있을까?\n29.1 Concurrent Counters 카운터는 가장 간단한 자료구조이고, 보편적이며, 인터페이스가 간단하다. 간단하지만, 확장성이 없다. typedef struct __counter_t { int value; } counter_t; void init(counter_t *c) { c-\u0026gt;value = 0; } void increment(counter_t *c) { c-\u0026gt;value++; } void decrement(counter_t *c) { c-\u0026gt;value--; } int get(counter_t *c) { return c-\u0026gt;value; } 일단 이렇게 구현하면 thread safa하게 만들수 있다. typedef struct __counter_t { int value; pthread_mutex_t lock; } counter_t; void init(counter_t *c) { c-\u0026gt;value = 0; pthread_mutex_init(\u0026amp;c-\u0026gt;lock, NULL); } void increment(counter_t *c) { pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value++; pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } void decrement(counter_t *c) { pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); c-\u0026gt;value--; pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); } int get(counter_t *c) { pthread_mutex_lock(\u0026amp;c-\u0026gt;lock); int rc = c-\u0026gt;value; pthread_mutex_unlock(\u0026amp;c-\u0026gt;lock); return rc; } 이상태에서는 간단하고 정확하게 동작하지만, 성능이 문제다. 저자의 테스트에서 카운트 100만번 계산하는데 싱글스레드는 0.03초 두개의 스레드는 5초 이상이 걸렸다고 한다. (\u0026hellip;) 완벽한 확장성이라는 것이랑 거리가 멀다 완벽한 확정성을 달성했다면 스레드의 갯수만큼 반비례로 시간이 줄어들었어야한다. 혹은 200만번을 진행했을때, 동일하게 0.03초가 걸리거나 확장성 있는 카운팅\n그래서 근사 카운터 (approximate counter)라고 불리는 기법을 사용한다고한다. 기본 개념은 스레드 로컬한 지역 카운터를 가지고 경쟁없이 증가시키고, 이건 지역락에 의해서만 보호한다. 그 다음 전역카운터값을 지역카운터값으로 갱신하고 그시점에 지역카운터 값은 0으로 초기화한다. 지역에서 전역으로 값을 전달하는 빈도는 S값에 의해서 설정된다. S값이 작을수록 (갱신빈도는 커질수록) 카운터의 확장성이 없어지며, S값이 클수록 (갱신빈조는 작아질수록) 전역카운터값이 실제 카운터 값과 일치하지 않을 확률이 커진다. typedef struct __counter_t { int global; // global count pthread_mutex_t glock; // global lock int local[NUMCPUS]; // per-CPU count pthread_mutex_t llock[NUMCPUS]; // ... and locks int threshold; // update frequency } counter_t; // init: record threshold, init locks, init values // of all local counts and global count void init(counter_t *c, int threshold) { c-\u0026gt;threshold = threshold; c-\u0026gt;global = 0; pthread_mutex_init(\u0026amp;c-\u0026gt;glock, NULL); for (int i = 0; i \u0026lt; NUMCPUS; i++) { c-\u0026gt;local[i] = 0; pthread_mutex_init(\u0026amp;c-\u0026gt;llock[i], NULL); } } // update: usually, just grab local lock and update // local amount; once local count has risen ’threshold’, // grab global lock and transfer local values to it void update(counter_t *c, int threadID, int amt) { int cpu = threadID % NUMCPUS; pthread_mutex_lock(\u0026amp;c-\u0026gt;llock[cpu]); c-\u0026gt;local[cpu] += amt; if (c-\u0026gt;local[cpu] \u0026gt;= c-\u0026gt;threshold) { // transfer to global (assumes amt\u0026gt;0) pthread_mutex_lock(\u0026amp;c-\u0026gt;glock); c-\u0026gt;global += c-\u0026gt;local[cpu]; pthread_mutex_unlock(\u0026amp;c-\u0026gt;glock); c-\u0026gt;local[cpu] = 0; } pthread_mutex_unlock(\u0026amp;c-\u0026gt;llock[cpu]); } // get: just return global amount (approximate) int get(counter_t *c) { pthread_mutex_lock(\u0026amp;c-\u0026gt;glock); int val = c-\u0026gt;global; pthread_mutex_unlock(\u0026amp;c-\u0026gt;glock); return val; // only approximate! } 29.2 Concurrent Linked List // basic node structure typedef struct __node_t { int key; struct __node_t *next; } node_t; // basic list structure (one used per list) typedef struct __list_t { node_t *head; pthread_mutex_t lock; } list_t; void List_Init(list_t *L) { L-\u0026gt;head = NULL; pthread_mutex_init(\u0026amp;L-\u0026gt;lock, NULL); } int List_Insert(list_t *L, int key) { pthread_mutex_lock(\u0026amp;L-\u0026gt;lock); node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(\u0026#34;malloc\u0026#34;); pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); return -1; // fail } new-\u0026gt;key = key; new-\u0026gt;next = L-\u0026gt;head; L-\u0026gt;head = new; pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); return 0; // success } int List_Lookup(list_t *L, int key) { pthread_mutex_lock(\u0026amp;L-\u0026gt;lock); node_t *curr = L-\u0026gt;head; while (curr) { if (curr-\u0026gt;key == key) { pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); return 0; // success } curr = curr-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); return -1; // failure } 마찬가지로 확장성이 좋지 않다는 문제가 있다. 이건 정말 필요한 부분만 락을 거는 방식으로 해결한다. void List_Init(list_t *L) { L-\u0026gt;head = NULL; pthread_mutex_init(\u0026amp;L-\u0026gt;lock, NULL); } void List_Insert(list_t *L, int key) { // synchronization not needed before allocation node_t *new = malloc(sizeof(node_t)); if (new == NULL) { perror(\u0026#34;malloc\u0026#34;); return; } new-\u0026gt;key = key; // just lock critical section pthread_mutex_lock(\u0026amp;L-\u0026gt;lock); new-\u0026gt;next = L-\u0026gt;head; L-\u0026gt;head = new; pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); } int List_Lookup(list_t *L, int key) { int rv = -1; pthread_mutex_lock(\u0026amp;L-\u0026gt;lock); node_t *curr = L-\u0026gt;head; while (curr) { if (curr-\u0026gt;key == key) { rv = 0; break; } curr = curr-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;L-\u0026gt;lock); return rv; // now both success and failure } 29.3 Concurrent Queue 꼭 필요한 부분에만 락을 걸어서 부하를 줄인 좋은 최적화 예제 typedef struct __node_t { int value; struct __node_t *next; } node_t; typedef struct __queue_t { node_t *head; node_t *tail; pthread_mutex_t head_lock, tail_lock; } queue_t; void Queue_Init(queue_t *q) { node_t *tmp = malloc(sizeof(node_t)); tmp-\u0026gt;next = NULL; q-\u0026gt;head = q-\u0026gt;tail = tmp; pthread_mutex_init(\u0026amp;q-\u0026gt;head_lock, NULL); pthread_mutex_init(\u0026amp;q-\u0026gt;tail_lock, NULL); } void Queue_Enqueue(queue_t *q, int value) { node_t *tmp = malloc(sizeof(node_t)); assert(tmp != NULL); tmp-\u0026gt;value = value; tmp-\u0026gt;next = NULL; pthread_mutex_lock(\u0026amp;q-\u0026gt;tail_lock); q-\u0026gt;tail-\u0026gt;next = tmp; q-\u0026gt;tail = tmp; pthread_mutex_unlock(\u0026amp;q-\u0026gt;tail_lock); } int Queue_Dequeue(queue_t *q, int *value) { pthread_mutex_lock(\u0026amp;q-\u0026gt;head_lock); node_t *tmp = q-\u0026gt;head; node_t *new_head = tmp-\u0026gt;next; if (new_head == NULL) { pthread_mutex_unlock(\u0026amp;q-\u0026gt;head_lock); return -1; // queue was empty } *value = new_head-\u0026gt;value; q-\u0026gt;head = new_head; pthread_mutex_unlock(\u0026amp;q-\u0026gt;head_lock); free(tmp); return 0; } 30 Condition Variables 락 이외에도 병행 프로그램을 제작할 수 있는 다른 기법들이 존재한다. 스레드가 실행을 계속하기 전에 특정 조건의 만족여부를 검사해야하는 경우가 많이 있다. void *child(void *arg) { printf(\u0026#34;child\\n\u0026#34;); // XXX how to indicate we are done? return NULL; } int main(int argc, char *argv[]) { printf(\u0026#34;parent: begin\\n\u0026#34;); pthread_t c; pthread_create(\u0026amp;c, NULL, child, NULL); // create child // XXX how to wait for child? printf(\u0026#34;parent: end\\n\u0026#34;); return 0; } 우리가 원하는것 parent: begin child parent: end 공유 변수를 쓸 수 있기도 하지만, 그러면 부모가 회전을 해야하기때문에 효율적이지 않다. 30.1 컨디션 변수의 개념과 관련 루틴 컨디션 변수는 일존의 큐 자료 구조이다. 어떤 상태가 원하는 것과 다를때 조건이 만족되기를 대기하는 큐이다. int done = 0; pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER; pthread_cond_t c = PTHREAD_COND_INITIALIZER; void thr_exit() { Pthread_mutex_lock(\u0026amp;m); done = 1; Pthread_cond_signal(\u0026amp;c); Pthread_mutex_unlock(\u0026amp;m); } void *child(void *arg) { printf(\u0026#34;child\\n\u0026#34;); thr_exit(); return NULL; } void thr_join() { Pthread_mutex_lock(\u0026amp;m); while (done == 0) Pthread_cond_wait(\u0026amp;c, \u0026amp;m); Pthread_mutex_unlock(\u0026amp;m); } int main(int argc, char *argv[]) { printf(\u0026#34;parent: begin\\n\u0026#34;); pthread_t p; Pthread_create(\u0026amp;p, NULL, child, NULL); thr_join(); printf(\u0026#34;parent: end\\n\u0026#34;); return 0; } pthread_cond_t c; 라고 써서 c가 컨디션 변수가 되도록 한다. 컨디션 변수에는 wait()과 signal()이라는 두개의 연산이 있다. wait은 스레드가 스스로를 잠재우기 위해서 signal은 조건이 만족되기를 대기하며 잠자고 있던 스레드를 깨울때 호출한다. pthread_cond_wait (pthread_cond_t *c, thread_mutex_t *m) ; pthread_cond_signal (pthread_cond_t *c) ; 과정을 명확히 기억해야 한다. 슬립에서 깨어난 프로세스는 리턴하기 전에 락을 재획득해야한다. 시그널을 받아서 대기상태에서 깨어났더라도 락획득에 실패하면 다시 슬립한다. 30.2 생산자/소비자 (유한버퍼) 문제 자주 사용되는 패턴 생산자는 데이터를 만들어 버퍼에 넣고, 소비자는 버퍼에서 데이터를 꺼내어 사용한다. 웹서버등 엄청 많이 사용되는 패턴 유닉스도 마찬가지이다. grep foo file.txt | wc -1 grep이 생산자 wc가 소비자 문제는 유한 버퍼가 공유 자원이라는 것이다, 경쟁 조건의 발생을 방지하기 위해 동기화기 필요하다. int buffer; int count = 0; // initially, empty void put(int value) { assert(count == 0); count = 1; buffer = value; } int get() { assert(count == 1); count = 0; return buffer; } 간단하다, 생산자는 버퍼가 비어있다면 (count = 0) 넣고, 소비자는 버퍼가 차있으면 (count = 1) 뺀다. void *producer(void *arg) { int i; int loops = (int) arg; for (i = 0; i \u0026lt; loops; i++) { put(i); } } void *consumer(void *arg) { while (1) { int tmp = get(); printf(\u0026#34;%d\\n\u0026#34;, tmp); } } 이런 코드는 제대로 동작하지 않는다. 공유변수 (count에서 경쟁 조건이 발생하기 때문이다.) 불완전한 해답. int loops; // must initialize somewhere... cond_t cond; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); // p1 if (count == 1) // p2 Pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(\u0026amp;cond); // p5 Pthread_mutex_unlock(\u0026amp;mutex); // p6 } } void *consumer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); // c1 if (count == 0) // c2 Pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(\u0026amp;cond); // c5 Pthread_mutex_unlock(\u0026amp;mutex); // c6 printf(\u0026#34;%d\\n\u0026#34;, tmp); } } 이코드는 동작할 것 같지만 스레드가 늘어나면 문제가 생긴다. 소비자 먼저 실행된다 (TC1) 락을 획득하고(c1) 버퍼를 소비할 수 있는지 검사한다(c2) 비어있음을 확인하고 대기하며 (c3) 락을 해제한다. 그리고 생산자가 실행된다. 락을 획득하고(p1), 버퍼가 비었는지 확인한다 (p2) 비어있음을 확인하고 버퍼를 채운다(p4) 버퍼가 가득찼다는 시그널을 보낸다 (p5) 소비자는 준비 큐로 이동한다. 소비자는 준비되었지만 실행가능하지는 않은 상태이다. 생산자는 실행을 계속한다. 버퍼가 차있으므로 대기상태로 전이한다.(p6, p1-p3) 여기서 문제가 발생한다. (Tc2)가 끼어들면서 버퍼값을 수행한다. Tc2가 버퍼를 소비한 직후 Tc1이 실행된다고 하자 절묘하게도 대기에서 리턴하기전에 락을 획득하지만 버퍼가 비어있다. Tc1이 버퍼를 읽는 행위를 막지 못했다. 문제의 원인은 단순하다 Tc1이 시그널을 받는 시점과 스레드가 실행되는 시점의 시차 때문이다. 깨운다는 행위의 본질은 스레드의 상태를 변경하는것이다, 깨우고 실되는 시점 사이에 버퍼는 다시 변경될 수 있다. 때문에 깨어난 스레드가 실제 실행되는 시점에는 시그널을 받았던 시점의 상태가 그대로 유지되어있는지를 체크해야한다. 이것을 Mesa semantic이라고 한다. 가장 간단한 해결책은 if를 while문으로 변경하는것이다 int loops; // must initialize somewhere... cond_t cond; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); // p1 while (count == 1) // p2 Pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); // p3 put(i); // p4 Pthread_cond_signal(\u0026amp;cond); // p5 Pthread_mutex_unlock(\u0026amp;mutex); // p6 } } void *consumer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); // c1 while (count == 0) // c2 Pthread_cond_wait(\u0026amp;cond, \u0026amp;mutex); // c3 int tmp = get(); // c4 Pthread_cond_signal(\u0026amp;cond); // c5 Pthread_mutex_unlock(\u0026amp;mutex); // c6 printf(\u0026#34;%d\\n\u0026#34;, tmp); } } 또하나의 문제가 있다.\n만약에 생산자가 버퍼를 채우고,\n소비자가 비우고,\n소비자를 또 깨우면\n세상에나 세개의 스레드가 다 자버릴 수 있다. 변수를 두개써서 해결할 수있기는하다.\ncond_t empty, fill; mutex_t mutex; void *producer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); while (count == 1) Pthread_cond_wait(\u0026amp;empty, \u0026amp;mutex); put(i); Pthread_cond_signal(\u0026amp;fill); Pthread_mutex_unlock(\u0026amp;mutex); } } void *consumer(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { Pthread_mutex_lock(\u0026amp;mutex); while (count == 0) Pthread_cond_wait(\u0026amp;fill, \u0026amp;mutex); int tmp = get(); Pthread_cond_signal(\u0026amp;empty); Pthread_mutex_unlock(\u0026amp;mutex); printf(\u0026#34;%d\\n\u0026#34;, tmp); } } 여기서 이것까지만 개선해주면! #define MAX 100 int buffer[MAX]; int fill = 0; int use = 0; int count = 0; void put(int value) { buffer[fill] = value; fill = (fill + 1) % MAX; count++; } int get() { int tmp = buffer[use]; use = (use + 1) % MAX; count--; return tmp; } 다중스레스 생산자/소비자 해법이 완료되었다. 스핀락(Spinlock)과 뮤텍스락(Mutex lock)의 주요 차이점\n동작 방식: 스핀락: 락을 획득하지 못하면 계속해서 락의 상태를 확인하며 기다립니다(바쁜 대기, busy waiting). CPU 자원을 계속 소모하면서 락이 풀릴 때까지 반복적으로 확인합니다. 뮤텍스락: 락을 획득하지 못하면 프로세스/스레드가 슬립(sleep) 상태로 전환되어 CPU를 양보하고, 락이 해제되면 깨어납니다. 자원 사용: 스핀락: CPU 시간을 계속 소모합니다. 대기 시간이 짧은 경우에 효율적입니다. 뮤텍스락: 대기 중에는 CPU를 사용하지 않습니다. 대기 시간이 길 경우 효율적입니다. 컨텍스트 스위칭: 스핀락: 컨텍스트 스위칭이 발생하지 않습니다. 뮤텍스락: 스레드가 슬립 상태로 전환될 때 컨텍스트 스위칭이 발생합니다. 용도: 스핀락: 멀티프로세서 환경에서 락 획득이 빠르게 이루어질 것으로 예상될 때 유용합니다. 뮤텍스락: 일반적인 상황에서 널리 사용되며, 특히 대기 시간이 길 수 있는 경우에 적합합니다. 구현 복잡성: 스핀락: 상대적으로 단순한 구현으로, 커널 레벨의 지원이 적게 필요합니다. 뮤텍스락: 조금 더 복잡한 구현으로, 커널의 스케줄링 메커니즘과 연동됩니다. 스핀락은 락을 획득하는 데 짧은 시간이 걸릴 것으로 예상되는 경우나 실시간 시스템에서 컨텍스트 스위칭을 피해야 할 때 유용하며, 뮤텍스락은 락 경쟁이 심하거나 락을 오래 보유해야 하는 상황에서 더 효율적\n31 세마포어 세마포어는 락과 컨디션 변수로 모드 사용할 수 있다. 핵심질문 : 세마포어를 어떻게 사용하는가\n32 병행성 관련 버그 32.1 오류의 종류 유명 오픈소스를 대상으로 한 연구에서, 105개의 오류중 74개가 교착상태와는 무관한 오류였다.(non-deadlock bug) 32.2 비 교착상태 오류 원자성 위반 오류 Thread 1:: if (thd-\u0026gt;proc_info) { fputs(thd-\u0026gt;proc_info, ...); } Thread 2:: thd-\u0026gt;proc_info = NULL; 원자성 위반에 대한 정의는 이렇다. \u0026ldquo;다수의 메모리 참조 연산들 간에 있어 예상했던 직렬성이 보장되지 않았다.\u0026rdquo; 원자성 위반 오류는 한 프로세스에서 기대하는 연산이 다른 프로세스의 개입 없이 완전히 수행되어야 하지만, 중간에 다른 프로세스가 개입하여 데이터의 일관성이 깨지는 경우 발생한다. 예를 들어, 두 개의 스레드가 공유 변수 X에 접근한다고 가정할 때, 하나의 스레드가 X를 읽고 수정하는 도중 다른 스레드가 X를 변경하면 예상치 못한 결과가 발생할 수 있다. 순서 위반의 오류 보통은 컨디션 변수같은것들로 해결 할 수 있다. 순서 위반 오류는 특정 코드 실행 순서가 예상과 다르게 진행되어 오류가 발생하는 경우를 의미한다. 두 개 이상의 스레드가 실행될 때, 특정 이벤트가 다른 이벤트보다 먼저 실행되어야 하는데, 실행 순서가 보장되지 않으면 문제가 발생할 수 있다. 예를 들어, 변수 Y가 초기화되기 전에 다른 스레드에서 이를 사용하려고 하면 오류가 발생할 수 있다. 32.3 교착상태 오류 l1, l2가 있을때 스레드가 서로 l2를얻고 l1을 기다림, l1을 얻고 l2를 기다림 과 같은 상황 사실 l1, l2를 동일한 순서로 얻으면 이런일은 발생을 안함 구성요소가 복잡해지면서 순환 의존성이 생기는 경우에 잘 발생됨 가장 흔하게는\nVector v1, v2; // Thread 1 v1.addAll(v2); // Thread 2 v1.addAll(v1); 교착 상태 발생 조건 상호 배제(Mutual Exclusion): 쓰레드가 자신이 필요로 하는 자원에 대한 독자적인 제어권을 주장한다 (예, 스레드가 락을 획득함 ). 점유 및 대기 (Hold-and-wait): 쓰레드가 자신에게 할당된 자원 ( 예 : 이미 획득한 락 ) 을 점유한 채로 다른 자원 ( 예 : 획득하고자 하는 락 ) 을 대기한다. 비 선점 (No preemption): 자원 ( 락 ) 을 점유하고 있는 쓰레드로부터 자원을 강제적으로 빼앗을 수 없다. 환형 대기(Circular wait): 각 쓰레드는 다음 쓰레드가 요청한 하나 또는 그 이상의 자원 ( 락 ) 을 갖고 있는 쓰레드들의 순환 고리가 있다. 교착 상태의 예방 순환 대기\n락획득을 하는 전체 순서를 정하는것 모든 스레드가 lock1 → lock2 → lock3 순서로만 락을 획득하도록 규칙을 정하면, 한 스레드가 lock1을 잡았을 때 lock2가 필요하면 lock2를 가진 스레드는 lock1을 기다릴 일이 없어진다. 이렇게 하면 환형 대기가 발생하지 않는다. 점유 및 대기\n모든 락을 단번에 획득하도록 하는것 lock1과 lock2가 모두 필요할 경우, lock1만 획득한 후 lock2를 기다리지 않고, 처음부터 lock1과 lock2를 한꺼번에 요청하여 획득해야 한다. 만약 두 개의 락을 동시에 얻을 수 없다면, 아예 락을 점유하지 않고 다시 시도하는 방식으로 설계할 수 있다. 비선점\n인터페이스를 잘 활용하기 (락의 점유 상태 등) 특정 락이 오래 점유되고 있으면 타임아웃을 설정하여 자동으로 해제되도록 하거나, 우선순위가 높은 작업이 요청되었을 때 현재 점유한 스레드가 자원을 양보하도록 설계할 수 있다 상호 배제\n이런 상황 자체를 줄이는법 읽기 전용 작업의 경우 락을 사용하지 않고 여러 스레드가 동시에 접근할 수 있도록 한다. 가능하면 락 대신 병렬 처리를 활용하는 구조로 변경한다. 데이터베이스에서는 여러 사용자가 읽기 작업을 수행할 수 있도록 READ COMMITTED 같은 격리 수준을 활용할 수 있다. ","permalink":"http://localhost:1313/_wiki/concurrency-intro/","summary":"25 병행성에 관한 대화 여러사람이 동시에 복숭아를 집을 수 있도록 했을때는 빨랐어요, 반면에 제 방법은 한번에 한명씩 집기 때문에 정확하겠지만 꽤 느리겠군요.\n멀티 쓰레드 프로그램이라고 불리는 프로그램들이 있네, 각 쓰레드는 독립된 객체로서 프로그램 내에서 프로그램을 대신하여 일으 하지, 이 쓰레드들은 메모리에 접근하는데, 쓰레드 입장에서 보면 메모리는 아까 이야기했던 복숭아와 같은 거야\n동시성을 운영체제에서 다뤄야 할 몇 가지 이유가 있지. 운영체제는 락과 컨디션 변수와 같은 기본 동적으로 멀티쓰레드 프로그램을 지원해야 한다네. 둘째로 운영체제는 그 자체로 최초의 동시 프로그램이기 때문이야","title":"Concurrency-Intro"},{"content":"19 페이징: 더 빠른 변환(TLB) 매핑 정보 저장(페이지 테이블 저장)을 위해 큰 메모리 공간이 요구됨 가상 주소에서 물리 주소로의 주소 변환을 위해 메모리에 존재하는 매핑정보를 읽어야함. 핵심 질문: 주소 변환 속도를 어떻게 향상할까?\n주소 변환을 빠르게 하기 위해 우리는 변환-색인 버퍼(translation-lookaside-buffer) 줄여서 TLB라고 부르는 것을 도입한다. 칩의 MMU(memory-management unit)의 일부라고 한다. 자주 참조되는 가상주소 - 실주소 변환 정보를 저장하는 하드웨어 캐시이다. 주소-변환 캐시가 좀 더 적합한 명칭이다. 19.1 TLB의 기본 알고리즘 // 가상 주소에서 VPN(가상 페이지 번호) 추출 VPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT; // TLB 조회 (TLB 히트 여부 확인) (Success, TlbEntry) = TLB_Lookup(VPN); if (Success == True) { // TLB Hit if (CanAccess(TlbEntry.ProtectBits) == True) { // 가상 주소에서 오프셋 추출 Offset = VirtualAddress \u0026amp; OFFSET_MASK; // TLB에서 가져온 PFN을 사용하여 물리 주소 계산 PhysAddr = (TlbEntry.PFN \u0026lt;\u0026lt; SHIFT) | Offset; // 물리 주소에서 데이터 읽기 Register = AccessMemory(PhysAddr); } else { // 접근 권한 없음 → 보호 오류 발생 RaiseException(PROTECTION_FAULT); } } else { // TLB Miss → 페이지 테이블 접근 // 페이지 테이블 엔트리(PTE) 주소 계산 PTEAddr = PTBR + (VPN * sizeof(PTE)); // PTE 가져오기 PTE = AccessMemory(PTEAddr); if (PTE.Valid == False) { // 페이지가 유효하지 않음 → 세그멘테이션 오류 발생 RaiseException(SEGMENTATION_FAULT); } else if (CanAccess(PTE.ProtectBits) == False) { // 접근 권한 없음 → 보호 오류 발생 RaiseException(PROTECTION_FAULT); } else { // TLB에 새로운 항목 삽입 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits); // 같은 명령어를 다시 실행하여 변환된 주소 사용 RetryInstruction(); } } 모든 캐시의 설계 철학처럼, TLB역시 주소 변환 정보가 대부분의 경우 캐시에 있다라는 가정을 전제로 만들어졌다. TLB는 프로세싱 코어와 가까운곳에 위치하고있어 주소변환은 그다지 부담스러운작업이아니다. 다만 미스가 발생하는 경우 엄청나게 커진다. 19.2 예제: 배열 접근 간단한 캐시 히트 관련 예제 다만 페이지 크기가 TLB 효용성과 성능에 매우 중요한 역할을 보여주는 예제이다. (a[0]부터) : miss, hit, hit, miss, hit, hit, hit, miss, hit, hit 이 예시에서 정말 첫접근부터 미스로 들어갔는데 70%의 히트율을 자랑한다. 이건 공간 지역성(Spatial Locality)때문에 그렇다 현재 참조한 데이터와 가까운 주소의 데이터도 곧 참조될 가능성이 높다. 예: 배열(Array)나 연속된 메모리 접근. 그리고 이후에는 히트할 확률이 더높은데 (tlb에 남아있는 동안 다시 참조가 일어날 가능성이 높다) 이것도 시간 지역성(Temoporal Locality)때문이다. 최근에 참조한 데이터는 곧 다시 참조될 가능성이 높다. 예: 루프(loop)에서 같은 변수를 반복적으로 참조함. 19.3 TLB 미\u001b스는 누가 처리할까? 예전에는 주로 하드웨어 요즘에는 os가 트랩 핸들러로 처리하기도 함 19.4 TLB의 구성: 무엇이 있나? 일반적으로 페이지테이블에 있는 것들중 일부 protection bit valid bit (근데 페이지 테이블의 valid-bit랑은 다름!!!!) 페이지 테이블은 : 아직 할당되느 않은 물리 페이지 프레임 tlb는 : 실제 유효한 캐시인지를 따짐, 컨텍스트 스위칭시 invalid로 다른 프로세스로부터의 접근을 막음! dirty bit 등등.. 19.5 TLB의 문제: 문맥 교환 요약하자면 컨텍스트 스위칭시 이전 프로세스의 tlb가 남아서 문제라는건데, 비우는 방식은 오버헤드를 크게 만든다 (valid bit를 건들어도 마찬가지) 그래서 주소 공간 식별자를 두거나 프로세스 식별자를 두는 방식으로 보완한다. 19.6 이슈: 교체 정책 캐시 교체 정책이 매우 중요하다. 핵심 질문: TLB 교체 정책은 어떻게 설계해야하는가? 목표는 미스율을 줄이고 히트율을 증가시켜 성능을 개선하는 것이다.\n일단 가능한건 지역성을 최대로 활용하는 LRU(least-recently-used)가 있다. 일반적으로 최근에 참조되지 않은 애들일수록 다시 참조될 가능성이 적음 또 다른 방법은 랜덤인데 조금더 안정적인 면이 있고 잘 동작한다. 고장난 시계는 2번은 맞지만 딱 1초 틀린 시계는\u0026hellip;.\n4개를 저장할수있는데 다섯개(p1,p2,p3,p4,p5)인 상황에서 p5 진입 시점에 p1을 버리고, 다음접근이 p1이라 맞물려 미스가 나는걸 의미 20 페이징: 더 작은 테이블 핵심 질문: 페이지 테이블을 어떻게 더 작게 만들까 단순한 배열 기반의 페이지 테이블은 크기가 크며 일반적인 시스템에서 메모리를 과도하게 차지한다.\n32비트 주소공간에서 4kb는 4mb의 페이지테이블을 가진다. 20.1 간단한 해법: 더 큰 페이지 32비트 주소공간에서 16kb를 가정해보자, 이제는 18비트 vpn과 14비트의 오프셋을 갖게된다. 문제는 이러면 내부 단편화가 심해진다. 결론적으로 옳바른 해결방법은 아니다. 20.2 하이브리드 접근 방법: 페이징과 세그먼트 힙 코드, 스택 세그먼트에 대한 페이지 테이블을 따로 주는것이다. 일견 좋아보이기는 하지만, 외부단편화, 내부단편화가 심했다. 20.3 멀티 레벨 페이지 테이블 페이지 테이블을 트리 구조로 표현한다. 매우 효율적이기 때문에 많은 현대 시스템에서 사용되고 있다.\n기본 개념은 간단하다. 먼저, 페이지 테이블을 페이지 크기의 단위로 다눈다. 그 다음, 페이지 테이블의 페이지가 유효하지 않은 항목이 있으면, 해당 페이지를 할당하지 않는다. 페이지 디렉터리라는 자료 구조를 사용하여 페이지 테이블 각페이지의 할당 여부와 위치를 파악한다. pfn은 page frame number valid는 그 페이지 내에 valid한 페이지가 있는지 없으면 그냥 메모리에 안올린다. 장점은 메모리 관리 자체가 유리하고, 사용된 주소 공간의 크기에 비례하여 페이지 테이블 공간이 생긴다는것 추가 비용은 tlb미스시 주소 변환을 위해 두번의 메모리 로드가 필요하다는것 리눅스(x86-64)에서는 **4단계 페이지 테이블(PML4, PDPT, PD, PT)**을 사용하여 필요한 부분만 동적 할당한다. 최신 Intel CPU에서는 5-Level 페이지 테이블을 지원하여 더 넓은 주소 공간을 관리한다. 64bit, 4kb기준 2^64/2^12 = (64비트 / 4kb) = 2^52개의 엔트리이고, 거기에 8byte를 곱하면 32(PB) VPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT; (Success, TlbEntry) = TLB_Lookup(VPN); if (Success == True) { // TLB 히트 (TLB에서 해당 가상 페이지 번호를 찾음) if (CanAccess(TlbEntry.ProtectBits) == True) { // 접근 권한 확인 Offset = VirtualAddress \u0026amp; OFFSET_MASK; PhysAddr = (TlbEntry.PFN \u0026lt;\u0026lt; SHIFT) | Offset; // 물리 주소 계산 Register = AccessMemory(PhysAddr); // 메모리 접근 } else { RaiseException(PROTECTION_FAULT); // 접근 권한이 없으면 예외 발생 } } else { // TLB 미스 (TLB에 해당 항목이 없음) PDIndex = (VPN \u0026amp; PD_MASK) \u0026gt;\u0026gt; PD_SHIFT; // 페이지 디렉터리에서 인덱스 추출 PDEAddr = PDBR + (PDIndex * sizeof(PDE)); // 페이지 디렉터리 엔트리 주소 계산 PDE = AccessMemory(PDEAddr); // 페이지 디렉터리 엔트리 가져오기 if (PDE.Valid == False) { // 페이지 디렉터리 엔트리가 유효하지 않음 RaiseException(SEGMENTATION_FAULT); // 세그멘테이션 오류 발생 } else { // 페이지 디렉터리 엔트리가 유효함 -\u0026gt; 페이지 테이블에서 PTE 조회 PTIndex = (VPN \u0026amp; PT_MASK) \u0026gt;\u0026gt; PT_SHIFT; // 페이지 테이블 인덱스 추출 PTEAddr = (PDE.PFN \u0026lt;\u0026lt; SHIFT) + (PTIndex * sizeof(PTE)); // 페이지 테이블 엔트리 주소 계산 PTE = AccessMemory(PTEAddr); // 페이지 테이블 엔트리 가져오기 if (PTE.Valid == False) { // 페이지 테이블 엔트리가 유효하지 않음 RaiseException(SEGMENTATION_FAULT); } else if (CanAccess(PTE.ProtectBits) == False) { // 접근 권한 확인 RaiseException(PROTECTION_FAULT); } else { TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits); // TLB에 페이지 테이블 엔트리 추가 RetryInstruction(); // 다시 명령어 실행 } } } 20.5 페이지 테이블을 디스크로 스와핑하기 말 그대로 너무 심하면 디스크로 스왑 21 물리 메모리 크기의 극복: 메커니즘 핵심 질문: 물리 메모리 이상으로 나아가기 위해서 어떻게할까 운영체제는 어떻게 크고 느린 장치를 사용하면서 마치 커다란 가상 주소 공간이 있는 것처럼 할 수 있을까?\n멀티프로그래밍 시스템이 발명되면서 많은 프로세스들의 페이지를 물리 메모리에 전부 저장하는것이 불가능하게 되었다. 그래서 일부 페이지들을 스왑 아웃하는 기능이 필요하게 되었다. 멀티프로그램밍과 사용 편의성 등의 이유로 실제 물리 메모리보다 더많은 용량의 메모리가 필요하게 됭ㅆ다. 이게 현대 Virtual Memory의 역할이다. 21.1 스왑 공간 먼저 디스크에 페이지들을 저장할 수 있는 일정 곤간을 확보하는게 필요하다. 이 용도의 공간을 스왑 공간이라고 한다. 운영체제는 스왑 공간에 있는 모든 페이지들의 디스크 주소를 기억해야한다. 이러면 운영체제는 프로세스들에게 매우 큰 메모리 공간이 있는것처럼 여겨지게 할 ㅅ ㅜ있다. 21.2 Present Bit 막간을 이용한 윗 내용 정리: 만약 vpn을 tlb에서 찾을 수 없다면, 하드웨어는 페이지 테이블의 메모리 주소를 파악하고(페이지 테이블 베이스 레지스터 이용) vpn을 인덱스하여 원하는 페이지 테이블 항목을 추출한다. 해당 페이지 테이블 항목이 유효하고 관련 페이지가 물리 메모리에 존재한다면 하드웨어는 pte에서 pfn정보를 추출하고 그 정보를 tlb에 탑재후 명령어를 재실행한다.\n여기서 디스크 스왑이 가능하려면, 하드웨어가 pte에서 해당 페이지가 물리 메모리에 존재하지 않는다는것을 표현해야한다. 그걸 present bit를 이용해서 하는데, 만약 해당 비트가 0이면 물리 메모리에 존재하지 않는다는 것이고, 그 상황을 page fault라고 한다. 페이지 폴트가 발생하면 page fault handler 가 실행된다. 21.3 페이지 폴트 페이지 폴트는 보통 운영체제에서 처리된다. 그러면 자연적으로 드는 의문이 있다. \u0026ldquo;디스크 어디에 있는 지 어떻게 알지?\u0026rdquo; 해당 정보는 페이지 테이블에 저장된다 pfn과 같은 pte 비트들은 페이지 디스크 주소를 나타내는데 사용할 수 있다. 이후 재실행하면 tlb미스가 발생할거고 그 미스를 처리하는 과정에서 tlb값이 갱신된다. 물론 이 과정은 I/O전송중에 차단된 상태가 된다. VPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT; (Success, TlbEntry) = TLB_Lookup(VPN); if (Success == True) { // TLB 히트 (TLB에서 해당 가상 페이지 번호를 찾음) if (CanAccess(TlbEntry.ProtectBits) == True) { // 접근 권한 확인 Offset = VirtualAddress \u0026amp; OFFSET_MASK; PhysAddr = (TlbEntry.PFN \u0026lt;\u0026lt; SHIFT) | Offset; // 물리 주소 계산 Register = AccessMemory(PhysAddr); // 메모리 접근 } else { RaiseException(PROTECTION_FAULT); // 접근 권한이 없으면 예외 발생 } } else { // TLB 미스 (TLB에 해당 항목이 없음) PTEAddr = PTBR + (VPN * sizeof(PTE)); // 페이지 테이블 엔트리 주소 계산 PTE = AccessMemory(PTEAddr); // 페이지 테이블 엔트리 가져오기 if (PTE.Valid == False) { // 페이지 테이블 엔트리가 유효하지 않음 RaiseException(SEGMENTATION_FAULT); } else { if (CanAccess(PTE.ProtectBits) == False) { // 접근 권한 확인 RaiseException(PROTECTION_FAULT); } else if (PTE.Present == True) { // 페이지가 물리 메모리에 존재하는 경우 // 하드웨어 관리 TLB를 가정 TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits); // TLB에 PTE 정보 삽입 RetryInstruction(); // 다시 명령어 실행 } else if (PTE.Present == False) { // 페이지가 메모리에 존재하지 않는 경우 RaiseException(PAGE_FAULT); // 페이지 폴트 예외 발생 } } } 하드웨어에서 PFN = FindFreePhysicalPage(); // 사용 가능한 물리 페이지를 찾음 if (PFN == -1) { // 사용 가능한 물리 페이지가 없음 PFN = EvictPage(); // 페이지 교체 알고리즘 실행 (기존 페이지를 제거) } DiskRead(PTE.DiskAddr, PFN); // 디스크에서 페이지를 읽어 물리 메모리에 로드 (I/O 대기) PTE.present = True; // 페이지 테이블 갱신: 페이지가 이제 메모리에 있음 PTE.PFN = PFN; // 페이지 프레임 번호(PFN) 설정 RetryInstruction(); // 원래 명령어 재시도 소프트웨어에서 21.4 메모리에 빈 공간이 없으면 페이지 교체를 통해서 물리메모리상의 페이지를 디스크로 내보낸다. 다음장의 정책에서 다룸! 물리메모리 크기의 극복 : 정책 위에 언급된 빈 굥간이 없으면 (디스크에서 불러올때) 메모리에 있는 페이지를 evict해야 하는데 이걸 교체정책이라고 한다. 핵심 질문 : 내보낼 페이지는 어떻게 결정하는가?\n22.1 캐시 관리 일단 이 상황 자체르 캐시로 볼 수 있다. 시스템의 가상 메모리 페이지를 가져다 좋기 위한 캐시로 메인 메모리를 생각 할 수 있다. 그렇다면 이 관리 정책은 캐시 미스를 최소화하고 캐시 히트를 최대화 하는 방식으로 접근 할 수 있다. 그리고 미스와 히트 정보를 안다면 프로그램의 amat (평균 메모리 접근 시간)을 계산 할 수있다. AMAT = TimeToMemory + (PageMissPercent * TimeToDiskk) 현대 시스템에서는 디스크 접근 비용이 너무 크기 때문에 아주 작은 미스가 전체적인 AMAT에 큰 영향을 주게 된다. 22.2 최적 교체 정책 Belady는 가장 나중에 접근될 페이지를 교체하는 것이 최적이며, 가장 적은 횟수의 미스를 발생시킨다는 것을 증명했다. 이 정책은 간단하지만 구현하기는 어려운 정책이다. 아주아주 심각한 맹점이 있다, 미래를 보는 경우에만 가능하다는 것이다! 하지만 확실한건 이건 최적의 선택이라는 것이다 즉 성능 판단의 지표가 미래를 보고 스케줄링했을때의 최적을 100점으로 두는 것이다. 22.3 간단한 정책: FIFO 간단하지만 성능이 안좋다 위의 최적이랑 비교했을시 coldstart 제외 57퍼센트 정도 22.4 또 다른 간단한 정책: 무작위 선택 위의 정책과 마찬가지로 구현이 편하지만 성능이 들쑥날쑥한다. 22.5 과거 정보의 사용: LRU least recently used가 선택되어 나간다. 빈도수(frequency), 최근성(recency)을 고려한다. 지역성 원칙을 이용하는 정책이다. 현실적으로 가장 많이 사용된다. 22.6 워크로드에 따른 성능 비교 지역성이 없는 경우 : LRU, FIFO, Random 모두 동일한 성능을 보인다. 80:20 워크로드 : 20퍼센트가 80퍼센트의 참조를 유발하는 상위에 몰린 워크로드, lru성능이 매우 좋다 순차 반복 워크로드 : 순차적으로 반복 참조가 일어나는 워크로드 22.7 과거 이력 기반 알고리즘 구현 LRU는 그래도 특정 워크로드와 평균적으로 매우 훌륭하지만, 구현이 너무 어렵다. 과거의 정보를 기록해야하는데 운영체제와 같은 부분에서그런걸 잘못하면 크게 성능이 감소한다. 23 완벽한 가상 메모리 시스템 핵심 질문 : 완전한 VM 시스템을 구현하는 방법\n2개의 시스템을 상세히 살펴보면서 이러한 구현방법에 대해 알아볼 예정이다. 첫 번째는 1970년대 초 개발된 것으로 \u0026ldquo;현대적인\u0026rdquo; 가상 메모리 관리자의 최초 사례중 하나로 VAX/VMS운영체제에서 찾을 수 있다. 두 번째는 Linux 가상 메모리 시스템으로서 가장 확장성이 뛰어난 다중 코어 시스템에서 효과적으로 실행된다. 23.1 vax/vms 가상 메모리 512바이트의 페이지 크기를 가진 vms의 설계자들의 가장 큰 이슈는 페이지 크기였다. (선형 페이지였음) 두가지 방법을 이용해서 메모리 압박을 이겨냈다. 첫째, 사용자 주소공간을 두개의 세그먼트로 나누어 프로세스마다 각 영역을 위한 페이지테이블을 가지도록 둘때, 사용자 페이지 테이블들을 커널의 가상 메모리에 배치 ","permalink":"http://localhost:1313/_wiki/paging-tlb/","summary":"19 페이징: 더 빠른 변환(TLB) 매핑 정보 저장(페이지 테이블 저장)을 위해 큰 메모리 공간이 요구됨 가상 주소에서 물리 주소로의 주소 변환을 위해 메모리에 존재하는 매핑정보를 읽어야함. 핵심 질문: 주소 변환 속도를 어떻게 향상할까?\n주소 변환을 빠르게 하기 위해 우리는 변환-색인 버퍼(translation-lookaside-buffer) 줄여서 TLB라고 부르는 것을 도입한다. 칩의 MMU(memory-management unit)의 일부라고 한다. 자주 참조되는 가상주소 - 실주소 변환 정보를 저장하는 하드웨어 캐시이다. 주소-변환 캐시가 좀 더 적합한 명칭이다. 19.1 TLB의 기본 알고리즘 // 가상 주소에서 VPN(가상 페이지 번호) 추출 VPN = (VirtualAddress \u0026amp; VPN_MASK) \u0026gt;\u0026gt; SHIFT; // TLB 조회 (TLB 히트 여부 확인) (Success, TlbEntry) = TLB_Lookup(VPN); if (Success == True) { // TLB Hit if (CanAccess(TlbEntry.","title":"OSTEP, 페이징"},{"content":"MySQL LZ77 빈\u001c도를 체크해서 치환하는 방식 자세한 구현은 -\u0026gt; 여기\n알고리즘 LZ77_압축(입력문자열): 압축결과 = 빈 리스트 검색버퍼크기 = N 전방버퍼크기 = M 현재위치 = 0 while 현재위치 \u0026lt; 입력문자열의 길이: // 검색 버퍼와 전방 버퍼 설정 검색버퍼시작 = max(0, 현재위치 - 검색버퍼크기) 검색버퍼끝 = 현재위치 전방버퍼끝 = min(현재위치 + 전방버퍼크기, 입력문자열의 길이) 최대일치위치 = 0 최대일치길이 = 0 // 검색 버퍼에서 가장 긴 일치 찾기 for 검색위치 = 검색버퍼시작 to 검색버퍼끝 - 1: 현재일치길이 = 0 while 현재위치 + 현재일치길이 \u0026lt; 전방버퍼끝 AND 검색위치 + 현재일치길이 \u0026lt; 현재위치 AND 입력문자열[검색위치 + 현재일치길이] == 입력문자열[현재위치 + 현재일치길이]: 현재일치길이 += 1 if 현재일치길이 \u0026gt; 최대일치길이: 최대일치길이 = 현재일치길이 최대일치위치 = 검색위치 if 최대일치길이 \u0026gt; 0: // 상대적 위치 계산 (검색 버퍼 내의 오프셋) 오프셋 = 현재위치 - 최대일치위치 다음문자 = 입력문자열[현재위치 + 최대일치길이] (전방버퍼끝에 도달했다면 null 또는 특수 문자) 압축결과.추가((오프셋, 최대일치길이, 다음문자)) 현재위치 += 최대일치길이 + 1 else: // 일치하는 것이 없으면 현재 문자를 그대로 출력 압축결과.추가((0, 0, 입력문자열[현재위치])) 현재위치 += 1 return 압축결과 \u0026ldquo;abracadabra\u0026quot;를 압축하는 과정 예시(검색버퍼 =7, 전방버퍼 =4)\n초기 상태: 현재위치: 0 검색버퍼: [] (비어있음) 전방버퍼: [a,b,r,a] 일치 없음 → (0,0,\u0026lsquo;a\u0026rsquo;) 출력 현재위치: 1 두 번째 단계: 현재위치: 1 검색버퍼: [a] 전방버퍼: [b,r,a,c] 일치 없음 → (0,0,\u0026lsquo;b\u0026rsquo;) 출력 현재위치: 2 세 번째 단계: 현재위치: 2 검색버퍼: [a,b] 전방버퍼: [r,a,c,a] 일치 없음 → (0,0,\u0026lsquo;r\u0026rsquo;) 출력 현재위치: 3 네 번째 단계: 현재위치: 3 검색버퍼: [a,b,r] 전방버퍼: [a,c,a,d] \u0026lsquo;a\u0026rsquo;가 검색버퍼의 첫 위치(오프셋=3)와 일치 → (3,1,\u0026lsquo;c\u0026rsquo;) 출력 현재위치: 5 다섯 번째 단계: 현재위치: 5 검색버퍼: [a,b,r,a,c] 전방버퍼: [a,d,a,b] \u0026lsquo;a\u0026rsquo;가 검색버퍼의 여러 위치와 일치하지만 가장 최근 위치(오프셋=2)를 선택 → (2,1,\u0026rsquo;d\u0026rsquo;) 출력 현재위치: 7 여섯 번째 단계: 현재위치: 7 검색버퍼: [a,b,r,a,c,a,d] 전방버퍼: [a,b,r,a] 검색버퍼에서 \u0026ldquo;abra\u0026quot;를 찾음(오프셋=7, 길이=4) → (7,4,null) 출력 현재위치: 11 (문자열 끝) 결과 :\n(0,0,\u0026#39;a\u0026#39;), (0,0,\u0026#39;b\u0026#39;), (0,0,\u0026#39;r\u0026#39;), (3,1,\u0026#39;c\u0026#39;), (2,1,\u0026#39;d\u0026#39;), (7,4,null) Huffman Encoding 허프만 코딩은 데이터의 문자 빈도수를 이용하여 가변 길이의 이진 코드로 압축하는 방식. 자주 등장하는 문자에는 짧은 코드를, 드물게 등장하는 문자에는 긴 코드를 할당하여 효율적인 압축을 수행한다.\n인코딩 각 문자의 빈도수 계산 입력 데이터에서 각 문자의 빈도를 계산한다.\n우선순위 큐(Priority Queue) 활용 빈도가 낮은 순서대로 정렬된 노드들을 관리하는 우선순위 큐를 사용한다.\n허프만 트리(Huffman Tree) 생성 빈도가 가장 작은 두 개의 노드를 선택하여 새로운 노드를 생성한다. 새 노드의 빈도수는 두 자식 노드의 빈도수를 합한 값이다. 이를 반복하여 하나의 트리가 완성될 때까지 수행한다.\n코드 할당 트리의 왼쪽 가지는 0, 오른쪽 가지는 1을 할당하여 각 문자에 고유한 이진 코드 부여한다.\n데이터 인코딩 원래 데이터를 허프만 코드로 변환하여 압축한다.\n디코딩 인코딩된 값을 트리에서 읽어감\n0001001011 이런식이라면,\n0에서 리프를 만나면 치환\n001 에서 리프를 만났으니 치환\n이런식으로 트리를 기반으로 치환해가며 디코딩\n","permalink":"http://localhost:1313/_wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%95%EC%B6%95/","summary":"MySQL LZ77 빈\u001c도를 체크해서 치환하는 방식 자세한 구현은 -\u0026gt; 여기\n알고리즘 LZ77_압축(입력문자열): 압축결과 = 빈 리스트 검색버퍼크기 = N 전방버퍼크기 = M 현재위치 = 0 while 현재위치 \u0026lt; 입력문자열의 길이: // 검색 버퍼와 전방 버퍼 설정 검색버퍼시작 = max(0, 현재위치 - 검색버퍼크기) 검색버퍼끝 = 현재위치 전방버퍼끝 = min(현재위치 + 전방버퍼크기, 입력문자열의 길이) 최대일치위치 = 0 최대일치길이 = 0 // 검색 버퍼에서 가장 긴 일치 찾기 for 검색위치 = 검색버퍼시작 to 검색버퍼끝 - 1: 현재일치길이 = 0 while 현재위치 + 현재일치길이 \u0026lt; 전방버퍼끝 AND 검색위치 + 현재일치길이 \u0026lt; 현재위치 AND 입력문자열[검색위치 + 현재일치길이] == 입력문자열[현재위치 + 현재일치길이]: 현재일치길이 += 1 if 현재일치길이 \u0026gt; 최대일치길이: 최대일치길이 = 현재일치길이 최대일치위치 = 검색위치 if 최대일치길이 \u0026gt; 0: // 상대적 위치 계산 (검색 버퍼 내의 오프셋) 오프셋 = 현재위치 - 최대일치위치 다음문자 = 입력문자열[현재위치 + 최대일치길이] (전방버퍼끝에 도달했다면 null 또는 특수 문자) 압축결과.","title":"자주 쓰이는 데이터 압축 정리"},{"content":"MySQL의 performance_schema.data_locks와 performance_schema.data_lock_waits 활용 예시 MySQL의 performance_schema.data_locks와 performance_schema.data_lock_waits 테이블을 활용하여 데이터베이스 락을 조회하는 다양한 예시와 결과를 정리.\nperformance_schema.data_locks와 performance_schema.data_lock_waits 개요 data_locks: 현재 활성화된 모든 락 정보를 포함하는 테이블 data_lock_waits: 트랜잭션이 기다리는 락 정보를 보여주는 테이블 (Deadlock 가능성 분석) 1. 기본적인 락 정보 조회 SELECT * FROM performance_schema.data_locks; ✅ 결과 예시 ENGINE OBJECT_SCHEMA OBJECT_NAME INDEX_NAME LOCK_TYPE LOCK_MODE LOCK_STATUS INNODB mydb users PRIMARY RECORD X GRANTED INNODB mydb orders NULL TABLE IX GRANTED LOCK_TYPE: TABLE, RECORD, AUTO_INC 등 LOCK_MODE: X(Exclusive), S(Shared), IX(Intent Exclusive), IS(Intent Shared) LOCK_STATUS: GRANTED, WAITING 2. 특정 테이블에 걸린 락 확인 SELECT ENGINE, OBJECT_SCHEMA, OBJECT_NAME, LOCK_TYPE, LOCK_MODE, LOCK_STATUS FROM performance_schema.data_locks WHERE OBJECT_SCHEMA = \u0026#39;mydb\u0026#39; AND OBJECT_NAME = \u0026#39;users\u0026#39;; ✅ 결과 예시 ENGINE OBJECT_SCHEMA OBJECT_NAME LOCK_TYPE LOCK_MODE LOCK_STATUS INNODB mydb users RECORD X GRANTED 3. 트랜잭션이 기다리고 있는 락 조회 SELECT * FROM performance_schema.data_lock_waits; ✅ 결과 예시 REQUESTING_ENGINE REQUESTING_THREAD_ID REQUESTING_TRANSACTION_ID BLOCKING_ENGINE BLOCKING_THREAD_ID BLOCKING_TRANSACTION_ID INNODB 12345 56789 INNODB 67890 34567 REQUESTING_TRANSACTION_ID: 락을 기다리는 트랜잭션 BLOCKING_TRANSACTION_ID: 락을 잡고 있는 트랜잭션 4. 특정 트랜잭션이 기다리고 있는 락 확인 SELECT dl.ENGINE, dl.OBJECT_SCHEMA, dl.OBJECT_NAME, dl.LOCK_TYPE, dl.LOCK_MODE, dl.LOCK_STATUS FROM performance_schema.data_locks dl JOIN performance_schema.data_lock_waits dlw ON dlw.REQUESTING_ENGINE = dl.ENGINE AND dlw.REQUESTING_THREAD_ID = dl.THREAD_ID; ✅ 결과 예시 ENGINE OBJECT_SCHEMA OBJECT_NAME LOCK_TYPE LOCK_MODE LOCK_STATUS INNODB mydb orders RECORD X WAITING 5. 특정 테이블에서 락을 대기 중인 트랜잭션 확인 SELECT dlw.REQUESTING_TRANSACTION_ID, dlw.BLOCKING_TRANSACTION_ID, dl.OBJECT_SCHEMA, dl.OBJECT_NAME, dl.LOCK_TYPE FROM performance_schema.data_lock_waits dlw JOIN performance_schema.data_locks dl ON dlw.REQUESTING_THREAD_ID = dl.THREAD_ID WHERE dl.OBJECT_SCHEMA = \u0026#39;mydb\u0026#39; AND dl.OBJECT_NAME = \u0026#39;orders\u0026#39;; ✅ 결과 예시 REQUESTING_TRANSACTION_ID BLOCKING_TRANSACTION_ID OBJECT_SCHEMA OBJECT_NAME LOCK_TYPE 56789 34567 mydb orders RECORD 📝 6. 특정 트랜잭션이 보유한 락과 대기 중인 락 함께 조회 SELECT dlw.REQUESTING_TRANSACTION_ID AS waiting_txn, dlw.BLOCKING_TRANSACTION_ID AS blocking_txn, r.OBJECT_SCHEMA AS blocking_schema, r.OBJECT_NAME AS blocking_table, w.OBJECT_SCHEMA AS waiting_schema, w.OBJECT_NAME AS waiting_table FROM performance_schema.data_lock_waits dlw JOIN performance_schema.data_locks r ON dlw.BLOCKING_THREAD_ID = r.THREAD_ID JOIN performance_schema.data_locks w ON dlw.REQUESTING_THREAD_ID = w.THREAD_ID; ✅ 결과 예시 waiting_txn blocking_txn blocking_schema blocking_table waiting_schema waiting_table 56789 34567 mydb orders mydb payments 📝 7. SHOW ENGINE INNODB STATUS와 비교하여 Deadlock 분석 SHOW ENGINE INNODB STATUS; ✅ 결과 예시 ------------------------ LATEST DETECTED DEADLOCK ------------------------ *** (1) TRANSACTION: TRANSACTION 56789, ACTIVE 10 sec LOCK WAIT on table `mydb`.`orders`... *** (2) TRANSACTION: TRANSACTION 34567, ACTIVE 12 sec LOCK WAIT on table `mydb`.`payments`... performance_schema.data_lock_waits와 비교하면 어떤 트랜잭션이 막혀 있는지 상세 확인 가능 🔥 정리 시나리오 조회 쿼리 모든 락 확인 SELECT * FROM performance_schema.data_locks; 특정 테이블의 락 조회 WHERE OBJECT_NAME = 'users' 트랜잭션 대기 중인 락 확인 SELECT * FROM performance_schema.data_lock_waits; 특정 트랜잭션이 대기 중인 락 JOIN performance_schema.data_locks ON THREAD_ID 대기 중인 트랜잭션과 보유 중인 트랜잭션 조회 JOIN data_locks 두 번 사용 Deadlock 상세 분석 SHOW ENGINE INNODB STATUS ","permalink":"http://localhost:1313/_wiki/mysql-record-lock-queries/","summary":"MySQL의 performance_schema.data_locks와 performance_schema.data_lock_waits 활용 예시 MySQL의 performance_schema.data_locks와 performance_schema.data_lock_waits 테이블을 활용하여 데이터베이스 락을 조회하는 다양한 예시와 결과를 정리.\nperformance_schema.data_locks와 performance_schema.data_lock_waits 개요 data_locks: 현재 활성화된 모든 락 정보를 포함하는 테이블 data_lock_waits: 트랜잭션이 기다리는 락 정보를 보여주는 테이블 (Deadlock 가능성 분석) 1. 기본적인 락 정보 조회 SELECT * FROM performance_schema.data_locks; ✅ 결과 예시 ENGINE OBJECT_SCHEMA OBJECT_NAME INDEX_NAME LOCK_TYPE LOCK_MODE LOCK_STATUS INNODB mydb users PRIMARY RECORD X GRANTED INNODB mydb orders NULL TABLE IX GRANTED LOCK_TYPE: TABLE, RECORD, AUTO_INC 등 LOCK_MODE: X(Exclusive), S(Shared), IX(Intent Exclusive), IS(Intent Shared) LOCK_STATUS: GRANTED, WAITING 2.","title":"MySQL 레코드 락 확인 쿼리들"},{"content":"MySQL 아키텍처 MySQL 엔진 관련 기본 핸들러, 엔진, 스토리지엔진, 하드웨어로 이루어짐 스레딩: 포어그라운드 스레드(클라이언트 스레드)와 백그라운드 스레드 MyISAM은 클라이언트스레드가 쓰기 작업까지 메모리: 글로벌영역과 클라이언트 로컬 글로벌 : 테이블 캐시, 버퍼풀, 해시인덱스, 리두로그 버퍼 로컬 : 커넥션, 정렬버퍼, 조인 버퍼 각 하위 작업이 MySQL 엔진 영역에서 처리되는지, 아니면 스토리지 엔진 영역에서 처리되는지 구분할 줄 알아야 한다.\n쿼리 실행 구조 SQL 요청 -\u0026gt; (MySQL 엔진에서) 쿼리파서 -\u0026gt; 전처리기 -\u0026gt; 옵티마이저(쿼리 변환, 비용 최적화, 실행 계획 수립) -\u0026gt; 쿼리실행기 (스토리지 엔진에서 실행)\n쿼리 파서 사용자 요청 쿼리를 토큰으로 분리해 트리구조로 만듦, 문법체크도 여기서 전처리기 문장의 구조적인 문제점 파악, 객체 존재여부나 접근권한 체크도 여기서 옵티마이저 가장 저렴한 비용의 실행계획 결정 이 책에서는 옵티마이저가 선택하는 내용을 설명할 것이며, 어떻게 하면 옵티마이저가 더 나은 선택을 할 수 있게 유도하는가를 알려줄 것이다.\n실행 엔진 만들어진 계획대로 각 핸들러에서 받은 요청을 다른 핸들러 요청의 입력으로 연결하는 역할\n그 외 각각의 세부 주제로 잡는게 좋은 것 같다. 무튼 아래와 같은 정보들이 엔진에서 지원한다.\n복제 쿼리 캐시 스레드 풀 트랜잭션 지원 메타데이터 InnoDB 스토리지 엔진 아키텍처 거의 유일하게 레코드 기반의 잠금을 제공한다.\n프라이머리 키에 의한 클러스터링 프라이머리 키 값의 순서대로 디스크에 저장됨 모든 세컨더리 인덱스는 레코드의 주소 대신 프라이머리 키의 값을 논리적인 주소로 사용(MyISAM에서는 실제 물리적인 주소) 외래 키 지원 실제 엔진레벨에서의 외래키 제약 조건에 대한 지원을 함 MVCC 일반적으로 레코드 레벨의 트랜잭션을 지원 하는 dbms가 제공하는 기능이며, 잠금을 사용하지 않는 일관된 읽기를 제공하는데 목적이 있따.\n언두로그를 통해 지원 multi version이란 하나의 레코드에 대해 여러개의 버전이 동시 관리된다는 것 구문 실행과 동시에 (커밋 여부와 관련 없이) innodb버퍼 풀에 반영, 디스크에는 반영여부가 확실치 않음 이 시점에서의 조회는 격리레벨에 따라 다르다. 크게 살펴보면 READ_UNCOMMITED : 버퍼에서 반환한다. READ_COMMITED 이상의 격리 레벨 : 커밋 전이면 언두로그에서 반환한다. 즉 innodb버퍼풀-디스크, 언두로그까지 멀티버전이 있는 것 잠금 없는 일관된 읽기 (Non-Locking Consitent Read) 간단하게 요약하면 읽기에 대한 락을 걸지 않고, 격리레벨설정에 따라서, 읽는 시점에 적절한 데이터를 읽어감 자동 데드락 감지 잠금 대기 목록을 그래프 형태로 관리 별도의 스레드가 해당 목록을 토대로 데드락을 감지 교착상태의 트랜잭션중 하나를 종료 트랜잭션 언두 로그를 기준으로(경제적인 관점에서) 강제종료할 트랜잭션을 선택 참고로 상위 레이어의 mysql엔진에서 테이블잠금이 된경우 데드락 판단이 불확실 할 수 있는데, 시스템 변수로 방지할수있음 innodb_table_locks 기본적으로 데드락 감지 스레드 자체의 부하나 리소스가 크지 않지만, 트랜잭션이 많아지면 부담이됨, 그리고 심지어는 위의 잠금 대기 목록에도 락을 걸기에, 다른 서비스 쿼리의 트랜잭션에도 지연을 유발함. 그래서 innodb_deadlock_detect를 끄고, innodb_lock_wait_timeout을 통해서 락시간을 통해 트랜잭션을 언두하는 방식으로 운영하기도 함. 책에서 나온 내용은 아니지만, 아마도 교착상태의 트랜잭션을 경제적으로 종료하는것은 아니라, 결과적인 부화는 더 안좋을 수 있을것 같다. (상황에 따라서) 자동화된 장애 복구 일반적으로 매우 견고한 장애복구 시스템이 있음 innodb_force_recovery : 장애가 나서 시작이 안되는경우 사용 위의 변수 설정으로 시작하면, 가능한 만큼 덤프로 데이터를 백업하고, 그 데이터로 테이블 다시 생성하는것이 좋다. 1=SRV_FORCE_IGNORE_CORRUPT : 인덱스나 테이블의 손상을 무시하고 시작 2=SRV_FORCE_NO_BACKUP : 메인스레드를 시작하지 않고 서버 시작, 메인스레드가 언두데이터 삭제하는과정에서 장애가 반복된다면 이거 사용 3=SRV_FORCE_NO_TRX_UNDO : 커밋되지 않고 종료된 트랜잭션의 롤백을 막음 4=SRV_FORCE_NO_IBUF_MERGE : 인서트 버퍼의 내용 무시하고 시작 5=SRV_FORCE_NO_UNDO_LOG_SCAN : 언두로그를 스캔하지 않고, 장애시점의 트랜잭션을 커밋한것처럼 동작 6=SRV_FORCE_NO_LOG_REDO : 마지막 체크포인트로 시작 이래도 안된다면, db백업과 바이너리를 통해서..\nInnoDB 버퍼 풀 InnoDB 스토리지 엔진에서 가장 핵심적인 부분, 디스크 데이터파일이나 인덱스 정보를 메모리에 캐시해두는 공간이다. 쓰기작업을 지연시켜 일괄 작업으로 처리해주는 버퍼 역할도 같이 한다.\n버퍼 풀의 크기 설정 os의 80퍼센트를 할당하라는 가이드라인은 잘못됨 경우에 따라서 레코드 버퍼의 메모리 사용될 수 있음 128mb의 청크를 단위로 조정 가능 버퍼 풀의 구조 거대한 메모리를 페이지크기로 쪼개서 관리한다. 크게 LRU 리스트, Flush 리스트, Free 리스트를 관리한다.\nLRU 리스트 조금 더 정확하게는, LRU와 MRU 리스트가 결합된 형태 각각 New 서브리스트와(MRU), Old 서브리스트(LRU)로 관리한다. 새로운 페이지는 New 리스트의 tail과 Old 리스트의 head의 접점에 삽입된다. 디스크 읽기를 최소화 하기 위해서 사용된다. InnoDB의 데이터 찾는 과정 필요한 레코드가 저장된 페이지가 버퍼 풀에 있는지 검사. (InnoDB 어댑티브 해시 인덱스로 페이지 찾기, 해당 테이블의 인덱스를 이용해 버퍼 풀에서 페이지 검색, 버퍼 풀에서 이미 페이지가 있다면 해당 페이지의 포인터를 New서브리스트 방향으로 승급) 디스크에서 필요한 데이터페이지를 버퍼 풀에 적재, 적재한 이후에 LRU 헤드 부분에 추가 버퍼 풀에 상주하는 페이지는 최근 접근 시간을 기준으로 age가 부여됨 필요한 데이터가 자주 접근됐다면 해당 페이지의 인덱스 키를 어댑티브 해시 인덱스에 추가 즉 자주 사용됐다면 MRU영역에서 오래 살아남고, 반대로는 LRU끝으로 밀려나서 메모리에서 해제됨 flush 리스트 디스크로 동기화되지 않은 데이터를 가진 데이터 페이지의 변경 시점 기준의 페이지 목록을 관리. 읽은 상태에서 수정이 있다면 플러시 리스트에 오르고, 관리되다가 디스크에 기록됨 변경이 되어 페이지의 데이터가 변경 되면 아까 본 리두 로그에 기록하는 (변경을) 과정이 일어남. 리두 로그가 디스크로 기록됐다고 해서 데이터 페이지가 디스크로 기록됐다는것을 항상 보장하지는 않음 free 리스트 실제 데이터로 채워지지 않는 여유공간 사용자의 쿼리가 새롭게 디스크의 데이터 페이지를 읽어와야하는 경우 사용됨 버퍼 풀과 리두 로그 논리적으로 디스크의 모든 데이터를 메모리에 올릴 수 있는 상황이 아니라면, 버퍼풀을 늘리면 쿼리 성능은 빨라짐 근본적으로 따져보면 InnoDB 버퍼 풀은 성능 향상을 위해 두가지 관점으로 접근함 데이터 캐시, 버퍼링 버퍼풀 늘리는건 전자에 관여 버퍼링을 늘리려면 버퍼풀과 리두 로그의 관계를 알아야 한다고 한다. 버퍼풀은 클린페이지와 더티페이지(디스크에서 읽어온 이후 변경이 발생한 페이지) 모두를 가지고 있다. 리두 로그는 1개 이상의 고정 크기 파일을 연결해서 순환 고리처럼 사용 데이터 변경이 계속 발생하면 리두 로그파일에 기록됐던 로그 엔트리는 어느 순간 다시 새로운 로그 엔트리로 덮어씌워짐 그래서 리두 로그파일에서 재사용가능한 공간과 불가능한 공간을 구분해서 관리해야하는데, 불가능한공간을 활성 리두 로그라고 한다. 기본적으로 리두 로그 파일은 순환되어 재사용되는데, 매 기록시마다 로그포지션이 증가 이것을 LSN이라고 한다. 그리고 InnoDB 스토리지 엔진은 주기적으로 체크포인트 이벤트를 발생시켜 리두 로그와 버퍼풀의 더티페이지를 디스크로 동기화하는데 발생한 체크포인트 중 가장 최근 체크포인트 지점의 LSN이 활성 리두 로그 공간의 시작점 하지만 활성 리두 로그 공간의 마지막은 계속해서 증가하기에 체크포인트와 무관 그래서 가장 최근 체크포인트의 lsn과 마지막 리두 로그 엔트리의 lsn의 차이를 체크포인트에이지라고 함 결론적으로 리두 로그 파일 크기가 적다면 너무 적은 더티 페이지의 제한때문에 쓰기가 자주일어나게 되고, 이러면 버퍼풀의 물리적인 메모리가 높아봐야 쓰기 버퍼링의 효과는 전혀 없다. 반대로 리두 로그 파일 크기가 전체 버퍼풀에 비해 터무니 없이 높다면 단 한 순간에 너무 큰 디스크 쓰기가 일어나게 된다. 버퍼 풀 플러시 더티페이지들의 디스크 동기화를 위해 다음과 같은 두가지의 기능을 백그라운드에서 실행하다. 플러시 리스트 플러시 리두 로그 공간의 재활용을 위해 주기적으로 오래된 리두 로그 엔트리가 사용하는 공간을 비워야한다. 그러려면 당연히 더티페이지가 먼저 디스크로 동기화 돼야 한다. 그러기 위해서 flush list flush 함수를 호출해서 이를 수행한다. innodb_page_cleaners : 더티페이지를 디스크로 동기화하는 클리너 스레드의 갯수 innodb_buffer_pool_instances : 여러개의 버퍼풀 인스턴스를 동시에 사용하는데 그 갯수 여기서 언급된 것은 클리너 스레드와 갯수를 자동적으로 맞춰주는게 디폴트로 되어있으며 굳이 변경할 이유가 없다는 언급과 함께 innodb_max_dirty_pages_pct : 버퍼풀에서 더티페이지가 차지할 수 있는 비율 innodb_max_dirty_pages_lwm : 쓰기 폭발 (Disk IO Burst)을 대비하여 특정 비율 이상인경우 주기적으로 쓰기를 하도록 설정하는 퍼센테이지 그외에도 capacity와 같은 값들이 있는데, 사실 여기 나머지 세세한 설정들은 hdd를 쓰던 시절 치명적이던 disk io를 줄이려고 한 노력에 더 가까워서 정말 예민하지 않으면 안 건들어도 될것 같다. LRU 리스트 플러시 프리페이지로 옮긴다, 정도 제외하곤 큰 차이 없다. 버퍼 풀 상태 백업 및 복구 잘 메모리 즉 버퍼풀에 올라간상태(warmed up)의 쿼리는 그렇지 않은 경우 대비 수십배 빠름 예전에는 이부분에 대한 관리가 잘 안되어 서비스전 풀테이블 스캔을 유발시켜서 워밍업을 매뉴얼하게 수행했음 지금은 그럴 필요 없이 버퍼 풀 덤프를 통해서 재실행되어도 버퍼가 채워져 있도록 관리 버퍼 풀의 적재 내용 확인 information schema -\u0026gt; innodb_buffer_page 테이블에서 버퍼풀 확인가능 select it.name table_name, ii.name index_name, ici.n_cached_pages n_cached_pages from information_schema.innodb_tables it inner join information_schema.innodb_indexes ii on ii.table_id = it.table_id inner join information_schema.innodb_cached_indexes ici on ici.index_id = ii.index_id where it.name=concat(\u0026#39;employees\u0026#39;,\u0026#39;/\u0026#39;,\u0026#39;employess\u0026#39;) ; 언두 로그 주 사용처는 위에서 언급한 것처럼 트랜잭션보장과 격리수준 보장 쿼리 실행 시점에 작성된다.(트랜잭션을 위해) 언두 로그 레코드 모니터링 일단 관리에 비용이 많이 든다. 1억건의 데이터를 날리거나 변경하는 dml이면? 그리고 트랜잭션의 관리가 안된다면, 언두로그가 다른트랜잭션의 영향을 받아 언두로그가 삭제가 안 될 수 있다. 트랜잭션 A가 실행되는 동안 B와 C가 dml 트랜잭션을 날린다면, b와 c의 Undo 로그는 삭제되지 않음. 이유는 트랜잭션 A가 여전히 해당 데이터를 읽을 가능성이 있기 때문. 8.0 이후 언두로그가 개선되어 언두로그를 순차적으로 사용하며 디스크 공간을 줄이는게 가능해졌음 참고로 테이블스페이스 인 만큼 이노디비 버퍼풀에 올라가기도 하지만 로그자체는 디스크 체인지 버퍼 체인지 버퍼는 인덱스 페이지의 변경 내용을 디스크가 아닌 메모리에 임시 저장하는 공간 InnoDB 버퍼 풀(Buffer Pool)의 일부로 관리되며 보조 인덱스(Secondary Index) 변경 사항을 저장 데이터 페이지를 즉시 디스크에 기록하지 않고 변경 사항을 누적하여 성능 최적화 데이터가 조회될 때 디스크와 동기화(merge)되며, 일정 주기마다 백그라운드 스레드가 자동으로 병합 동작 예\u001b시 사용자가 보조 인덱스에 대한 DML(INSERT, DELETE, UPDATE)을 실행 변경된 인덱스 페이지가 버퍼 풀에 없다면, 체인지 버퍼에 변경 사항을 기록 이후 해당 인덱스 페이지가 조회되면 체인지 버퍼에서 변경 사항을 적용(merge) 백그라운드 스레드가 일정 시간마다 디스크에 반영 innodb_change_buffer_max_size 설정을 통해 크기 조절 가능 트랜잭션이 롤백되면 체인지 버퍼도 롤백됨 기본 키(Primary Key)에는 적용되지 않으며 보조 인덱스에만 사용 자주 변경되는 보조 인덱스가 많은 테이블에서 성능 최적화 효과가 큼 리두 로그 리두 로그는 트랜잭션 변경 내용을 디스크에 영구 반영하기 전에 로그로 기록하는 구조\n시스템 장애 발생 시 리두 로그를 이용해 미완료된 변경 사항을 복구할 수 있음\nInnoDB는 변경 사항을 먼저 로그 파일에 기록한 후 데이터 페이지에 반영\n리두 로그를 통해 MySQL이 ACID 특성을 보장하며, COMMIT된 데이터의 영속성을 유지\n사용자가 DML(INSERT, UPDATE, DELETE)을 실행하면 변경된 데이터가 InnoDB 버퍼 풀에 반영됨\n변경된 내용이 리두 로그 버퍼에 기록된 후, 일정 조건이 충족되거나 COMMIT 발생 시 리두 로그 버퍼의 내용을 디스크에 순차적으로 기록\n이후 InnoDB의 백그라운드 플러시 스레드가 변경된 데이터를 실제 데이터 파일로 반영\n시스템 장애 발생 시 리두 로그를 사용하여 변경 사항을 복구\n리두 로그 파일은 ib_logfile0, ib_logfile1 등의 파일로 저장되며 순환 방식으로 동작\n특정 크기에 도달하면 덮어쓰기 방식으로 재사용\ninnodb_log_files_in_group 설정을 통해 다중 로그 파일을 구성할 수 있음\ninnodb_log_file_size는 각 리두 로그 파일의 크기를 설정하며, 크기가 너무 작으면 체크포인트가 자주 발생하여 성능이 저하될 수 있음\n크기가 너무 크면 복구 시간이 길어질 수 있음\ninnodb_flush_log_at_trx_commit 값에 따라 리두 로그의 디스크 반영 시점이 조정됨\n0으로 설정하면 1초마다 리두 로그를 디스크에 기록하여 성능이 향상되지만 장애 발생 시 데이터가 유실될 수 있음\n1은 매 트랜잭션 COMMIT 시 리두 로그를 디스크에 기록하여 안정성을 보장함\n2는 매 COMMIT 시 OS 버퍼에 기록하고, 1초마다 디스크에 기록하여 성능과 안정성의 균형을 맞춤\nWAL 기법을 사용하여 데이터를 변경하기 전에 먼저 로그를 기록하여 장애 발생 시 복구가 가능함\n로그 버퍼는 리두 로그가 먼저 저장되는 메모리 공간으로 이후 디스크로 플러시됨\n체크포인트는 리두 로그 크기 초과를 방지하기 위해 특정 시점의 변경 사항을 데이터 파일에 반영하는 과정\n리두 로그 파일은 순환 구조이므로 사용된 로그는 체크포인트 이후 덮어쓰기됨\n트랜잭션 안전성을 보장하며 장애 발생 시 빠른 복구가 가능함\n데이터 페이지 변경이 비동기적으로 디스크에 기록되므로 성능이 향상됨\n순차적인 로그 쓰기로 인해 디스크 I/O 부하가 감소함\n리두 로그가 가득 차면 새로운 트랜잭션 처리가 지연될 수 있으므로 적절한 크기 설정이 필요함\n어댑티브 해시 인덱스 자주 사용되는 페이지에 innodb엔진이 직접 생성하는 인덱스 b+ 트리는 종단노드까지 가야 레코드가 있으니까 이걸 그냥 해쉬로 최적화시킴 해쉬값의 키로는 인덱스 고유값 + 인덱스 실제 키값 을 씀 예전 버전까지는 어댑티브 해쉬 인덱스는 하나의 메모리 객체인 이유로 어댑티브 해시 인덱스의 경합이 심했다 그래서 8.0부터는 내부 잠금 경합을 줄이기위해 어댑티브 해쉬 인덱스의 파티션기능을제공한다 (대충 이것도 하나라 경합이 심했는데 파티션을 해준다는 이야기)\u001d 도움 잘되는 경우 디스크데이터가 버퍼풀이랑 비슷한경우 동등조건 검색동등비교와 in연산 많은경우 쿼리가 데이터중에서 일부데이터에 집중되는경우 도움 안되는 경우 디스크읽기가 많은 경우 특정패턴의 쿼리가 많은경우 (join like) 매우 큰 데이터를 가진 테이블레ㅔ코드를 폭넓게 읽는 경우 트랜잭션과 잠금 잠금과 트랜잭션은 서로 비슷한 개념 같지만, 사실 잠금은 동시성을 제어하기 위한 기능이고 트랜잭션은 데이터의 정합성을 보장하기 위한 기능이다.\nMySQL 엔진의 잠금 글로벌 락 FLUSH TABLES WITH READ LOCK으로 획득\nMySQL에서 제공하는 잠금 가운데 가장 범위가 크다. 서버 전체에 영향을 미치며, 테이블은 물론 데이터베이스가 달라도 영향을 미친다. sqldump수준으로 백업을 할때나 사용하고 그마저도 8.0에서는 백업락을 사용 백업락의 경우 객체 db/table등 모든 객체 생성 변경은 막히고, 유저관련도 막히지만 일반적인 테이블의 데이터 변경은 가능하다. 테이블 락 LOCK TABLES table_name [read | write] 로 획득\n마찬가지로 특별한 상황이 아니면, 어플리케이션에서 사용할일 없다. DDL에 잠깐 걸림 네임드 락 말그대로 특정 문자열에대한 락을 획득하는것 여러 클라이언트의 경쟁조건이나 데이터 동기화에 쓰이기도함 메타데이터 락 명시적이지 않음 InnoDB 스토리지 엔진 잠금 레코드 기반 락을 지원 원래는 잠금 정보를 얻는게 까다로웠는데, information_schema 데이터베이스의 INNODB_TRX, INNODB_LOCKS, INNODB_LOCK_WAITS 테이블을 조인해서 확인가능 최근에는 Performance Schema를 이용해서 모니터링도 가능 레코드 락 다른 디비의 레코드락이랑 거의 똑같지만, InnoDB 스토리지 엔진은 레코드 자체가 아니라 인덱스의 레코드를 잠근다. 인덱스가 하나도 없는 테이블이더라도 내부적으로 자동 생성된 클러스터 인덱스를 사용한다. 갭 락 MySQL만의 특수한 락 레코드 자체가 아니라 레코드와 바로 인접한 레코드 사이의 간격을 잠금 넥스터 키 락과 같이 설명되어야함 넥스트 키 락 레코드락과 갭락을 합쳐놓은 형태 STATEMENT 포맷의 바이너리 로그를 사용하기 위해서 쓴다고함 바이너리 로그에 기록되는 쿼리가 레플리카 서버에서 실행될 때, 소스 서버에서 만들어낸 결과와 동일한 결과를 만들어내도록 보장하는것이 주목적 근데 데드락이 은근 걸려서 그냥 ROW 포맷의 로그를 쓰기를 권한다. 전체적인설명 AUTO_INCREMENT 락 테이블락이었다. 명시적으로 얻을 방법은 없다.(postgres 최고..) 인덱스와 잠금 인덱스 기반 락이기 때문에, 업데이트되는 레코드가 인덱스가 안걸려 있다면, 해당하는 모든 데이터가 락이걸린다. 풀테이블 스캔을 하면 테이블락이 걸린다. CREATE TABLE orders ( id INT AUTO_INCREMENT PRIMARY KEY, customer_id INT, amount DECIMAL(10,2), status VARCHAR(20), INDEX idx_customer (customer_id) -- customer_id에 인덱스 추가 ) ENGINE=InnoDB; INSERT INTO orders (customer_id, amount, status) VALUES (1, 100.00, \u0026#39;pending\u0026#39;), (1, 200.00, \u0026#39;pending\u0026#39;), (1, 300.00, \u0026#39;pending\u0026#39;), (2, 400.00, \u0026#39;pending\u0026#39;), (2, 500.00, \u0026#39;pending\u0026#39;); BEGIN; UPDATE orders SET status = \u0026#39;completed\u0026#39; WHERE customer_id = 1 AND amount = 300; -- customer id 1인 주문 rows 다잠김 레코드 수준의 잠금 확인 및 해제 information_schema는 deprecated 되는중 performance_schema의 data_locks, data_lock_waits를 위주로 사용할 것\n조회 예시는 [[MySQL-Record-Lock-Queries]] 여기에 별도 정리\nMySQL의 격리 수준 격리 수준 Dirty Read Non-repeatable Read Phantom Read 설명 READ UNCOMMITTED O O O 커밋되지 않은 데이터를 읽을 수 있음 READ COMMITTED X O O 다른 트랜잭션이 커밋한 데이터만 읽을 수 있음 (Oracle 기본값) REPEATABLE READ X X O 동일한 트랜잭션 내에서는 같은 데이터를 읽을 수 있음 (InnoDB에서는 방지됨) (MySQL 기본값) SERIALIZABLE X X X 모든 트랜잭션을 직렬화하여 처리, 동시성을 거의 허용하지 않음 Dirty Read: 다른 트랜잭션에서 아직 커밋되지 않은 데이터를 읽는 것 Non-repeatable Read: 동일한 트랜잭션 내에서 같은 데이터를 읽었을 때 다른 값이 반환되는 것 Phantom Read: 동일한 트랜잭션 내에서 새로운 데이터가 삽입되거나 삭제되는 것이 감지되는 현상 아래로 갈수록 격리(고립) 정도가 높아지며, 동시처리 성능이 떨어진다. SQL표준 상 REPEATABLE READ에서 Pantom read는 발생할수 있지만, MySQL특성상 발생하지 않는다. 일반적인 온라인 서비스 용도의 데이터베이스는 주로 READ COMMITTED, REPEATABLE READ 중 하나를 사용한다.\nREAD_UNCOMMITTED Dirty Read가 발생함. 트랜잭션 격리 수준으로 인정하지 않을정도로 정합성에 문제가 많음. READ COMMITTED 요점은 다른 트랜잭션이 진행중이면, 언두로그에서 레코드를 읽어간다는 것. \u0026lsquo;일반적인\u0026rsquo;온라인 서비스에서 가장 많이 사용되는 트랜잭션 레벨 Non-repeatable-read는 발생함 참고로 READ_COMMITTED, REPEATABLE READ 에서의 가장 큰 차이점은 select READ_COMMITED는 한 트랜잭션 진행중에 다른트랜이 커밋을 성공하면 그 트랜잭션은 동일한 select를 보장받지 못한다. REPEATABLE READ READ COMMITTED와의 차이점은, 언두영역에 백업된 레코드의 몇번째 이전 버전으로 찾아들어가냐에 있다. 모든 InnoDB의 트랜잭션은 고유한 트랜잭션 번호를 가지며, 언두영역에 백업된 모든 레코드에는 변경을 발생시킨 트랜잭션의 번호가 포함돼있다. 그리고 언두영역의 백업된 데이터는 InnoDB 스토리지 엔진이 불필요하다고 판단하는 시점에 주기적으로 삭제한다. REPEATABLE READ 격리 수준에서는 MVCC를 보장하기 위해 실행중인 트랜잭션 가운데 가장 오래된 트랜잭션 번호보다 트랜잭션 번호가 앞선 언두 영역의 데이터는 삭제할 수 가 없다. 그렇다고 가장 오래된 트랜잭션 번호 이전의 트랜잭션에 의해 변경된 모든 언두 데이터가 필요한것은 아니다. 더 정확하게는 특정 트랜잭션 번호의 구간 내에서 백업된 언두데이터가 보존돼야 한다. 1. A 트랜잭션이 100번으로 시작 2. B 트랜잭션이 101번으로 A가 보고있는 레코드를 변경하고 커밋 3. C 트랜잭션이 102번으로 동일한 데이터를 변경하고 커밋 이 상황에서 READ COMMITTED는 B,C 트랜잭션의 커밋과 함께 해당 레코드의 언두로그를 전부 삭제 할 수 \u0026#39;있지만\u0026#39;, REPEATABLE READ에서는 100번이 실행중인동안은 언두로그를 100번이전으로 삭제를 못하게 막아준다는 이야기! SERIALIZABLE 가장 단순한 격리수준이자, 가장 엄격한 격리수준 동시 처리 작업은 떨어짐 현실성도 잘 없지만, 그나마 고려하는 이유가 pantom read인데 mysql에서는 그것 조차도 방지돼서 사용할 이유가 사실상 없음 데이터 압축 페이지압축 서버가 디스크에 저장하는 시점에 압축하고, 불러오면 압축이 해제됨 즉 버퍼풀에 데이터 페이지가 적재되면 압축이 해제된 상태로만 관리 운영체제와 하드웨어에서 둘 다 지원해야 유의미함 그래서 잘 사용안함 테이블압축 일반적으로 활용도 높음 아래와 같은 단점도 있음 버퍼풀 공간 활용률이 낮음 쿼리처리 성능이 낮음 빈번한 데이터 변경시 압축률이 떨어짐 페이지 크기에 따라서 페이지 타겟(압축 목표 크기)를 설정하는데, 압축 결과가 다를수 있고 실제로 타겟보다 크게되면 스플릿을 한다. 테스트를 잘 해보고 설정해야함 예를들어 타겟이 4kb, 8kb인데 실제 결과 차이가 별로 안난다면 8kb 기본적으로 테이블압축에서는 InnoDB 버퍼풀로올리면, 압축된페이지와 해제된 페이지 모두를 관리해야하고, 압축 자체가 cpu소모가 엄청나기에 신중하게 사용해야할것\nLZ77, Huffman Encoding을 사용, 관련 내용 정리 -\u0026gt; [[데이터-압축]]\n데이터 암호화 다른 부분에서는 암호화가 되지 않고 디스크 I/O 즉 쓰기, 읽기시에만 암호화 복호화가 이루어져 사용자는 신경을 쓸 필요는 없음 master key와 tablespace key(private key)라는 두 종류의 키를 이용 외부 키 관리 솔루션 혹은 디스크의 파일에서 마스터키를 가져오고, 암호화된 테이블이 생성될 때 마다 해당 테이블을 위한 임의의 테이블 스페이스 키를 발급. 마스터키의 관리를 유의해야함, 마스터키가 변경되면 기존 키로 테이블스페이스키를 복호화 하고 다시 새로운 키로 암호화함 이런 구현때문에 기본적으로 꼭 필요한 경우가 아니면 db기능을 이용하기 위해서 db암호화를 하는게 나음(어플리케이션 암호화보다) 바이너리 로그나 언두로그는 평문으로 저장될 수 있어 설정에 유의 인덱스 디스크 읽기 방식 Random I/O와 Sequential I/O정리, 데이터베이스나 쿼리튜닝에 어느 정도 지식을 갖춘 사용자가 절감하고 있듯이, 데이터베이스의 성능 튜닝은 어떻게 Disk I/O를 줄이느냐가 관건일 때 가 상당히 많다.\nHDD vs SSD 한번에 많은 데이터를 읽는 순차 I/O에서는 SSD가 HDD보다 조금 빠르거나 거의 비슷한 성능을 보이기도 한다. 하지만 랜덤 I/O가 훨씬 빠르다는게 장점이다.\nRandom I/O vs Sequential I/O 원래는 하드디스크는 실제 원판을 돌려서 데이터가 저장된 위치로 디스크 헤더를 이동시킨다음 데이터를 읽었음 거기서 나온 용어 실제 3개의 페이지를 삽입하더라도, 연속적으로 삽입하는것과 랜덤한 위치에 삽입하는경우 디스크 헤더를 돌리는 시스템콜의 횟수가 세배 차이 + 디스크 회전에 걸리는 시간까지 사실 쿼리를 튜닝해서 랜덤 i/o를 순차 i/o로 바꿔서 실행할 방법은 그다지 많지 않다. 일반적으로 쿼리를 튜닝하는 것은 랜덤i/o 자체를 줄여주는것이 목적이다. 여리서 랜덤 i/o를 줄인다는 것은 쿼리를 처리하는데 꼭 필요한 데이터만 읽도록 쿼리를 개선하는 것을 의미한다.\n인덱스란? 칼럼의 값과 해당 레코드가 저장된 주소를 키밸류로 삼아 인덱스를 만든다. 정렬을 유지한다. sorted 결론적으로 데이터의 저장의 성능을 희생하고(정렬하느라), 읽기속도를 높이는 기능이다. 이 책에서는 키라는 말과 인덱스는 같은 의미로 사용하겠다\n인덱스의 역할별 구분 Primary Key : 그 레코드를 대표하는 칼럼의 값으로 만들어진 인덱스 (테이블에서 레코드를 식별하는 기준값 - 식별자) Secondary Key : 프라이머리키를 제외한 나머지 모든 인덱스 B-Tree 인덱스 B-Tree 인덱스의 구조 및 특성 최상위 하나의 루트노드와 하위에 자식 노드가 붙어있음 가장 하위의 노드를 리프노드라고 하며, 중간에 있으면 브랜치 노드라고 함 리프노트드는 실제 데이터 레코드를 찾아가기 위한 주솟값을 가지고 있음 레코드는 당연히 정렬돼 있지 않고, insert된 순서로 저장되어있지도 않다.\n참고로 MySQL, InnoDB의 세컨더리 인덱스의 리프노드는 레코드 주소를 프라이머리키로 논리적 주소로 쓰고 있다. 결론적으로 PK의 b트리를 다시 타야 실제 레코드 주소를 알 수 있다. B-Tree 인덱스 키 추가 및 삭제 인덱스 키 추가\n새로운 키 값이 B-Tree에 저장될 때, 테이블의 스토리지 엔진에 따라 새로운 키 값이 즉시 인덱스에 저장될 수 도 있고 그렇지 않을 수도 있다. 기본적으로 키를 저장하려면 적절한 위치를 탐색하고, 해당위치의 리프노드에 레코드 키값과, 주소정보를 리프노드에 저장해야한다. 리프노드가 꽉차면 split이 일어나야하는데, 이 split은 브랜치노드에도 영향을 미칠수 있어 복잡한 작업이다. 인덱스의 추가로 인해 Insert, Update에 갈 영향을 대략적으로 계산하는법 기본 비용을 1이라 가정 인덱스에 키를 추가하는 작업 비용을 1.5라 가정 예를들어 3개인경우 (1.5 * 3 + 1) 5.5가 소요 이건 인덱스마다 인덱스페이지를 읽고 써야해서 걸리는 것이다. InnoDB는 참고로 키추가에 약간의 최적화가 되어있다. 만약 Unique가 아니면 필요한 경우 지연시킴 인덱스 키 삭제\n삭제는 간단하다, 그냥 리프노드를 찾아서 삭제 마크만 하면 완료된다.(추후 재활용하거나 삭제 가능) 물론 스플릿같은 부분에서 절차적으로 간단한 것이지 disk i/o는 발생한다. 인덱스 키 변경\n부하가 가장 심함, 삭제를 하고 추가하는 방식으로 진행된다. 인덱스 키 검색 트리탐색, log n 복잡도, 위의 것들을 감수한만큼 빠른 성능 100퍼센트 일치, 혹은 값의 앞부분만 일치하는 경우에 사용 가능 (like test%) 부등호 비교 조건에서도 인덱스를 활용 할 수 있지만, 인덱스를 구성하는 키 값의 뒷부분만 검색하는 용도로는 인덱스를 사용 할 수 없다. 인덱스 키값에 변형이 가해진 후 비교되는경우에는 B-Tree의 빠른 검색기능을 이용할 수 없다. SELECT * FROM users WHERE LOWER(email) = \u0026#39;test@example.com\u0026#39;; InnoDB 스토리지 엔진의 인덱스는 더 특별한 의미가 있다. InnoDB 테이블에서 지원하는 레코드 잠금이나, 넥스트 키락이 검색을 수행한 인덱스를 잠근 후 테이블의 레코드를 잠그는 방식으로 구현되어 있다. 따라서 UPDATE, DELETE문장이 실행 될 때 테이블에 적절히 사용할 수 있는 인덱스가 없으면 불필요하게 많은 레코드를 잠근다.\nB-Tree 인덱스 사용에 영향을 미치는 요소 인덱스를 구성하는 칼럼의 크기와 레코드의 건수, 그리고 유니크한 인덱스 키 값의 개수등에 의해 검색이나 변경 작업의 성능이 영향을 받는다.\n인덱스 키 값의 크기\nInnoDB 스토리지 엔진은 디스크에 데이터를 저장하는 가장 기본 단위를 페이지 또는 블록이라고 하며, 디스크의 모든 읽기 및 쓰기 작업의 최소 작업 단위가 된다. 또한 페이지는 InnoDB 스토리지 엔진의 버퍼 풀에서 데이터를 버퍼링하는 기본 단위이기도 하다. 인덱스도 결국은 페이지 단위로 관리되며, 루트와 브랜치 리프를 구분한 기준이 바로 페이지 단위이다.\n기본적으로 innoDB의 페이지 엔진 단위는 16kb (설정 가능) 인덱스 키가 16byte, 자식노드의 주소가 대력적으로 12byte라고 가정했을때 하나의 인덱스 페이지(16kb)에 585개 정도의 키를 저장할 수 있다. 문제는 인덱스 키값이 커지면 페이지에 저장되는 인덱스가 줄어들것이고, 그 줄어든게 성능에 직접적인 영향을 미친다. 예를들어 500개의 범위를 긁어오는 쿼리를 날렸는데, 키가 커져서 페이지당 300개의 인덱스를 보관한다면, 최소 두번의 disc I/O가 발생 추가적으로 인덱스 키값이 커지면, 인덱스 자체의 크기가 커지는것으로, 메모리에 캐시해둘 수 있는 레코드수는 감소한다. B-Tree의 깊이\n키값이 늘어나서 페이지당 키값이 줄어들면 깊이도 늘어난든다. 사실 큰 문제가 되는건 아니고 인덱스 키값을 줄이는게 낫다는 이야기를 하기위해서 강조했다고 한다. Selectivity(Cardinality)\n거의 같은 의미로 사용되며 모든 인덱스 키값가운데 유니크한 값의 수를 의미 전체 인덱스 키값이 100개인데 10개가 유니크하다면 selectivity 는 10 선택도가 높을수록 검색 대상이 줄어들기 때문에 그만큼 빠르게 처리된다. 물론 정렬이나 그루핑과 같은 작업을 위해 좋지않은 선택도라도 인덱스를 넣는경우도 많다. -- country, city칼럼이 있으며, 전체 레코드는 1만건, country테이블만 인덱스가 있을 때 -- 케이스 A: country 칼럼의 유니크한 값의 개수가 10개 -- 케이스 b: country 칼럼의 유니크한 값의 개수가 1000개 select * from tb_test where country=\u0026#39;KOREA\u0026#39; and city=\u0026#39;SEOUL\u0026#39;; -- 만약 이 조건을 만족하는 레코드가 단 한 건이라면? 위의 예시에서, a의경우 평균적으로 1000건을 조회하게되고, b의 경우 평균적으로 10건을 조회하게 된다. 읽어야 하는 레코드의 건수\n인덱스를 통해 테이블의 레코드를 읽는 것은 인덱스를 거치지 않고 바로 테이블의 레코드를 읽는것보다 높은 비용이 드는 작업이다.\n일반적으로는 레코드 한건을 그냥읽는 것 대비 인덱스를 타고 읽는게 4~5배 정도 비용이 많이 든다고 언급된다. 즉 만약 테이블의 20~25%가 조회대상인경우, 전체를 읽고 필요한 레코드만 가려내는 방식으로 처리하는것이 효율적이다. 이런 계산은 옵티마이저가 해주긴 하지만, 알고 있어야 한다. 예를들어 실제 조회때마다 테이블의 30퍼센트 남짓을 퍼가야 하는데 그것 \u0026lsquo;때문에\u0026rsquo; 인덱스를 추가하는짓은 하지 말아야한다. B-Tree 인덱스를 통한 데이터 읽기 어떠한 경우에 인덱스를 사용하게 유도할지, 반대로 사용하지 못하게 할지 판단하려면 MySQL더 정확하게는 스토리지엔진이 어떻게 인덱스를 이용해서 실제 레코드를 읽어내는지 알아야 한다.\n인덱스 레인지 스캔\n가장 대표적인 접근 방식이고, 뒤에 설명할 나머지 두가지 접근 방식보다는 빠른 방법. 검색해야할 인덱스의 범위가 결정됐을때 사용하는 방식 처음에는 리프노드까지 가서 찾고, 순차적으로 읽어서 긁어온다(스캔) 보통 리프노드에서 레코드(의 주소는) 연결리스트로 되어있어 다음 노드도 바로 접근이 가능하다. 어떤 방식으로 스캔하든 관계없이, 해당 인덱스를 구성하는 칼럼의 정순 또는 역순으로 정렬된 상태로 가져온다. 별도의 정렬과정이 수반되는것이아니라 인덱스 자체의 정렬 특성때문에 그런것 인덱스의 리프노드에서 검색조건에 일치하는 건들은 데이터파일에서 레코드를 읽어오는 과정이 필요하다. 이 때 리프노드에 저장된 레코드 주소로 데이터파일의 레코드를 읽어오는데 레코드 한건 한건 단위로 랜덤 I/O가 한번 씩 일어난다. 결론적으로 Index seek : 인덱스에서 조건을 만족하는 값이 저장된 위치를 찾는다. Index sacn : 탐색된 위치부터 필요한 만큼 인덱스를 쭉읽는다. Index scan의 결과로 읽어들인 키와 레코드 주소를 이용해 레코드가 저장된 페이지를 가져오고 최종 레코드를 읽어온다. 위의 3번의 과정이 필요없는 경우(즉 인덱스 내의 처리에서만으로 조회 대상이 끝나는 경우)를 Covering Index라고 하는데 성능이 좋다. show status like \u0026#39;Handler%\u0026#39;; 변수명 값 설명 Handler_commit 120 트랜잭션이 커밋된 횟수 Handler_delete 35 테이블에서 행이 삭제된 횟수 Handler_discover 0 NDB Cluster에서 자동으로 테이블을 발견한 횟수 Handler_external_lock 500 테이블 잠금을 획득한 횟수 Handler_mrr_init 0 다중 범위 읽기(MRR)가 초기화된 횟수 Handler_prepare 60 트랜잭션이 준비된 횟수 (2PC에서 사용) Handler_read_first 5 인덱스의 첫 번째 행을 읽은 횟수 Handler_read_key 300 인덱스를 사용하여 행을 찾은 횟수 Handler_read_next 450 인덱스 스캔에서 다음 행을 읽은 횟수 Handler_read_prev 20 인덱스 스캔에서 이전 행을 읽은 횟수 Handler_read_rnd 15 특정 위치에서 행을 읽은 횟수 Handler_read_rnd_next 700 전체 테이블 스캔에서 다음 행을 읽은 횟수 Handler_rollback 10 트랜잭션이 롤백된 횟수 Handler_update 80 행이 업데이트된 횟수 Handler_write 200 새로운 행이 삽입된 횟수 Handler_read_key → 인덱스를 이용하여 데이터를 조회한 횟수 값이 높다면 인덱스를 잘 활용하고 있는 것 값이 낮다면 테이블 스캔이 발생하고 있을 가능성이 있음.\nHandler_read_rnd_next → 전체 테이블 스캔을 통해 데이터를 읽은 횟수 값이 높다면 인덱스 없이 전체 테이블을 반복 탐색하고 있을 가능성이 높음. 인덱스를 추가하여 최적화할 필요가 있음.\nHandler_read_first → 인덱스의 첫 번째 행을 읽은 횟수 ORDER BY 또는 GROUP BY 쿼리에서 주로 발생.\nHandler_read_next / Handler_read_prev → 인덱스 범위 스캔이 얼마나 일어나는지 측정 Handler_read_next 값이 높다면, 인덱스 범위 검색이 활발하게 이루어지고 있는 것.\nHandler_read_rnd → 랜덤하게 특정 위치에서 데이터를 읽은 횟수 값이 높다면 파일 정렬(File Sort) 이 자주 발생할 가능성이 있음.\nHandler_commit \u0026amp; Handler_rollback → 트랜잭션이 얼마나 자주 커밋되고 롤백되는지 트랜잭션이 너무 잦으면 성능 저하의 원인이 될 수 있음.\n인덱스 풀 스캔\n인덱스 레인지 스캔과 마찬가지로 인덱스를 사용하지만, 레인지스캔과는 달리 인덱스의 처음부터 끝까지 모두 읽는 방식 쿼리의 조건절에 사용된 칼럼이 인덱스의 첫번째 칼럼이 아닌 경우 인덱스 풀스캔 반식이 사용된다. 즉 쿼리가 인덱스에 명시된 칼럼만으로 조건을 처리할 수 있는경우에 이렇게 처리된다. 루스 인덱스 스캔\n집계 쿼리에서 필요없는값 넘기는 인덱스 a, b 칼럼 복합인덱스인데, b가 정렬되어있으면 a를 기준으로 건너뛰면서 첫줄의 b값만 가져와서 처리하면된다. 인덱스 스킵 스캔\n인덱스를 스킵한 것처럼 최적화 해주는것 복합인덱스에서, 인덱스가 없는 선행칼럼의 유니크값들을 다 뽑아서 여러번의 쿼리를 날리는것과 비슷한 형태의 최적화 MySQL에서는 커버링 인덱스인경우만 가능 다중 칼럼 인덱스 복수의 키 왼쪽부터 정렬 칼럼의 위치를 신중하게 결정해야함 B-Tree 인덱스의 정렬 및 스캔 방향 항상 오름차순이거나 내림차순으로 정렬됨 옵티마이저가 실시간으로 정리해서 실행계획 수립 인덱스의 정렬 설정할 때 가능 8.0 이상\ncreate index ix_teamname_userscore on employees (team_name asc, user_score desc) 스캔 방향\n옵티마이저가 알아서 잘 선택 B-Tree 인덱스의 가용성과 효율성 select * from dept_emp where dept_no=\u0026#39;d002\u0026#39; and emp_no \u0026gt;= 10114 ; 케이스 a: index(dept_no, emp_no) 케이스 b: index(emp_no, dept_no) 케이스 a : \u0026ldquo;dept_no = \u0026lsquo;d002\u0026rsquo; and emp_no \u0026gt;= 10114\u0026rdquo; 인 레코드를 찾고, d002가 아닐때까지 쭉 읽기만 하면 됨 - 효율적 케이스 b : \u0026ldquo;dept_no = \u0026lsquo;d002\u0026rsquo; and emp_no \u0026gt;= 10114\u0026rdquo; 인 레코드를 찾고, 그 이후 모든 레코드가 d002인지 비교해야한다. case a 에서는 두조건이 작업 범위를 결정하도록 동작했다. case b 에는 dept_no가 필터링역할만 했다. 가저오는 레코드는 줄었기때문에 이것을 쿼리의 비용이 줄었다고 착각하기 쉬워서 나온 예시 같다. 결론적으로는 조건절에서 주는 조건들이 작업범위를 제한해줘서 쿼리의 성능을 높이는지, 그게아니면 필터링역할만 하는지 잘 구분해야한다는것.\n인덱스의 가용성\n항상 왼쪽 범위 정렬을 염두에 둬야한다. %like vs like% : 후자만 인덱스를 효율적으로 이용한다. 마찬가지로 케이스 a에서 만약 그냥 dept_no를 안줬다면 직전의 예시와 똑같다. 가용성과 효율성 판단\n기본적으로 아래의 조건에서는 작업 범위 조건으로 인덱스를 활용할 수 없다 NOT-EQUAL로 비교된 경우 \u0026lt;\u0026gt;, not in, is not null like 앞의 % 스토어드 함수나 다른 연산자로 인덱스 칼럼이 변형된 후 비교된 경우 비결정적 함수가 비교조건에 사용된경우 데이터타입이 서로 다른 비교 문자열 데이터 타입의 콜레이션이 다른 경우 클러스터링 인덱스 pk를 기준으로 물리적으로 가까운 위치에 데이터를 저장 사실 인덱스 알고리즘이라기보다 테이블 레코드의 저장방식임 레코드 저장이나 프라이머리 키의 변경이 상대적으로 느림 기본적으로 지원하며, 그래서 pk가 없어도 기준에따라 클러스터링 키를 정함 그래서 프라이머리키를 논리적주소로 사용하는것 왜나하면 프라이머리키의 변경이 있을때마다 실제 레코드 주소가 변경되면 모든 인덱스의 물리적 주소를 바꿔줘야 하기 때문에 그래서 커버링인덱스를 조금 더 잘 활용해야함 마지막으로 장단점 요약은 읽기에서 거의 득을 보지만 쓰기에서 실이 있는 구조라 온라인서비스에 더 적합 아 진짜 마지막으로, 그래서 snowflake같은걸 써주면 좋음 (snowflake의 생성시간 기반 unique) 구분 장점 단점 유의할 점 스토리지 구조 데이터가 프라이머리 키 순서 로 정렬되어 있어 범위 조회(RANGE SCAN)가 빠름 PK가 랜덤한 값(UUID 등)일 경우, 페이지 분할(Page Split) 이 자주 발생하여 성능 저하 프라이머리 키를 AUTO_INCREMENT로 설정하면 성능 최적화 가능 세컨더리 인덱스 세컨더리 인덱스가 PK를 가지고 있어 인덱스 루프 조인(INDEX NESTED LOOP JOIN) 최적화 가능 세컨더리 인덱스의 크기가 커짐 (PK가 길면 모든 인덱스 크기가 증가) 프라이머리 키를 짧고 정수 타입으로 설정하는 것이 유리 SELECT 성능 PK 기반 조회가 매우 빠름 (B+Tree 구조의 이점) 세컨더리 인덱스 조회 시 PK를 추가 조회해야 하므로 (인덱스 -\u0026gt; PK 조회) 속도가 다소 느려짐 세컨더리 인덱스를 너무 많이 만들면 오버헤드 발생 INSERT 성능 PK 순서대로 삽입하면 성능이 좋음 (INSERT 시 정렬 부담 적음) PK 값이 랜덤하면 Page Split 발생으로 인해 성능 저하 랜덤한 PK(UUID)보다 AUTO_INCREMENT가 성능상 유리 UPDATE 성능 프라이머리 키는 불변(Immutable)으로 설계하면 성능이 좋음 PK를 변경하면 해당 레코드가 삭제 후 재삽입됨 (즉, 비용이 매우 큼) PK는 절대 변경되지 않도록 설계하는 것이 중요 DELETE 성능 PK 기반 삭제는 빠름 (B+Tree 구조 활용) 세컨더리 인덱스가 많으면 삭제 시마다 정리 비용(리프 노드 삭제)이 큼 불필요한 세컨더리 인덱스를 최소화하는 것이 좋음 유니크 인덱스 더 성능이 좋지는 않다, 쓰기성능은 살벌하고\n외래키 부모 테이블(PK 테이블) 변경 시\nINSERT: 자식 테이블에서 참조하는 PK가 있는 경우, 부모 테이블의 해당 PK에 대해 S(공유) 락이 걸림. UPDATE: 부모 테이블의 기본 키(PK)를 변경하려면, 자식 테이블이 이를 참조하고 있기 때문에 X(배타적) 락이 발생함. DELETE: 부모 테이블의 PK를 삭제하려면 자식 테이블의 FK가 이를 참조하는지 확인해야 하므로 X(배타적) 락이 발생. 자식 테이블(FK 테이블) 변경 시\nINSERT: 부모 테이블에 존재하는 PK를 참조해야 하므로, 부모 테이블에서 해당 PK에 대해 S(공유) 락이 발생. UPDATE: 자식 테이블의 FK 값을 변경하는 경우, 기존 및 새로운 FK 값이 부모 테이블에 존재하는지 확인해야 하므로 부모 테이블에 S(공유) 락이 발생. DELETE: 자식 테이블의 행을 삭제하는 것은 일반적으로 락을 유발하지 않지만, ON DELETE CASCADE 설정이 되어 있다면 부모 테이블에도 X(배타적) 락이 발생할 수 있음. 옵티마이저와 힌트 결과는 동일하지만 내부적으로 그 결과를 만들어내는 방법은 매우 다양하다. 이런 다양한 방법중에서 어떤 방법이 최적이고 최소의 비용이 소모될지 결정해야한다. (동일한 결과 다양한 방법중에서의 최적화가 옵티마이저)\n개요 쿼리 실행 절차 첫 단계 : 사용자로부터 요청된 SQL 문장을 잘게 쪼개서 MySQL 서버가 이해할 수 있는 수준으로 분리 (parse tree) 한다. 문법적으로 잘못됐으면 여기서 걸러짐 MySQL 서버는 파스트리를 이용해 쿼리를 실행한다. 두번째 단계 : SQL의 파싱 정보 (파스 트리)를 확인하면서 어떤 테이블부터 읽고 어떤 인덱스를 이용해 테이블을 읽을지 선택한다. 불필요한 조건제거하고 가능하다면 복잡한 연산을 단순화한다. 여러 테이블의 조인이 있는 경우 어떤 순서로 읽을지 결정한다. 각 테이블에 사용된 조건과 인덱스 통계 정보를 이용해 사용할 인덱스를 결정한다. 가져온 레코드들을 임시 테이블에 넣고 다시 한 번 가공해야 하는지 결정한다. 세번째 단계 : 두 번째 단계에서 결정된 테이블의 읽기 순서나 선택된 인덱스를 이용해 스토리지 엔진으로부터 데이터를 가져온다. 옵티마이저의 종류 CBO (Cost Based Optimizer) : 여러가지 가능한 방법을 만들고 각 단위작업의 비용정보와 대상 테이블의 예측된 통계 정보를 이용해 실행계획별 비용을 산출한다. RBO (Rule Based Optimizer) : 그냥 옵티마이저에 내장된 우선순위에 따라 실행 계획을 수립한다. 다만 요즘은 거의 CBO를 이용한다. 인덱스나 테이블의 통계정보가 없고 CPU연산이 느리던 시절에 사용했었읍 기본 데이터 처리 풀 테이블 스캔과 풀 인덱스 스캔 풀테이블 스캔은 말 그대로 테이블의 테이터를 처음부터 끝까지 읽어서 요청을 처리하는것 옵티마이저가 풀테이블 선택을 선택하는경우 테이블 레코드 건수가 너무 작아서 인덱스보다 풀테이블스캔이 빠른경우 (페이지 1개로 구성된경우) where절이나 on절에 인덱스를 이용할 수 있는 적절한 조건이 없는 경우 인덱스 레인지 스캔을 사용할 수 있는 쿼리라고 하더라도 옵티마이저가 판단한 조건 일치 레코드 건수가 너무 많은 경우 (인덱스 b-tree를 샘플링해서 조사한 통계정보 기준) 리드 어헤드(read ahead)가 일어남 포어그라운드 스레드가 페이지를 읽다가, 읽는 작업을 백그라운드 스레드에 양도하는일 일반적으로 디폴트로 리드어헤드 설정을 쓰지만, 데이터 웨어하우스용으로 사용하면 이 옵션을 더 낮은 값으로 설정해서 리드어헤드를 빠르게 유발하는게 나은 경우도 있다. (애초에 시퀀셜 스캔이 많고, 백그라운드가 빨리 처리해놓는게 낫기 때문에) 풀 인덱스 스캔은 집계쿼리등에서 자주 일어남 레코드의 데이터가 필요 없고 적절한 인덱스를 찾을 수 있다면 데이터 크기가 압도적으로 적어서 유리 병렬 처리 하나의 쿼리를 나눠서 처리한다는걸 이야기한다. 여러개의 스레드가 각각의 쿼리는 원래도 됐었다.\nset session innodb_parallel_read_threads=1; set count(*) from salaries; 1 row in set (0.32 sec) set session innodb_parallel_read_threads=2; set count(*) from salaries; 1 row in set (0.20 sec) set session innodb_parallel_read_threads=3; set count(*) from salaries; 1 row in set (0.13 sec) Order by 처리 (Using filesort) 메모리에서 별도의 정렬을 진행하는것 레코드 크기에 비례해서 쿼리의 속도가 줄어든다 아래와 같은 경우에 주로 사용 정렬기준이 너무 많아서 요건별로 모두 인덱스 생성이 불가능한경우 group by의 결과 또는 distict 같은 처리의 결과를 정렬해야하는경우 Union의 결과 같이 임시 테이블의 결과를 다시 정렬해야하는경우 랜덤하게 결과 레코드를 가져와야하는 경우 소트 버퍼 메모리내에서 정렬하는데 쓰이는 버퍼 문제는 레코드가 너무 크면 disk i/o가 발생해서 성능이 현저히 줄어든다. 그렇다고 메모리를 늘리는건 부작용이 너무 커서 신중하게 결정해야한다. (전체적인 서버풀의 메모리 부족인경우 종료대상 프로세스 1순위) 정렬 알고리즘 크게는 투패스와 싱글패스가 있다. 레코드 전체를 소트버퍼에 담으면 싱글패스, 정렬 기준 칼럼을 분리하면 투패스 Single Pass Sort\n말 그대로 쿼리 요청의 모든 칼럼을 버퍼에 담고, 그 버퍼를 정렬시킨뒤 반환 Two Pass Sort\n정렬 대상 칼럼과 프라이머리 키 값만 소트 버퍼에 담아서 정렬을 수행하고, 정렬된 순서대로 다시 프라이머리키로 select\n최신 버전에서는 보통은 Single Pass 를 이용하지만, 경우에따라 Two Pass를 사용하기도 한다.\n레코드 크기가 시스템 변수에 설정된 소트할 대상 레코드 값보다 클 때 BLOB or Text Type Comlumn이 Select 대상에 포함될 때 그 외에도 일반적으로 레코드 크기가 커질수록 Two Pass Sort가 빠르다. (다만 큰 경우는 인덱스를 태울것 같아서 이렇게 이야기 한 것 같다) 정렬 처리 방법 쿼리에 order by가 사용되면 반드시 아래 세개 처리방법이 사용된다. 인덱스를 이용한 정렬 : (extra column에) 별도 표기 없음 조인에서 드라이빙 테이블만 정렬 : (extra column에) \u0026ldquo;Using filesort\u0026rdquo; 조인에서 조인 결과를 임시 테이블로 저장 후 정렬 : (extra column에) \u0026ldquo;Using temporary; Using filesort\u0026rdquo; 만약 조인이 낀다면 조인의 드라이빙 테이블만 정렬한 다음 조인 수행 조인이 끝나고 일치하는 레코드를 모두 가져온 후 정렬을 수행 당연하지만, 전자가 훨씬 공간효율성이 높기때문에 전자를 먼저 고려할 것이다. 인덱스를 이용한 정렬\n반드시 order by에 명시된 칼럼이 제일 먼저 읽는 테이블에 속하고, order by 순서대로 생성된 인덱스가 있어야함. 또한 where절에 첫 번째로 읽는 테이블의 칼럼에 대한 조건이 있다면 그 조건과 orderby는 같은 인덱스를 사용할 수 있어야 한다. 여러 테이블이 조인되는 경우 네스티드 루프 방식의 조인에서만 이 방식을 이용할 수 있다. 이렇게 조건을 만족하면 엔진에서 별도의 처리를 하지는 않는다 정렬된 인덱스대로 읽어온다. CREATE TABLE customers ( customer_id INT PRIMARY KEY, customer_name VARCHAR(100) ); CREATE TABLE orders ( order_id INT PRIMARY KEY, customer_id INT, order_date DATE, amount DECIMAL(10, 2), FOREIGN KEY (customer_id) REFERENCES customers(customer_id) ); CREATE INDEX idx_orders_order_date ON orders(order_date); EXPLAIN ANALYZE SELECT o.order_id, o.order_date, c.customer_name, o.amount FROM orders o JOIN customers c ON o.customer_id = c.customer_id WHERE o.order_date \u0026gt;= \u0026#39;2024-02-02\u0026#39; ORDER BY o.order_date; -- Index Scan using idx_orders_order_date on orders o -- Index Cond: (order_date \u0026gt;= \u0026#39;2024-02-02\u0026#39;) -- -\u0026gt; Nested Loop Join with customers c -- Filter: o.customer_id = c.customer_id SELECT o.order_id, o.order_date, c.customer_name, o.amount FROM orders o JOIN customers c ON o.customer_id = c.customer_id WHERE o.order_date \u0026gt;= \u0026#39;2024-02-02\u0026#39; ORDER BY c.customer_name; -- Warn : customers 테이블의 컬럼으로 정렬 조인에서 드라이빙 테이블만 정렬\nSELECT * FROM employees e, salaries s WHERE s.emp_no=e.emp_no AND e.emp_no BETWEEN 10002 AND 10010 ORDER BY e.last_name; employees 에서 e.emp_no BETWEEN 10002 AND 10010 만족하는 9건을 검색 이 단계에서 Filesort by last_name 정렬된 결과로 조인을 수행 임시 테이블을 이용한 정렬\nSELECT * FROM employees e, salaries s WHERE s.emp_no=e.emp_no AND e.emp_no BETWEEN 10002 AND 10010 ORDER BY s.salary; employees 에서 e.emp_no BETWEEN 10002 AND 10010 만족하는 9건을 검색 이 단계에서 Filesort를 할 수 없음 조인 이후 정렬해서 반환 (메모리는 많이 낭비) 정렬 처리 방법의 성능 비교\n잘못된 order by나 group by 때문에 쿼리가 느려지는 경우가 있음 왜 쿼리에서 인덱스를 사용하지 못하는 정렬이나 그루핑 작업이 느리게 동작하는지 확인 그러기 위해서 쿼리가 처리되는 방식을 \u0026ldquo;스트리밍처리\u0026rdquo;, \u0026ldquo;버퍼링처리\u0026quot;로 구분해야한다. 스트리밍 방식\n레코드가 검색될 때마다 바로바로 클라이언트로 전송 클라이언트는 곧바로 원했던 첫 번째 레코드를 전달받음 OLTP 환경에서는 쿼리의 첫 요청에서부터 첫 레코드를 전달받게까지의 응답시간이 가장 중요해서 자주쓰임 이 방식에서는 LIMIT이 쿼리의 비용을 상당히 줄여줌 버퍼링방식\nORDER BY나 GROUP BY같은 처리는 쿼리의 결과가 스트리밍되는 것을 불가능하게 한다. 일단 모든 레코드를 가져온 다음에 처리를해야 논리적으로 충족되기 때문 네트워크로 전송되는 레코드의 건수를 줄일수는 있으나 성능향상에는 도움이 별로 안된ㄷ다 (서버작업 측면에서는 기다지 변화가 없음) 아래를 다시 보면 인덱스를 이용한 정렬 : 스트리밍 방식으로 limit 충족할때까지 읽어서 그때그때 던져주면 된다. 조인에서 드라이빙 테이블만 정렬 : limit 의미없음, filesort 대상이 되는 레코드들을 불러와 정렬한뒤 잘라서 던져줘야한다. 조인에서 조인 결과를 임시 테이블로 저장 후 정렬 : 위와 마찬가지 select * from tb_test1 t1, tb_test2 t2 where t1.col1 = t2.col2 order by t1.col2 limit 10 ; -- tb_test1의 레코드가 100건이고, tb_test2의 레코드가 1000건 (1건의 tb_test1당 test2에 10건 존재 가정) tb_test1이 드라이빙 되는 경우 (인덱스)읽어야할 건수 : t1 - 1건, t2 - 10건 (인덱스)조인 횟수 1번 (인덱스)정렬대상 건수 : 0건 (조인의 드라이빙 테이블만 정렬) 읽어야할 건수 : t1 - 100건, t2-10건 (조인의 드라이빙 테이블만 정렬) 조인 횟수 : 1번 (조인의 드라이빙 테이블만 정렬) 정렬 대상 건수 : 100건 (t1의 레코드 건수 만큼) (임시 테이블 사용후 정렬) 읽어야할 건수 : t1 - 100건, t2 - 1000건 (임시 테이블 사용후 정렬) 조인 횟수 : 100번 (t1의 레커드 건 수 만큼) (임시 테이블 사용후 정렬) 정렬대상 건수 : 1000건 tb_test2이 드라이빙 되는 경우 (인덱스)읽어야할 건수 : t1 - 10건, t2 - 10건 (인덱스)조인 횟수 10번 (인덱스)정렬대상 건수 : 0건 \u0026hellip; 결론은 가능하면 인덱스를 사용하도록 유도하고, 그게 어렵더라도 드라이빙 테이블만 정렬해도 되도록 처리해야한다.\n정렬 관련 상태 변수 변수명 설명 Sort_merge_passes 정렬을 위해 병합이 수행된 횟수 Sort_range ORDER BY가 범위 스캔을 사용하여 정렬된 횟수 Sort_rows 정렬을 위해 처리된 총 행 수 Sort_scan ORDER BY가 전체 테이블 스캔을 사용하여 정렬된 횟수 Group by 처리 Group by 또한, order by와 같이 쿼리가 스트리밍된 처리를 할 수 없게함 group by에 사용된 조건을 인덱스를 사용해서 처리될 수 없으므로 having절을 튜닝하려고 인덱스를 생성하거나 할 필요는 없음\n인덱스 스캔을 이용하는 group by (타이트 인덱스 스캔) 조인의 드라이빙 테이블에 속한 칼럼만 이용해 그루핑 할 때 group by 칼럼으로 이미 인덱스가 있다면 그 인덱스를 차례대로 읽으면서 그루핑 작업을 수행하고 그 결과로 조인을 처리함 물론 집계함수등을 쓰면서 임시 테이블이 필요 할 수 있긴 함 루스 인덱스 스캔을 이용하는 group by GROUP BY 연산 시 일부 인덱스 키만 읽고, 나머지 행을 건너뛰는 방식 GROUP BY 대상 컬럼이 인덱스의 선두(prefix) 부분과 일치해야 한다. -- min, max 이외의 집합 함수 사용시 루스인덱스 안탐 select col1, sum(col2) from test group by col1; -- group by에 사용된 칼럼이 인덱스 구성 칼럼의 왼쪽부터 일치하지 않기 때문에 사용 불가 select col1, col2 from test group by col2, col3; -- select절의 칼럼이 group by와 일치하지 않기 때문에 사용 불가 select col1, col3 from test group by col1, col2; 비교 항목 타이트 인덱스 스캔 루스 인덱스 스캔 처리 방식 모든 인덱스를 읽음 일부 인덱스만 읽음 성능 보통 빠름 더 빠름 적용 가능 함수 COUNT() 가능 MIN(), MAX() 가능 WHERE 절 필요 여부 필요 없음 WHERE가 있으면 더 효과적 FileSort 사용 여부 사용 안 함 사용 안 함 임시 테이블을 사용하는 group by GROUP BY 대상 컬럼이 적절한 인덱스를 활용하지 못할 때 GROUP BY에 포함되지 않은 컬럼을 SELECT 할 때 (Loose Index Scan 적용 불가) ORDER BY가 GROUP BY와 다른 경우 HAVING 절이 포함된 경우 Distinct 처리 특정 칼럼의 유니크한 값만 조회하려면 distinct를 사용한다. distinct는 min, max 또는 count같은 집합함수와 함께 사용되는경우와 그렇지 않은 경우가 다르다. 그리고 집합함수와 같이 distinct가 사용되는 쿼리의 실행 계획에서 distinct처리가 인덱스를 사용하지 못할 때 항상 임시 테이블이 필요하다. (실행계획의 extra column에서는 using temporary가 출력되진 않는다.)\nselect distinct \u0026hellip; -- 8.0 이상에서는 group by 수행하는 쿼리에 orderby절이 없으면 정렬을 사용하지 않기 때문에, -- 다음의 두 쿼리는 내부적으로 같은 작업을 수행한다. select distinct emp_no from salaries; select emp_no from salaries group by emp_no; 집합 함수와 함께 사용된 distinct 집합 함수가 없는 select쿼리에서 distinct는 조회하는 모든 칼럼의 \u0026lsquo;조합이\u0026rsquo; 유니크한 것들만 가져온다. 하지만 집합함수 내에서 사용된 distinct는 그 집합 함수의 \u0026lsquo;인자로 전달된 칼럼값이 유니크한 것들\u0026rsquo;을 가져온다. id department role salary 1 HR Manager 60000 2 HR Staff 50000 3 HR Staff 50000 4 IT Engineer 70000 5 IT Engineer 75000 DISTINCT 사용 방식 동작 방식 예제 쿼리 결과 예시 집합 함수 없이 사용 조회하는 모든 컬럼의 조합이 유니크한 값들만 반환 SELECT DISTINCT department, role FROM employees; HR, Manager\nHR, Staff\nIT, Engineer 집합 함수 내에서 사용 함수의 인자로 전달된 컬럼에서 유니크한 값들만 고려하여 연산 수행 SELECT COUNT(DISTINCT department) FROM employees; 2 SUM(DISTINCT salary) salary 컬럼의 고유한 값들만 합산 SELECT SUM(DISTINCT salary) FROM employees; 255000 -- 쿼리 A select distinct first_name, last_name from employees where emp_no between 10001 and 10200; -- 쿼리 B select distinct count(distinct first_name), count(distinct last_name) from employees where emp_no between 10001 and 10200; -- 쿼리 C select count(distinct first_name, last_name) from employees where emp_no between 10001 and 10200; 쿼리 내부 테이블 생성 방식 정렬 및 인덱스 사용 처리 방식 쿼리 A first_name, last_name을 포함하는 임시 테이블 생성 first_name, last_name을 기준으로 정렬하여 중복 제거 테이블을 스캔한 후 중복을 제거하여 유니크한 (first_name, last_name) 조합만 반환 쿼리 B first_name과 last_name 각각의 유니크한 값만 저장하는 임시 테이블 두 개 생성 first_name과 last_name 각각 인덱스를 활용할 수 있음 first_name과 last_name을 개별적으로 정렬 후 유니크한 값들의 개수를 계산 쿼리 C (first_name, last_name) 조합을 저장하는 단일 임시 테이블 생성 (first_name, last_name)을 기준으로 정렬하여 중복 제거 후 개수 계산 전체 데이터를 스캔한 후 (first_name, last_name) 조합을 중복 없이 저장하고 개수를 계산 내부 테이블 생성 관점에서의 차이점 첫 번째 쿼리는 first_name, last_name을 포함하는 임시 테이블을 만들고, 전체 데이터를 스캔하여 중복을 제거한 후 반환한다. 두 번째 쿼리는 first_name과 last_name을 각각 다루므로, 내부적으로 두 개의 별도 집합을 생성하여 각 컬럼에서 유니크한 값을 카운트한다. 세 번째 쿼리는 (first_name, last_name)의 조합이 유니크한 개수를 찾기 위해 단일 임시 테이블을 생성하고, 해당 조합을 정렬한 후 중복을 제거하여 개수를 반환한다. 인덱스 사용 여부 first_name, last_name에 개별 인덱스가 있다면, 두 번째 쿼리는 인덱스를 활용할 가능성이 높다. 하지만 첫 번째와 세 번째 쿼리는 두 개의 컬럼을 동시에 고려해야 하므로, 단일 컬럼 인덱스만으로 최적화되기 어렵고, 정렬(Sort) 또는 임시 테이블을 사용하여 처리될 가능성이 높다. (first_name, last_name) 복합 인덱스가 존재한다면, 첫 번째와 세 번째 쿼리는 성능이 개선될 수 있다. 결론\n단순한 DISTINCT 조회(SELECT DISTINCT first_name, last_name)는 결과 집합을 반환해야 하므로, 임시 테이블을 생성하고 정렬을 수행해야 한다. **COUNT(DISTINCT 컬럼)을 사용할 경우, 컬럼별로 중복을 제거하는 방식이 다르며, 인덱스를 더 효과적으로 활용할 가능성이 있다. 두 개 이상의 컬럼을 DISTINCT로 개수를 세는 경우(COUNT(DISTINCT first_name, last_name))는 (first_name, last_name)을 하나의 조합으로 인식하여 처리하는 단일 임시 테이블을 사용한다. 내부 임시 테이블 활용 정렬 혹은 그루핑 할 때 암시적으로 사용하는 테이블, 즉 직접 만든 create temporary table과는 다름 디스크에 임시테이블이 만들어질때도 있음\ndisk vs memory 1gb가 넘으면 디스크로 넘김 오버헤드가 적은 mmap으로 넘기는게 기본 변수로 설정되어있음 임시테이블이 필요한 쿼리 order by, group by에 명시된 칼럼이 다른 쿼리 order by, group by에 명시된 칼럼이 조인의 순서상 첫 번째 테이블이 아닌 쿼리 distinct와 order by가 동시에 쿼리에 존재하는경우 또는 distinct가 인덱스로 처리되지 못하는 쿼리 union이나 union distinct가 사용된 쿼리 쿼리 실행 계획에서 select_type이 derived인 쿼리 고급 최적화 고급최적화 인덱스 푸쉬 다운 고급회적화2 쿼리 힌트 실행 계획 통계 정보 8.0 버전 이후부터 인덱스되지 않은 칼럼들에 대해서도 데이터 분포도를 수집해서 저장하는 히스토그램이 도입됐다. 테이블 및 인덱스 통계정보 비용기반 최적화에서 가장 중요한건 통계정보 8.0 이전까지는 통계정보가 지나치게 부정확해서 이슈였음 MySQL 서버의 통계 정보\n기존에는 통계정보가 메모리에만 있어서 휘발성이 있었음 그러나 최근에는 테이블로 관리함으로써 유지 database_name table_name index_name stat_name stat_value sample_size last_update employees employees PRIMARY n_diff_pfx01 300024 100 2025-03-01 employees employees PRIMARY n_leaf_pages 1024 NULL 2025-03-01 employees employees PRIMARY size 2048 NULL 2025-03-01 employees employees idx_lastname n_diff_pfx01 250000 100 2025-03-01 employees employees idx_lastname n_leaf_pages 512 NULL 2025-03-01 employees employees idx_lastname size 1024 NULL 2025-03-01 각 칼럼의 의미 컬럼명 의미 database_name 해당 인덱스가 속한 데이터베이스의 이름 (employees) table_name 해당 인덱스가 속한 테이블의 이름 (employees) index_name 해당 테이블에서 수집된 통계 정보를 가진 인덱스의 이름 (PRIMARY, idx_lastname 등) stat_name 인덱스의 통계 정보 항목 (설명은 아래 참고) stat_value 해당 통계 항목의 값 sample_size 통계를 수집할 때 사용한 샘플 크기 (일부 통계 항목에 적용됨) last_update 통계 정보가 마지막으로 업데이트된 날짜 및 시간 stat_name 항목 설명 stat_name 설명 n_diff_pfx01 인덱스의 첫 번째 컬럼에서 서로 다른 값의 개수 (카디널리티) n_leaf_pages 해당 인덱스의 리프(leaf) 페이지 개수 (B-트리 인덱스의 리프 노드) size 해당 인덱스가 차지하는 전체 페이지 수 (n_leaf_pages보다 크거나 같음) n_rows 전체 레코드 건수 clustered_index_size 프라이머리 키의 크기 (InnoDB 페이지 개수) sum_of_other_index_size 프라이머리 키를 제외한 인덱스의 크기 히스토그램 분포를 보기위함 직접 수집되지는 않고 명시적으로 analyze table ... update histogram이라는 쿼리로 수행해야함 샘플링 갯수등을 설정 가능함 환경변수값으로 옵티마이저가 히스토그램을 참고할지 말지 정할 수 있음 히스토그램의 용도\n버킷별로 레코드의 갯수와, 유니크한 값의 개수 정보를 가진다. 이 정보를 토대로 성능적으로 유리한 선택을 한다. 주로 인덱스 되지 않은 칼럼에 분포를 사용할 때 씀 조인 전에 작은 테이블을 필터링하면 빠름, 분포가 25퍼센트가 넘는다고 판단하면 풀테이블 스캔이 빠름 등등으로 유리한 선택을 한다는 뜻.\n히스토그램과 인덱스\n사실 통계정보만 활용하는것이 아니라, 인덱스를 샘플링해서 계획을 수립하는 경우가 많음 조건절의 레코드 건수를 예측하기 위해 옵티마이저는 실제 인덱스의 b-tree를 샘플링해서 살펴본다. 이 작음을 Index Dive라고 함 코스트 모델 mysql 서버가 쿼리를 처리하려면 다음과 같은 다양한 작업을 필요로 한다. 디스크로부터 데이터 페이지 읽기 메모리로부터 데이터 페이지 읽기 인덱스 키 비교 레코드 평가 메모리 임시 테이블 작업 디스크 임시 테이블 작업 위와 같은 작업이 얼마나 필요할지 예측하고 전체 작업ㅂ 비용을 계산한 결과를 바탕으로 최적의 실행 계획을 찾는다. 이렇게 전체 쿼리의 비용을 계산하는데 필요한 단위 작업들의 비용을 Cost Model이라고 한다. 결론적으로 8.0 이상의 코스트모델은 다음 두개의 설정값을 사용한다. server_cost: 인덱스를 찾고 레코드를 비교하고 임시 테이블 처리에 대한 비용 관리 engine_cost: 레코드를 가진 데이터 페이지를 가져오는 데 필요한 비용 관리 두 값은 테이블로 관리되는데 다음과같은 칼럼들을 가지고 있다. 이하 공통 cost_name: 코스트 모델의 각 단위 작업 default_vallue: 각 단위 작업의 비용 cost_value : dbms관리자가 설정한 값 last_updated : 단위 작업의 비용이 변경된 시점 comment : 비용에 대한 추가 설명 이하 engine_cost에만 추가적으로 있는 칼럼 engine_name : 비용이 적용된 스토리지 엔진 device_type : 디스크 타입 단위 작업 기본값 (Default Value) 설명 엔진 코스트 서버 코스트 높이면 disk_temptable_create_cost 20.0 디스크 기반 임시 테이블을 생성하는 비용. 내부적으로 디스크 기반 스토리지 엔진(InnoDB 또는 MyISAM)을 사용하는 임시 테이블 생성 시 발생. ✔ 디스크의 임시 테이블을 만들지 않는 방향으로 실행계획 수립 disk_temptable_row_cost 0.5 디스크 기반 임시 테이블에 행을 추가하는 비용. ✔ 디스크의 임시 테이블을 만들지 않는 방향으로 실행계획 수립 memory_temptable_create_cost 1.0 메모리 기반 임시 테이블을 생성하는 비용. MEMORY 스토리지 엔진을 사용하는 임시 테이블 생성 시 발생. ✔ 메모리의 임시 테이블을 만들지 않는 방향으로 실행계획 수립 memory_temptable_row_cost 0.1 메모리 기반 임시 테이블에 행을 추가하는 비용. ✔ 메모리의 임시 테이블을 만들지 않는 방향으로 실행계획 수립 key_compare_cost 0.05 레코드 키를 비교하는 비용. 이 값이 높을수록 많은 키 비교를 수행하는 쿼리 계획의 비용이 증가하여, 정렬을 피하기 위해 인덱스를 사용하는 쿼리 계획을 선호하게 됨. ✔ 정렬을 수행하지 않는 방향의 수행 계획을 수립 row_evaluate_cost 0.1 단일 행을 평가(계산)하는 비용. ✔ 풀스캔을 실행하는 비용이 늘어나서 가능한 인덱스 스캔을 실행하도록 실행계획 수립 io_block_read_cost 1.0 디스크에서 블록을 읽는 비용. ✔ 버퍼풀에서 사용할 가능성 높아짐 memory_block_read_cost 0.25 메모리에서 블록을 읽는 비용. ✔ row_evaluate_cost : 스토리지 엔진이 반환한 레코드가 쿼리의 조건에 일치하는지를 평가하는 단위 작업 이 값이 증가할수록 풀테이블 스캔과 같이 많은 레코드를 처리하는 비용이 높아지고, 반대로 레인지 스캔과 같이 상대적으로 적은 수의 레코드를 처리하는 쿼리의 비용이 낮아진다. key_compare_cost : 키값의 비교작업에 필요한 비용을 의미하는데, 레코드 정렬과 같이 키값 비교 처리가 많은 경우 쿼리의 비용이 높아진다. 확실히 DBA의 영역인 것 같다\n실행 계획 확인 실행 계획 출력 포맷 FORMAT= 으로 줄 수 있음 (json, tree 등등) 쿼리의 실행 시간 확인 EXPLAIN ANALYZE로 트리형식으로 단계별 소요시간을 볼 수 있음 EXPLAIN ANALYZE SELECT e.emp_no, AVG(s.salary) FROM employees e INNER JOIN salaries s ON s.emp_no = e.emp_no AND s.salary \u0026gt; 50000 AND s.from_date \u0026lt;= \u0026#39;1990-01-01\u0026#39; AND s.to_date \u0026gt; \u0026#39;1990-01-01\u0026#39; WHERE e.first_name = \u0026#39;Matt\u0026#39; GROUP BY e.hire_date; A) -\u0026gt; Table scan on \u0026lt;temporary\u0026gt; (actual time=0.001..0.004 rows=48 loops=1) B) -\u0026gt; Aggregate using temporary table (actual time=3.779..3.808 rows=48 loops=1) C) -\u0026gt; Nested loop inner join (cost=685.24 rows=135) (actual time=0.367..3.602 rows=48 loops=1) D) -\u0026gt; Index lookup on e using ix_firstname (first_name=\u0026#39;Matt\u0026#39;) (cost=215.08 rows=233) (actual time=0.348 1.046 rows=233 loops=1) E) -\u0026gt; Filter: (...where절 필터들) F) -\u0026gt; Index lookup on s using primary (emp_no=e.emp_no) 들여쓰기가 같은 레벨에서는 상단의 라인이 먼저 들여쓰기가 다른 레벨에서는 가장 안쪽에 위치한 라인이 먼저 그래서 아래처럼 실행된다\n1. D) Index lookup on e using ix_firstname // employees 테이블의 인덱스를 통해 first_name=Matt조건의 레코드 찾기 2. F) Index lookup on s using primary // salaries 테이블의 pk로 emp_no가 1번 결과의 emp_no와 동일한 레코드를 찾아서 3. E) filter // 2번을 filter하고 일치하는값 뽑기 4. C) Nested loop inner join // 1,3번의 결과를 조인해서 5. B) aggregate using temporary table // 임시테이블에 결과를 저장하며 group by 집계 6. A) table scan on \u0026lt;temporary\u0026gt; // 임시테이블의 결과를 반환 실행 계획 분석 id칼럼 select별로 부여되는 id 접근 순서를 의미하지는 않음 select_type 칼럼 각 단위 select쿼리가 어떤 타입의 쿼리인지 표시되는 칼럼 simple : union이나 서브쿼리를 사용하지 않는 단순한 select, 쿼리가 아무리 복잡해도 단 하나(일반적으로 제일 바깥) primary : union이나 서브쿼리의 실행계획에서 가장 바깥쪽, 마찬가지로 단하나 union : 유니온으로 결합하나는 단위 셀렉트 쿼리 가운데 첫 번째를 제외한 두 번째 이후 단위의 셀렉트 쿼리의 타입, 유니온의 첫번째 단위 셀렉트의 타입은 union되는 쿼리 결과들을 모아서 저장하는 임시테이블(derived)가 select_type으로 설정됨 dependent union : union 혹은 union all로 결합된 단위 쿼리가 외부 쿼리에 의해 영향을 받는걸 의미 union result : union결과를 담는 테이블 (실제 쿼리에서 단위 쿼리가 아니기에 별도의 id 없음) explain select emp_no from salaries where salary \u0026gt; 100000 union distinct select emp_no from dept_emp where from_date \u0026gt; \u0026#39;2001-01-01\u0026#39; id select_type table type possible_keys key key_len ref rows Extra 1 PRIMARY salaries ref salary_index salary_index 4 const 100 Using where 2 UNION dept_emp range from_date_index from_date_index 3 NULL 200 Using where NULL UNION RESULT NULL NULL NULL NULL NULL NULL NULL Using temporary subquery : from절 이외에서 사용되는 서브쿼리만을 의미 ","permalink":"http://localhost:1313/_wiki/real-my-sql/","summary":"MySQL 아키텍처 MySQL 엔진 관련 기본 핸들러, 엔진, 스토리지엔진, 하드웨어로 이루어짐 스레딩: 포어그라운드 스레드(클라이언트 스레드)와 백그라운드 스레드 MyISAM은 클라이언트스레드가 쓰기 작업까지 메모리: 글로벌영역과 클라이언트 로컬 글로벌 : 테이블 캐시, 버퍼풀, 해시인덱스, 리두로그 버퍼 로컬 : 커넥션, 정렬버퍼, 조인 버퍼 각 하위 작업이 MySQL 엔진 영역에서 처리되는지, 아니면 스토리지 엔진 영역에서 처리되는지 구분할 줄 알아야 한다.\n쿼리 실행 구조 SQL 요청 -\u0026gt; (MySQL 엔진에서) 쿼리파서 -\u0026gt; 전처리기 -\u0026gt; 옵티마이저(쿼리 변환, 비용 최적화, 실행 계획 수립) -\u0026gt; 쿼리실행기 (스토리지 엔진에서 실행)","title":"RealMySql 8.0"},{"content":"B+ 트리 구현 1. 기본 구조 구현 노드(Node)와 트리(BPlusTree) 구조체 정의 제네릭 타입 매개변수 (K: Ord, V) Box, Rc, RefCell을 사용한 메모리 관리 기본 생성자 (new) 구현 트리가 비어있는지 확인하는 기능 (is_empty) 2. 검색 기능 구현 단일 키 검색 메서드 (search) 이진 검색을 사용한 키 찾기 내부 노드 탐색 리프 노드에서 값 찾기 테스트 케이스 작성 3. 삽입 기능 구현 insert 메서드 구현 첫 노드 생성 처리 리프 노드 찾기 리프 노드에 키-값 쌍 삽입 노드 분할 (split) 구현 분할 시점 결정 (order 기반) 리프 노드 분할 내부 노드 분할 부모 노드로 키 전파 루트 노드 분할 처리 리프 노드 연결 리스트 관리 테스트 케이스 작성 4. 순회 및 범위 검색 범위 검색 메서드 (range_search) 구현 시작 키의 리프 노드 찾기 리프 노드 연결 리스트 순회 범위 내의 모든 키-값 쌍 수집 반복자 구현 IntoIterator 트레이트 구현 순차 접근 반복자 범위 접근 반복자 테스트 케이스 작성 5. 삭제 기능 구현 delete 메서드 구현 삭제할 키의 리프 노드 찾기 리프 노드에서 키-값 쌍 제거 언더플로우 처리 최소 키 개수 확인 형제 노드와 재분배 형제 노드와 병합 부모 노드의 키 업데이트 루트 노드 처리 리프 노드 연결 리스트 업데이트 테스트 케이스 작성 ","permalink":"http://localhost:1313/_wiki/kotlin-b-plus-tree/","summary":"B+ 트리 구현 1. 기본 구조 구현 노드(Node)와 트리(BPlusTree) 구조체 정의 제네릭 타입 매개변수 (K: Ord, V) Box, Rc, RefCell을 사용한 메모리 관리 기본 생성자 (new) 구현 트리가 비어있는지 확인하는 기능 (is_empty) 2. 검색 기능 구현 단일 키 검색 메서드 (search) 이진 검색을 사용한 키 찾기 내부 노드 탐색 리프 노드에서 값 찾기 테스트 케이스 작성 3. 삽입 기능 구현 insert 메서드 구현 첫 노드 생성 처리 리프 노드 찾기 리프 노드에 키-값 쌍 삽입 노드 분할 (split) 구현 분할 시점 결정 (order 기반) 리프 노드 분할 내부 노드 분할 부모 노드로 키 전파 루트 노드 분할 처리 리프 노드 연결 리스트 관리 테스트 케이스 작성 4.","title":"b+ tree on kotlin"},{"content":"알고리즘 목록 자료구조 목록 [[Kotlin-B-Plus-Tree]] ","permalink":"http://localhost:1313/_wiki/kotlin-algorithms/","summary":"알고리즘 목록 자료구조 목록 [[Kotlin-B-Plus-Tree]] ","title":"Rust로 알고리즘들 구현해보기"},{"content":"토비의 스프링 관심사 \u0026ldquo;모든 변경과 발전은 한가지 관심에 집중해서 일어난다. 문제는 다만 그에 따른 변경이 한가지 관심에 집중해 있지 않다는 것이다. 그래서 우리가 해야 할 일은, 한가지 관심이 한군데 집중되게 하는 것이다.\u0026rdquo;\n관계 모델링 시점의 오브젝트 간 관계를 기반으로, 런타임 오브젝트 관계를 갖는 구조를 만들어주는것은 \u0026ldquo;클라이언트의 책임\u0026quot;이다. 클라이언트는 자기가 UserDao를 사용해야 할 입장이기에, UserDao의 세부 전략이라고도 볼 수 있는 구현클래스를 선택하고 선택한 클래스의 오브젝트를 생성해서 연결해줄 수 있다.\nOCP 클래스나 모듈은 확장에는 열려있어야 하고, 변경에는 닫혀있어야 한다.\n구현체를 추가하는 방식의 확장을, 기존 로직의 수정 없이 가능한 구조 조금 더 추상적인 것에 의존하며 책임을 분리함으로 달성 높은 응집도, 낮은 결합도 관심사가 같은 것들이 응집해 있는것, 책임과 관심사가 다른 오브젝트 또는 모듈과는 낮은 결합ㄴ도. 결합도랑 하나의 오브젝트가 변경이 일어날 때 관계를 맺고 있는 다른 오브젝트에게 \u0026lsquo;변화를 요구하는 정도\u0026rsquo;\nStrategy Pattern 자신의 기능 context에서, 필요에 따라 변경이 필요한 알고리즘을 인터페이스를 통해 통째로 외부로 분리시키고, 이를 구현한 구체적인 알고리즘 클래스를 필요에 따라 바꿔서 사용할 수 있게 하는 디자인 패턴.\n오브젝트 팩토리 스프링이 제어권을 가지고 직접 만들고 관리하는 오브젝트 : bean 빈의 생성과 관계설정 같은 제어를 담당하는 IoC오브젝트를 : beanFactory 이를 확장한 application context (ioc 방식의 bean factory) 헷갈리는 IOC 용어 정리 bean : ioc방식으로 관리하는 오브젝트 bean factory : ioc를 담당하는 핵심 컨테이너, 빈 등록, 생성 조회, 반환 그 외 부가적인 빈 관리 기능, 보통 이걸 확장한 애플리케이션 컨텍스트 이용 application context : 빈 팩토리를 확장한 ioc 컨테이너, 스프링이 제공하는 각종 부가서비스 추가 configuration metadata : ioc를 적용하기 위해 사용하는 메타데이터 container, ioc container : 빈팩토리나 애플리케이션을 지칭 DL(Dependency Lookup)이 필요한 경우 프로토타입 스코프 빈 사용 시\n프로토타입 빈은 매번 새로운 인스턴스가 필요할 때 사용된다. DI로는 한 번만 주입되므로, 여러 번 새 인스턴스가 필요하면 ObjectProvider나 Provider를 통한 DL이 필요. 선택적 의존성(Optional Dependencies) 처리\n특정 빈이 있을 수도, 없을 수도 있는 상황에서 유연하게 대응해야 할 때 순환 의존성 문제 해결\n두 빈이 서로를 참조하는 순환 의존성이 있을 때, DL을 사용하여 지연 로딩으로 해결할 수 있습니다. 스프링 컨테이너 외부에서 빈을 사용해야 할 때\n스프링 관리 객체가 아닌 일반 객체에서 스프링 빈을 사용해야 하는 경우 런타임에 빈 선택이 필요한 경우\n사용자 입력이나 설정에 따라 다른 빈을 사용해야 할 때 지연 초기화(Lazy Initialization)가 필요할 때\n특정 빈의 초기화 비용이 높고, 실제 사용 시점까지 초기화를 미루고 싶을 때 메소드를 이용한 의존관계 주입 setter 주입 일반 메소드 이용한 주입 @Bean public UserDao userDao() { UserDao userDao = new UserDao(); userDao.setConnectionMaker(connectionMaker()); return userDao; } 템플릿 이 문제의 핵심은 변하지 않는, 그러나 많은 곳에서 중복되는 코드와 로직에 따라 자꾸 확장되고 자주 변하는 코드를 잘 분리해내는 작업이다.\n결국 DI란 이러한 전략 패턴의 장점을 일반적으로 활용할 수 있도록 만든 구조라고 볼 수 있다.\n스프링 DI는 넓게 보자면 객체의 생성과 관계 설정에 대한 제어권한을 오브젝트에서 제거하고 외부로 위임한다.\n// 1. 콜백 인터페이스 정의 interface Callback { void execute(); } // 2. 템플릿 클래스 정의 class Template { public void execute(Callback callback) { startOperation(); // 공통 시작 작업 try { callback.execute(); // 콜백 실행 (변하는 부분) } catch (Exception e) { handleException(e); // 예외 처리 } finally { endOperation(); // 공통 종료 작업 } } private void startOperation() { System.out.println(\u0026#34;작업을 시작합니다.\u0026#34;); // 리소스 초기화, 연결 설정 등 } private void handleException(Exception e) { System.out.println(\u0026#34;예외가 발생했습니다: \u0026#34; + e.getMessage()); // 로깅, 롤백 등 } private void endOperation() { System.out.println(\u0026#34;작업을 종료합니다.\u0026#34;); // 리소스 정리, 연결 종료 등 } } // 3. 템플릿 콜백 패턴 사용 예시 (파일 작업) class FileProcessor { private final Template template; public FileProcessor() { this.template = new Template(); } public void processFile(final String filePath) { template.execute(new Callback() { @Override public void execute() { System.out.println(\u0026#34;파일 \u0026#34; + filePath + \u0026#34;을 처리합니다.\u0026#34;); // 실제 파일 처리 로직 } }); } } // 4. 템플릿 콜백 패턴 사용 예시 (데이터베이스 작업) class DatabaseProcessor { private final Template template; public DatabaseProcessor() { this.template = new Template(); } public void executeQuery(final String query) { template.execute(new Callback() { @Override public void execute() { System.out.println(\u0026#34;쿼리를 실행합니다: \u0026#34; + query); // 실제 쿼리 실행 로직 } }); } } // 5. 제네릭을 활용한 확장 예시 interface CallbackWithResult\u0026lt;T\u0026gt; { T execute(); } class GenericTemplate { public \u0026lt;T\u0026gt; T executeWithResult(CallbackWithResult\u0026lt;T\u0026gt; callback) { startOperation(); try { T result = callback.execute(); // 결과를 반환하는 콜백 실행 return result; } catch (Exception e) { handleException(e); return null; } finally { endOperation(); } } private void startOperation() { System.out.println(\u0026#34;작업을 시작합니다.\u0026#34;); } private void handleException(Exception e) { System.out.println(\u0026#34;예외가 발생했습니다: \u0026#34; + e.getMessage()); } private void endOperation() { System.out.println(\u0026#34;작업을 종료합니다.\u0026#34;); } } // 결과를 반환하는 제네릭 템플릿 사용 예시 class ResultExample { public static void main(String[] args) { GenericTemplate template = new GenericTemplate(); // 문자열 결과를 반환하는 템플릿 콜백 String result = template.executeWithResult(() -\u0026gt; { return \u0026#34;작업 결과입니다.\u0026#34;; }); System.out.println(\u0026#34;반환된 결과: \u0026#34; + result); } } public class TemplateCallbackPatternExample { public static void main(String[] args) { FileProcessor fileProcessor = new FileProcessor(); fileProcessor.processFile(\u0026#34;example.txt\u0026#34;); DatabaseProcessor dbProcessor = new DatabaseProcessor(); dbProcessor.executeQuery(\u0026#34;SELECT * FROM users\u0026#34;); ModernUsage.main(args); ResultExample.main(args); } } 예외 이전에는 복구할 가능성이 조금이라도 있다면 체크 예외로 만든다고 생각했는데, 지금은 항상 복구할 수 있는 예외가 아니라면 일단 언체크 예외로 만드는 경향이 있다.\nChecked Exception :\n안잡을수 없음 Unchecked Exception : 예외가 호출 스택을 따라 상위로 전파된다. 어떤 메서드에서도 처리되지 않으면 JVM까지 전달된다. JVM이 예외 정보를 표준 오류 스트림에 출력한다. 해당 스레드가 종료된다. 메인 스레드였다면 애플리케이션 전체가 종료된다. 비표준 SQL 다양한 db를 쓸 수 있도록 유연하게 하기위한 jdbc의 노력\n두가지 이슈가 있음 비표준 sql -\u0026gt; db 고유의 문법과 방언 각각 다른 에러코드 에러코드 관련해서는 일단 구현체는 만들기 쉽고 거의 있음 기본 -\u0026gt; 약간의 상태값을 가진 SQLException SQLException은 사실상 복구 불능 checked로 던질 이유가 없어서 jdbc가 바꿔서 던져줌 DataAccessException : 엄청 상세한 서브클래스를 제공 BadSqlGrammarException, DataIntegrityViolationException,DuplicatedException 근데 문제는 db마다 에러코드 자체가 다름 Transaction 동기화 jdbc의 예시에서 트랜잭션의 경계설정이 필요한 경우 :\n커넥션이 필요함 커넥션에 AutoCommit을 false로 설정하는 설정을 진행 이후 commit(), rollback()의 트랜잭션 종료를 명시적으로 수행해줘야함 그 커넥션을 여기저기 계층에 전달시켜야함 (메서드 파라미터 지저분해짐, 커넥션을 서비스에서 여기저기 전달해줘야함, 그리고 dao가 전달받은 커넥션을 사용해야한다는것은 dao, service에서 특정 인터페이스에 대한 종속을 야기\u001b) 당장 JTA (Java Transaction API), Hibernate, JDBC등 다양한 인터페이스가 있는데 특정 인터페이스에 의존성이 생기는 상황을 막기 위해 트랜잭션을 추상화한다.\n기본적으로\n커넥션을 저장하는 저장소를 통해서 동기화 트랜잭션 경계 설정 등 관련한 공통 성질을 인터페이스로 추상화 해뒀음 : PlatformTransactionManager 이 인터페이스의 적절한 구현체를 사용하면서 트랜잭션을 이용할 수 있음 예를들어 JTA가 필요하다면 JTATransactionManager, JPATransactionManager 등 당연히 구현체를 직접 쓰는건 아쉬운 선택이니까 DI를 고려하게 되는데, PlatformTransactionManager는 싱글톤으로 사용해도 안전함 이부분은 나도 예전에 rust로 프로젝트를 했을 때, 엄청 고민을 많이했던 부분인데 뭔가 확실히 스프링은 해주는게 많다는걸 다시 느꼈다.\n여기처럼 트랜잭션 매니저를 직접 구현해서\nuse sqlx::{Pool, Postgres, Transaction}; use std::sync::Arc; use crate::error::db_error::DbError; #[derive(Clone)] pub struct TransactionManager { pool: Arc\u0026lt;Pool\u0026lt;Postgres\u0026gt;\u0026gt;, } impl TransactionManager { pub fn new(pool: Pool\u0026lt;Postgres\u0026gt;) -\u0026gt; Self { Self { pool: Arc::new(pool), } } pub async fn begin_tx(\u0026amp;self) -\u0026gt; Result\u0026lt;Transaction\u0026lt;\u0026#39;static, Postgres\u0026gt;, DbError\u0026gt; { self.pool .begin() .await .map_err(|e| DbError::SomethingWentWrong(e.to_string())) } } 서비스에서 주입받고 #[derive(Clone)] pub struct UserTicketService { tx_manager: Arc\u0026lt;TransactionManager\u0026gt;, user_ticket_repo: Arc\u0026lt;dyn UserTicketRepositoryTrait\u0026gt;, } 아래처럼 사용했었다. pub async fn create_tickets_for_users( \u0026amp;self, user_ids: Vec\u0026lt;i32\u0026gt;, ) -\u0026gt; Result\u0026lt;Vec\u0026lt;TicketCreationResult\u0026gt;, ApiError\u0026gt; { let mut tx = self .tx_manager .begin_tx() .await .map_err(ApiError::Db)?; let mut results = Vec::new(); for user_id in user_ids { let ticket_result = self .user_ticket_repo .create_ticket_in_tx(\u0026amp;mut tx, user_id) .await .map_err(|e| ApiError::Db(DbError::SomethingWentWrong(e.to_string())))?; results.push(ticket_result); } tx.commit() .await .map_err(|e| ApiError::Db(DbError::SomethingWentWrong(e.to_string())))?; Ok(results) } 당시에도 이 책에서 읽은 내용이 생각나서 비슷하게 따라해본 것 도 있지만, 스프링 특유의 di집착이 지금생각하면 좋은 습관처럼 남아있게되어 이러한 부분을 인지시켜주나 싶긴 하다. 실제로도 책을 다시 읽으면서 아래와 같은 문장을 다시 보니까 그냥 생각나서 주저리 한 이야기 객체지향 기술이나 패턴을 익히고 적용하는일이 어렵고 지루하게 느껴진다면, 스프링에서 DI가 어떻게 적용되고 있는지를 살펴보면서 이를 따라해보는것도 좋은 방법이다. 그러면서 좋은 코드의 특징이 무엇이고, 가치가 있는지 살펴보는 것이다. (중략) 스프링을 열심히 사용하다보면, 어느 날 자신이 만든 코드에 객체지향 원칙과 디자인 패턴의 장점이 잘 녹아있다는 사실을 발견하게 될 것 이다. 그것이 스프링을 사용함으로써 얻을 수 있는 가장 큰 장점이다.\n일반적으로 서비스 추상화라고 하면 트랜잭션과 같이 기능은 유사하나 사용 방법이 다른 로우레벨의 다양한 기술에 대해 추상 인터페이스와 일관성 있는 접근 방법을 제공해주는 것을 말한다. 반면 MailService와 같이 테스트를 어렵게 만드는 건전하지 않은 방식으로 설계된 API를 사용할 때도 유용하게 쓰일 수 있다.\nDynamic Proxy와 Proxy Bean 프록시의 특징은 타깃과 같은 인터페이스를 구현했다는 것과 프록시가 타깃을 제어할 수 있는 위치에 있다는 것이다.\n데코레이터 패턴은 타깃에 부가적인 기능을 런타임에 다이나믹하게 부여해주기 위해 프록시를 사용하는 패턴을 말한다.\n프록시로서 동작하는 각 데코레이터는 위임하는 대상에도 인터페이스로 접근하기 때문에 자신이 최종 타깃으로 위임하는지, 아니면 다음 단계의 데코레이터 프록시로 위임하는지 알지 못한다. 그래서 데코레이터의 다음 위임 대상은 인터페이스로 선언하고 생성자나 수정자 메소드를 통해 위임 대상을 위부에서 런타임 시에 주입받을 수 있도록 만들어야 한다.\n// 1. 컴포넌트 인터페이스 정의 interface DataSource { String read(); void write(String data); } // 2. 구체적인 컴포넌트 - 기본 데이터 소스 class FileDataSource implements DataSource { private String fileName; public FileDataSource(String fileName) { this.fileName = fileName; } @Override public String read() { System.out.println(\u0026#34;기본 데이터 읽기: \u0026#34; + fileName); return \u0026#34;원본 데이터\u0026#34;; } @Override public void write(String data) { System.out.println(\u0026#34;기본 데이터 쓰기: \u0026#34; + data + \u0026#34; to \u0026#34; + fileName); } } // 3. 암호화 데코레이터 class EncryptionDecorator implements DataSource { private DataSource wrappee; public EncryptionDecorator(DataSource source) { this.wrappee = source; } @Override public String read() { System.out.println(\u0026#34;암호화 데코레이터: read() 호출 전\u0026#34;); // wrappee가 기본 컴포넌트인지 다른 데코레이터인지 알 수 없음 String data = wrappee.read(); System.out.println(\u0026#34;암호화 데코레이터: wrappee.read() 반환 값: \u0026#34; + data); String decrypted = decrypt(data); System.out.println(\u0026#34;암호화 데코레이터: 복호화 결과: \u0026#34; + decrypted); return decrypted; } @Override public void write(String data) { System.out.println(\u0026#34;암호화 데코레이터: write() 호출됨, 데이터: \u0026#34; + data); String encrypted = encrypt(data); System.out.println(\u0026#34;암호화 데코레이터: 암호화 결과: \u0026#34; + encrypted); // wrappee가 기본 컴포넌트인지 다른 데코레이터인지 알 수 없음 wrappee.write(encrypted); System.out.println(\u0026#34;암호화 데코레이터: wrappee.write() 완료\u0026#34;); } private String encrypt(String data) { return \u0026#34;암호화[\u0026#34; + data + \u0026#34;]\u0026#34;; } private String decrypt(String data) { if (data.contains(\u0026#34;암호화\u0026#34;)) { return data.replace(\u0026#34;암호화[\u0026#34;, \u0026#34;\u0026#34;).replace(\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;); } return \u0026#34;복호화[\u0026#34; + data + \u0026#34;]\u0026#34;; } } // 4. 압축 데코레이터 class CompressionDecorator implements DataSource { private DataSource wrappee; public CompressionDecorator(DataSource source) { this.wrappee = source; } @Override public String read() { System.out.println(\u0026#34;압축 데코레이터: read() 호출 전\u0026#34;); // wrappee가 체인의 마지막인지 알 수 없음 String data = wrappee.read(); System.out.println(\u0026#34;압축 데코레이터: wrappee.read() 반환 값: \u0026#34; + data); String decompressed = decompress(data); System.out.println(\u0026#34;압축 데코레이터: 압축해제 결과: \u0026#34; + decompressed); return decompressed; } @Override public void write(String data) { System.out.println(\u0026#34;압축 데코레이터: write() 호출됨, 데이터: \u0026#34; + data); String compressed = compress(data); System.out.println(\u0026#34;압축 데코레이터: 압축 결과: \u0026#34; + compressed); // wrappee가 체인의 마지막인지 알 수 없음 wrappee.write(compressed); System.out.println(\u0026#34;압축 데코레이터: wrappee.write() 완료\u0026#34;); } private String compress(String data) { return \u0026#34;압축[\u0026#34; + data + \u0026#34;]\u0026#34;; } private String decompress(String data) { if (data.contains(\u0026#34;압축\u0026#34;)) { return data.replace(\u0026#34;압축[\u0026#34;, \u0026#34;\u0026#34;).replace(\u0026#34;]\u0026#34;, \u0026#34;\u0026#34;); } return \u0026#34;압축해제[\u0026#34; + data + \u0026#34;]\u0026#34;; } } // 5. 로깅 데코레이터 class LoggingDecorator implements DataSource { private DataSource wrappee; public LoggingDecorator(DataSource source) { this.wrappee = source; } @Override public String read() { System.out.println(\u0026#34;로깅 데코레이터: read() 호출 전\u0026#34;); String result = wrappee.read(); System.out.println(\u0026#34;로깅 데코레이터: wrappee.read() 반환 값: \u0026#34; + result); return result; } @Override public void write(String data) { System.out.println(\u0026#34;로깅 데코레이터: write() 호출됨, 데이터: \u0026#34; + data); wrappee.write(data); System.out.println(\u0026#34;로깅 데코레이터: wrappee.write() 완료\u0026#34;); } } // 6. 클라이언트 코드 public class DecoratorPatternDemo { public static void main(String[] args) { // 기본 컴포넌트 System.out.println(\u0026#34;=== 데코레이터 체인 생성 시작 ===\u0026#34;); DataSource source = new FileDataSource(\u0026#34;data.txt\u0026#34;); System.out.println(\u0026#34;기본 컴포넌트 생성: FileDataSource\u0026#34;); // 암호화 데코레이터로 감싸기 source = new EncryptionDecorator(source); System.out.println(\u0026#34;1번째 데코레이터 추가: EncryptionDecorator\u0026#34;); // 압축 데코레이터로 감싸기 source = new CompressionDecorator(source); System.out.println(\u0026#34;2번째 데코레이터 추가: CompressionDecorator\u0026#34;); // 로깅 데코레이터로 감싸기 source = new LoggingDecorator(source); System.out.println(\u0026#34;3번째 데코레이터 추가: LoggingDecorator\u0026#34;); // 데이터 쓰기 - 연쇄적 호출 시작 System.out.println(\u0026#34;\\n=== 데이터 쓰기 연쇄 호출 시작 ===\u0026#34;); source.write(\u0026#34;테스트 데이터\u0026#34;); System.out.println(\u0026#34;=== 데이터 쓰기 연쇄 호출 완료 ===\\n\u0026#34;); // 데이터 읽기 - 연쇄적 호출 시작 System.out.println(\u0026#34;\\n=== 데이터 읽기 연쇄 호출 시작 ===\u0026#34;); String result = source.read(); System.out.println(\u0026#34;=== 데이터 읽기 연쇄 호출 완료 ===\u0026#34;); System.out.println(\u0026#34;최종 결과: \u0026#34; + result); } } 일반적으로 사용하는 프록시라는 용어와 디자인 패턴에서 말하는 프록시 패턴은 구분할 필요가 있다. 전자는 클라이언트와 사용 대상 사이에 대리 역할을 맡은 오브젝트를 두는 방법을 총칭한다면,\n후자는 프록시를 사용하는 방법중에서 타깃에 대한 접근방법을 제어하려는 목적을 가진 경우를 가리킨다.\n프록시 패턴의 프록시는 타깃의 기능을 확장하거나 추가하지 않는다. 대신 클라이언트가 타깃에 접근하는 방식을 변경해준다.\n리플렉션 리플렉션은 자바의 코드 자체를 추상화해서 접근하도록 만든 것이다.\n다이나믹 프록시 런타임시 프록시 팩토리에 의해 만들어지는 오브젝트 타겟의 인터페이스와 같은 타입으로 만들어짐 프록시로서 필요한 부가기능 제공 코드는 직접 작성 필요. interface Hello { String sayHello(String name); String sayHi(String name); String sayThankyou(String name); } class HelloTarget implements Hello { @Override public String sayHello(String name) { return \u0026#34;Hello \u0026#34; + name; } @Override public String sayHi(String name) { return \u0026#34;Hi \u0026#34; + name; } @Override public String sayThankYou(String name) { return \u0026#34;Thank you \u0026#34; + name; } } public class UpperCaseHandler implement InvocationHandler { Hello target; public UpperCaseHandler(Hello target) { this.target = target; } public Object invoke(Object proxy, Method method, Objects[] args) throws Throwable { String ret = (String) method.invoke(target, args); return ret.toUpperCase(); } } ... Hello proxiedHello = (Hello) Proxy.newProxyInstance( Hello.class.getClassLoader(), // 클래스 로더 new Class[]{Hello.class}, // 구현할 인터페이스들 new UpperCaseHandler(new HelloTarget()) // 프록시 인스턴스의 메서드 호출을 처리할 InvocationHandler ); 문제는 이렇게 newProxyInstance()를 통해 만들어진 다이나믹 프록시를 빈등록해서 DI를 할수 없다는것 그래서 팩토리 빈을 사용 public interface FactoryBean\u0026lt;T\u0026gt; { T getObject() throws Exception; Class\u0026lt;? extends T\u0026gt; getObjectType(); boolean isSingleton(); } 이 인터페이의 구현체를 스프링 빈으로 등록하면 팩토리 빈으로 동작하며 getObject()를 빈으로 관리해줌 다이나믹 프록시를 적용한 TransactionInterceptor의 동작 방식 정리 인터셉터 구조:\nMethodInterceptor 인터페이스를 구현한다. AOP 프록시 체인에서 메서드 호출을 가로채 트랜잭션 로직을 추가한다. public class TransactionInterceptor extends TransactionAspectSupport implements MethodInterceptor, Serializable { @Override public Object invoke(MethodInvocation invocation) throws Throwable { // 트랜잭션 처리 로직 return invokeWithinTransaction(invocation.getMethod(), invocation.getTargetClass(), invocation::proceed); } } invoke() 메서드:\ninvoke(MethodInvocation invocation) 메서드가 핵심. 타겟 메서드 호출을 가로채 트랜잭션 처리 로직을 적용한다. 트랜잭션 속성 결정:\nTransactionAttributeSource를 사용해 메서드에 적용할 트랜잭션 속성을 결정한다. @Transactional 애노테이션 설정에서 속성을 가져온다. TransactionAttributeSource tas = getTransactionAttributeSource(); TransactionAttribute txAttr = tas.getTransactionAttribute(method, targetClass); 트랜잭션 처리 과정:\n// invokeWithinTransaction 메서드의 핵심 로직 protected Object invokeWithinTransaction(Method method, Class\u0026lt;?\u0026gt; targetClass, InvocationCallback invocation) throws Throwable { // 1. 트랜잭션 속성 및 트랜잭션 매니저 조회 TransactionAttributeSource tas = getTransactionAttributeSource(); TransactionAttribute txAttr = tas.getTransactionAttribute(method, targetClass); PlatformTransactionManager tm = determineTransactionManager(txAttr); // 2. 트랜잭션 시작 TransactionInfo txInfo = createTransactionIfNecessary(tm, txAttr, methodName); Object retVal; try { // 3. 실제 타겟 메서드 호출 retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // 4. 예외 발생 시 롤백 처리 completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { // 5. 트랜잭션 리소스 정리 cleanupTransactionInfo(txInfo); } // 6. 트랜잭션 커밋 commitTransactionAfterReturning(txInfo); return retVal; } 트랜잭션 생성 로직:\ncreateTransactionIfNecessary 메서드는 속성과 현재 상태에 따라 트랜잭션을 시작하거나 참여한다. 트랜잭션 전파 속성에 따라 다른 동작을 수행한다. protected TransactionInfo createTransactionIfNecessary(PlatformTransactionManager tm, TransactionAttribute txAttr, String joinpointIdentification) { // 트랜잭션 상태 조회 TransactionStatus status = tm.getTransaction(txAttr); return prepareTransactionInfo(tm, txAttr, joinpointIdentification, status); } 예외 처리 및 롤백 결정:\ncompleteTransactionAfterThrowing 메서드로 예외 유형에 따라 롤백 여부를 결정한다. protected void completeTransactionAfterThrowing(TransactionInfo txInfo, Throwable ex) { if (txInfo != null \u0026amp;\u0026amp; txInfo.hasTransaction()) { if (txInfo.transactionAttribute.rollbackOn(ex)) { // 롤백 조건 만족 시 롤백 수행 txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); } else { // 롤백 조건 미만족 시 커밋 수행 txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); } } } 트랜잭션 연결:\nTransactionSynchronizationManager를 통해 트랜잭션 리소스를 현재 실행 스레드와 연결한다. // DataSourceTransactionManager의 예 protected void doBegin(Object transaction, TransactionDefinition definition) { // 커넥션 획득 및 설정 Connection con = DataSourceUtils.getConnection(dataSource); // 트랜잭션 속성 설정 con.setAutoCommit(false); // 현재 스레드에 리소스 바인딩 TransactionSynchronizationManager.bindResource(dataSource, new ConnectionHolder(con)); // 트랜잭션 동기화 활성화 TransactionSynchronizationManager.initSynchronization(); } 참고 : [[스프링-트랜잭션-정리]]\nTLDR 컨텍스트에서 트랜잭션 관리 기능이 중복됨 프록시를 통해 트랜잭션 관리를 해주는 데코레이터를 추가 해당 데코레이터를 자동으로 만들어주는 다이나믹 프록시 기능이 있음 다이나믹 프록시는 타겟의 인터페이스 정보를 바탕으로 리플렉션을 이용해서 인터페이스의 메소드와 아규먼트를 가로채서 전달해줌 다이나믹 프록시를 생성하려면 데코레이터에 InvocationHandler를 구현해놔야하는데, 여기서 override하는 invoke()메소드는 프록시가 호출되었을때, method(리플렉션의)와 arguments들을 전달받음 즉 구현한 invoke()메서드 안에서 데코레이팅 로직을 수행하고, 타겟의 메서드를 호출해주는식 그리고 이 다이나믹 프록시를 빈등록해야하는데, 그게 생성자통해서 오브젝트가 생성되는 구조가 아니기 때문에 FactoryBean을 구현해서 빈을 등록 즉 아래처럼 등록된 서비스에 트랜잭션 기능을 일괄 적용한다면 \u0026lt;bean id=\u0026#34;someServiceTarget\u0026#34; class=\u0026#34;complex.module.SomeServiceImpl\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;someDao\u0026#34; ref=\u0026#34;someDao\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 이처럼 구현해서 풀 수 있다.\n\u0026lt;bean id=\u0026#34;someService\u0026#34; class=\u0026#34;springprjt.service.TxProxyFactoryBean\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;target\u0026#34; ref=\u0026#34;someServiceTarget\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;transactionManager\u0026#34; ref=\u0026#34;transactionManager\u0026#34; /\u0026gt; \u0026lt;property name=\u0026#34;serviceInterface\u0026#34; ref=\u0026#34;complex.module.CoreService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; 프록시가 좋음에도 프록시를 구현하지 않았던 두가지 이유\n프록시를 적용할 대상이 구현하고 있는 인터페이스를 구현하는 프록시 클래스를 일일히 만들어야함 부가적인 기능이 여러 메소드에 반복되어 나타나게됨 을 해결한것 1번은 리플렉션 기반의 동적 프록시를 이용해서 인터페이스 없이 Method의 추상화와 argument전달등을 통해 2번은 1번이 되니까 (reflection을 통해 타겟 인터페이스를 모르는 상태로 호출하는게 되니까) 한번만 invoke()해도 되니까 해결됨 근데 또 프록시 팩토리 빈의 한계 하나의 클래스 안에 존재하는 여러 개의 메소드에 부가기능을 한 번에 제공하는건 어렵지 않지만, 한번에 여러개의 클래서에 공통적인 부가기능을 제공해야 한다면? 하나의 타겟에 여러개 제공도 xml설정이 엄청 늘어난다면? 그리고 TransactionHandler가 엄청나게 많아지는 이슈 (오브젝트 수가) ProxyFactoryBean 자바에는 jdk에서 제공하는 다이나믹 프록시 외에도 편리하게 프록시를 만들 수 있도록 지원해주는 다양한 기술이 존재한다. 따라서 스프링은 일관된 방법으로 프록시를 만들 수 있게 도와주는 추상 레이어를 제공한다.\n스프링의 ProxyFactoryBean은 프록시를 생성해서 빈 오브젝트로 등록하게 해주는 팩토리 빈이다. 기존 FactoryBean과는 달리 ProxyFactoryBean은 순수하게 프록시를 생성하는 작업만을 담당하고 프록시를 통해 제공해줄 부가기능은 별도의 빈에 둘 수 있다. 그리고 여기서 생성하는 프록시에서 사용할 부가기능은 MethodInterceptor인터페이스를 통해서 만든다. MethodInterceptor는 InvocationHanlder와 비슷하지만 한가지 다른점이 있는데, invoke()메소드는 타깃 오브젝트에 대한 정보를 제공하지 않는다는 것이다. 그래서 타겟에 대한 정보는 InvocationHanlder를 구현한 클래스가 직접 알고 있어야 했다. 반면에 MethodInterceptor는 타겟 오브젝트의 정보도 제공받는다. 그래서 타깃 오브젝트와 상관 없이 독립적으로 만들어 질 수 있고, 타겟이 다른 여러 프록시에서 함께 사용할 수있다. 어드바이스: 타깃이 없는 순수한 부가기능 MethodInvocation은 일종의 콜백 오브젝트로, proceed() 메소드를 실행하면 타깃 오브젝트의 메소드를 내부적으로 실행해주는 기능이 있다. \u0026ldquo;그렇다면 MethodInvocation 구현 클래스는 일종의 공유 가능한 탬플릿처럼 동작하는 것이다.\u0026rdquo; ProxyFactoryBean은 작인 단위의 탬플릿/콜백 구조를 응용해서 적용했기 때문에 탬플릿 역할을 하는 MethodInvocation을 싱글톤으로 두고 공유할 수 있다. 마치 SQL 파라미터 정보에 종속되지 않는 JdbcTemplate이기 때문에 수많은 DAO메서드가 하나의 jdbcTemplate 오브젝트를 공유할 수 있는 것과 마찬가지이다.\nMethodInterceptor처럼 타겟 오브젝트에 적용하는 부가기능을 담은 오브젝트를 스프링에서는 어드바이스라고 부른다.\n타겟의 인터페이스 타입을 제공받지 않고도 ProxyFactoryBean은 어떻게 인터페이스를 구현한 프록시를 만들어 낼 수 있을까? 그냥 자동 검출 기능이 있음.. 뭐 리플렉션에서 받아오겠지?\n포인트컷: 부가기능 적용 대상 메서드 선정 방법 템플릿/콜백 구조를 응용했고, 싱글톤 빈으로 해둔 덕분에 여러 프록시가 공유해서 사용할 수 있지만, 대신 어떤 메소드가 호출될지와 같은 구현과 관련한 부가정보를 담을수는 없다. MethodInterceptor는 InvocationHandler와는 다르게 프록시가 클라언트로부터 받는 요청을 일일이 전달받을 필요는 없다. MethodInterceptor에는 재사용 가능한 순수한 부가기능 제공 코드만 남겨주는 것이다. 대신 프록시에 부가기능 적용 메소드를 선택하는 기능을 넣는다. 물론 프록시의 핵심 가치는 티겟을 대신해서 클라이언트의 요청을 받아 처리하는 오브젝트로서의 존재 자체이므로 메소드를 선별하는 기능은 프록시로부터 다시 분리하는 편이 낫다. 기존 InvocationHandler 오브젝트는, 오브젝트 차원에서 특정 타겟을 위한 프록시에 제한된다는 뜻이다. 그래서 InvocationHandler는 굳이 빈으로 등록하는 대신 팩토리 내부에서 매번 생성하도록 만들었던 것이다.\n스프링은 부가기능을 제공하는 오브젝트를 어드바이스라고 부르고, 메소드 선정 알고리즘을 담은 오브젝트를 포인트컷이라고 부른다. 어드바이스와 포인트컷은 모두 프록시에 DI로 주입돼서 사용된다. 두가지 모두 여러 프록시에서 공유가 가능하도록 만들어지기 때문에 싱글톤 빈으로 등록이 가능하다.\n프록시는 클라이언트로부터 요청을 받으면 먼저 포인트컷에게 부가기능을 부여할 메소드인지를 확인해달라고 요청한다. 포인트컷은 Pointcut 인터페이스를 구현해서 만들면 된다. 프록시는 포인트컷으로부터 부가기능을 적용할 대상 메소드인지 확인 받으면, MethodInterceptor 타입의 어드바이스를 호출한다. 어드바이스는 jdk의 다이나믹 프록시처럼 직접 타겟을 호출하지 않는다. 자신이 공유돼야 하므로 타깃 정보라는 상태를 가질 수 없다. 따라서 타겟에 직접 의존하지 않도록 일종의 템플릿 구조로 설계되어 있다. 어드바이스가 부가기능을 부여하는 중에 타깃 메소드의 호출이 필요하면 프록시로부터 전달받은 MethodInvocation 타입 콜백 오브젝를 실행하기 때문이다.\n실제 위임 대상인 타겟 오브젝트의 레퍼런스를 갖고 있고, 이를 이용해 타겟 메소드를 직접 호출하는 것은 프록시가 메소드 호출에 따라 만드는 Invocation 콜백의 역할이다.\n@Test public void pointcutAdvisor() { ProxyFactoryBean pfBean = new ProxyFactoryBean(); pfBean.setTarget(new HelloTarget()); NameMatchPoincut poincut = new NameMatchPointCut(); poincut.setMappedName(\u0026#34;sayH*\u0026#34;); // Pointcut Advice 같이 전달 // 여러 포인트컷과 어드바이스를 매핑할 수 있기에 이렇게 두개 전다. // 어드바이저 = 포인트컷 + 어드바이스 pfBean.addAdvisor(new DefaultPointcutAdvisor(pointcut, new UppercaseAdvice())); Hello proxiedHello = (Hello) pfBean.getObject(); assertThat(proxiedHello.sayHello(\u0026#34;Toby\u0026#34;), is(\u0026#34;HELLO TOBY\u0026#34;)); assertThat(proxiedHello.sayHello(\u0026#34;Toby\u0026#34;), is(\u0026#34;HI TOBY\u0026#34;)); assertThat(proxiedHello.sayHello(\u0026#34;Toby\u0026#34;), is(\u0026#34;Thank You TOBY\u0026#34;)); } 지금까지 해왔던 작업의 목표는 비즈니스 로직에 반복적으로 등장해야만 했던 트랜잭션 코드를 깔끔하고 효과적으로 분리해내는 것이다. 이렇게 분리해낸 트랜잭션 코드는 투명한 부가기능 형태로 제공돼야 한다. 투명하다는건 부가기능을 적용한 후에도 기존 설계와 코드에는 영향을 주지 않는다는 뜻이다/\n빈 후처리기를 이용한 자동 프록시 생성기 스프링 빈 오브젝트로 만들어지고 난 이후에 오브젝트를 다시 가공하는 인터페이스 DafaultAdvisorAutoProxyCreator : 자동 프록시 생성기 -\u0026gt; 빈을 만들때마다 후처리기로 보내고, 여기서 모든 어드자이저 내의 포인트컷을 뒤지고 대상이라면 그때 프록시를 만들어 어드바이저를 연결해준다. 이건 아래의 인터페이스를 보면 알 수 있듯, Pointcut이 클래스필터와 메소드 매처 두가지를 돌려주는 메소드를 가지고 있기 때문에 가능하다. public interface Pointcut { ClassFilter getClassFilter(); // 프록시를 적용할 클래스인지 확인 MethodMatcher getMethodMatcher(); // 어드바이스를 적용할 메소드인지 확\u001b인 } Aspect란 그 자체로 애플리케이션의 핵심 기능을 담고 있지는 않지만, 애플리케이션을 구성하는 중요한 한 가지 요소이고, 핵심 기능에 부가되어 의미를 갖는 특별한 모듈\nAOP 용어 정리 타겟 : 부가기능을 부여할 대상, 핵심기능을 담은 클래스일 수 있지만 경우에 따라서는 다른 부가기능을 제공하는 또다른 프록시 일 수 있음 어드바이스 : 타겟에 제공할 부가기능을 담은 모듈, 메소드 레벨의 정의도 가능함, 호출 과정 전반에 참여할수도있지만 예외가 동작할때만 동작하는 어드바이스처럼 호출 과정의 일부에만 동작할수도 있음 조인 포인트 : 어드바이스가 적용될 수 있는 위치 포인트컷 : 어드바이스를 적용할 조인 포인트를 선별하는 작업 또는 그 기능을 정의한 모듈 프록시 : 클라이언트와 타겟 사이에 투명하게 존재하면서 부가기능을 제공하는 오브젝트 어드바이저: 포인트컷과 어드바이스를 하나씩 가지고 있는 오브젝트, 어떤 부가기능을 어디에 전달할 것인가를 알고있는 가장 기본 모듈 프록시 방식 aop는 같은 타겟 오브잭트 내의 메소드를 호출할 때는 적용되지 않는다 클라이언트가 호출하면 프록시가 호출되고 트랜잭션 프록시를 타게된다, 다만 타겟 오브젝트 내에서 다른 메소드를 호출하는 경우에는 직접 호출된다. 기껏해야 get으로 시작하는 메서드에 읽기전용 속성을 부여하고 REQUIRED전파 속성을 사용하는 정도에는 무시해도 된다. 다만 복잡한 트랜잭션 전파속성을 적용해야하는 경우는 주의가 필요하다.\n읽기전용 속성은 데이터베이스 최적화를 위한 힌트일 뿐이다. REQUIRED 전파 속성은 이미 트랜잭션이 있으면 그것을 사용하므로 내부 호출에도 트랜잭션 컨텍스트가 유지된다. 해결방법은 두가지이다. Aspectj 사용 스프링 API를 이용해 프록시 오브젝트에 대한 레퍼런스를 가져온 뒤에 같은 오브젝트의 메소드 호출도 프록시를 타게 강제하는 방법 -\u0026gt; 권장하지 않는다. Transactional 어노테이션 @Target({ElementType.METHOD, ElementType.TYPE}) // 어노테이션 사용 대상 @Retention(RetentionPolicy.RUNTIME) // 어노테이션 정보 유지 기한 @Inherited // 상속해도 가능하도록 @Documented public @interface Transactional { String value() default \u0026#34;\u0026#34;; Propagation propagation() default Propagation.REQUIRED; Isolation isolation() default Isolation.Default; ... } 자바 ORM 표준 JPA 프로그래밍 영속성 컨텍스트가 엔티티관리하는 장점 1차 캐시 : 영속성 컨텍스트의 캐시는 인스턴스를 캐시하므로 동일성이 보장됨 + 어플리케이션 레벨의 REPEATABLE READ 동일성 보장 트랜잭션을 지원하는 쓰기 지연 변경 감지 지연 로딩 결론적으로 그냥 db io를 줄여줌, jpa, hibernate 크게는 orm의 독자적인 장점으로 보기는 어렵지만 생태계가 이쪽으로 발전했기 때문에 이만큼 해주는게 없지않나 싶음, 난이도나 공수가 올라가거나\njpa 수정 @org.hibernate.annotations.DynamicUpdate : 특정 칼럼만 업데이트 하는 update쿼리를 작성해줌, 오버헤드를 따져봤을때 칼럼 30개이상은 되어야 유의미한것같음 [[양방향-순환참조]]\n프록시와 지연로딩 // 내부적으로 생성되는 프록시 클래스의 이론적 구조 public class MemberProxy extends Member { private Member target = null; @Override public String getName() { if (target == null) { // 초기화 요청 initializeTarget(); } return target.getName(); } private void initializeTarget() { // 영속성 컨텍스트를 통해 실제 엔티티 로딩 // target 필드에 할당 } } 위는 이론적 구조이고, 실제는 자바 바이트코드 조작 라이브러리를 이용해서 처리됨\n컬렉션을 하나 이상 즉시 로딩하는것은 권장하지 않음, 컬렉션과 조인한다는것은 일대다 조인으로 이뤄지는데 n x m 조인이 이루어지는경우가 생김 그리고 외부조인으로 사용되기때문에 더더욱 안됨 컬렉션 즉시 로딩(EAGER)의 문제점 카테시안 곱(Cartesian Product) 문제 여러 컬렉션을 즉시 로딩하면 SQL JOIN에서 N × M 개의 결과 행이 발생함 이는 애플리케이션에 불필요한 데이터가 로드되어 성능과 메모리에 심각한 영향을 미침 외부 조인(OUTER JOIN) 사용 JPA는 일대다 관계에서 기본적으로 외부 조인을 사용함 여러 외부 조인은 쿼리 성능을 더욱 저하시킴 엔티티 클래스 @Entity public class User { @Id @GeneratedValue private Long id; private String name; @OneToMany(mappedBy = \u0026#34;user\u0026#34;, fetch = FetchType.EAGER) private List\u0026lt;Order\u0026gt; orders = new ArrayList\u0026lt;\u0026gt;(); @OneToMany(mappedBy = \u0026#34;user\u0026#34;, fetch = FetchType.EAGER) private List\u0026lt;Post\u0026gt; posts = new ArrayList\u0026lt;\u0026gt;(); } @Entity public class Order { @Id @GeneratedValue private Long id; private String orderNumber; @ManyToOne private User user; } @Entity public class Post { @Id @GeneratedValue private Long id; private String title; @ManyToOne private User user; } 샘플 데이터 User 테이블:\nid name 1 Alice 2 Bob Order 테이블:\nid order_number user_id 1 ORD-001 1 2 ORD-002 1 3 ORD-003 2 Post 테이블:\nid title user_id 1 First Post 1 2 Second Post 1 3 Hello World 2 4 My Story 2 생성되는 SQL 예시 SELECT u.*, o.*, p.* FROM User u LEFT OUTER JOIN Order o ON u.id = o.user_id LEFT OUTER JOIN Post p ON u.id = p.user_id 결과 (N × M 문제) u.id u.name o.id o.order_number o.user_id p.id p.title p.user_id 1 Alice 1 ORD-001 1 1 First Post 1 1 Alice 1 ORD-001 1 2 Second Post 1 1 Alice 2 ORD-002 1 1 First Post 1 1 Alice 2 ORD-002 1 2 Second Post 1 2 Bob 3 ORD-003 2 3 Hello World 2 2 Bob 3 ORD-003 2 4 My Story 2 문제점 설명:\nUser \u0026lsquo;Alice\u0026rsquo;가 2개의 주문과 2개의 게시물을 가지고 있어 4개의 행이 생성됨(2×2=4) User \u0026lsquo;Bob\u0026rsquo;이 1개의 주문과 2개의 게시물을 가지고 있어 2개의 행이 생성됨(1×2=2) 원래 User는 2명이지만, 결과 행은 총 6개로 증가함 데이터가 불필요하게 중복되어 메모리 사용량 증가 및 성능 저하 대안 지연 로딩(LAZY) 사용 컬렉션은 항상 지연 로딩으로 설정하고 필요할 때만 로딩 페치 조인(Fetch Join) 사용 // 필요한 컬렉션만 선택적으로 로딩 String jpql = \u0026#34;SELECT u FROM User u JOIN FETCH u.orders WHERE u.id = :id\u0026#34;; User user = em.createQuery(jpql, User.class) .setParameter(\u0026#34;id\u0026#34;, userId) .getSingleResult(); @EntityGraph 사용 @EntityGraph(attributePaths = {\u0026#34;orders\u0026#34;}) @Query(\u0026#34;SELECT u FROM User u WHERE u.id = :id\u0026#34;) User findUserWithOrders(@Param(\u0026#34;id\u0026#34;) Long id); DTO 사용 @Query(\u0026#34;SELECT new com.example.UserOrderDTO(u.id, u.name, o.id, o.orderNumber) \u0026#34; + \u0026#34;FROM User u JOIN u.orders o WHERE u.id = :id\u0026#34;) List\u0026lt;UserOrderDTO\u0026gt; findUserOrderDTOs(@Param(\u0026#34;id\u0026#34;) Long id); 배치 사이즈 조정 (@BatchSize) @OneToMany(mappedBy = \u0026#34;user\u0026#34;, fetch = FetchType.LAZY) @BatchSize(size = 100) private List\u0026lt;Order\u0026gt; orders = new ArrayList\u0026lt;\u0026gt;(); N+1 문제는 여전히 발생하지만, IN 쿼리를 사용해 한 번에 여러 컬렉션을 로딩하도록 최적화 영속성전이와 고아객체 영속성 전이 부모 엔티티의 영속성 상태 변화가 자식 엔티티에게도 전이되는 기능 예를 들어 부모를 persist(), remove() 하면 자식도 같이 persist(), remove() 됨 주로 @OneToMany, @ManyToOne, @OneToOne 관계에서 사용 옵션 설명 PERSIST 부모 저장 시 자식도 저장 REMOVE 부모 삭제 시 자식도 삭제 MERGE 부모 갱신 시 자식도 갱신 DETACH 부모 detach 시 자식도 detach REFRESH 부모 refresh 시 자식도 refresh ALL 위의 모든 기능 포함 고아객체 부모와의 관계가 끊어진(연관관계가 제거된) 자식 엔티티를 자동으로 remove() 처리하는 기능 물리적으로 DB에서 자식 row를 삭제함 orphanRemoval = true 로 설정 동작 조건\n자식이 부모 컬렉션에서 제거되거나, 부모 엔티티와의 연관관계가 끊어질 때 보통 정말 명확하면 : CascadeType.ALL + orphanRemoval = true 애매하면 : CascadeType.PERSIST ","permalink":"http://localhost:1313/_wiki/%EC%8A%A4%ED%94%84%EB%A7%81%EB%B6%80%ED%8A%B8/","summary":"토비의 스프링 관심사 \u0026ldquo;모든 변경과 발전은 한가지 관심에 집중해서 일어난다. 문제는 다만 그에 따른 변경이 한가지 관심에 집중해 있지 않다는 것이다. 그래서 우리가 해야 할 일은, 한가지 관심이 한군데 집중되게 하는 것이다.\u0026rdquo;\n관계 모델링 시점의 오브젝트 간 관계를 기반으로, 런타임 오브젝트 관계를 갖는 구조를 만들어주는것은 \u0026ldquo;클라이언트의 책임\u0026quot;이다. 클라이언트는 자기가 UserDao를 사용해야 할 입장이기에, UserDao의 세부 전략이라고도 볼 수 있는 구현클래스를 선택하고 선택한 클래스의 오브젝트를 생성해서 연결해줄 수 있다.\nOCP 클래스나 모듈은 확장에는 열려있어야 하고, 변경에는 닫혀있어야 한다.","title":"스프링 부트 관련 🌿"},{"content":"2024-02-03 197. Rising Temperature LeetcodeLink\n처음쿼리 2000ms\nselect W1.id from Weather W1 join Weather W2 on DATEDIFF(W1.recordDate, W2.recordDate) = 1 where W1.temperature \u0026gt; W2.temperature; 인덱스 타도록 개선 800ms\nselect W1.id from Weather W1 join Weather W2 on W1.recordDate = W2.recordDate + INTERVAL 1 DAY where W1.temperature \u0026gt; W2.temperature; 다른 사람들의 쿼리들도 봤는데, 날짜 제한같은 편법들을 이용한거 외에는 고성능 쿼리는 없는 것 같다. 셀프조인이나 셀프조인과 다름없는 쿼리들과 비슷한 맥락\n1661. Average Time of Process per Machine LeetcodeLink\nselect a1.machine_id, ROUND(AVG(a2.timestamp - a1.timestamp),3) as processing_time from Activity a1 join Activity a2 on a1.process_id = a2.process_id and a1.machine_id = a2.machine_id and a1.timestamp \u0026lt; a2.timestamp group by a1.machine_id; 서브쿼리로도 풀 수 있긴 한데, 이게 차라리 깔끔한 것 같다. 근데 왜 easy지..\n577. Employee Bonus LeetcodLink\nselect name, bonus from Employee left join Bonus on Employee.empId = Bonus.empId where bonus \u0026lt; 1000 or bonus is null; 바로 다음 문제인데, 왜 이것들이 같이 묶여있는지 모르겠다. 이런건 스킵해야겠다.\n2025-02-05 LeecodeLink\nselect s.student_id, s.student_name, sub.subject_name, coalesce(count(e.student_id), 0) as attended_exams from students s join subjects sub on 1=1 left join examinations e on s.student_id = e.student_id and sub.subject_name = e.subject_name group by s.student_id, s.student_name, sub.subject_name order by s.student_id, sub.subject_name; students 테이블과 subjects 테이블을 on 1=1로 단순하게 조인하여 모든 학생과 모든 과목의 조합을 생성 생성된 학생-과목 쌍을 examinations 테이블과 left join으로 연결 coalesce(count(e.student_id), 0)을 사용하여 참석 기록이 없는 경우 0으로 반환 1번을 cross join을 이용해서 가능하다고 하는데, cross join을 쓰는게 생각이 안났다.\nselect m.name from employee e join employee m on e.managerId = m.id group by m.id, m.name having count(e.id) \u0026gt;= 5; 이건 왜 medium일까\n","permalink":"http://localhost:1313/_wiki/interview-queries/","summary":"2024-02-03 197. Rising Temperature LeetcodeLink\n처음쿼리 2000ms\nselect W1.id from Weather W1 join Weather W2 on DATEDIFF(W1.recordDate, W2.recordDate) = 1 where W1.temperature \u0026gt; W2.temperature; 인덱스 타도록 개선 800ms\nselect W1.id from Weather W1 join Weather W2 on W1.recordDate = W2.recordDate + INTERVAL 1 DAY where W1.temperature \u0026gt; W2.temperature; 다른 사람들의 쿼리들도 봤는데, 날짜 제한같은 편법들을 이용한거 외에는 고성능 쿼리는 없는 것 같다. 셀프조인이나 셀프조인과 다름없는 쿼리들과 비슷한 맥락\n1661. Average Time of Process per Machine LeetcodeLink","title":"Coding Interview SQL"},{"content":" 코틀린 완벽 가이드 책과 코드스피츠 유튜브 스터디 영상 내용을 정리하거나 생각을 정리한 문서 (인용 태그를 제외한 모든 텍스트들은 스터디 내용을 필사하거나, 책에서 정리한 내용입니다.)\n출쳐 : 코틀린완벽가이드, 코드스피츠 유튜브 영상\n7장 컬렉션과 I/O 자세히 알아보기 Iterable \u0026ldquo;일반적으로 즉시(eager) 계산되는 상태가 있는(stateful) 컬렉션\u0026rdquo;\n그 외에는 java와 동일\nComparable과 Comparator compareTo() : 자바와 동일, 수신객체 인스턴스가 상대방 인스턴수보다 크면 양수, 같으면 0\ncompareBy() : 비교 가능 객체를 제공\n컬렉션 생성 ~Of() 로 간단하게 생성 가능\nval list = mutableListOf(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;) val mutableMap = mutableMapOf(10 to \u0026#34;Ten\u0026#34;) known element인 시퀀스를 만드는 sequenceOf()가 있으며 기존 컬렉션으로부터 얻는 asSequence()\nsequenceOf(1,2,3).iterator().next() listOf(1,2,3).asSequence().iterator().next() 제네레이터 함수를 바탕으로 시퀀스를 만드는 것도 지원\nval numbers = generateSequence{ readLine()?.toIntOrNull() } val evens = generateSequence(10) { if (it \u0026gt;= 2) it -2 else null } yield(), yieldAll() 도 지원\nval numbers = sequence { yield(0) yieldAll(listOf(1,2,3)) } 컬렉션 접근 first(), last(), firstOrNull(), lastOrNull() : 첫(마지막)원소 접근과 nullsafe\nelementAt() : get()의 일반화된 버전, 다만 random access list가 아닌 컬렉션에서는 접근이 n복잡도를 가짐\n컬렉션 조건 검사 all() : 모든 원소가 조건절을 만족하면 true\nnone() : all과 반대\nany() : 하나라도 만족하는지 여부\n컬렉션 집계 count() : 갯수 반환인데, 오버로딩된 버전이 있다.\nlistOf(1,2,3,4).count { it \u0026lt; 0 } average(), sum() : 평균, 합계값 반환\nminWithOrNull(), maxWithOrNull() minByOrNull(), maxByOrNull()\nclass Person( val firstName: String, val familyName: String, val age: Int ) { val fullName get() = \u0026#34;$firstName $familyName\u0026#34; } val FULL_NAME_COMPARATOR = Comparator\u0026lt;Person\u0026gt; { p1, p2 -\u0026gt; p1.fullName.compareTo(p2.fullName) } fun main() { val persons = sequenceOf( Person(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, 24), Person(\u0026#34;Hello\u0026#34;, \u0026#34;Doe\u0026#34;, 24), Person(\u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;, 26), Person(\u0026#34;Eli\u0026#34;, \u0026#34;Doe\u0026#34;, 25), ) println(persons.minByOrNull { it.firstName }) println(persons.maxByOrNull { it.firstName }) println(persons.minByOrNull { it.age }) println(persons.minWithOrNull(FULL_NAME_COMPARATOR)) println(persons.maxWithOrNull(FULL_NAME_COMPARATOR)) } joinToString()도 따로 있음, 추가적으로 빌더(appendable)을 반환받고싶으면 그냥 joinTo()사용\nreduce(), fold() : 첫 집계값을 이용하기 위해서\n하위 컬렉션 추출 slice, subList, take, drop 등이 있음.\nslice() 함수는 지정된 인덱스 범위의 요소들로 새로운 리스트를 생성\n원본 리스트를 변경하지 않고 새로운 리스트를 반환. IntRange나 List를 인자로 받아 특정 인덱스의 요소들을 선택할 수 있음. val numbers = listOf(10, 20, 30, 40, 50, 60, 70) val slicedNumbers = numbers.slice(1..4) println(slicedNumbers) // [20, 30, 40, 50] subList() 함수는 원본 리스트의 지정된 범위의 뷰를 반환\n원본 리스트의 변경 사항이 subList에도 반영됨. 메모리 효율적이며, 구조적 변경이 필요한 경우에 적합. val numbers = mutableListOf(10, 20, 30, 40, 50, 60, 70) val sublistNumbers = numbers.subList(2, 5) println(sublistNumbers) // [30, 40, 50] sublistNumbers[0] = 99 println(numbers) // [10, 20, 99, 40, 50, 60, 70] take() 함수는 컬렉션의 앞에서부터 지정된 수만큼의 요소를 가져와 새로운 리스트를 생성\n원본 컬렉션을 변경하지 않음. takeLast()를 사용하면 뒤에서부터 요소를 가져올 수 있음. val numbers = (0..10).toList() println(numbers.take(3)) // 출력: [0, 1, 2] println(numbers.takeLast(3)) // 출력: [8, 9, 10] drop() 은 take와 동일하지만 반대 (건너뜀)\nList 리스트 원소 바꾸는 방법 var, 읽기전용 리스트, +- 연산자 사용 자유도가 높음 val, 가변 리스트, MutableList 메서드 사용 효율적임 성능관점에서 Array, IntArray(기본형 배열) 항목 Array IntArray List 타입 Array (객체 타입 배열) Primitive Array (int 배열) List (인터페이스) 저장 방식 객체 타입(Int 객체들) 기본형(int) 저장, 더 가볍고 빠름 객체 타입(Int) 저장 메모리 사용 큼 (박싱(Boxing) 발생) 작음 (No 박싱) 큼 (박싱 발생) 크기 변경 불가 불가 불변(listOf()) or 가변(mutableListOf()) 주요 생성 방법 arrayOf(1, 2, 3) intArrayOf(1, 2, 3) listOf(1, 2, 3) 성능 보통 가장 빠름 가장 느릴 수 있음 메서드 지원 배열 기본 연산 (get, set, size) 배열 기본 연산 (get, set, size) 다양한 컬렉션 연산 (filter, map, groupBy 등) 정렬 자바와 별 차이 없음\n코틀린의 타입 시스템 선요약 클래스는 객체를 생성하는 템플릿, 타입은 객체에 기대하는 바와 기능을 정의 모든 클래스는 두개의 타입, 즉 널 가능한 타입과 널 가능하지 않은 타입을 생성 널 가능한 타입은 널 가능하지 않은 타입의 슈퍼타입 모든 타입의 슈퍼타입은 Any? 모든 타입의 서브타입은 Nothing null의 타입은 Nothing? Nothing을 결과 타입으로 선언한 표현식이 있다면 코틀린 컴파일러는 해당 표현식 뒤에 오는 코드는 도달 불가능하다고 이해한다. Nothing -\u0026gt; Nothing? ↑ ↑ Dog -\u0026gt; Dog? ↑ ↑ Animal -\u0026gt; Animal? ↑ ↑ Any -\u0026gt; Any? Nothing 타입이란?\nNothing은 모든 타입의 하위 타입(subtype)이다. 실제 값을 가질 수 없는 타입이다. 즉, 어떤 값도 Nothing 타입의 인스턴스가 될 수 없다. 주로 “정상적으로 끝나지 않는 코드”에 쓰인다. 예: 무조건 예외를 던지거나, 무한 루프에 빠지는 함수의 반환 타입. throw가 Nothing인 이유\nthrow는 절대 정상적으로 값을 반환하지 않는다. 따라서 throw 표현식의 타입은 Nothing이다. Nothing은 모든 타입의 하위 타입이기 때문에, 어떤 타입이 필요한 곳에서도 throw를 집어넣을 수 있다. 즉, “값이 필요한 곳”에도 throw를 쓸 수 있는 이유가 바로 Nothing 때문이다. fun getLength(str: String?): Int { return str?.length ?: throw IllegalArgumentException(\u0026#34;str is null\u0026#34;) } 이 코드의 의미:\nstr?.length 결과가 null이면, throw를 실행한다. throw는 Nothing이므로 Int 타입이 필요한 ?: 오른쪽 자리에 둘 수 있다. 코드 흐름 설명: str?.length : Int? 타입 ?: : 좌항이 null이면 우항으로 대체 우항인 throw는 타입이 Nothing Nothing은 Int의 서브타입으로 간주되어 문제 없음 결론: throw가 Nothing 타입이기 때문에 ?: 우항에 올 수 있다.\n제네릭 널 불가능 표기 \u0026amp; Any fun \u0026lt;T\u0026gt; T.orThrow(): T \u0026amp; Any = this ?: throw Error() 제약조건 : Type class ListAdapter\u0026lt;T: ItemAdapter\u0026gt;(){} // ItemAdapter의 서브타입만 // 두 개 이상의 경우 fun \u0026lt;T\u0026gt; pet(animal: T) where T : Animal, T: GoodTempered {} // 주로 Iterable, Comparable같은 것들이나, 널체크를 위한 Any도 제약조건으로 자주 쓰임 스타프로젝션 : 구체적인 타입 인수를 지정하고 싶지 않을 때 (소거 관련) a is List\u0026lt;*\u0026gt; // Any? 타입 인수와 혼동하면 안됨 fun main() { val l1: MutableList\u0026lt;Any?\u0026gt; = mutableListOf(\u0026#34;A\u0026#34;) val r1 = l1.first() // r1의 타입은 Any?입니다. l1.add(\u0026#34;B\u0026#34;) // 기대되는 인수 타입은 Any?입니다. val l2: MutableList\u0026lt;*\u0026gt; = mutableListOf(\u0026#34;A\u0026#34;) val r2 = l2.first() // r2의 타입은 Any?입니다. // l2.add(\u0026#34;B\u0026#34;) // 에러 발생 // 기대되는 인수 타입이 Nothing이므로 인수로 어떠한 값도 사용할 수 없습니다. } 언더스코어 연산자 여러개의 타입 인수 중 하나만 지정하고 나머지는 컴파일러가 유추하게 하고 싶을 때 이때 언더스코어를 쓰면 컴파일러가 유추해야 하는 타입 인수를 지정함. // reified는 런타임에 타입정보를 소거시키지 않고 남기도록 하는 키워드 // 그래서 인라인이어야함 // 참고로 이 코드상에서도, 현실적으로도 굳이 * 안쓰고 Any 써도 됨 inline fun \u0026lt;K, reified V\u0026gt; Map\u0026lt;K, *\u0026gt;.filterValueIsInstance(): Map\u0026lt;K, V\u0026gt; = filter { it.value is V } as Map\u0026lt;K, V\u0026gt; fun main() { val props = mapOf( // Map\u0026lt;K, Any\u0026gt; \u0026#34;name\u0026#34; to \u0026#34;Alex\u0026#34;, \u0026#34;age\u0026#34; to 25, \u0026#34;city\u0026#34; to \u0026#34;New York\u0026#34; ) val strProps = props.filterValueIsInstance\u0026lt;_, String\u0026gt;() println(strProps) // {name=Alex, city=New York} } ","permalink":"http://localhost:1313/_wiki/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%99%84%EB%B2%BD-%EA%B0%80%EC%9D%B4%EB%93%9C-7%EC%9E%A5-12%EC%9E%A5/","summary":"코틀린 완벽 가이드 책과 코드스피츠 유튜브 스터디 영상 내용을 정리하거나 생각을 정리한 문서 (인용 태그를 제외한 모든 텍스트들은 스터디 내용을 필사하거나, 책에서 정리한 내용입니다.)\n출쳐 : 코틀린완벽가이드, 코드스피츠 유튜브 영상\n7장 컬렉션과 I/O 자세히 알아보기 Iterable \u0026ldquo;일반적으로 즉시(eager) 계산되는 상태가 있는(stateful) 컬렉션\u0026rdquo;\n그 외에는 java와 동일\nComparable과 Comparator compareTo() : 자바와 동일, 수신객체 인스턴스가 상대방 인스턴수보다 크면 양수, 같으면 0\ncompareBy() : 비교 가능 객체를 제공\n컬렉션 생성 ~Of() 로 간단하게 생성 가능","title":"코틀린 완벽 가이드 간단 정리"},{"content":"Intro 👋 배경 : 본인인증 서비스 리뉴얼하는 태스크를 진행했었다.\nAS-IS 수도코드로 구현한 기존 구조는 아래와 같다.\n마찬가지로 백엔드 로직은 예민할 수 있어 정말 최소한의 수도코드만 작성했다.\n본인인증 시작점\n\u0026lt;button name=\u0026#39;본인인증 버튼\u0026#39; onClick=doAuth() /\u0026gt; \u0026lt;script\u0026gt; function doAuth() { window.afterCallback = afterCallbackFunc; // 윈도우객체에 콜백함수 삽입 window.open(\u0026#39;authWindow\u0026#39;, \u0026#39;/PhoneAuth\u0026#39;) ; // 본인인증 창 열어주기 } \u0026lt;/script\u0026gt; 먼저 callback함수를 윈도우객체에 심는다. callback함수 내부에는 본인인증 이후에 할 행동들(회원가입관련 검증 api를 호출한다던가, 단순 인증완료후 페이지 이동이라던가) 이 정의되어있다. 서버의 엔트리포인트\n@GetMapping(\u0026#34;/PhoneAuth\u0026#34;) public String authEntryPoint() { doingSomeReserveActions(); // 인증을 위한 작업 진행 setReserveDataOnSession(); // 작업 결과 데이터중 특정 값들을 세션에 저장 setDataForCallingModuleOnModel(); // 모델에 본인인증 모듈 호출을 위한 값들을 심어주고 return \u0026#34;authView\u0026#34;; // 뷰를 리턴한다. } 간단하게 소개하면 딱 이정도 인 것 같다. 세션에 인증 예약정보를 심어주고, 모듈 호출을 위한 메타데이터들을 모델에 싣어준다. 서버 엔트리포인트가 반환한 뷰에서\n\u0026lt;form name=\u0026#34;본인인증 폼\u0026#34;\u0026gt; \u0026lt;fieldsFromServer /\u0026gt; \u0026lt;fieldsFromServer /\u0026gt; \u0026lt;fieldsFromServer /\u0026gt; \u0026lt;form /\u0026gt; \u0026lt;script\u0026gt; ... $form.submit(); // 본인인증 사이트 이동! \u0026lt;/script\u0026gt; fieldsFromServer는 위에서 모델에 실어준 데이터고, form을 submit하면서 본인인증사이트로 접근한다. 본인인증 사이트가 콜백해주는 api\n@GetMapping(\u0026#34;/PhoneAuthCallback\u0026#34;) public String authEntryPoint() { setAuthHashOnSession(); // 세션에 인증 완료 데이터를 심는다 setDataOnModel(); // 마찬가지로 인증 결과 데이터를 모델에 싣고 return \u0026#34;afterCallback\u0026#34;; // 뷰를 리턴한다. } 콜백함수가 반환하는 뷰에서\n\u0026lt;div /\u0026gt; \u0026lt;script\u0026gt; var params = getParamsOnModel(); // 본인인증 이후 데이터를 추출해서 opener.afterCallback(...params); // 부모창에 아까 심어뒀던 함수를 호출해주고 window.close(); // 창을 닫아준다. \u0026lt;/script\u0026gt; 아까 심어뒀던 callBack함수를 호출하면서 끝난다. 해야 할 일 정리하기 ✅ 백엔드는 api 정리하는게 복잡하고 일이 조금 많았지만, 해야 할 일은 단순했다.\n세션에 데이터 심어주고 모델에 주던 데이터를 내려주는 인터페이스로 만들기 프론트가 콜백을 받게 되었으니, 기존 Callback api에서 해주던 일을 하는 인터페이스 추가하기 callback 이후 호출하는 api들도 view와 엮여있다면 restApi로 정리하기 이렇게 끝이었다. 다만 신규 프론트엔드 프로젝트에서 보안적인 이유로 window를 직접 이용하는게 불가능하게 되었고, 본인인증 api를 호출하기 위한 컨텍스트가 부족해서 다른 로직이 생겨났는데, 정교하게 관리할 필요가 생겼다.\n또 심지어 신규도입하기로한 특정 인증대행사의 sdk는 정말 독특한구조를 가지고 있어서 opener로 처리 할 수 없었다. (sdk를 실행시킬때 윈도우에 심어둔 함수 이름을 적어서 실행시킨다던가\u0026hellip;)\n이런저런 시행착오를 겪던 도중 postMessage를 프론트 팀원분께 소개받아서 해당 기능을 이용하기로 했다.\n결론적으로 정리하면\n백엔드 api 개편 기존 로직을 신규 프론트엔드에서 postMessage로 리뉴얼 TO-BE 인증창을 열어주는 부분\nexport const openIdentityVerificationWindow = ( authType: AuthType, setAuthData: (authData: IAuthData, someToken: string) =\u0026gt; void // 인증 이후 콜백 ) =\u0026gt; { let openUrl: string; let target: string; let features: string; if (authType === AuthType.Phone) { openUrl = OUR_AUTH_PAGE_URL; target = \u0026#39;popupPhoneAuth\u0026#39;; features = PHONE_WINDOW_FEATURES; } const handleMessage = async (event: MessageEvent) =\u0026gt; { // 콜백을 실행시키는 이벤트핸들러 if (event.origin !== window.location.origin) { return; } const { data } = event; if (data.type === \u0026#39;AUTH_SUCCESS\u0026#39;) { const { authData, someToken } = data.payload; await setAuthData(authData, csrfToken); window.removeEventListener(\u0026#39;message\u0026#39;, handleMessage); } }; window.addEventListener(\u0026#39;message\u0026#39;, handleMessage); // 이벤트 핸들러 등록 window.open(openUrl, target, features); }; 서로 다른 오리진끼리의 통신이 가능한게 주요한 특징이다. 우리는 콜백받아서 부모창을 호출하는 용도이므로 보안적으로 꼭 오리진 체크를 해줘야한다. postMessage참고! 콜백과 추가적으로 별도의 인증로직을 정갈하게 정리 할 수있다. 아무튼 콜백은 창을 열어주는 시점에 전달하는것은 동일하지만, 윈도우객체에 직접 심어주는것에서 postMessage 호출 이벤트의 리스너에서 호출하도록 수정했다. 인증 윈도우 페이지\nconst PhoneAuthPage = () =\u0026gt; { const { isSuccess: hasAuth } = useObserverAuthRefresh(); const formRef = useRef\u0026lt;ElementRef\u0026lt;\u0026#39;form\u0026#39;\u0026gt; | null\u0026gt;(null); // 아까 그 model에 실어주던 데이터 const { mutate: mutationKcb } = useMutationMembershipPhoneAuthInfo\u0026lt;PhoneAuthInfo\u0026gt;({ onSuccess: ({ data: { 데이터들 } }) =\u0026gt; { if (formRef.current) { // form 데이터 셋해주기! } formRef.current.submit(); }, onError(error) { console.error(\u0026#39;응답 오류 : \u0026#39;, error); ... }, }); useEffect(() =\u0026gt; { if (hasAuth \u0026amp;\u0026amp; formRef.current) { mutationPhoneAuth(); } }, [hasAuth, mutationPhoneAuth, formRef]); return \u0026lt;PhoneAuthForm ref={formRef} /\u0026gt;; }; export default PhoneAuthPage; 자세히 이야기 하기는 어렵지만, 새 창에서 인증관련 컨텍스트가 부족해서 호출이 안되는 부분을 보완하기위해 별도의 훅을 만들어서 처리했다. 그 외에는 tanstack의 useQuery, useMutation을 프론트분들이 예쁘게 사용하는걸 보고 나도 작성해서 사용했다. 콜백 페이지\nconst PhoneAuthCallbackPage = () =\u0026gt; { const searchParams = useSearchParams(); const { isSuccess: hasAuth, data: authData } = useObserverAuthRefresh(); const { isApp } = useDevice(); const { mutate: mutatePhoneAuthCallback } = useMutationMembershipPhoneAuthCallback({ onSuccess: (response) =\u0026gt; { if (authData) { handleAuthSuccess(response, authData); } }, onError: () =\u0026gt; { handleAuthFailure(failureMessage); }, }); useEffect(() =\u0026gt; { if (hasAuth \u0026amp;\u0026amp; authData \u0026amp;\u0026amp; searchParams) { mutatePhoneAuthCallback({ searchParams }); } }, [hasAuth, authData, searchParams]); return \u0026lt;div /\u0026gt;; }; export default PhoneAuthCallbackPage; export const handleAuthSuccess = (ourData: ResData\u0026lt;ourData\u0026gt;, authData: OurAuthData) =\u0026gt; { if (response.data \u0026amp;\u0026amp; authData?.ourToken) { const payload = { type: \u0026#39;AUTH_SUCCESS\u0026#39;, payload: { authData: ourData.data, ourToken: authData.ourToken, }, }; } window.opener.postMessage(payload, window.location.origin); self.close(); return; }}; 위와 같이 아까 등록한 이벤트리스너가 호출되도록 함수를 호출한다. 그러면 미리 저장했던 콜백함수가 호출되면서 이후 절차로 넘어가게 된다. 후기 막상 정말 많은 작업과 시행착오를 거쳤는데, 보안관련된 부분이 많아 자세히 작성할 수 없어서 중간에 포스팅을 그만할까 고민했다. 그래도 postMessage관련해서 사용예시를 정리한 정도로도 괜찮을 것 같아서 작성했다.\n기존 구조를 그대로 유지하면서 보완하는 것보다, 새로운 패턴을 도입하는 것이 유지보수성 측면에서 더 나은 경우가 있다.\n기존 구조를 수정하는 방향도 검토했지만, 결국 보안성과 확장성을 고려하면 새로운 방식이 더 적합했다. 보안과 확장성을 고려한 API 설계의 중요성\n오리진 체크를 철저히 해야 하고, 인증 데이터를 안전하게 주고받을 수 있도록 설계해야 했다. 단순히 기능 구현이 아닌, “이 방식이 앞으로도 안전하고 유연하게 유지될 수 있을까?” 라는 질문을 계속 던지며 설계했다. 사실 일정이 촉박해지고 나서는 \u0026ldquo;이 방식이 기존 방식 만큼은 안전한가\u0026quot;를 주요한 기준으로. 프론트엔드와 백엔드 간 명확한 역할 분리 필요\n기존 구조에서는 백엔드에서 인증 후 UI 로직까지 일부 관여하고 있었지만, 리뉴얼 후에는 백엔드는 인증 결과를 반환하는 API 제공에 집중하고, 프론트엔드는 이를 처리하는 역할로 분리되었다. 덕분에 백엔드 API도 RESTful하게 정리할 수 있었고, 프론트엔드에서도 관리가 용이해졌다. 새로운 기술을 도입할 때는 작은 실험과 반복적인 검증이 중요하다.\n처음에는 postMessage를 도입하는 것이 최선인지 확신이 없었고, 몇 가지 다른 방식도 고려했지만, 실제로 작동하는 최소한의 프로토타입을 만들어보면서 점진적으로 확신을 가지게 되었다. ","permalink":"http://localhost:1313/_wiki/%EC%8B%A0%EA%B7%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EC%97%90%EC%84%9C-%EB%B3%B8%EC%9D%B8%EC%9D%B8%EC%A6%9D-%EC%97%B0%EB%8F%99-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/","summary":"Intro 👋 배경 : 본인인증 서비스 리뉴얼하는 태스크를 진행했었다.\nAS-IS 수도코드로 구현한 기존 구조는 아래와 같다.\n마찬가지로 백엔드 로직은 예민할 수 있어 정말 최소한의 수도코드만 작성했다.\n본인인증 시작점\n\u0026lt;button name=\u0026#39;본인인증 버튼\u0026#39; onClick=doAuth() /\u0026gt; \u0026lt;script\u0026gt; function doAuth() { window.afterCallback = afterCallbackFunc; // 윈도우객체에 콜백함수 삽입 window.open(\u0026#39;authWindow\u0026#39;, \u0026#39;/PhoneAuth\u0026#39;) ; // 본인인증 창 열어주기 } \u0026lt;/script\u0026gt; 먼저 callback함수를 윈도우객체에 심는다. callback함수 내부에는 본인인증 이후에 할 행동들(회원가입관련 검증 api를 호출한다던가, 단순 인증완료후 페이지 이동이라던가) 이 정의되어있다.","title":"PostMessage를 이용해서 본인인증 안전하게 처리하기 🛟"},{"content":"Intro ⏳ 배경 프론트엔드 프로젝트의 전면 리뉴얼로 기존 view를 직접 반환하는 mvc 서비스에서 결제 관련 서비스들을 rest-api전환하고 모든 결제 모듈들을 다시 연동해야하는 이슈를 배정받았다.\nAS-IS 기존에도 프론트엔드 프로젝트는 따로 next.js로 따로 서비스되고 있었지만 전시영역을 제외한 로그인/마이페이지와 같은 인증관련된 페이지들, 결제/주문 관련된 페이지들은 기존 메인 백엔드 서버가 뷰까지 반환하고 있었는데, 이번 전면 리뉴얼을 통해 해당 페이지들도 신규 프로젝트로 전환 작업이 필요했다.\n문제점 은 당연히 시간이었다⏳.\n주문/결제쪽이 가장 기획이 늦게 나온 도메인이기도 했고, 일부 파악할 시간을 미리 가지긴 했지만 태스크에 배정받은 시간이 1달 약간 넘는 빠듯한 시간으로 적었고, 프론트엔드 백엔드 작업을 모두 혼자 진행해야 했었다.\n당장 연동해야하는 pg사가 네,카,토 페이 + 기존 카드결제 계좌이체 결제 + 사이트 전용 결제와 같이 매우 다양한(\u0026hellip;) 모듈을 연동해야 했다.\n물론 일정이 마일스톤으로 잡힌건 아니고, 감안해서 버퍼를 주시긴 하셨지만 전체적으로 오픈/QA일정이 촉박해서 일정압박이 거셌다.\n해야하는 일 파악하기 🤔 기존에 진행했던 프로젝트에서도 결제를 새로 구현한 적이 있었고, 당시에 결제 모듈을 보고 공부하면서 생긴 노하우와 그 때 봐왔던 코드들이 있어서 일단 업무를 검토하기는 부분은 조금 수월하게 진행되었다.\n결제과정의 추상화 결제단계는 크게 두가지로 추상화 할 수 있다. 출처 : https://docs.tosspayments.com/guides/v2/get-started/payment-flow\n결제 인증 단계\n요청한 클라이언트가 pg사를 통해 본인과 요청 그리고 지불 능력이 있는지를 검증하는 결제 인증단계 결제 승인 단계 요청의 결과와 각 서버의 결제 로직을 기반으로 실제 결제를 진행하는 결제 승인단계. 사실 이번 기회에 다른 모듈들도 검토해봤을 때 요즘 사용하는 대부분 pg사들은 위의 두가지를 기준으로 단계를 나누고 있는 것 같다.\n약간의 차이점이 있어봐야 결제 \u0026lsquo;인증\u0026rsquo; 과정에 조금 차이가 있거나 한 정도인 것 같다.\n예를 들어 인증 전에 미리 \u0026lsquo;결제 인증\u0026rsquo;을 위한 식별값을 조금 더 대조한다던지, 클라이언트의 결제 요청이 갈 것 이라고 미리 알려야 한다던지 하는 정도.\n이와 같은 관점을 기준으로 하면 구현해야 할 부분을 조금 더 단순하게 구분 할 수 있다.\n1. 결제 요청을 위한 준비를 한다. 2. 클라이언트가 실제로 결제 요청을 하면 pg사로 이동 3. 결제 \u0026#39;인증\u0026#39;의 결과를 콜백받는다. 4. 결제 인증 결과를 기반으로 내부로직을 처리하고 \u0026#39;승인\u0026#39; 요청 api를 날린다. 5. 결제 \u0026#39;승인\u0026#39;결과를 분기로 결제를 완료처리한다. 이렇게 단계를 나누고 기존 연동 코드와 연동 문서를 검토했을 때, 해당 흐름을 벗어나는 pg사는 다행히 없었다.\n결제 요청을 위한 준비를 하는 부분, pg사 이동 크게는 체크아웃을 위한 서버 내부 로직,\n(특정 pg사 만) 결제를 위한 예약(?) 핸드쉐이크(?) 작업,\n(pg사에 따라서) 클라이언트 키와 같은 식별값을 클라이언트에 내려주기,\n(클라이언트) 결제 모듈 sdk init하기\n로 나누어 볼 수 있다.\nAS-IS에서는\ncheckoutViewFile 반환\npublic String checkout() { doSomeServerCheckoutLogic(); //결제 예약을 위한 서버 로직 setSomeDataToSession(); return checkoutPage; } checkoutPage.hbs\n\u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- 결제 관련 PG 스크립트 --\u0026gt; \u0026lt;script src=\u0026#34;https://pg1.example.com/sdk.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://pg2.example.com/sdk.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button id=\u0026#34;payButton\u0026#34;\u0026gt;결제하기\u0026lt;/button\u0026gt; \u0026lt;script\u0026gt; document.getElementById(\u0026#34;payButton\u0026#34;).addEventListener(\u0026#34;click\u0026#34;, handleClickPay); function handleClickPay() { // 결제 준비 요청을 서버에 보냄 let someData = callPrepareCheckout(); // 결제 모듈 SDK 호출 (someData를 이용) if (someData.pgType === \u0026#34;KAKAO_PAY\u0026#34;) { callKakaoPaySdk(someData); } else if (someData.pgType === \u0026#34;PG2\u0026#34;) { callPg2Sdk(someData); } else { console.error(\u0026#34;지원하지 않는 PG 타입입니다.\u0026#34;); } } function callPrepareCheckout() { return { pgType: \u0026#34;KAKAO_PAY\u0026#34;, // PG사 타입 paymentInfo: {} // 기타 필요한 데이터 }; } function callKakaoPaySdk(data) { console.log(\u0026#34;카카오페이 SDK 호출\u0026#34;, data); // 실제 카카오페이 SDK 호출 로직 } function callPg2Sdk(data) { console.log(\u0026#34;PG2 SDK 호출\u0026#34;, data); // 실제 PG2 SDK 호출 로직 } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 결제 버튼을 누르면\n@GetMapping(\u0026#34;/prepare\u0026#34;) public ResponseEntity\u0026lt;?\u0026gt; prepareCheckout(PgType pgType) { ... switch (pgType) { case KAKAO_PAY: doingSomeJobs(); // PG사별로 별도의 작업 수행 saveSomeDataAtSession(); // 결제 요청 관련 데이터를 세션에 저장 break; } ... return someDataForCallingPaymentModule(); // 결제 모듈 호출을 위한 추가 데이터 반환 } 이런식으로 되어있었다.\n이부분을 이런식으로 리팩토링 했다.\npublic interface PgType { Map\u0026lt;String, String\u0026gt; reserve(HttpServletRequest request, PaymentInfo paymentInfo); } @Component public class KakaoPayPg implements PgType { @Override public Map\u0026lt;String, String\u0026gt; reserve(HttpServletRequest request, PaymentInfo paymentInfo) { HttpSession session = request.getSession(); session.setAttribute(\u0026#34;pg_kakao_orderId\u0026#34;, paymentInfo.getOrderId()); session.setAttribute(\u0026#34;pg_kakao_amount\u0026#34;, paymentInfo.getAmount()); Map\u0026lt;String, String\u0026gt; result = new HashMap\u0026lt;\u0026gt;(); result.put(\u0026#34;pg\u0026#34;, \u0026#34;kakao\u0026#34;); result.put(\u0026#34;orderId\u0026#34;, paymentInfo.getOrderId()); result.put(\u0026#34;amount\u0026#34;, paymentInfo.getAmount()); result.put(\u0026#34;redirectUrl\u0026#34;, \u0026#34;https://kakaopay.com/init\u0026#34;); return result; } } 결제를 승인하는 부분 \u0026ldquo;그때 그렇게 한 것은 그때의 이유가 있다!\u0026rdquo;\n보통 결제는 인증의 처리한 결과를 미리 pg사와 약속을 해놓는다. 최신 sdk혹은 모듈들은 sdk를 호출하는 시점에 callback받을 endpoint를 넘기고, 그렇지 않은 모듈들은 미리 알려주거나 등록해야 하는 정도가 다르다.\n그래서 approval과 같은 하나의 엔드포인트로 그걸 처리한다.\nAS-IS에서는\nclass ApprovalHandler { private PgService kakaoPayService; private PgService pg1Service; // 다른 pg사 서비스들 ... public Boolean approval(HttpServletRequest req); } @GetMapping(\u0026#34;/approval\u0026#34;) public String approval(HttpServletRequest req, PgType pgType) { switch (pgType) // 이후 짐작가능한대로 } 눈여겨 볼점은 승인과 관련한 데이터를 dto로 미리 받아놓지 않고, 그냥 req객체에서 pg사 서비스들이 알아서 뽑아쓰도록 해뒀다는 것이다.\n물론 변경에 유연하거나 좋고 예쁜 코드는 아니지만, 그래도 리퀘스트를 직접 넘기는 식으로 구현되었기 때문에 각 결제대행사의 프로토콜대로 직접 구현해야하는 부분의 코드가 확 줄었다.\n이 시점에서 정해진 기간 내로 구현할 수 있겠다는 생각이 되었다.\n즉 승인 이후의 시점은 우리 프론트엔드 서버가 인증 콜백으로 받은 요청을 백엔드 서버로 동일하게 포워드 해줄수 있으면 내가 신경을 쓸 필요가 없었다.\n진짜 해야할 일 정리 ✅ 체크아웃 준비, 주문서 뷰 반환하는 api에서 체크아웃 준비하는 부분을 별도의 요청으로 분리하고 뷰를 그릴때 필요한 정보 정리해서 api추가하기 (보안상의 이유로 서버컴포넌트로 처리하기위해서 next.js와 백엔드 서버가 직접 통신하도록 구현) next.js에서 \u0026lsquo;인증 결과\u0026rsquo; 콜백 받을 수 있도록 엔드포인트 추가하기 콜백받은 \u0026lsquo;인증 결과\u0026rsquo; 포워드하여 우리 백엔드 서버의 승인 로직 호출 이걸 위한 수많은 프론트엔드 코드 추가 (\u0026hellip;) Impl \u0026amp; TroubleShootings 🚀 백엔드 부분은 아무리 예시코드로 주요 로직을 수도코드로 작성해도 예민한 부분일 수 있어 로직적인 부분을 이야기하기가 어렵다.\n위에 작성한 1번의 내용에서 크게 벗어나지 않는 작업들과 세부사항 처리, 엔드포인트들을 새로운 인터페이스맞게 정리하고 몇가지 리팩토링한게 전부이다.\n반면 클라이언트쪽은 예시코드가 가장 잘 공개되어있는 토스 모듈을 기준으로 하고 예민한 부분들을 제거하고 포스팅했다.\n이후부터는 일단 결제를 준비하기 위한 주문서 로직을 처리한 이후의 구현이다. 기본 구조를 아래와 같이 정리했다.\n(주문서 진입 요청 이전에 서버에는 주문서 데이터의 결제 관련 준비가 되어있음) 1. 결제 버튼 클릭 데스크탑이면 -\u0026gt; 새로운 window open (결제 모듈 페이지) 모바일이면 -\u0026gt; 결제 모듈 페이지로 이동 2. 결제 모듈 페이지에서 결제 준비 api호출, 결제 모듈 준비 3. 인증 이후 콜백을 route.ts로 받은 이후 request데이터와 함께 callback페이지로 리다이렉트 4. callback 페이지에서 승인 api 호출 결제 완료! TroubleShooting : 결제창 열기 결제창을 데탑에서는 별도의 윈도우로 처리하고 있었다.\n그리고 해당 윈도우에서 스크립트를 호출하면 결제사 사이트로 이동하는 구조였고,\n해당 창에서 성공/실패한경우 opener 객체에 있는 주렁주렁 함수로 콜백을 처리하기도 했다.\n당시에 opener를 직접 참조하는것과 윈도우객체에 꼭 필요한 것들만 정의해서 사용하자는 프론트분들의 룰이 있었다.\n그래서 창간의 통신을 postMessage를 이용해서 처리하도록 수정했다.\n꼭 필요한 콜백의 경우 명시적으로 postMessage로 부모창에 메세지를 전달하고 해당 메세지를 처리하는 핸들러를 두었다.\nconst usePaymentPopup = () =\u0026gt; { useEffect(() =\u0026gt; { const handleMessage = (event: MessageEvent) =\u0026gt; { if (event.origin === window.location.origin \u0026amp;\u0026amp; event.data === \u0026#39;someId\u0026#39;) { clearPaymentInterval(); setIsWindowOpen(false); payWindowRef.current = null; } }; if (isWindowOpen) { // handleMessage로 새로 열린 결제페이지에서 보낸 콜백을 받아 처리한다 window.addEventListener(\u0026#39;message\u0026#39;, handleMessage); intervalRef.current = setInterval(() =\u0026gt; { if (payWindowRef?.current?.closed) { if (!payWindowRef.current) return; clearPaymentInterval(); Alert(\u0026#39;결제가 취소되었습니다\u0026#39;).then(() =\u0026gt; { setIsWindowOpen(false); payWindowRef.current = null; }); } }, 100); } return () =\u0026gt; { clearPaymentInterval(); window.removeEventListener(\u0026#39;message\u0026#39;, handleMessage); }; }, [isWindowOpen, clearPaymentInterval]); return { openPaymentPopup }; }; Impl : 결제페이지 구현하기 프론트엔드 컴포넌트를 개편한 백엔드 api 단계에 맞게 추상화해서 구현\nPaymentPage 예시\nexport default function TossPaymentPage() { const { data: response, isFetching, isSuccess, isError } = useQueryPaymentPrepare\u0026lt;TossPreparePaymentData\u0026gt;(\u0026#39;TOSS\u0026#39;); usePaymentPreparation\u0026lt;PreparePaymentResponse\u0026lt;TossPreparePaymentData\u0026gt;\u0026gt;({ isFetching, isError, isSuccess, response, }); if (isSuccess \u0026amp;\u0026amp; response.data) { return \u0026lt;\u0026gt;{isSuccess \u0026amp;\u0026amp; response \u0026amp;\u0026amp; \u0026lt;TossPaymentHandler preparePaymentData={response.data} /\u0026gt;}\u0026lt;/\u0026gt;; } return \u0026lt;div /\u0026gt;; } \u0026ldquo;서버의 pg사별 결제 데이터 준비, 세팅\u0026rdquo;,\n\u0026ldquo;결제 모듈을 호출하기 위한 정보 조회 api\u0026rdquo;,\n\u0026ldquo;클라이언트 사이드의 결제 모듈 준비\u0026rdquo;\n와 같은 단계로 나누어 컴포넌트를 작성했다.\nuseQueryPaymentPrepare 에서 useQuery를 이용해서 pg사별 백엔드 결제 준비 api를 호출한다.\n백엔드 결제 준비 api호출부\n// 제네릭은 pg사를 의미! interface UsePaymentPreparationHandlerProps\u0026lt;T\u0026gt; { isFetching: boolean; isError: boolean; isSuccess: boolean; response: { data: T } | undefined; } export default function usePaymentPreparation\u0026lt;T\u0026gt;({ isFetching, isError, isSuccess, response, }: UsePaymentPreparationHandlerProps\u0026lt;T\u0026gt;) { useOverlayLoadingContext(Boolean(isFetching)); useEffect(() =\u0026gt; { if (!isFetching) { if (isError) { alert(\u0026#39;결제 준비 성공!\u0026#39;); if (opener) { self.close(); } else { gotToCheckoutPage(); } return; } if (isSuccess \u0026amp;\u0026amp; !response) { alert(\u0026#39;결제 준비 실패!\u0026#39;); if (opener) { self.close(); } else { gotToCheckoutPage(); } return; } } }, [isSuccess, isError, isFetching, response]); } 참고로 준비와, sdk 호출을 위한 데이터를 받아오는 api 분리한 이유는 다른 pg사를 고려했을때, 이렇게 단계를 나누는게 유리했고 서버쪽에서 작업하기 이렇게 단계를 나누는게 편리했기 때문이었다.\n결제모듈 준비\nexport default function TossPaymentHandler({ preparePaymentData: data }: TossPaymentHandlerProps) { const isProcessingRequestRef = useRef(false); const [scriptLoaded, setScriptLoaded] = useState(false); useEffect(() =\u0026gt; { if (scriptLoaded \u0026amp;\u0026amp; window.TossPayments \u0026amp;\u0026amp; !isProcessingRequestRef.current) { isProcessingRequestRef.current = true; const tossPrepareData = data.preparePaymentData; const clientKey = tossPrepareData.clientKey; const payParams = { ...tossPrepareData?.payParams, }; const tossPayments = window.TossPayments(clientKey); tossPayments .requestPayment(\u0026#39;토스결제\u0026#39;, { amount: payParams.amount, orderId: payParams.orderId, orderName: payParams.goodsName, customerName: payParams.buyerName, successUrl: `${payParams.returnUrl}?pgType=TOSS`, failUrl: payParams.cancelUrl, }) .catch(function (error: unknown) { const newError = error as { code: string }; if (newError.code === \u0026#39;USER_CANCEL\u0026#39;) { if (opener) { alert(\u0026#39;결제를 취소하셨습니다.\u0026#39;); self.close(); } } }); } }, [data, scriptLoaded]); return ( \u0026lt;Script src=\u0026#34;https://js.tosspayments.com/v1\u0026#34; strategy=\u0026#34;afterInteractive\u0026#34; onLoad={() =\u0026gt; setScriptLoaded(true)} onError={() =\u0026gt; { console.error(\u0026#39;토스가 스크립트를 안줬어요 ㅠㅠ\u0026#39;); }} /\u0026gt; ); } 여기까지 구현했을때, 내가 설계하고 개편한 백엔드 인터페이스와 프론트엔드 컴포넌트 단계를 나누어 설계한게 모든 pg사에 적용 가능한 구조라서 너무 행복했었다.\n그리고 여기까지가 결제 \u0026ldquo;인증\u0026quot;의 끝점이다.\nImpl : 승인 관련 클라이언트에서 해주는 일들! 일단 콜백을 프론트엔드에서 받아야 하기에 엔드포인트를 next.js의 route.ts를 이용해서 뚫었다.\n그리고 상기한 이유로 콜백받은 요청을 그대로 백엔드 서버로 포워드 해줘야 하기 때문에,\n요청을 포워드하기위한 util.ts 함수를 만들어 구현했다.\n콜백 주소가 여러개인 이유는 결제라인(?)이 다르고 각각 다른 인터페이스를 호출해야하는데 그걸 식별해야 하기 때문에 기존 엔드포인트들이 분기되어 있었기 때문이다.\n(예를들어 배송비, 교환관련, 수선관련, 실제 주문 결제 등등)\n무튼 pg사로부터 인증결과 콜백을 전달받으면 이 api로 받아서 next.js페이지로 직접 리다이렉트 해주는식으로 처리된다.\napps └── 모노레포web ├── app │ ├── (api) │ │ ├── Pay │ │ │ ├── authorizeCallback │ │ │ │ └── route.ts # 요런데로 pg사 콜백 api를 받아서 next.js 페이지로 리다이렉트! │ │ │ ├── authorizeCallback2 │ │ │ │ └── route.ts │ │ │ ├── authorizeCallback3 │ │ │ ├── util.ts │ ├── proxy │ ├── layout.tsx 리다이렉트 페이지에서 호출하는 콜백 함수\nexport default function useAfterPaymentCallback(params: { callbackType: PaymentCallbackType }) { const isProcessingRequestRef = useRef(false); const payParams = usePayParams(); const callbackType = params?.callbackType ?? \u0026#39;\u0026#39;; // 클라이언트가 요청을 승인 api로 포워드할때 pg사 콜백과 동일하게 만들어주고 몇몇 보안관련 이슈를 해결하는 유틸함수 const params = useMemo(() =\u0026gt; { forwardParams(payParams); }, [searchParams]); // 실제 서버 승인 api 호출 const { mutate: mutateFinishCallback } = useMutationPaymentFinishPayment({ // 승인 api 호출 결과에 따라 처리로직은 그냥 따로. onSuccess: (result) =\u0026gt; handleSuccess(callbackType, result), onError: (error) =\u0026gt; handleError(callbackType, error), }); useEffect(() =\u0026gt; { if (!isProcessingRequestRef.current) { isProcessingRequestRef.current = true; if (!callbackType) { alert(\u0026#39;결제 과정 중 문제가 발생하였습니다.\u0026#39;); return; } mutateFinishCallback({ callbackType, params }); } }, [callbackType, queryParams]); useOverlayLoadingContext(); } 드디어 길고 긴 과정이 끝났다!\n결론 💪 결제 서비스를 혼자서 백엔드 프론트엔드 전부 리뉴얼했다. 의도한대로, 작업이 진행되었고 그 결과가 처음 의도와 딱 맞아 떨어지는게 쾌감이 좋았다. ","permalink":"http://localhost:1313/_wiki/%EA%B2%B0%EC%A0%9C-%EC%84%9C%EB%B9%84%EC%8A%A4-%EB%A6%AC%EB%89%B4%EC%96%BC%ED%95%98%EA%B8%B0/","summary":"이걸 전부 내가 했다고.. 스스로 뿌듯해서 쓰는 후기","title":"레거시 결제 서비스 리뉴얼, 모든 pg 서비스 연동 개발 회고 💸"},{"content":"Learners High Week 3,4 Summary! 카프카를 헥사고날 아키텍처를 토대로 클론코딩 해봤다. 깃허브 주소\nWeek 3,4 Intro 인사이동이 있었다. 부서이동으로 인한 OJT가 완료되어야 다음 이슈를 받을 수 있는 상황이었고, 기존에 받았던 이슈들은 처리가 완료되었다.\n일부 운영 이슈가 있었지만, 그것도 다 처리가 완료되어있어서 진짜 뭘 해야할지 모르겠는 상황이었다.\n새로운 프로젝트가 열리고, 업무를 파악하며 개선하고 싶은 부분들을 찾아서 열심히 코드를 봤지만, 그래도 당장 진행한다고 하기가 어려웠다.\n원래같았으면 공부나 발전을 하기에 오히려 좋았을 환경이었겠지만, 당장 나의 미션에 적합하지는 않다고 생각해서 굉장히 우울해 있다가, 털고 일어나서 지금 OJT기간을 가장 치열하게 보낼 수 있는 일들을 찾아봤다.\n옮기는 부서의 특징은 다음과 같았다. 일단 파트너오피스로 고객사와 md들이 사용하는 백오피스를 개발하는 부서였고, 가장 주요한 업무는 거의 스트림과 연관이 되어 있었다. (상품 정보 연동, 수정과 같은 이벤트들의 스트림)\n그리고 추가적으로 메인 프로덕트에 헥사고날 아키텍처를 도입해서 개발/유지/보수 하고 있었다.\n헥사고날 아키텍처는 많이 생소했고, 실제로 하는걸 본 소스코드는 이번이 처음이었다.\n그래서 이번 OJT 기간동안 헥사고날 아키텍처와 스트림(메세지브로커)를 공부하기 위해서 카프카를 헥사고날 아키텍처 형태로 클론코딩하기로 했다.\nStart with Codecrafters 먼저 코드크래프터스라는 사이트의 도움을 받았다. 해당 사이트는\n위처럼 특정 기술을 구현하는데, 단계를 나눠주고, 해당 구현 단계마다 통합테스트를 진행해주는 사이트이다. 그리고 구현을 위해 필요한 프로토콜등의 정보를 보기 쉽게 정리하고 요약해서 제공해주기도 한다.\n다만 요청/응답을 실제 해당 기술이 사용하는 프로토콜을 통해서 진행되어야 한다. 요청 예시, 응답 예시와 같이 실제 요청도 바이트 버퍼로 오고, 응답도 바이트 버퍼로 인코딩해서 보내야한다.\n다만 문제는 아직 카프카는 베타로 지원하는중이라, 절반정도만 구현이 되어있다는 것이었다. 이 시점까지의 github 링크 저기까지 구현했을 때, kraft 메타데이터 정보와 일부 consumer 인터페이스만 구현이 되어있었다.\n가장 중요한 메세지 저장 로직과, 컨슈머 그룹관리, 오프셋 커밋하는 인터페이스들은 안되어 있었고, 레플리케이션 관련 로직도 아직 없었다.\n레플리케이션 로직은 어렵다고 쳐도, 그래도 실제 카프카처럼 어느정도 동작한다고 하려면 기본적인 producer, consumser api들과 오프셋 커밋,등이 되어 있어야 한다고 생각했는데, 이부분이 너무 아쉬웠다.\n내가 스스로 요구사항을 정의하고 추가 구현을 진행하기로 그래서 새로 레포를 파고, 추가 구현을 진행했다.\n최대한 프로토콜을 지키면서 진행하려고 했고, 아직 구현되지 않은 요구사항은 통합테스트로 작성했다. /tests/integration_test.rs\n#[tokio::test] async fn test_message_log_persistence() -\u0026gt; Result\u0026lt;()\u0026gt; { print_test_header(\u0026#34;Message Log Persistence Test\u0026#34;); let temp_dir = TempDir::new().expect(\u0026#34;Failed to create temp dir\u0026#34;); let config = StoreConfig { max_segment_size: 1024, max_buffer_size: 2, flush_interval: Duration::from_millis(100), }; let store = DiskMessageStore::new(temp_dir.path().to_path_buf(), config); // 테스트 메시지들 준비 let test_messages = vec![ KafkaMessage { correlation_id: 1, topic: \u0026#34;test-topic\u0026#34;.to_string(), partition: 0, offset: 0, timestamp: 1234567890, payload: \u0026#34;First message\u0026#34;.as_bytes().to_vec(), }, KafkaMessage { correlation_id: 2, topic: \u0026#34;test-topic\u0026#34;.to_string(), partition: 0, offset: 0, timestamp: 1234567891, payload: \u0026#34;Second message\u0026#34;.as_bytes().to_vec(), }, KafkaMessage { correlation_id: 3, topic: \u0026#34;test-topic\u0026#34;.to_string(), partition: 0, offset: 0, timestamp: 1234567892, payload: \u0026#34;Third message\u0026#34;.as_bytes().to_vec(), }, ]; println!(\u0026#34;\\n=== 메시지 저장 시작 ===\u0026#34;); let mut stored_offsets = Vec::new(); for (i, message) in test_messages.iter().enumerate() { print_message_details(\u0026amp;format!(\u0026#34;저장할 메시지 {}\u0026#34;, i + 1), message); let offset = store.store_message(message.clone()).await?; stored_offsets.push(offset); println!(\u0026#34;메시지 {} 저장됨, 오프셋: {}\u0026#34;, i + 1, offset); } // 버퍼가 디스크에 플러시되도록 잠시 대기 println!(\u0026#34;\\n버퍼 플러시 대기 중...\u0026#34;); tokio::time::sleep(Duration::from_millis(200)).await; // 로그 파일 확인 let topic_dir = temp_dir.path().join(\u0026#34;test-topic-0\u0026#34;); let base_offset = (stored_offsets[0] / 1000) * 1000; let log_file = topic_dir.join(format!(\u0026#34;{:020}.log\u0026#34;, base_offset)); let index_file = topic_dir.join(format!(\u0026#34;{:020}.index\u0026#34;, base_offset)); println!(\u0026#34;\\n=== 로그 파일 정보 ===\u0026#34;); println!(\u0026#34;로그 파일 경로: {:?}\u0026#34;, log_file); println!(\u0026#34;인덱스 파일 경로: {:?}\u0026#34;, index_file); assert!(log_file.exists(), \u0026#34;로그 파일이 존재해야 함\u0026#34;); assert!(index_file.exists(), \u0026#34;인덱스 파일이 존재해야 함\u0026#34;); let log_metadata = fs::metadata(\u0026amp;log_file).await?; let index_metadata = fs::metadata(\u0026amp;index_file).await?; println!(\u0026#34;로그 파일 크기: {} bytes\u0026#34;, log_metadata.len()); println!(\u0026#34;인덱스 파일 크기: {} bytes\u0026#34;, index_metadata.len()); // 저장된 메시지 읽기 및 검증 println!(\u0026#34;\\n=== 저장된 메시지 검증 ===\u0026#34;); for (i, offset) in stored_offsets.iter().enumerate() { let read_result = store .read_messages(\u0026#34;test-topic\u0026#34;, 0, *offset as i64) .await?; match read_result { Some(data) =\u0026gt; { println!(\u0026#34;\\n메시지 {} (오프셋 {}):\u0026#34;, i + 1, offset); println!(\u0026#34;원본 메시지: {:?}\u0026#34;, String::from_utf8_lossy(\u0026amp;test_messages[i].payload)); println!(\u0026#34;읽은 메시지: {:?}\u0026#34;, String::from_utf8_lossy(\u0026amp;data)); assert_eq!(\u0026amp;data, \u0026amp;test_messages[i].payload, \u0026#34;메시지 내용이 일치해야 함\u0026#34;); } None =\u0026gt; panic!(\u0026#34;메시지를 찾을 수 없음: offset {}\u0026#34;, offset), } } // 로그 파일 내용 직접 확인 (처음 100바이트만) println!(\u0026#34;\\n=== 로그 파일 원시 내용 ===\u0026#34;); let mut log_file = File::open(\u0026amp;log_file).await?; let mut buffer = vec![0u8; 100]; let n = log_file.read(\u0026amp;mut buffer).await?; println!(\u0026#34;처음 {} 바이트: {:?}\u0026#34;, n, \u0026amp;buffer[..n]); Ok(()) } 사실 원대한 목표는 통합 테스트 코드를 작성하고, 해당 통합 테스트 코드에 카프카 클라이언트 라이브러리를 붙여서 실제로 기능이 동작하는지를 보고싶었는데, 생각보다 더 많은 요구사항을 구현해둔 뒤에야 실제 카프카 클라이언트 라이브러리를 붙있 수 있었다.\n사실 통합 테스트로 보기 어려운 부분은 하나 더 있었는데 바로 실제 입력 버퍼로 요청을 보내는 부분을 생략했다는 점이다. 테스트 코드를 위한 정확한 입력 버퍼를 바이트코드로 직접 인코딩을 해야하는데, ai툴을 이용해도 오류가 생각보다 많고 별 것 아닌 프로토콜 바이트 오류 때문에 디버깅하는시간이 너무 길어져서 본질과는 다른일을 하고있다는 생각이 들었다.\n시작 전에 고민하던 것들 처음부터 어느정도의 추상화와 설계를 하고 진행해야 한다. 해당 사이트에서 레디스를 구현하는 프로젝트를 진행한적이 있는데, 중간에 구조적으로 잘못되어 있는 부분들을 리팩토링 하다가 너무 힘들어서 해맸던 경험이 있다. 결국 러스트 사용자 모임 디스코드에서 질문을 올리고 답변받아 진행했는데, 그와 같은 경험을 하고싶지는 않았다. [[난개발된-레디스를-이벤트루프-기반으로-리팩토링하기]] 관련한 이야기인데, 도메인로직을 최대한 정의하고 시작해보려고 노력했다. 관련해서 ddd와 헥사고날과 관련한 공부를 미리 진행했다. [[헥사고날-아키텍처]] 카프카 내부 구현에 대한 내용을 미리 알고 시작하면 좋을 것 같았다. 그래서 간단하게 카프카 관련 서적을 읽기는 했는데, 주로 설정과 운영노하우에 대한 이야기가 많아서 내 목적에는 조금 부합하지 않았던 것 같다. Impl and TroubleShootings 01 어려운건 헥사고날이 아니라 DDD.. 먼저 처음 시작 할 때는, 도메인 로직에 대한 정의가 어려웠고, 하던 중에는 도메인 로직인지 아닌지가 항상 헷갈렸고, 끝나고 나서는 내가 도메인 로직을 잘 발라냈는지가 아직도 의문이었다. 그만큼 도메인 로직 자체를 미리 바르는것도, 내가 구현해야할 프로젝트의 도메인 로직을 전부 알아야 하는것도 너무 어려웠다. 그래서 DDD에 대해서는 항상 생각이 많았지만, 도메인 로직이 확실히 격리, 분리되어있어야 하는 헥사고날 아키텍처에서는 이부분이 가장 어려웠다. 그래서 이게 헥사고날의 문제냐 하면 그게 맞는 것 같다고 느낀 이유는 작업 도중에 코드를 정리하는 난이도가 기존 layered arhcitecture에서는 어느정도 가능했지만, 헥사고날에서는 더 어려웠다는 생각이 들었기 때문이었다.\n아무튼 구조를 잘 잡아보려고 노력했을 때 나의 프로젝트는 다음과 같은 구조가 나왔다. /adapters/incoming/tcp_adapter.rs\npub struct TcpAdapter { listener: TcpListener, broker_incoming_port: Arc\u0026lt;dyn BrokerIncomingPort\u0026gt;, protocol_parser: KafkaProtocolParser, } impl TcpAdapter { pub async fn new( addr: \u0026amp;str, broker_incoming_port: Arc\u0026lt;dyn BrokerIncomingPort\u0026gt;, protocol_parser: KafkaProtocolParser, ) -\u0026gt; Result\u0026lt;Self\u0026gt; { let listener = TcpListener::bind(addr) .await .map_err(ApplicationError::Io)?; Ok(Self { listener, broker_incoming_port, protocol_parser, }) } pub async fn run(\u0026amp;self) -\u0026gt; Result\u0026lt;()\u0026gt; { println!(\u0026#34;Server listening on port 9092\u0026#34;); loop { match self.listener.accept().await { Ok((stream, _)) =\u0026gt; { let message_handler = Arc::clone(\u0026amp;self.broker_incoming_port); let protocol_parser = self.protocol_parser.clone(); tokio::spawn(async move { if let Err(e) = handle_connection(stream, message_handler, protocol_parser).await { println!(\u0026#34;Connection error: {}\u0026#34;, e); } }); } Err(e) =\u0026gt; println!(\u0026#34;Accept error: {}\u0026#34;, e), } } } } async fn handle_connection( mut stream: TcpStream, broker_incoming_port: Arc\u0026lt;dyn BrokerIncomingPort\u0026gt;, protocol_parser: KafkaProtocolParser, ) -\u0026gt; Result\u0026lt;()\u0026gt; { println!(\u0026#34;Accepted new connection\u0026#34;); loop { // 1. 요청 크기 읽기 let mut size_bytes = [0u8; 4]; if let Err(e) = stream.read_exact(\u0026amp;mut size_bytes).await { if e.kind() == std::io::ErrorKind::UnexpectedEof { println!(\u0026#34;Client closed connection\u0026#34;); return Ok(()); } return Err(ApplicationError::Io(e)); } let message_size = i32::from_be_bytes(size_bytes); // 2. 요청 데이터 읽기 let mut request_data = vec![0; message_size as usize]; stream .read_exact(\u0026amp;mut request_data) .await .map_err(ApplicationError::Io)?; // 3. 프로토콜 파싱 let request = protocol_parser.parse_request(\u0026amp;request_data)?; // 4. 비즈니스 로직 처리 let response = broker_incoming_port.handle_request(request).await?; // 5. 응답 인코딩 및 전송 let encoded = protocol_parser.encode_response(response); stream .write_all(\u0026amp;encoded) .await .map_err(ApplicationError::Io)?; } } /ports/incoming/broker_incoming_port.rs\n#[async_trait] pub trait BrokerIncomingPort: Send + Sync { async fn handle_request(\u0026amp;self, request: KafkaRequest) -\u0026gt; Result\u0026lt;KafkaResponse\u0026gt;; } /application/broker_service.rs\n#[allow(dead_code)] pub struct BrokerService { message_store: Box\u0026lt;dyn MessageOutgoingPort\u0026gt;, metadata_store: Box\u0026lt;dyn MetadataOutgoingPort\u0026gt;, } impl BrokerService { pub fn new( message_store: Box\u0026lt;dyn MessageOutgoingPort\u0026gt;, metadata_store: Box\u0026lt;dyn MetadataOutgoingPort\u0026gt;, ) -\u0026gt; Self { Self { message_store, metadata_store, } } #[async_trait] impl BrokerIncomingPort for BrokerService { async fn handle_request(\u0026amp;self, request: KafkaRequest) -\u0026gt; Result\u0026lt;KafkaResponse\u0026gt; { if !request.header.is_supported_version() { return Ok(KafkaResponse::new( request.header.correlation_id, UNSUPPORTED_VERSION, ResponsePayload::ApiVersions(ApiVersionsResponse::default()), )); } match request.header.api_key { API_VERSIONS_KEY =\u0026gt; Ok(KafkaResponse::new( request.header.correlation_id, 0, ResponsePayload::ApiVersions(ApiVersionsResponse::default()), )), FETCH_KEY =\u0026gt; self.handle_fetch_request(\u0026amp;request, \u0026amp;request.payload).await, DESCRIBE_TOPIC_PARTITIONS_KEY =\u0026gt; { self.handle_describe_topic_partitions(\u0026amp;request, \u0026amp;request.payload) .await } PRODUCE_KEY =\u0026gt; { self.handle_produce_request(\u0026amp;request, \u0026amp;request.payload) .await } _ =\u0026gt; Ok(KafkaResponse::new( request.header.correlation_id, 0, ResponsePayload::ApiVersions(ApiVersionsResponse::new(vec![])), )), } } } 뭔가 습관적으로 Controller를 도메인 단위로 분리하는게 생각나서 그렇게 할 까 했지만, 그것보다는 별도의 설정을 위한 cli나 새로운 입력 어댑터로 분류 할 수 있는 경우가 생겨야 분리하는게 낫다는 생각이 들어 모든 요청을 하나의 어댑터에서 처리했다.\n02 프로토콜은 도메인 로직일까? 일단 내 프로젝트의 계층 구조는 아래와 같다.\nsrc/ ├── adapters/ │ ├── incoming/ │ │ ├── mod.rs │ │ ├── tcp_adapter.rs │ ├── outgoing/ │ │ ├── README.md │ │ ├── disk_store.rs │ │ ├── kraft_metadata_store.rs │ │ ├── mod.rs │ ├── protocol/ │ │ ├── dto/ │ │ ├── parser/ │ │ │ ├── constants.rs │ │ │ ├── kraft_record_parser.rs │ │ │ ├── mod.rs │ │ │ ├── tcp_parser.rs │ │ ├── mod.rs ├── application/ ├── config/ ├── domain/ ├── ports/ ├── lib.rs └── main.rs 여기서 프로토콜 부분이 참 애매했는데, 내가 내린 결론은 위처럼 반영되어있다.\n먼저 내가 카프카를 개발하는 개발자 관점이었다면 프로토콜이 가지는 도메인적 의의가 충분하다.\n당연히 버퍼를 어떻게 해석해야 하는지와 같은 도메인 로직도 있고,\n심지어 클라이언트와 핸드쉐이크(정확히는 핸드쉐이크로 통칭하지는 않지만) 과정에서 아래와 같은 일이 일어난다.\n클라이언트 : 안녕 지원하는 버전좀 알려줘 카프카 : { \u0026#34;ErrorCode\u0026#34;: 0, \u0026#34;ApiKeys\u0026#34;: [ { \u0026#34;Index\u0026#34;: 0, \u0026#34;MinVersion\u0026#34;: 0, \u0026#34;MaxVersion\u0026#34;: 8 }, { \u0026#34;Index\u0026#34;: 1, \u0026#34;MinVersion\u0026#34;: 0, \u0026#34;MaxVersion\u0026#34;: 12 }, // ... 다른 API 키들 ... ], \u0026#34;ThrottleTimeMs\u0026#34;: 0 } 클라이언트 : 카프카와 본인이 지원하는 가장 높은 버전으로 버퍼를 인코딩해서 요청 결국 내가 카프카를 개발하는 개발자 관점에서는 분명히 프로토콜은 도메인 로직이다.\n내가 어떠한 버전을 지원하는지, 입력 버퍼를 어떻게 디코드/인코드 해야하는지에 대한 정보이며 유지보수 관리되어야 하기 때문이다.\n문제는 그렇게 했을때, 어댑터 레이어에서는 프로토콜을 모른채로 포트를 통해 어댑터로 입련된 일련의 바이트 버퍼를 내려보내주고 서비스 레이어 이하에서 실제 프로토콜대로 버퍼를 파싱하는 로직이 붙게 된다.\n그러면 그 구조는 자연스러운가 했을때 기본적으로 의아한점이 분명히 있기도 하고, 두 번째로 말이 쉽지 incoming에서 프로토콜을 전혀 모른채로 버퍼를 어디까지 읽어들인다음에 내려보내야하는지도 전혀 알 수 없다. (어댑터에서 프로토콜을 전혀 모른다면 어디까지가 요청인지에 대한 구분이 어려움)\n그래서 어댑터 레이어에서 프로토콜을 알게 한다면 바로 헥사고날 아키텍처를 깨뜨린다 (어댑터의 도메인 로직 참조)\n결론적으로 이 두가지 내용이 맞지 않다고 생각되어 adapters/ 하위에 protocol을 두기는 했다.\n이부분은 옮기는 팀에서 처음 프로젝트를 빌딩한 분께 여쭤봐서 같이 고민해봤는데도 \u0026ldquo;애매하네..\u0026rdquo; 와 같은 결론만 나왔다. 굉장히 묘한 문제는 맞는 것 같다.\n03 메세지를 영속화 하는 문제 이건 그냥 실수인데, 바꾸기에는 해당 부분 코드가 너무 비대해졌다. 카프카가 메세지를 바로 디스크에 영속화 하는것은 알고 있지만 자세한 실제 구현사항을 나중에 알게되었다.\n책에서 본 바로는 일단 기본적으로 바로 영속화를 하고, 지금 작업중인 세그먼트를 포함해서 최근의 세그먼트를 페이지캐시해서 속도를 유지한다고 한다. 그래서 실시간성이 중요한 프로젝트에서는 특히 프로듀서의 메세지 생성과 컨슈머의 소비 시간의 격차가 캐시할 수 있는 세그먼트 범주에 들어있어야 제성능이 나온다고 한다.\n이걸 자세히 보기 전에 내 의식의 흐름은 아래와 같았다.\n1. 카프카는 메세지를 디스크에 쓴다 -\u0026gt; 맞음 2. 카프카는 빠르다 -\u0026gt; 맞음 3. 그러면 분명히 메모리에 올릴거야 -\u0026gt; 맞음 4. 정확히는 컨슈머가 아직 안빼간 데이터를 메모리에 두고 있다가 디스크에 플러시하겠지? -\u0026gt; 틀림 5. 컨슈머가 늦게 빼가면 그걸 메모리에 올리는 별도의 로직이 있을꺼야! -\u0026gt; 틀림 이 치명적인 오류를 가졌음에도, \u0026lsquo;아니 이방법 말고 디스크에 쓰는놈이 어떻게 빠를 수 있는데\u0026rsquo;와 같은 마음을 먹고 당당하게 구현을 시작했다.\npub fn new(log_dir: PathBuf, config: StoreConfig) -\u0026gt; Self { let (flush_sender, flush_receiver) = mpsc::channel(100); let is_running = Arc::new(AtomicBool::new(true)); let segments = Arc::new(RwLock::new(HashMap::new())); let store = Self { log_dir, segments: segments.clone(), config: config.clone(), flush_sender, is_running: is_running.clone(), }; // 플러시 작업을 처리할 백그라운드 태스크 시작 store.start_flush_task(flush_receiver, config.flush_interval); store } // 대충 주기적인 플러시와 롤링이 일어날때 명시적인 플러시를 당당하게 구현해놓은 함수 fn start_flush_task( \u0026amp;self, mut flush_receiver: mpsc::Receiver\u0026lt;FlushMessage\u0026gt;, interval_duration: Duration, ) { let segments = self.segments.clone(); let is_running = self.is_running.clone(); tokio::spawn(async move { let mut interval = interval(interval_duration); while is_running.load(Ordering::SeqCst) { tokio::select! { _ = interval.tick() =\u0026gt; { // 주기적인 플러시 let segments_guard = segments.read().await; for (_topic_partition, cache) in segments_guard.iter() { for (_base_offset, segment) in cache.segments.iter() { let mut segment = segment.write().await; if let Err(e) = DiskMessageStore::flush_segment(\u0026amp;mut segment).await { eprintln!(\u0026#34;Error flushing segment: {:?}\u0026#34;, e); } } } } Some(msg) = flush_receiver.recv() =\u0026gt; { match msg { FlushMessage::Flush(topic_partition, base_offset) =\u0026gt; { let segments_guard = segments.read().await; if let Some(cache) = segments_guard.get(\u0026amp;topic_partition) { if let Some(segment) = cache.segments.get(\u0026amp;base_offset) { let mut segment = segment.write().await; if let Err(e) = DiskMessageStore::flush_segment(\u0026amp;mut segment).await { eprintln!(\u0026#34;Error flushing segment: {:?}\u0026#34;, e); } } } } FlushMessage::Shutdown =\u0026gt; break, } } } } }); } 지난번 레디스를 구현 할 때 배웠던 mpsc까지 써가며 열심히 플러시 로직을 구현했다. 주기적으로 메모리 버퍼를 락걸고 플러시하거나, 쓰기요청때 정해진 버퍼가 가득 차면 플러시를 하도록 하는 코드를 구현하고 매우 뿌듯하게 만족하고 있었다.\n#[async_trait] impl MessageOutgoingPort for DiskMessageStore { async fn store_message(\u0026amp;self, message: KafkaMessage) -\u0026gt; Result\u0026lt;u64\u0026gt; { let segment = self .get_or_create_segment( \u0026amp;TopicPartition { topic: message.topic.clone(), partition: message.partition, }, message.offset, ) .await?; let mut segment = segment.write().await; let new_offset = segment.allocate_offset(); let mut message = message.clone(); message.offset = new_offset; // 메모리 버퍼에 추가 시도 if !segment.buffer.add_message(new_offset, message.clone()) { // 메모리 제한에 도달한 경우 먼저 플러시 DiskMessageStore::flush_segment(\u0026amp;mut segment).await?; // 플러시 후 다시 시도 if !segment.buffer.add_message(new_offset, message) { return Err(DomainError::StorageError(\u0026#34;Message too large for buffer\u0026#34;.to_string()).into()); } } // 버퍼가 가득 찼거나 설정된 크기에 도달하면 플러시 if segment.buffer.is_full() || segment.buffer.messages.len() \u0026gt;= self.config.max_buffer_size { match DiskMessageStore::flush_segment(\u0026amp;mut segment).await { Ok(_) =\u0026gt; (), Err(e) =\u0026gt; { eprintln!(\u0026#34;Flush failed: {:?}, retrying...\u0026#34;, e); for _ in 0..3 { // 최대 3번 재시도 if DiskMessageStore::flush_segment(\u0026amp;mut segment).await.is_ok() { break; } tokio::time::sleep(Duration::from_millis(100)).await; } } } } Ok(new_offset) } // ... 그리고 위와 같은 로직을 작성하고 열심히 통합테스트를 돌리다 위화감을 느끼고 검색한 결과 실제 구현로직을 알게되었다. (놀랍게도 사전에 읽은 책에도 분명히 나와있던 내용이었다.)\n즉, 메모리에 메시지를 올려두고 있다가 플러시를 수행하는 방식을 구현했지만, 실제 카프카는 다르게 동작한다는 것을 나중에 깨달았다.\n카프카는 메시지를 바로 디스크에 기록하지만, OS의 페이지 캐시를 활용하여 성능을 최적화한다.\n그렇기 때문에 애초에 내가 구현한 것처럼 직접 메모리에 유지하고 있다가 플러시하는 방식이 필요하지 않았다.\n결국 아래와 같은 문제가 발생했다.\n설계가 복잡해짐 • 불필요한 플러시 타이머와 명시적인 플러시 요청 로직이 추가됨.\n• segments를 RwLock으로 보호해야 하는 등, 동기화 비용 증가.\n성능이 예상보다 낮음 • 초반에는 성능이 좋아 보였지만, 실제로 메모리 소비가 많고, 특정 조건에서 성능이 급격히 저하됨.\n• OS 페이지 캐시를 활용하는 것이 아니라, 직접 메모리를 관리하려다 보니 비효율적인 설계가 되어버림.\n결국 이 부분을 수정하려 했지만, 이미 해당 구조를 전제로 한 많은 코드가 있었기 때문에 완전히 다시 짜야 하는 상황이었다.\n그래서 당장은 그대로 두었고, 추후 개선 포인트로 남겨두었다.\n결론 프로젝트 진행상태 리뷰 일단 codecrafters 사이트에서 나와있는 모든 카프카 관련 기능들은 클론을 마쳤다. 추가적으로 프로듀서와 컨슈머 관련 api를 프로토콜 기반해서 스스로 문제를 정의해서 구현을 했다. producer api - 토픽, 파티션에 메세지 저장, 오프셋 기반으로 저장하기, 세그먼트와 인덱스파일 저장하기 consumer api - 특정 오프셋부터 읽어가기 등 아직 구현하지 못한 부분이지만 가장 아쉬운 것들 위주로 작성하면 아래와 같다. 리밸런싱, 혹은 키값을 지정해서 자동으로 파티션 할당 (메세지 입력순서 보장을 위한 핵심적인 기능이라고 생각한다.) 마찬가지로 컨슈머 그룹 관리 및 자동으로 파티션 할당 (라운드로빈) 위의 것들을 구현하면 뭔가 클라이언트를 실제로 붙일 수 있을 것 같기에 위의 과제를 가장 최우선적으로 보충해보고 싶다. 헥사고날 아키텍처에 익숙해졌나요? 반은 맞고 반은 틀린것같다. 상기한 이유로 애초에 잘 맞는지 모르겠으며 개인적인 \u0026ldquo;지금까지의 느낌\u0026quot;을 약간만 보충하면 헥사고날 아키텍처보다는 DDD가 어려운 것 같다. 사실 잘 어울리는 구조였는지는 모르겠다. 그리고 DDD를 잘 해야 헥사고날을 진짜로 잘 할 수 있을 것 같은 느낌이 들었고, DDD를 잘 하려면 처음부터 해당 도메인과 비즈니스 로직이 명확하게 잘 알고 있는 상태로 프로젝트의 첫 발을 놓아야 한다는 생각이 들었다.\n구조 자체에 대한 이해는 어느정도 피상적으로 한 것 같지만, 본질적인 부분은 DDD인 것 같았다는 것 자체가 배움이었던 것 같다.\n그래도 헥사고날 아키텍처에서 사용하는 관용구들과 컨벤션 이름들에 익숙해진 시간은 된 것 같다.\n메세지 브로커에 대해서 잘 알게 되었나요? 이전의 나와 이 프로젝트를 진행 한 이후의 나를 비교하면 매우 그런것 같다. 실제 구현을 하고 실수를 해보면서 카프카의 구조에 대해서 훨씬 더 잘 알게 된 것 같고. \u0026ldquo;왜 이렇게 되어있지?\u0026rdquo; 와 같은 부분에 대한 답변을 조금이나마 더 할 수 있게 된 것 같다.\n","permalink":"http://localhost:1313/_wiki/%EC%B9%B4%ED%94%84%EC%B9%B4%EB%A5%BC-%ED%97%A5%EC%82%AC%EA%B3%A0%EB%82%A0%ED%95%98%EA%B2%8C-%ED%81%B4%EB%A1%A0%EC%BD%94%EB%94%A9-%ED%95%B4%EB%B3%B4%EA%B8%B0/","summary":"Learners High Week 3,4 Summary! 카프카를 헥사고날 아키텍처를 토대로 클론코딩 해봤다. 깃허브 주소\nWeek 3,4 Intro 인사이동이 있었다. 부서이동으로 인한 OJT가 완료되어야 다음 이슈를 받을 수 있는 상황이었고, 기존에 받았던 이슈들은 처리가 완료되었다.\n일부 운영 이슈가 있었지만, 그것도 다 처리가 완료되어있어서 진짜 뭘 해야할지 모르겠는 상황이었다.\n새로운 프로젝트가 열리고, 업무를 파악하며 개선하고 싶은 부분들을 찾아서 열심히 코드를 봤지만, 그래도 당장 진행한다고 하기가 어려웠다.\n원래같았으면 공부나 발전을 하기에 오히려 좋았을 환경이었겠지만, 당장 나의 미션에 적합하지는 않다고 생각해서 굉장히 우울해 있다가, 털고 일어나서 지금 OJT기간을 가장 치열하게 보낼 수 있는 일들을 찾아봤다.","title":"러너스 하이 3~4주차 회고"},{"content":"00. Why..? 😬 일단 vimwiki 자체는 매우 만족하면서 잘 쓰고 있다. 다만 vimwiki는 몇몇 플러그인들과 호환성이 좋지 않거나, 설정이 변경되면 신경쓰이거나, 긴 마크다운을 편집할때 성능적으로 아쉬운 점이 많다.\n사실 대부분은 [[Vim-Profile-Log-Debugging]] 와 같이 디버깅을 하면 심각한건 해결이 되는데, 긴 글이나 특정한 플러그인과는 호환성이 좋지는 않은 것 같다.\n이런게 다 관리포인트라고 생각해서 고민하다가 옵시디언으로 기존 vimwiki가 관리하던 디렉토리를 열어봤는데, 너무 잘 호환이 되고 있었다.\n일단 당연하게도 기존에 사용하던 frontmatter 같은 것들은 예쁘게 잘 보여지고 있었고, 우연히인지 원래 마크다운 표준인지는 모르겠지만\n빔위키에서 사용하던 internal link의 태그가 obsidian에서도 internal link로 인식되어 관리되고 있었다.\n그래서 마이그레이션이라고 할 것 도 없이 바로 몇몇가지 설정을 추가하고 병용 가능하도록 작업을 했다.\n01. vimwiki에서 해주던 일들 🤔 일단 기본적으로 vimwiki를 사용하면서 가장 필수적이라고 느꼈던 것들을 추려보면 아래와 같다.\n자동 프론트매터 삽입 (vimscript) 자동으로 마지막 수정일자 업데이트 (vimscript) 링크 생성과 관리 홈(인덱스) 페이지 관리 및 자동 이동 vim 이다! 이것들이 가장 필수적이라고 느꼈고, 이게 가장 시급한 건데 이것들을 금방 대체 할 수 있는지를 찾아봤고 결과는 전부 가능하다였다.\n1번의 프론트매터는 templater라는 옵시디언의 플러그인이 있어서 매우 간단하게 해결했다. function! NewTemplate() let l:current_path = expand(\u0026#39;%:p:h\u0026#39;) if l:current_path !~ expand(g:vimwiki_primary_path) \u0026amp;\u0026amp; l:current_path !~ expand(g:vimwiki_secondary_path) return endif if line(\u0026#34;$\u0026#34;) \u0026gt; 1 return endif \u0026#34; 템플릿 let l:template = [ \\ \u0026#39;---\u0026#39;, \\ \u0026#39;title: \u0026#39;, \\ \u0026#39;summary: \u0026#39;, \\ \u0026#39;date: \u0026#39; . strftime(\u0026#39;%Y-%m-%d %H:%M:%S +0900\u0026#39;), \\ \u0026#39;lastmod: \u0026#39; . strftime(\u0026#39;%Y-%m-%d %H:%M:%S +0900\u0026#39;), \\ \u0026#39;tags: \u0026#39;, \\ \u0026#39;categories: \u0026#39;, \\ \u0026#39;description: \u0026#39;, \\ \u0026#39;showToc: true\u0026#39;, \\ \u0026#39;tocOpen: true\u0026#39;, \\ \u0026#39;---\u0026#39;, \\ \u0026#39;\u0026#39;, \\ \u0026#39;# \u0026#39; \\ ] call setline(1, l:template) normal! G$ endfunction 요런 프론트매터를 붙여줬어야 하는데, templater로 간단하게 해결했다.\n2번은 억지로(?) 해결.. 사실 이부분도 업데이트 시간을 체크해주는 플러그인이 있기는 한데, 해당 플러그인 업데이트가 엄청 오래전인데다가 마음에 들지 않는 부분도 있었다.\n그래서 글 수정시점 말고 커밋하고 푸시하는 시점으로 lastmod를 수정하도록 간단한 git pre-commit hook을 만들어서 등록해뒀다.\n#!/bin/bash echo \u0026#34;Starting pre-commit hook...\u0026#34; # 스테이징된 마크다운 파일들을 찾습니다 files=$(git diff --cached --name-only --diff-filter=ACM | grep \u0026#39;\\.md$\u0026#39;) # 파일 목록 출력 echo \u0026#34;Found files: $files\u0026#34; for file in $files; do echo \u0026#34;Processing file: $file\u0026#34; current_time=$(date \u0026#39;+%Y-%m-%d %H:%M:%S +0900\u0026#39;) echo \u0026#34;Current time: $current_time\u0026#34; tmp_file=$(mktemp) cat \u0026#34;$file\u0026#34; \u0026gt; \u0026#34;$tmp_file\u0026#34; awk -v time=\u0026#34;$current_time\u0026#34; \u0026#39; /^lastmod:/ {print \u0026#34;lastmod: \u0026#34; time; next} {print} \u0026#39; \u0026#34;$tmp_file\u0026#34; \u0026gt; \u0026#34;$file\u0026#34; rm \u0026#34;$tmp_file\u0026#34; git add \u0026#34;$file\u0026#34; echo \u0026#34;Updated and staged: $file\u0026#34; done echo \u0026#34;Pre-commit hook completed\u0026#34; exit 0 스크립트를 조금 더 깔끔하게 할 수 있었는데, 이게 스테이징된 파일을 추적하는게 잘 안됐고 이런저런 이슈가 있어서 임시방편으로 아래와 같이 했다. 수정 할 예정이다.\n3번은 살짝 귀찮게 되긴 했는데, 방법을 찾아봐야 할 것 같다. 기존에는 vim 커서 아래에 대상을 두고 엔터를 치면 간단하게 연결이 되었다. 하지만 obsidian에는 당연하게도 그런 기능은 제공하지 않아서 내가 링크할 파일을 직접 선택해야 한다. 다만 뒤로가기 같은 것들과 다음 링크로 이동하는 것 자체는 기본적으로 몇가지 단축키와 함께 해결이 가능하고, 링크 생성하는 것 자체는 gui와 자체 검색기능을 제공해줘서 참고 쓸 수 있는 범주인 것 같다.\n4번 역시 플러그인이 있다. home이라는 플러그인을 사용하면, 언제든지 인덱스 페이지로 이동이 가능하며, home탭을 고정시켜둘 수 있어서 매우 편하게 사용이 가능하긴 하다.\n5번은 놀랍게도 obsidian은 vim keymapping을 지원한다. 물론 퓨어 vim 수준의 아주 간단한 정도로 지원하지만, 이게 은근히 단점이 아니었던 부분이 여러가지가 있는데, 내가 실제 neovim을 사용 할 때 사용하는 커맨드들이나 매크로 등 몇몇 기능을 원래 vimwiki를 사용할 때도 잘 사용하지 않았던 것 같다. (아마도 \u0026lsquo;한글\u0026rsquo; \u0026lsquo;문서\u0026rsquo;를 편집하거나 작성 할 때 확 효용이 떨어지는 플러그인들이 많았어서 그런 것 같다. 코드와 영어는 대체 불가능하겠지만..)\n그래서 기본적, 습관적으로 사용하는 커서 이동, 문서 편집 단축키들이 잘 동작하는것만으로도 상당히 감지덕지였다.\n02. 생각하지 못했던 좋은 점들 🥸 마크다운을 편집하는 중에도 인라인 코드블럭 하이라이팅이 됨.. (vimwiki는 안됨) catppucin, nord, tokyo night등 유명한 ide 컬러스킴들이 이미 있음 nerdfont 지원함 editor 관련 설정들이 매우 상세하면서도 잘 구조화 되어있음. 03. 후기 아마도 성능과 관련한 부분에 있어서 특히, 그리고 점점 신경쓸 건덕지가 떨어진다는 점에서 obsidian을 한동안 편하게 사용 할 것 같다. 지금은 러너스하이 관련해서 진행했던 업무를 정리해야하는데, 주렁주렁 큰 블럭이 많은 문서들을 작성하게 될 것이라서 obsidian을 위주로 사용해보고 만약 사용감이 좋다면 추가적으로 옵시디언을 사용하게 될 것 같다.\n","permalink":"http://localhost:1313/_wiki/vimwiki-obsidian-%EA%B0%99%EC%9D%B4-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","summary":"00. Why..? 😬 일단 vimwiki 자체는 매우 만족하면서 잘 쓰고 있다. 다만 vimwiki는 몇몇 플러그인들과 호환성이 좋지 않거나, 설정이 변경되면 신경쓰이거나, 긴 마크다운을 편집할때 성능적으로 아쉬운 점이 많다.\n사실 대부분은 [[Vim-Profile-Log-Debugging]] 와 같이 디버깅을 하면 심각한건 해결이 되는데, 긴 글이나 특정한 플러그인과는 호환성이 좋지는 않은 것 같다.\n이런게 다 관리포인트라고 생각해서 고민하다가 옵시디언으로 기존 vimwiki가 관리하던 디렉토리를 열어봤는데, 너무 잘 호환이 되고 있었다.\n일단 당연하게도 기존에 사용하던 frontmatter 같은 것들은 예쁘게 잘 보여지고 있었고, 우연히인지 원래 마크다운 표준인지는 모르겠지만","title":"vimwiki obsidian 같이 사용하기"},{"content":" 코틀린 완벽 가이드 책과 코드스피츠 유튜브 스터디 영상 내용을 정리하거나 생각을 정리한 문서 (인용 태그를 제외한 모든 텍스트들은 스터디 내용을 필사하거나, 책에서 정리한 내용입니다.)\n출쳐 : 코틀린완벽가이드, 코드스피츠 유튜브 영상\n1~3장 - 코틀린 기본 식이 본문인 함수란 무엇인가? 블록이 본문인 함수 대신 식이 본문인 함수를 쓰면 어떤 경우가 좋은가? 간결하고, 명료할 수 있음 그러나 코틀린의 식은 문을 포함한 식이 될 수 있어 간단하게 이야기 하기는 어려움\n(참고)함수의 타입추론 기능 사용의 장단점\n타입추론을 사용하지 않는 경우 : 명시적인 반환타입을 가짐, 사고가 반환타입을 의도하고 정해두고 내가 몸체를 작성하는 흐름이 됨\n타입추론을 사용하는 경우 : (ide의 도움을 받으면) 컴파일러가 내 함수 몸체를 어떻게 평가하는지를 중간중간 확인하면서 코딩 할 수 있음, 다만 반환타입은 any로 가며, 복잡성이 높아질수록 컴파일 속도가 느려짐\n디폴트 파라미터와 함수 오버로딩 중 어느 쪽을 써야 할지 어떻게 결정할 수 있을까? 오버로딩을 하는 이유가 특정 파라미터의 값을 디폴트로 주고싶어서인 경우 디폴트 파라미터 사용\n// overloading fun readInt() = readLine()!!.toInt() fun readInt(radix: Int) = readLine()!!.toInt(radix) // default param fun readInt(radix: Int = 10) = readLine()!!.toInt(radix) (참고) 디폴트 파라미터가 오버로딩을 대체하지 못하는 케이스는 다른 형을 받을 때 이다.\n(참고) 현대의 언어들은 함수 콜스택 런타임에서 좌에서 우로 해석되고, 인자를 해석하는 별도의 스택을 가지고 있다. 그래서 뒷부분의 인자들은 앞부분의 인자를 이미 알고있어 오버로딩의 역할을 많이 대체 할 수 있다.\n(결론) 형이 변경되는게 아닌 인자를 줄이거나 하는 필요가 있을 때는 가급적 디폴트파라미터 사용\n이름 붙은 인자를 사용할 경우의 장단점은 무엇인가? 장점 : 호출부에서, 어떤 오버로딩 함수가 호출되는지 힌트를 주는식으로 표현력을 높여줄 수 있을 것 같다. 단점 : 안쓰면 그만이라 잘 모르겠다.\n장점 : 디폴트 인자가 많으면 순서 상관없이 인자를 넘길 수 있다, 인자가 너무 많거나, 디폴트 인자가 많으면 명시적으로 보일 수 있다.\nUnit과 Nothing 타입을 어디에 사용하는가? 이들을 자바의 void와 비교해 설명하라. Nothing이나 Unit이 타입인 함수를 정의해 사용할 수 있는가? Unit : unit값을 반환하지만 반환한 값이 쓸데없음, void : 값을 반환지 않고 타입에도 void는 없음, Nothing : 값이 반환 될 수 없음을 명시하는데 쓰이지만 모든 타입의 하위타입인 Nothing값을 반환하여 식으로 쓸 수 는 있음 (예외처리에 쓰이긴 함)\n자바의 가시성은 패키지 가시성, 코틀린은 모듈가시성이 디폴트 그런데, 코틀린에 패키지가시성이 없어서 불편해서 파일가시성이 나왔다.\n그래서 최상위 함수의 private은 파일 internal로 취급된다.\n코틀린의 패키지와 자바의 패키지 차이와 관련해서 c언어 : 모듈에 대한 참조가 물리적인 파일의 위치로 결정 (include)\n자바 : 어떤 물리적인 위치에 있어서 컴파일 시작 포인트로부터 계산되는 폴더의 경로만 일치하면 참조가능 (상대경로 완화)\n코틀린 : 니 편한대로 쓰고 코드의 패키지 선언에 있는 문자열로 패키지를 인식한다.\nwhile, do while을 언제 써야할까? // 외부 변수를 미리 선언하고 정리한 후에 사용 = while이 일어나기전에 예상할 수 있다. var i - 10 // 사실 그래서 이건 for문을 써야함 while (i-- \u0026gt; 0) { // ... // 만약 바디가 루프계획에 영향을 미치는 동적계획인겨우만 진짜 while } // 정말 얼마나 돌 지 모르겠는 경우 do { var j = 10 } while (j-- \u0026gt; 0) 4장 - 코틀린 클래스 코틀린 클래스의 기본적인 구조, 자바 클래스와의 차이는? 문법적인 차이 빼고는 별로 없다고 생각한다.\n상속할 때 반드시 super를 호출해야하는점이 큰 차이점\nopen class Parent(val data: String) { init { println(\u0026#34;Parent init: $data\u0026#34;) } } class Child : Parent { private val processedData: String constructor(rawData: String) : super(rawData.trim()) { processedData = rawData.uppercase() println(\u0026#34;Child init: $processedData\u0026#34;) } } inner class의 의의는 뭘까? // 1. 이걸 하고싶어서 class Possesion2(val person: Person, discription: String) { fun getOwner = person.familyName // Err } // 2. 이렇게 한다면 class Person(val firstName: String, private val familyName: String) { inner class Possesion(val discription: String) { fun getOwner() = this@Person.familyName } } // 3. 그냥 이렇게 하면 되잖아 class Person2(val firstName: String, private val familyName: String) { class Possesion(val person: Person2, val discription: String) { fun getOwner() = person.familyName // Ok!! } } // 내부 합성의 의의가 private property의 참조라면, 그건 그냥 static을 써도 되잖아 // 두번째로 환경을 캡쳐하면서 클로저와 동일하게 gc 이슈가 발생 지연초기화 매커니즘의 요지는? 실제 lateinit의 장점은? 지연 초기화 매커니즘의 요지는 지연 초기화 객체를 주는것, 지연 초기화 객체에 getX를 했을때 초기화 됐으면 내주고 아니면 초기화 로직 즉 초기화 한 값을 캐시로 잡는 상태를 내부에 내포한 객체로 제공해줘야함\n즉 lateinit은 by lazy의 편의 문법\nclass Example { lateinit var lateinitProperty: String val lazyProperty: String by lazy { println(\u0026#34;Lazy property initialized\u0026#34;) \u0026#34;Lazy Value\u0026#34; } fun initLateinitProperty() { lateinitProperty = \u0026#34;Lateinit Value\u0026#34; } fun accessProperties() { if (::lateinitProperty.isInitialized) { println(lateinitProperty) } else { println(\u0026#34;Lateinit property not initialized\u0026#34;) } println(lazyProperty) println(lazyProperty) // 두 번째 접근 } } fun main() { val example = Example() println(\u0026#34;====== first accessProperties() ======\u0026#34;) example.accessProperties() // 그냥 첫 접근시 초기화 되어 나옴 내부적으로 참조가 일어날때까지 초기화를 안할 뿐 println(\u0026#34;====== initLateinitProperty() ======\u0026#34;) example.initLateinitProperty() // lateinit 명시적 초기화 필요 println(\u0026#34;====== second accessProperties() ======\u0026#34;) example.accessProperties() } // 결론적으로 lateInit인 경우 제어권을 좀 더 줬을 뿐 추가적으로 delegate 관련 정리\nclass Person { // 1. lateinit - 나중에 초기화 lateinit var name: String // 2. lazy - 최초 접근 시 초기화 val lazyName: String by lazy { println(\u0026#34;lazyName 초기화 중...\u0026#34;) \u0026#34;John\u0026#34; } // 3. observable - 값 변경 감지 var age: Int by Delegates.observable(20) { _, oldValue, newValue -\u0026gt; println(\u0026#34;age 변경: $oldValue -\u0026gt; $newValue\u0026#34;) } // 4. vetoable - 값 변경 검증 var grade: Int by Delegates.vetoable(1) { _, _, newValue -\u0026gt; newValue in 1..6 // 1~6학년만 허용 } // 5. Custom Lazy Delegate val customLazyName: String by CustomLazy { println(\u0026#34;customLazyName 초기화 중...\u0026#34;) \u0026#34;Jane\u0026#34; } // 6. Custom Delegate with Provider val delegateName by DelegateProvider(\u0026#34;Lee\u0026#34;) } // Custom Lazy Delegate class CustomLazy\u0026lt;T\u0026gt;(private val initializer: () -\u0026gt; T) : ReadOnlyProperty\u0026lt;Any, T\u0026gt; { private var _value: T? = null override fun getValue(thisRef: Any, property: KProperty\u0026lt;*\u0026gt;): T { if (_value == null) { _value = initializer() } return _value!! } } // Custom Delegate Provider class DelegateProvider(private val initValue: String) : PropertyDelegateProvider\u0026lt;Any, ReadOnlyProperty\u0026lt;Any, String\u0026gt;\u0026gt; { override fun provideDelegate(thisRef: Any, property: KProperty\u0026lt;*\u0026gt;): ReadOnlyProperty\u0026lt;Any, String\u0026gt; { if (property.name != \u0026#34;delegateName\u0026#34;) { throw IllegalArgumentException(\u0026#34;delegateName만 연결 가능\u0026#34;) } return ReadOnlyProperty { _, _ -\u0026gt; initValue } } } // 사용 예 fun main() { val person = Person() // 1. lateinit person.name = \u0026#34;Kim\u0026#34; println(\u0026#34;name: ${person.name}\u0026#34;) // 2. lazy println(\u0026#34;lazyName: ${person.lazyName}\u0026#34;) // 3. observable person.age = 25 // 값 변경 로그 출력 // 4. vetoable person.grade = 3 // 허용 println(\u0026#34;grade: ${person.grade}\u0026#34;) person.grade = 7 // 변경되지 않음 println(\u0026#34;grade: ${person.grade}\u0026#34;) // 5. Custom Lazy Delegate println(\u0026#34;customLazyName: ${person.customLazyName}\u0026#34;) // 6. Custom Delegate with Provider println(\u0026#34;delegateName: ${person.delegateName}\u0026#34;) } val을 사용하지 않고 읽기 전용 프로퍼티를 만들수있는법 var age:Int = 3 private set 요지는 getter의 가시성이 setter의 가시성보다 커야한다.\nlateinit vs by lazy lateinit -\u0026gt; var, by lazy -\u0026gt; val 초기화 이후로 값이 계속 바뀌는 경우에 한정해서 lateinit을 사용 lazy는 값을 만드는 방법을 내포하고있지만, lateinit은 외부에서 주입되어야함 framework의 di를 이용 할 때 프레임워크가 꼭 넣어준다는 확신이 있을때만 쓰는게 낫다 기본형에는 lateinit 못씀 5장 고급 함수와 함수형 프로그래밍 활용하기 함수관련 슈가신택스가 가장 많은데, 실제로 많이들 써서..\n// 기본 시그니처 fun max(a:Int, b:Int): Int { if (a \u0026gt; b) { return a } else { return b } } // 표현식 return 가능 fun max2(a:Int, b:Int): Int { return if (a \u0026gt; b) { a } else { b } } // = 으로 선언 가능, 식하나인경우 중괄호 생략 가능 fun max3(a:Int, b:Int): Int = if (a \u0026gt; b) { a } else { b } // 반환값 추론 가능 fun max4(a:Int, b:Int) = if (a \u0026gt; b) a else b fun repeat(str: String, num: Int = 3, useNewLine: Boolean = true) { for (i in 1..num) { if (useNewLine) { println(str) } else { print(str) } } } // 확장함수(확장 프로퍼티도 동일) // 1. 만약 수신객체에 시그니처가 같은 멤버함수가 있으면 멤버함수 호출 // 2. 해당 변수의 현재 타입, 즉 정적인 타입에 의해 어떤 확잠함수가 호출될지 결정됨 (상속관계 등 에서) // 3. private, protected 접근 안됨 fun String.lastChar(): Char { return this[this.length -1] } // infix 함수 // 변수.함수이름(인자) 대신 // 변수 함수이름 인자 이렇게 호출 가능 (인자가 하나인 경우에) infix fun Int.plus(other: Int): Int { return this + other } fun testInfix(): Int { return 3 plus 4 } // 그 외에 지역함수, 인라인함수도 가능 // 함수형 기능 // 변수 할당가능, 익명함수 val isPositive = fun(num: Int): Boolean { return num \u0026gt; 0 } // 람다 val isPositive2 = { num: Int -\u0026gt; num \u0026gt; 0 } // 타입추론 가능하고 파라미터가 하나면 it 사용 가능 val isPositive3: (Int) -\u0026gt; Boolean = { it \u0026gt; 0 } // 클로저 사용 가능 fun closureTest() { val num = 3 val numList = mutableListOf(1, 2, 3, 4, 5, 6, 7) numList.asSequence().filter { it \u0026gt; num } } 람다식 반환타입을 적을 수 없고, 익명함수는 적을 수 있다. 람다식은 return 불가, 익명함수는 가능 스코프 함수 : 어떤 식을 계산한 값을 문맥 내부에서 임시로 사용할 수 있도록 해주는 함수 인자로 제공한 람다를 간단하게 실행시켜주는 역할을 하지만 관점에 따라 용도가 나뉜다. 문맥 식을 계산한 값을 영역함수로 전달할 때 수신 객체로 전달하는가?, 일반적인 함수 인자로 전달하는가? 영역 함수의 람다 파라미터가 수신 객체 지정 람다인가 아닌가? 영역 함수의 반환값이 람다의 결과값인가, 컨텍스트 전체를 계산한 값인가?\ndata class Person(var name: String = \u0026#34;\u0026#34;, var age: Int = 0) fun main() { // let: public inline fun \u0026lt;T, R\u0026gt; T.let(block: (T) -\u0026gt; R): R // null 체크 이후 블록 실행 // 전달된 람다 블록의 반환값을 반환 val nullableString: String? = \u0026#34;Hello\u0026#34; nullableString?.let { // let: String length is 5 println(\u0026#34;let: String length is ${it.length}\u0026#34;) } // with: public inline fun \u0026lt;T, R\u0026gt; with(receiver: T, block: T.() -\u0026gt; R): R // 수신 객체의 컨텍스트 확용 가능한 블럭 생성 val person1 = Person(\u0026#34;John\u0026#34;, 30) with(person1) { // with: Name is John, Age is 30 println(\u0026#34;with: Name is $name, Age is $age\u0026#34;) } val result = with(StringBuilder()) { append(\u0026#34;Hello\u0026#34;) append(\u0026#34;, \u0026#34;) append(\u0026#34;World!\u0026#34;) toString() } println(result) // \u0026#34;Hello, World!\u0026#34; // run: public inline fun \u0026lt;T, R\u0026gt; T.run(block: T.() -\u0026gt; R): R // with와 비슷, 그러나 확장함수로 호출됨 val person2 = Person(\u0026#34;Alice\u0026#34;, 25) val runResult = person2.run { println(\u0026#34;run: Name: $name, Age: $age\u0026#34;)맥 식을 \u0026#34;Person info: $name, $age\u0026#34; } println(\u0026#34;run result: $runResult\u0026#34;) // apply: public inline fun \u0026lt;T\u0026gt; T.apply(block: T.() -\u0026gt; Unit): T // let과 비슷 this로 참조 가능 val person3 = Person().apply { name = \u0026#34;Bob\u0026#34; age = 35 } // apply: Created person - Name: Bob, Age: 35 println(\u0026#34;apply: Created person - Name: ${person3.name}, Age: ${person3.age}\u0026#34;) // also: public inline fun \u0026lt;T\u0026gt; T.also(block: (T) -\u0026gt; Unit): T val numbers = mutableListOf(1, 2, 3) numbers.also { println(\u0026#34;also: The list elements before adding: $it\u0026#34;) }.add(4) println(\u0026#34;also: The list elements after adding: $numbers\u0026#34;) } data class Person(var name: String = \u0026#34;\u0026#34;, var age: Int = 0) fun main() { // 1. let 없이 null 체크 후 사용 val nullableString: String? = \u0026#34;Hello\u0026#34; if (nullableString != null) { val length = nullableString.length println(\u0026#34;String length is $length\u0026#34;) } // 2. with 없이 객체 프로퍼티 사용 (반복되는 참조) val person1 = Person(\u0026#34;John\u0026#34;, 30) val name1 = person1.name val age1 = person1.age println(\u0026#34;Name is $name1, Age is $age1\u0026#34;) val sb = StringBuilder() sb.append(\u0026#34;Hello\u0026#34;) sb.append(\u0026#34;, \u0026#34;) sb.append(\u0026#34;World!\u0026#34;) val result = sb.toString() println(result) // \u0026#34;Hello, World!\u0026#34; // 3. run 없이 객체 프로퍼티 사용 및 반환값 활용 val person2 = Person(\u0026#34;Alice\u0026#34;, 25) println(\u0026#34;Name: ${person2.name}, Age: ${person2.age}\u0026#34;) val runResult = \u0026#34;Person info: ${person2.name}, ${person2.age}\u0026#34; println(\u0026#34;run result: $runResult\u0026#34;) // 4. apply 없이 객체 생성 및 설정 (변수를 여러 번 참조) val person3 = Person() person3.name = \u0026#34;Bob\u0026#34; person3.age = 35 println(\u0026#34;Created person - Name: ${person3.name}, Age: ${person3.age}\u0026#34;) // 5. also 없이 리스트 요소 출력 후 추가 (중간 상태를 저장해야 함) val numbers = mutableListOf(1, 2, 3) val beforeAdding = numbers.toList() // 원본 보존 println(\u0026#34;The list elements before adding: $beforeAdding\u0026#34;) numbers.add(4) println(\u0026#34;The list elements after adding: $numbers\u0026#34;) } 람다, 함수타입 관련 자바와 코틀린의 차이 왜 코틀린은 auto SAM 인터페이스가 안될까?\n코틀린은 람다가 type임 반대로 자바는 편의문법임 (인터페이스 혹은 클래스에 속함 - java lamda factory) 입장이 정 반대임, 이미 코틀린은 람다 type을 가지고 있기 때문에, 굳이 특정 인터페이스를 지정해줘야 캐스팅이됨 수식 객체가 있는 함수타입과 수신 객체가 없는 함수타입을 비교해 설명하라. 변수 범위 내에서의 쉐도잉 문제가 코틀린에서도 엄청 자주 발생함.\n쉐도우의 유일한 장점은 안의 스코프에서 밖의 스코프를 참조 못하게 할 수있다는 것.\n심하게는 쉐도잉과 this 사용 자체를 금지하는 경우도 있다고 한다.\n확장함수를 한계는 명확하게 존재하면서(public만 참조가능), 실익은 크지 않고 나중에 혼란을 가중시킨다고 보는 것 같다. (this를 필두로한 섀도잉 등)\n추가로 공부하다가 본 내용 업캐스팅시에 타입에 맞는 확장함수를 쓸 수 있게 해주긴한다. 확장함수 실제 컴파일시 첫 번째 인수로 확장함수의 리시버를 받기 때문 대표적으로 널러블한 타입이나, 제네릭에도 확장함수를 구현 할 수있다. 어노테이션 처리기의 관심 대상은 아니다. 인터페이스를 깔끔하게 유지 할 수 있다. (이터러블 인터페이스는 iterator하나만 두고 나머지는 표준 라이브러리에 확장 함수 형태로 정의해뒀음) 람다를 쓰는 것보다 익명 함수를 쓰는 것이 더 좋은때는 언제인가? 익명함수 -\u0026gt; return으로 제어흐름 바꿀 수 있으니까 필요 할 때? 말고 잘 모르겠음\n아래 참고 단락은 인라인 함수의 경우 익명함수와 람다의 차이를 이야기하다가 나온 이야기이다.\n정확히는 람다가 조금 더 유연한 점을 표현한 이야기.\n이러한 이야기가 나온 것 자체가 뭔가 이야기 하다 보니 아래와 같은 엣지케이스를 제외하고는,\n람다보다는 익명함수를 쓰는게 좋을 때 가 많다는 식으로 조금 결론이 지어지는 것 같다.\n참고 Inline함수와 람다\ninline fun testInlint(block: () -\u0026gt; Unit) { block() } fun wrapper(): Int { val a: () -\u0026gt; Unit = { return 3 // 불가! } testInline(a) testInline { return 3; // 가능.. } return 3 } 컴파일러는 직접 생성된 람다에 하에서만 리턴을 허용한다..?\n이부분이 이해가 안가고 헷갈려서 찾아봤다. 컴파일은 아래와 같은 로직으로 이루어 진다고 한다.\nfun wrapper(): Int { val a: () -\u0026gt; Unit = { return 3 // 불가 (독립적인 함수 객체) } testInline(a) // 일반적인 함수 호출 // `testInline { return 3 }`이 아래처럼 인라인됨! run { return 3 // 가능 (wrapper()의 return으로 변환됨) } return 3 } 호출 가능 참조란 무엇인가? 호출 가능 참조의 여러 가지 형태를 설명하라. 각각의 형태를 자바의 메서드 참조와 비교하라. 어떠한 값이나 메서드가 리플렉션으로 봤을 때, KFunction이라는 뜻. 즉 KFunction을 얻기 위해 ::를 쓰는것.\n참고로 코틀린 리플렉션의 장점은 런타임 리플렉션이 아니라 컴파일 타임 리플렉션을 하는 것 이라고 함.\n성능상 장점 (런타임에 클래서 정의영억에서 참조하는 메모리 공간을 찾아서 정의를 찾아서 리플렉션함)\nclass Test { val f: ()-\u0026gt; Unit = {} fun action() {} } fun main() { // KProperty.value:(()-\u0026gt;Unit).invoke() 즉 KProperty의 참조값이 콜러블이라 invoke Test()::f.invoke() // KFunction.invoke() Test()::action.invoke() } 인라인 함수 관련 인라인 연쇄의 예시\n// foreach의 시그니처, 불필요한 인스턴스 생성 등을 막기 위해 기본적으로 inline으로 최적화를 해뒀다. public inline fun \u0026lt;T\u0026gt; Iterable\u0026lt;T\u0026gt;.forEach(action: (T) -\u0026gt; Unit): Unit {} fun inlineTest(block: () -\u0026gt; Unit): Map\u0026lt;String, () -\u0026gt; Unit\u0026gt; { val f = block return hashMapOf(\u0026#34;a\u0026#34; to f) } fun main() { val list = listOf(1, 2, 3, 4) val map = inlineTest { list.forEach { // 그러면 여기는 inline\b 화 가 될까? -\u0026gt; 인라인 연쇄 문제 print(it) } } } 컴파일 디컴파일하면 아래와 같이 나온다.\npublic final class MainKT { @NotNull public static final Map a(@NotNull Function0 block) { Intrinsics.checkNotNullParameter(block, \u0026#34;block\u0026#34;); return (Map) MapsKt.hashMapOf(new Pair(TuplesKt.to(\u0026#34;a\u0026#34;, block))); } public static final void wrapper() { final List list = CollectionsKt.listOf(new Integer[]{1, 2, 3, 4}); Map map = a((Function0) (new Function0() { // 감싼 람다는 함수객체를 만들어야함 public Object invoke() { this.invoke(); return Unit.INSTANCE; } public final void invoke() { Iterable $this$forEach$iv = (Iterable) list; // 이부분은 (forEach) 인라인화 성공! int $i$f$forEach = false; Iterator var3 = $this$forEach$iv.iterator(); while (var3.hasNext()) { Object element$iv = var3.next(); int it = ((Number) element$iv).intValue(); int var6 = false; System.out.println(it); } } })); } } 이런 상황도 있고 약간의 억지스러운 상황을 더 가정하면, inline 키워드가 있다고 무조건적으로 inline이 되지는 않는다.\n성능에 예민한 로직 혹은 프로젝트라면, inline을 더 조심해서 사용해야함.\n6장 특별한 클래스 사용하기 Enum 모든 열거형 클래스는 다음 컴패니언 객체 함수를 가진다.\nentries: 열거형 클래스의 모든 값을 리스트로 가지는 프로퍼티 valueOf: 입력받은 문자열과 이름이 일치하는 열거형 원소를 반환 도은 enum의 공통 프로퍼티, 메서드들\nordinal : 인덱스 name : 이름 열거형 값에는 상태가 있을 수 있음\n\u0026ldquo;절대 열거형 값의 상태는 변하지 않도록 만들 것\u0026rdquo;\nSealed Class 서브클래싱은 자유롭게 허용하지만, 정해진 타입 집합만 상속 가능하게 제한\n같은 파일 내에서만 서브클래스를 정의할 수 있음 컴파일러가 타입이 열거형처럼 “완전”하다고 가정할 수 있게 도와줌 주로 when 표현식과 함께 사용되어, 모든 하위 타입을 다룰 수 있음을 보장 sealed class는 런타임에 타입을 제한하는 것이 아니라, 컴파일 시점에 타입을 제한합니다.\nsealed class Response data class Success(val data: String) : Response() data class Error(val message: String) : Response() object Loading : Response() fun handle(response: Response) { when (response) { is Success -\u0026gt; println(\u0026#34;Success: ${response.data}\u0026#34;) is Error -\u0026gt; println(\u0026#34;Error: ${response.message}\u0026#34;) Loading -\u0026gt; println(\u0026#34;Loading...\u0026#34;) } } 구분 enum sealed class 목적 고정된 “값” 집합 고정된 “타입” 집합 상속 불가 (모든 값 타입 동일) 가능 (각 값이 다른 타입일 수 있음) 추가 데이터 보유 필드로 제한 다양한 프로퍼티 및 메서드 가질 수 있음 패턴 매칭 when에서 이름 비교 when에서 타입 매칭 Data Class 동등성 비교나 간단한 보일러 플레이트를 컴파일러가 작성해줌\ndata class Human( val firstName: String, val familyName: String, val age: Int ) data class MailBox( val address: String, val person: Human ) fun main() { val box1 = MailBox(\u0026#34;Unknown\u0026#34;, Human(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, 25)) val box2 = MailBox(\u0026#34;Unknown\u0026#34;, Human(\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, 25)) println(box1 == box2) // true, 그러나 Human이 data클래스가 아니면 falsee } 주생성자의 파라미터에서 선언한 프로퍼티만 equals()/hashCode()/toString() 구현의 대상임.\ncopy로 복사기능도 구현됨 (shallow copy)\nfun main() { val jane = Human(\u0026#34;Jane\u0026#34;, \u0026#34;Doe\u0026#34;, 32) jane.copy().show() jane.copy(familyName = \u0026#34;Smith\u0026#34;).show() } 데이터 클래스는 필수 프로퍼티들이 모두 주 생성자에 담겨 있따고 가정합니다. 본문 코드에는 필수 프로퍼티들에 기반한 불변 프로퍼티만 담겨 있어야 합니다.\n","permalink":"http://localhost:1313/_wiki/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%99%84%EB%B2%BD-%EA%B0%80%EC%9D%B4%EB%93%9C-1%EC%9E%A5-6%EC%9E%A5/","summary":"코틀린 완벽 가이드 책과 코드스피츠 유튜브 스터디 영상 내용을 정리하거나 생각을 정리한 문서 (인용 태그를 제외한 모든 텍스트들은 스터디 내용을 필사하거나, 책에서 정리한 내용입니다.)\n출쳐 : 코틀린완벽가이드, 코드스피츠 유튜브 영상\n1~3장 - 코틀린 기본 식이 본문인 함수란 무엇인가? 블록이 본문인 함수 대신 식이 본문인 함수를 쓰면 어떤 경우가 좋은가? 간결하고, 명료할 수 있음 그러나 코틀린의 식은 문을 포함한 식이 될 수 있어 간단하게 이야기 하기는 어려움\n(참고)함수의 타입추론 기능 사용의 장단점","title":"코틀린 완벽 가이드 간단 정리"},{"content":"2025-01-08 너무 바빠서 뭘 못하고있다. 2025-01-11 착한회사 vs 착하지 않은 회사 : 사실상 의미가 없는 것 같기도 하다 굳이 착해야 할 필요도 없을 뿐더러 착한게 좋은지 아닌지도 모르겠다, 다만 그래서인지는 모르겠지만 착한회사는 없다고 보는게 마음다칠 일이 없다고 생각이 든다. 좋은회사 vs 나쁜회사 : 본인의 비즈니스를 성공시키는 유능한 회사와 그렇지 못하는 회사 2025-01-13 일어날일은 일어난다 2025-01-17 vimwiki와 옵시디언을 병행해서 사용하게 될 것 같다. 2025-01-18 기나긴 회고를 작성할 예정이다. 파란색을 좋아하는데, catppuccin으로 블로그 테마를 변경하니까 가시성이 개선되어 우울해졌다. 2025-01-24 좋은일만 있길! 2025-01-30 할게 많고, 커밋수가 늘어나면 잘 안오게 되는 것 같다. 그러지 말아야지 그래도 보람찬 연휴를 보내고 있는 것 같다. 이것저것 공부가 잘된다. yazi 관련한 포스팅을 좀 해볼까한다. 연휴가 끝나기 전에 2025-02-02 운영체제 아주 쉬운 세가지 이야기를 오늘 내일 사이에 다 읽는 목표를 가지며 주말을 마무리하기 2025-02-06 아주아주 하기 싫은 날 특징 할일을 늘어놓는다. (코테준비, 쿼리 - 금토일 데일리) (강의 전부 다듣기 - 이번주말까지) 방청소마냥 블로그를 새단장한다 (놀랍게도 한거임) 2025-02-07 컨디션이 쉽지는 않다, 그래도 할일은 해서 뿌듯하다 2025-02-09 늦은 나이까지 일을 하기 위해서 뭘 미리하면 좋을지에 대한 이야기를 많이 하는 것 같다. 2025-02-10 2년 뒤에 이런 식견을 이야기 할 수 있으면 좋겠다 2025-02-12 모던 유닉스 툴을 사용하면 좋지만 지나치게 nerd-font에 있는 아이콘들을 사용해서 pbcopy와 같은 것들을 이용할때 귀찮아 지는 경우가 있다. 완벽한 설정은 없으려나! 2025-02-04 jdtls가 쓸만해졌으면 좋겠다. 인텔리제이가 싫은건 아는데 주언어가 묶여있어야 하는건 싫다. 2025-02-15 당신의_블로그에는_아무도_관심이_없습니다 : ga가 찐빠나도 느긋하게 생각하는 개인 블로그에 지나치게 내 생각을 검열하지는 않나? 하는 생각을 했다. 2025-02-16 다음 해야 할 일을 알아보는날 2025-02-19 감사합니다! 2025-02-22 조금 더 긴 호흡으로 준비하게 될 것 같다. 그래서 일단 레디스를 다시 시작, 내일은 강의듣기 완료가 목표 2025-02-24 TIL처럼 DailyLog를 작성하려고 틀었다. TIL : 주말동안 cli로 llm클라이언트를 만들어보려고 여기저기 레포를 뜯어보다가 알게된 사실은 llm에서 대화라는 것 자체는 환상이라는 것 이다. claude api는 애초에 대화 세션 아이디 같은게 없고, 직전까지의 대화를 보내기 최적화된 인터페이스를 제공한다. 그리고 사실상 완전히 stateless하게 운영한다. open api는 일부 상태를 갖긴 하는데, 서비스 레벨에서 이루어지는 내용이고, 결국 모델은 처음부터 (이전 대화내용이 조금 더 붙은) 문자열 토큰으로 새로운 추론을 하는 것 뿐이다. 작성하고보니 당연한가 싶긴 한데, 그래도 조금 신기했다. 2025-02-25 다시 레디스를 만들고 있다. 프로젝트를 갈아엎는게 나은가 싶은 좋은 코드를 보게되어 우울하다. 생각보다 조금 더 러스트는 절차형 코드가 예쁘게 잘 나오는 것 같다. 생각보다 조금 더 나는 자바스럽게 (주로 안좋은 의미로) 코딩하고 있는 것 같다. TIL : 러스트에서는 오너십을 다시 가져오기 위해서 take와 같은 패턴이 있다. 안전함 측면에서는 Rc/Arc가 맞지만, 정말 명확하게 문제를 인지 할 수 있고, 비동기 코드를 잘 구현해놓을수 있다면 Rc/Arc가 필요하다고 생각되어지는 경우를 대부분 대체 할 수 있다. 오버헤드는 사실 걱정할정도로 뭔가 해본적은 없지만, 코드가 불필요한 await로 지저분해지는것을 막을 수 있다. 내일부터는 진짜진짜 다시 leetcode로 돌아가야지 2025-02-26 빅 샤이닝 슈퍼해피 2025-02-28 TIL : saga 패턴에는 두가지 방식이 존재한다 Choreography Saga : 메세지브로커로 이벤트를 교환하며 진행하는 방식 단일장애점이 없음, 현재 상태 추적이 어려움 Orchestration Saga : orchestration을 둔다 Orchestrator가 단일 장애점, 현재 상태 추적이 용이하다. 난 이런 고민 없이, 데이터서버가 orchestrator역할을 수행하게 되었던 것 같다. 1 - ~ real mysql 2,3 - 데이터베이스 인터널스 3,4 - 대규모 1,2 5 - 버퍼 6,7,8,9 - jvm, ostep 카프카 prj, springboot, 2025-03-05 늘 하던 뭐시기니까? 2025-03-06 미뤄뒀던일을 더 미룰 명확한 이유가 있긴하지만 밀려가는걸 보는게 약간 아쉬웠던 날 2025-03-09 원래도 하고있던 방식에 뭔가 멋진 패턴 혹은 아키텍처 이름이 붙어있다는걸 알게되는 요즘이다 확실히 잘하는 동료들이 많은 회사였던 것 같다. 2025-03-16 많이 아쉬운 만큼 많이 배운 것 같다 실제 잘못된 부분의 회사 코드를 수정했다. 많이 준비한 부분보다, 그렇지 않은 부분에 대해서만 대화가 이루어진 부분에 대해서는 준비 방향성도 고민을 많이 해봤지만, 이건 시행횟수의 문제점이라고 생각했다. 준비 방향성 자체가 문제라고 해도 그걸 생각해서 지금 하는 방법을 바꾸는것은 내 스스로의 성장에 아쉬운 방향인 것 같다. 물어보지 않는 것에 대한 공부를 배제하려고 하는 것 일 수 있다. 2025-03-22 이래저래 바쁜와중에 사카모토 데이즈를 보고있다. 상당히 재미있다. 그리고 모처럼 쉬는게 진짜 좋다. 리노가 밥을 덜먹는게 일시적인게 맞으면 좋겠다. 2025-03-23 리노 병원 다녀와서 오늘은 휴식! 2025-03-26 TIL : go struct에는 메모리 패딩이 적용된다. package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) type User struct { A int8 B int C int8 D int E int8 } func main() { user := User{1, 2, 3, 4, 5} fmt.Println(unsafe.Sizeof(user)) } 2025-03-29 문제삼기 전까지 문제가 아닌 것들이 가장 큰 문제이더라 밀물이 들어오면 모든 배가 뜬다. 아무 의미심장한 의도 없이 그냥 여기저기 돌아다니다 본 문장들이 와닿아서 써봄.. 2025-03-31 시간은 정말 빨리가네 오늘부터는 별도로 노션에 정리하는 부분이 있을 것 같다. 2025-04-01 결국 via 사용이 가능한 키보드를 들였다. 적응할 건덕지가 많기는 하다 세상에서 가장 독특한 한영키 위치를 만들수 있게 되었다. 한eng 2025-04-02 TIL : CQS 메서드는 상태를 변경하는 명령이거나 값을 반환하는 질의중 하나여야 한다 2025-04-03 좀 더 릴렉스 한 상태로 생각했다면 좋았을 것 같다. 내손을 떠났으니 겸허하게 기다리기..는 경험이 너무 좋았어서 너무 아쉽고 살짝 자책이 든다 🥲 2025-04-04 공부해야할 주제를 공부한 시간이었다. structured output gpt functionCalling mcp browser-use minus agent 2025-04-05 프레임워크의 종말 이라는 도발적인 영상 물론 \u0026ldquo;클리셰수준으로 나오는 이야기\u0026quot;라는 의견에도 동의하지만 llm관련해서 나오는 이야기랑 엮어서 보면 이번에는 또 혹시 모른가 싶긴 하다. 다만 영상은 이러한 관점이라기보다는 프레임워크의 유무에 대해서만 다루고있어서 아쉽다 난 항상 진짜 최고의 ai가 나오면 과연 코드를 어느레벨에서 관리할지가 궁금했는데 확실히 프레임워크까지 올 것 같지는 않아서 동의가 되는 부분도 있다. 바로 윗줄과 관련해서 이런 긱뉴스도 있다. 결과는 결과로 두고 내 할일을 열심히해서 살아남아야지 영어를 다시 갈고 닦아야 할 이유가 생겨나는 요즘이긴 하다.(물론 그 필요성을 이야기하는것과는 다른 맥락이고 그런 관점에 동의하지 않는다.) 학부때 읽었던 소쉬르 책을 읽고싶어지긴 했다 (지금 드는 생각들이 그 책을 다시 읽어야 정리하고 말 할 수 있을 것 같은 느낌) 2025-04-06 뭐가 손에 잘 안잡혀서 오랫만에 엄청 잘 쉬었다. 해야할일은 산더미인데 뭐가 손에 안잡힌다 마찬가지로 할일을 하지 않으면 할일을 정리하는것으로 정신승리를 한다. golang 공부하기 mcp, function calling, browser-use등 공부하기 via layout 확정하기 중간고사 레포트 쓰기 강의 수강하기 2025-04-07 내일부턴 진짜 뭔가를 해야겠다 go부터 시작해야 할 것 같다. 같은 옷 입기, 외부모니터 안쓰기 와 같은 쉽지않은 이야기를 보고 다시 해피해킹으로.. 2025-04-08 go를 시작했다 쉽지않은 일도 뭐 이래저래 있고.. 외부모니터 안쓰는건 모르겠고, 해피해킹으로 돌아가는건 그럴만할지도 2025-04-14 안읽은 좋은 책들이 많은것같다 프로그래머로 사는 법 리눅스 커맨드라인 완벽 입문서 http 완벽 가이드 프로그래밍 수련법 로젠의 이산수학 (은 읽었지만 모종의 이유로 다시 구해야 한다) 기술적인걸 대비하면서는 진짜 공부를 많이하게 되었는데, 문화적인걸 대비하면서 나에대해 진심으로 생각해보고있는 중이다. 2025-04-15 좋은 책을 읽고, 조금 더 생각을 많이하기로 그리고 솔직하게 2025-04-16 회사일이 유난히 즐거웠다 2025-04-18 결과는 별로 상관없는데, 물렁한 사람으로 보인게 많이 화난다 2025-04-24 중심을 잘 잡고 잘하는걸 더 잘하기로 2025-04-26 코틀린, 러스트 관련 읽을 책들 함수형, 멀티패러다임, ps 강의 하이버네이트 강의 ","permalink":"http://localhost:1313/_wiki/daily-log-2025/","summary":"2025-01-08 너무 바빠서 뭘 못하고있다. 2025-01-11 착한회사 vs 착하지 않은 회사 : 사실상 의미가 없는 것 같기도 하다 굳이 착해야 할 필요도 없을 뿐더러 착한게 좋은지 아닌지도 모르겠다, 다만 그래서인지는 모르겠지만 착한회사는 없다고 보는게 마음다칠 일이 없다고 생각이 든다. 좋은회사 vs 나쁜회사 : 본인의 비즈니스를 성공시키는 유능한 회사와 그렇지 못하는 회사 2025-01-13 일어날일은 일어난다 2025-01-17 vimwiki와 옵시디언을 병행해서 사용하게 될 것 같다. 2025-01-18 기나긴 회고를 작성할 예정이다. 파란색을 좋아하는데, catppuccin으로 블로그 테마를 변경하니까 가시성이 개선되어 우울해졌다.","title":"Daily Log 2025"},{"content":"출처 만들면서 배우는 헥사고날 아키텍처 설계와 구현 - 링크 도메인 주도 개발 시작하기 - 링크\n도메인 헥사곤 문제 영역에서 라우터가 고정된 것이 아니고, 라우터의 특성이 변경될 수 있다는 사실을 알 수 있다. 이 때문에 라우터는 수명주기를 가진다고 말할 수 있다. 이외에도 모든 라우터는 인벤토리에서 고유해야하므로 식별자를 가져야 한다. 이러한 \u0026lsquo;연속성\u0026rsquo;과 \u0026lsquo;정체성\u0026rsquo;은 엔티티를 결정하는 요소이다.\nDDD의 그 도메인을 이야기한다. Entity, Value Object, aggregate의 개념도 그대로 있다. 아마 아래에서 한 번 더 정리할 것 같다. 여기서는 \u0026lsquo;헥사고날 아키텍처에서는 가장 안쪽 Layer를 이루고 있다.\u0026lsquo;는 사실이 중요하다. 애플리케이션 헥사곤 비즈니스 규칙을 \u0026lsquo;지원\u0026rsquo;하지만, 소프트웨어의 컨텍스트 외부에는 존재하지 않는다. 애플리케이션에 특화된 오퍼레이션이다. 유즈케이스, 입력포트, 출력 포트를 기반으로 구성되어있다.\n유즈케이스 (Use Case) 유즈케이스는 시스템이 제공해야 하는 동작(특정 작업 흐름)을 정의하며, 도메인 규칙을 실행하기 위해 외부와 도메인을 연결하는 역할을 한다. 입력 포트와 출력 포트를 통해 도메인과 외부 시스템을 연결하는 핵심 동작을 구현한다. class CreateOrderInteractor( private val inventoryOutputPort: InventoryOutputPort, private val orderOutputPort: OrderOutputPort ) : CreateOrderUseCase { override fun execute(request: CreateOrderRequest) { // Step 1: 재고 확인 if (!inventoryOutputPort.checkInventory(request.productId, request.quantity)) { throw IllegalArgumentException(\u0026#34;재고가 부족합니다.\u0026#34;) } // Step 2: 도메인 객체 생성 val order = Order( productId = request.productId, quantity = request.quantity, userId = request.userId ) // Step 3: 출력 포트를 통해 주문 저장 orderOutputPort.saveOrder(order) } } 입력 포트 (input port) 입력 포트는 시스템이 외부로부터 들어오는 요청을 도메인 유즈케이스로 전달하는 인터페이스. interface CreateOrderUseCase { fun execute(request: CreateOrderRequest) } 출력 포트 (output port) 출력 포트는 도메인이 외부 시스템(DB, API 등)과 상호작용할 때 사용하는 인터페이스이다. interface InventoryOutputPort { fun checkInventory(productId: String, quantity: Int): Boolean } interface OrderOutputPort { fun saveOrder(order: Order) } 프레임워크 헥사곤 Driving Operation과 Input Adapter 외부 요청을 받아서 이를 도메인 로직(유즈케이스)으로 전달하는 역할 사용자가 시스템과 상호작용하거나, 외부 시스템이 애플리케이션을 호출할 때 사용하는 진입점 주로 컨트롤러, 이벤트 리스너, 또는 메시지 큐 소비자가 인풋 어댑터의 역할을 수행 Driven Operation과 Output Adapter **도메인 로직(유즈케이스)**에서 발생한 작업 결과를 외부 시스템에 전달하는 역할 도메인 로직이 직접 외부 시스템(DB, API, 메시지 브로커 등)과 상호작용하지 않고, 출력 포트를 통해 이 어댑터를 호출 주로 리포지토리, API 클라이언트, 메시지 발행자가 아웃풋 어댑터의 역할을 수행 흐름 정리와 내 생각 외부 요청 → 인풋 어댑터: 외부 요청이 컨트롤러(인풋 어댑터)를 통해 시스템으로 들어온다 인풋 어댑터 → 유즈케이스: 입력 포트를 통해 유즈케이스를 호출 유즈케이스 → 출력 포트: 비즈니스 로직 처리 후, 출력 포트를 호출하여 외부 작업을 위임 출력 포트 → 아웃풋 어댑터: 출력 포트의 구현체인 아웃풋 어댑터가 외부 시스템과 상호작용 개요만 봤을때는 크게 와닿지는 않았다.\n대충 비유하자면 DDD를 레이어드 아키텍처로 구현한걸로 비교했을 때, 표현계층이 InputAdapter로, 인프라계층이 OutputAdapter로 도메인은 그대로 도메인, 서비스에서 도메인을 호출하던 로직을 작게 나누어 유즈케이스로 나눈다 정도인것같고,\nInputAdapter, OutputAdapter는 유연하게, 어떠한 어댑터를 만들어 끼워도 동작할 수 있도록 포트를 잘 설정해두는 것 정도가 중요한 것 같다. 도메인을 가운데 두고 기술적인 코드와 비즈니스 로직(도메인의)을 분리한다 라는 말이 아직 잘 와닿지는 않는다. 다만 부정적인 감상을 이야기하는 것은 아니고, 조금 더 봐야 할 것 같다는 이야기이다.\n","permalink":"http://localhost:1313/_wiki/%ED%97%A5%EC%82%AC%EA%B3%A0%EB%82%A0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/","summary":"출처 만들면서 배우는 헥사고날 아키텍처 설계와 구현 - 링크 도메인 주도 개발 시작하기 - 링크\n도메인 헥사곤 문제 영역에서 라우터가 고정된 것이 아니고, 라우터의 특성이 변경될 수 있다는 사실을 알 수 있다. 이 때문에 라우터는 수명주기를 가진다고 말할 수 있다. 이외에도 모든 라우터는 인벤토리에서 고유해야하므로 식별자를 가져야 한다. 이러한 \u0026lsquo;연속성\u0026rsquo;과 \u0026lsquo;정체성\u0026rsquo;은 엔티티를 결정하는 요소이다.\nDDD의 그 도메인을 이야기한다. Entity, Value Object, aggregate의 개념도 그대로 있다. 아마 아래에서 한 번 더 정리할 것 같다.","title":"헥사고날 아키텍처 정리 🧔‍♂️"},{"content":"Learners High Week 2,3 Summary! Thread local한 MDC를 이용해서 로그에서 요청을 단위로 식별 할 수 있게 했다. PII가 아니면서도 사용자를 식별 할 수 있는 값으로 사용자의 연속성 있는 요청 흐름을 볼 수 있게 보완했다. 그라파나에 관련한 메트릭을 추가했다. 해당 이슈도 해결하고, 과정중에서 밝혀진 숨겨진 이슈도 특정해서 해결했다. Learners High Week 2,3 Intro 커뮤니티 관련 프론트엔드 백엔드 작업을 마치고, qa가 완료되었다. qa기간중이기는 하지만 일정상 여유가 생긴 덕에 다음 작업을 준비할 시간이 생겼었다. 다음 이슈는 소셜로그인 관련 오류를 해결하는 운영이슈였는데, 해당 이슈를 요약하자면\n사용자의 소셜 로그인이 실패하는 이슈 특정 환경에서만 재현이 가능함 (운영 + 특정한 조건) 그 외에 환경에서는 정상적으로 동작하고 있음 와 같은 특징을 가지고 있었다. 먼저 고객 센터를 통해서 인입이 된 이슈였는데, 2번의 특정 재현 조건을 알기가 어려워서 지난 번 인입때, 운영 로그를 뒤적이다가 이슈를 해결하지 못하고, 다른 업무를 본 이후에 처리하기로 되어 있는 이슈였다.\n지난번 인입때, 해당 시간대의 gb 단위의 로그를 보다가 결국 찾거나 특정하지 못하고 덮어뒀었는데, 로그로 이슈를 해결 할 수 없었던 이유가, 여러가지 있었다.\n멀티스레드 환경에서 요청과 관련한 로그를 특정할 식별자가 없어서 다른 수많은 로그들과 섞인다. 소셜로그인 같은 요청은 서버와 클라이언트가 하나의 목적을 가지면서 연속적으로 요청 응답 하는데 이 과정을 연속성 있게 볼 방법이 없다. 그냥 로그가 잘 안되어 있었다. 사실 디버깅을 하는 용도의 스테이징 환경이 잘 되어있어 크게 불편함 없이 위와 같은 상태로 개발을 해왔던 것 같다. 실제로도 디버깅을 하는건, 로컬에서 하거나 몇가지 로그를 추가해서 스테이징에 올려두면 거의 운영과 동일한 상태로 로그를 볼 수 있기 때문에 위와 같은 불편함을 겪을 상황은 그렇게 많지 않기도 했다. 다만 지금처럼 실제로 운영 로그를 봐야 하는 경우에는 극도로 불편하기도 했고, 우리가 로그를 이용해서 문제를 얼마나 잘 인지하고 있을 지, 지금처럼 고객센터를 통한 인입이 되어야 이슈를 인지하는 상황이 맞는지 의문이 들었다.\nAbout MDC 위에서 설명한 불편한 일들을 가지고 동료와 이야기를 나누던 도중 mdc에대해서 알게 되었고, 딱 필요한 부분이 mdc라는 것을 알게 되었다. 간단하게 찾아본 내용들을 요약하면, 쓰레드로컬을 사용하는 로그 전용 키밸류 저장소였다.\n보통 인프라 가장 앞단에서 x-trace-id와 같은 uuid 난수 기반 헤더와 함께 요청을 식별하는데 쓰이는 경우가 많은 것 같다.\n로그 시스템과 통합되어 있기도 하고, 쓰레드로컬에 직접 사용하는 것보다 더 편리한 몇가지 기능들을 제공한다.\n다만 초기화를 잘 해줘야하는데, 초기화가 안된경우 적게는 메모리 누수부터(\u0026hellip;) 크게는 다른 요청에서 직전 요청과 관련된 값을 이용하게 될 수 있다.\n어떠한 값을 식별값으로 두는게 좋을까? PII와 관련된 개인정보 보안 측면에서 그 다음으로 고민 한 것은 어떠한 값을 식별값으로 두는게 좋을지, 더 정확하게는 어떠한 값을 식별값으로 둬도 될지 였다.\n보통은 리버스프록시쪽에 x-trace-id와 같은 식별값을 인프라레벨에서 붙이는 모양인데, 내가 보고싶었던 것은 연속성 있는 사용자에 대한 식별정보였다.\n우리는 세션을 이용한 로그인 방식을 채택하고 있었고, 세션 클러스터링도 지원하고 있어서 처음에는 아주 쉽게 session_id를 식별값으로 두는게 낫다는 생각을 하고 있었다.\n다만 다른 케이스들을 찾아보고 적용예시들을 찾아봐도 세션아이디를 직접적으로 이용하는 경우를 찾아 볼 수 없었다.\n생각으로는 세션아이디가 가장 편리한 식별값인데도 왜 사용하지 않을까 생각해서 우리 프로젝트에서도 검색해봤는데, 세션아이디를 직접적으로 로깅하는 부분은 하나도 찾을 수 없었다.\n결국 관련해서 검색하다보니 세션아이디가 pii일 수 있다는 논의를 보게 되었다. 링크\n여기도 논의를 요약하면\n비로그인한 사용자의 세션아이디를 사용하는건 \u0026ldquo;개인정보 저장 및 처리에 대한 동의\u0026quot;를 구하지 않은것이고 로그인한 사용자의 세션아이디를 사용하는건 개인을 식별 할 수 있는 값으로 쓰일 수 있다는 것이다. 결론적으로 세션아이디를 직접 사용하는건 최소 논쟁적일 여지가 충분하다는 생각이 들어서 조금 더 고민을 했다.\n성능과 리소스 측면에서 물론 커스텀 헤더 하나와 uuid 생성하는 정도의 비용이 크지는 않지만, 연속성 있게 식별하기 위해서 값을 추가로 설정하는 측면에서 생각하면 분명히 생각해봐야 할 문제였고, 기존의 메인 백엔드 서버가 워낙 비대하고 성능이슈가 많은 부분이라서, 보수적으로 접근해야 머지할 수 있을 것 같았다.\n실제로 관련해서 팀장님과 이야기를 나누었을 때, 운영팀에서 분명히 성능 걱정을 할 수 있을것이라는 우려를 들었다.\n그래서 관점을 기존에 사용하던 값 혹은 어쩔 수 없이 쓰고 있던 값을 기준으로 찾아보게 되었다.\n식별값 결론 위와 같은 관점으로 고민하다 보니, 이미 사용하고 있던 적합한 값을 찾게 되었다. 프론트의 첫 요청(익명 사용자의 세션이 발급된 시점과 거의 동일하게)에 생성되는 특정 난수값이 있었다. 해당 난수값의 특징은 아래와 같았다.\n원래 용도는 cloudfront 람다에서 사용하기 위한 키값이고 이미 사용하고 있음 람다에서 캐시를 식별하기 위한 최소한의 정보 + sessionId 를 암호화한 해쉬값 그래서 프론트에서 이 해쉬부분만 잘라서 사용한다면, 이 값을 사용하는데 있어 추가적인 리소스를 거의 사용하지 않고, pii와 관련된 이슈도 없어서 매우 적합하다는 생각이 되었다.(세션아이디를 마스킹하거나 해쉬하면 사용가능하다고 한다)\n로그 관련 작업 시작 기존 프로젝트, 환경 검토 메인 백엔드 서버\n사용하고 있는 Hybris라는 솔루션에서, 로그 관련 설정을 래핑해서 구현체를 제공하고 있었다. 그리고 실제로도 솔루션의 그 설정등을 그대로 이용하고 있다. Hybris-Log 검토했을 때 래핑해서 몇가지 편의사항을 제공하기는 했지만, 특이한 건 없었다. 프론트엔드 서버\n최근 새로 프로젝트 자체를 전부 리뉴얼하면서 fetchClient가 잘 관리되고 있었다. 백엔드 서버로 보내는 요청을 잘 한곳에서 관리하도록 되어있어 특정 헤더를 보내는건 매우 쉬웠다. 인프라\n인프라 업무를 보는 동료에게 도움을 요청해서 확인한 바로는 그라파나에 일단 기본적인 Loki설정은 되어있다고 했다. 서버 설정과 연관되어 있는 이야기인데 기본적으로 파일로그는 fluentbit이라는 것을 사용하고 있었다. 쿠버네티스, eks환경에서 간단하게 사용하고 싶을때 많이 사용하는 것 같았다. 결론적으로 해당 레이아웃을 건들지 않으면 로그가 차지하는 용량 부담은 없었다. 반면 콘솔로그는 로키와 그라파나에서 볼 수 있도록 기본적인 설정들은 잘 되어있었다. 다만 메트릭 자체가 설정되어있거나 한건 아주 기본적인 부분 외에는 없었다. 추가적으로 fluentbit으로 관리되는 파일로그와, 콘솔로그는 기본적으로 레이아웃을 별도로 설정해서 사용하고 있었다.\n# 약간 이런식 log4j2.logger.fluentbit.layout = %d{yyyy-MM-dd\u0026#39;T\u0026#39;HH:mm:ss.SSSZ} [%-5p] [%24F:%L] - %m%n log4j2.logger.console.layout = [%-5p] [%24F:%L] - %m%n 작업내용, 순서 정리 프론트엔드 서버가 아까 말한 요청을 식별하는 hash값을 별도의 커스텀 헤더에 추가해서 발송. 모든 요청에서 해당 헤더를 보낼 수 있도록 fetch를 래핑한 client구현체에 추가 next.js 서버가 직접 요청을 포워드하는 몇몇 서버 컴포넌트들이 있어 관련한 middleware 로직 추가 메인 백엔드 로그 관련 작업 (mdc, 로그보완 등) grafana에 인증관련 대시보드, 메트릭 추가 Impl and Touble Shootings 레거시 로그 버전의 레이아웃이 잘 설정 안되는 이슈 먼저, mdc 구현체를 사용하는것, 시큐리티 인증 필터의 가장 앞단에 헤더에 있는 trace-id값을 추가하는 것 등은 아주 문제 없이 잘 되었다.\n@Component public class OurNewTraceIdFilter extends OncePerRequestFilter { private static final String TRACE_ID_HEADER = \u0026#34;X-Trace-Id\u0026#34;; private static final String DEFAULT_TRACE_ID = \u0026#34;N/A\u0026#34;; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String traceId = Collections.list(request.getHeaderNames()).stream() .filter(header -\u0026gt; TRACE_ID_HEADER.equalsIgnoreCase(header)) .findFirst() .map(request::getHeader) .filter(value -\u0026gt; !value.isEmpty()) .orElse(DEFAULT_TRACE_ID); MDC.put(\u0026#34;TraceId\u0026#34;, traceId); try { filterChain.doFilter(request, response); } finally { MDC.remove(\u0026#34;TraceId\u0026#34;); } } } 그리고 이걸 간단하게 아래처럼 레이아웃을 수정해서 사용하려고 했는데,\nlog4j2.logger.console.layout = [%-5p] [%X{TraceId}] [%24F:%L] - %m%n 레이아웃 포매팅이 잘 되지 않았다.\n확인해봤을때 우리 프로젝트가 완전 레거시라.. Log4J 1.2.x 버전을 사용하고 있었고, 해당 버전에서는 포매팅등 설정하는게 제한적이었다. (정확히는 레이아웃 설정은 가능한데 조건부 생략과 같은 것들은 잘 안됐다)\n관련해서 EnhancedPatternLayout이라는 구현체를 썼을 때 조금 더 유동적인 포매팅을 레이아웃으로 추가 할 수 있기는 했지만, 조건부로 생략되어도 괄호가 남아있는등 설정이 여의치 않았다.\n이것도 찾아보니까 별도의 레이아웃 구현체를 설정하는 방법이 있어서 해당 방법으로 추가했다.\npublic class CustomPatternLayout extends EnhancedPatternLayout { private static final String TRACE_ID_KEY = \u0026#34;TraceId\u0026#34;; private static final String TRACE_ID_PLACEHOLDER = \u0026#34;N/A\u0026#34;; @Override public String format(LoggingEvent event) { String traceId = Optional.ofNullable((String) event.getMDC(TRACE_ID_KEY)) .filter(id -\u0026gt; !id.isEmpty() \u0026amp;\u0026amp; !TRACE_ID_PLACEHOLDER.equals(id)) .orElse(null); String baseLog = super.format(event); return (traceId != null) ? baseLog.replaceFirst(event.getLevel() .toString(), event.getLevel() + \u0026#34; [ TraceId : \u0026#34; + traceId + \u0026#34;]\u0026#34;) : baseLog; } } log4j.appender.CONSOLE = org.apache.log4j.ConsoleAppender log4j.appender.CONSOLE.layout = ourpackage.util.CustomPatternLayout Optional을 사용하는게 더 좋은 코드인것은 맞지만, 로그 전범위에 적용될 수정이라서 인스턴스 생성이 안일어나도록 직접 null체크 하는 것으로 수정했다.\npublic class CustomPatternLayout extends EnhancedPatternLayout { private static final String TRACE_ID_KEY = \u0026#34;TraceId\u0026#34;; private static final String TRACE_ID_PLACEHOLDER = \u0026#34;N/A\u0026#34;; @Override public String format(LoggingEvent event) { // MDC에서 TraceId 가져오기 Object traceIdObj = event.getMDC(TRACE_ID_KEY); String traceId = (traceIdObj instanceof String) ? (String) traceIdObj : null; // TraceId가 유효하지 않으면 null 처리 if (traceId == null || traceId.isEmpty() || TRACE_ID_PLACEHOLDER.equals(traceId)) { traceId = null; } // 기본 로그 메시지 가져오기 String baseLog = super.format(event); // TraceId가 존재하면 로그 메시지에 추가 if (traceId != null) { return baseLog.replaceFirst(event.getLevel().toString(), event.getLevel() + \u0026#34; [ TraceId : \u0026#34; + traceId + \u0026#34; ]\u0026#34;); } return baseLog; } } 그리고 grafana에 몇몇 쿼리를 추가해서 메트릭을 추가했다.\n예를들어 특정 traceId를 기준으로 로그를 그룹화 해서 본다던가.\n{job=\u0026#34;your-service\u0026#34;} |~ \u0026#34;traceID=(?P\u0026lt;TraceId\u0026gt;[a-zA-Z0-9]+)\u0026#34; 동일한 traceId로 발생한 에러 횟수에 대한 임계값을 설정해서 보여준다.(사실 slack훅연동까지 생각했지만 이건 내가 하지는 않고 필요하면 할 수 있도록 임계값 관련 시간 메트릭을 추가)\nsum(count_over_time({job=\u0026#34;your-service\u0026#34;} |= \u0026#34;error\u0026#34; |~ \u0026#34;traceID=(?P\u0026lt;TraceId\u0026gt;[a-zA-Z0-9]+)\u0026#34; [1h])) by (traceid) Loki관련 설정을 해둔 대시보드는 사실상 몇개 없고 테스트 수준이었지만, 그래도 레이아웃의 변경이 기존 메트릭에 영향을 줄 수 있는 부분이 있는지 면밀하게 확인했다.\n사실 이 시점에 이슈는 확인됨 (소 뒷걸음 치다가\u0026hellip;) 여기서 관련한 이슈는 배포하면서 찾게 되었다. 원인은 자세히 이야기하기는 그렇지만, 인프라 관련해서 환경이 다를 때 커스텀 헤더를 포워드 해주는 기준이 달랐고, 프론트엔드 서버가 분리되면서 별도 처리를 위한 프론트 헤더값이 있었는데 해당 헤더값이 요청 포워드 과정에서 누락되어 발생한 이슈였다.\n나도 우연히 trace-id와 같은 커스텀 헤더를 추가하다가 해당 정책에 대해서 알게되었고 나의 이슈는 마무리 했다.\n추가작업 1 : 로그와 메트릭은 조금 더 과감하게 추가해도 괜찮을 것 같다. 작업이 마무리되는 도중 이렇게 로그를 많이 찍고 로그 양 자체가 추가되는게 운영팀에서 걱정할 수 있다는 이야기를 들었다. 다만 이 즈음에 진행되는 토스 세션에서 로그를 굉장히 많이 찍고, 요청 시점과 요청 끝점은 무조건 포함된다는 이야기를 들었다.\n사실 아무리 생각해봐도 로그를 많이찍는 것 자체가 오버헤드나 로그양의 증가보다는 효용이 클 것 같다는 생각에 근거(?)가 생긴 것 같아 조금 더 공격적으로 접근했다.\n요청의 끝점으로 볼 수 있는 부분들과 요청 시작지점에도 로그를 추가했고, 비즈니스 로직이 아닌 이유로 요청이 실패로 끝나는 에러 케이스에는 요청 헤더와 같은 요청 환경에 대한 로그도 찍었다.\n특히 위와 같은 로그들은 traceid로 그룹화 할 수 있어 요청을 찾아보기 매우 편리해 졌다.\n추가작업 2 : 해당 작업을 진행하다가 알게된 추가이슈 수정 과정에서 특정 로그인 상황에 잘못된 플래그를 보고 불필요하게 crm 수정 api를 호출하는 이슈를 찾아냈다. 정상 로그인이 되었고 정상적인 과정이었음에도 불구하고 불필요하게 crm 인터페이스를 호출하고 있었는데, 워낙 자주 호출될 이유가 있는 api이고, 호출 시점의 로그가 상세하지 않은 경우라서 지금까지 발견이 안되었던 것 같다.\n이부분을 trace-id를 찍어서 보니까 같은 유저의 로그인시마다 반복호출되는 부분을 알게 되었고 간단한 이슈라 가볍게 수정했다.\n결론 AS-IS 멀티쓰레도 환경에서 로그를 보기 어려웠고, 단발성으로 필요한 로그를 추가하고 지우는 것의 반복이었다. 고객센터의 인입 외에 인증관련 로그를 우리가 선제적으로 인지하기 어려웠다. TO-BE 로그를 조금 더 잘 보고 구분할 수 있는 traceId를 추가했다. 특정 traceid에 대한 threshold값을 이용한다면 아마도 유저가 직면한 이슈를 고객센터 인입 전에 조금 더 빠르게 캐치 할 수 있을 것 같다. 이슈가 인입되어도 traceid로 그룹화 하기에, 고객센터에서 식별한 시간대의 유저와 에러만 특정한다면 이후 로그를 보기 쉬워졌다. 추가적으로 보관용 로그의 레이아웃을 수정하지는 않았고, 다른 컴포넌트의 호출에는 해당 식별값이 붙지 않기에 관련해서 너무 많은 공간을 쓰거나 하지는 않도록 최적화에 신경썼다. 결과적으로 as-is에서 기존 레서시 서버에서 사실상 사용하고 있지 않았던, Loki 메트릭에 TraceId 기반 로그가 추가되었다. 이전에는 사용자의 오류를 선제적으로 감지 될 방법도 없고, 고객센터를 통해 인입되었을 때 이슈가 발생한 시점 부근의 로그 데이터에서 에러 이름으로 하나하나 검색하며 찾았다면, 지금은 해당 에러로 검색해서 TraceId만 식별해낼 수 있다면 그룹화 해서 볼 수 있도록 로그 메트릭이 되어있다.\n위와 같은 부분들은 팀장님의 입회하에 운영팀에 이야기해서 잘 받아들여 진다면, 실제로 운영환경에 적용이 될 수 있도록 하기로 했다.\n","permalink":"http://localhost:1313/_wiki/%EB%A0%88%EA%B1%B0%EC%8B%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8%EC%9D%98-%EB%A1%9C%EA%B9%85-%EA%B0%9C%EC%84%A0%ED%95%98%EA%B8%B0/","summary":"Learners High Week 2,3 Summary! Thread local한 MDC를 이용해서 로그에서 요청을 단위로 식별 할 수 있게 했다. PII가 아니면서도 사용자를 식별 할 수 있는 값으로 사용자의 연속성 있는 요청 흐름을 볼 수 있게 보완했다. 그라파나에 관련한 메트릭을 추가했다. 해당 이슈도 해결하고, 과정중에서 밝혀진 숨겨진 이슈도 특정해서 해결했다. Learners High Week 2,3 Intro 커뮤니티 관련 프론트엔드 백엔드 작업을 마치고, qa가 완료되었다. qa기간중이기는 하지만 일정상 여유가 생긴 덕에 다음 작업을 준비할 시간이 생겼었다.","title":"러너스 하이 2~3주차 회고"},{"content":"LearneWeek 1,2 Summary! 미리 할당되어있던 2주 남짓 분량의 프론트엔드 태스크들을 완료했다. 테스트코드가 사실상 없던 프로젝트에 테스트코드를 도입하고 커버리지를 10% 까지 끌어올렸다 테스트코드를 작성하던 도중 알게되어 하수라 관련 안전한 트랜잭션이 되도록 로직 보완했다. 전시영역을 담당하는 백엔드 nodejs 서버 프로젝트에 테스트코드 도입하기 \u0026ldquo;Hasura 라고 있어요 \u0026hellip;\u0026rdquo; (전시영역 관련 독특한 구조) 우리회사는 커머스의 전시영역과 전시영역 관련한 데이터(이벤트, 기획전, 배너, 프론트엔드 컴포넌트 등)를 별도의 프로젝트와 DB로 분리해서 관리하고 있다.\n그리고 해당 프로젝트는 Hasura라는 오픈소스를 사용하는데, 짧게 요약하면 DB스키마를 보고 자동으로 gql api를 만들어준다.(gql특유의 이슈들도 잘 관리되어 최적화를 해준다)\n물론 전시영역 관련된 데이터이지만, 디비 전부를 인터페이스화 할 수 는 없기에 그 앞단에 게이트웨이성 nodejs서버를 두고 하수라 엔진에 질의하며 응답을 포워드 해주는 구조이다.\n초창기에는 위에서 언급한 정도의 역할만 하며 해당 프로젝트가 잘 지켜졌다. 전시영역 관련된 뷰테이블에 간단한 질의 하는 정도 위주로 코드가 작성되어있었다.\n다만 해당 프로젝트 특성상 여러 데이터소스 컴포넌트들이 붙게 되거나 다른 서버랑 통신하는 경우들이 늘어났다.\n과정중에 결코 가볍지 않은 비즈니스 로직들도 늘어가기 시작했다.\n결국 도메인 하나를 무리없이 도입하게 될 정도로 프로젝트에 비즈니스 로직이 추가됐고, 위의 그림처럼 이번에는 커뮤니티 관련 기능들이 해당 프로젝트에 추가되는 수준의 지경에 이르렀다.\n그리고 특히 테스트코드에 엄청 자율적인 회사 특성상, 테스트 코드는 없는 상태로 프로젝트가 유지보수 되고 있다.\nAS-IS 테스트코드-ASIS\n언급한 것처럼 테스트코드에 매우 자율적인 기조를 유지해왔기 때문에, 이 프로젝트에 테스트코드는 jest기준 0%대 였다.\n그나마 설정되어있는 것들과 작성되어 있는 테스트코드 역시 입사 완전 초기에 나와 같이 실험적으로 도입하면서 설정해 둔 것 이며, 유일한 테스트코드도 기존에 내가 작성해둔 것 이 전부였다.\n해당 테스트코드는 특정 인증관련 해쉬값을 디코드해서 나온 정보대로 잘 캐시를 타는지 정도를 테스트해둔 코드였고, 이게 전부였다.\n소스코드-ASIS\n디렉토리 구조의 예시는 다음과 같았다.\nsrc/ └── (인가 분리)/ └── (인가에 따른 client 객체들 설정)/ ├── client_settings.ts └── schemas/ ├── common.ts ├── hasura-banner.ts ├── hasura-community.ts # 신규 프로젝트로 작성/수정 중 └── (...) 그리고 schemas/some-domain.ts에 외부에 노출되는 gql api들이 정의 되어 있는데, 해당 파일의 구조들은 다음과 같다.\n// 타입 정의들 interface IBannerDetailArgs { ... } interface IBannerSchedule { ... } interface IBanner { ... } // gql type defs const typeDefs = ` ${defaultTypeDefs} type Query { ... } type BannerSchedule { ... } type Banner { ... } `; // resolver(핸들러) const bannerSchedule = async () =\u0026gt; { ... }; // resolver 등록 export const resolvers = { Query: { } }; export const schema = makeExecutableSchema({ typeDefs, resolvers }); TroubleShootings 1 - 하나의 리졸버 핸들러가 여러번 외부 컴포넌트를 호출하는 이슈.\n처음에는 어찌됐던 client객체가 종단지점이라고 생각했고, client객체들만 잘 모킹하면 간단하게 해결 될 줄 알았다. 언급한것처럼, 비즈니스 로직이 늘어나면서 하나의 핸들러가, 다른 모듈과 외부 통신을 하거나, 하수라 엔진에 여러번 질의를 진행하는 경우가 많이 있었다.\n이부분 때문에 도메인 하나를 전부를 리팩토링했다.\n여러번 질의하거나 내부적으로 외부 컴포넌트를 호출하는 경우 무조건적으로 함수를 분리했다.\n분리한 함수들 (즉 리졸버에 등록되지 않으면서, 리졸버를 처리하기 위해 질의하는 로직들)을 모듈화 했고, 그 덕분에 쉽게 모킹 할 수 있었다.\nconst some_resolver = async () =\u0026gt; { bool isOk = await client.query({ ... }); // 이런 부분을 모듈화해서 분리, 이후 모킹 if (isOk) { const res = await client.query({ ... }); return res; } } 2 - test env 분리하기\n프로젝트 특성상 외부 컴포넌트 혹은 데이터소스에 변경을 유발하는 쿼리들이 정의되어있다. 그리고 기존에는 test를 고려하지 않고 작성되어 있어, 실제 운영 env와 함께 동작하면 안되는 위험한 함수들이 있었다. 결론적으로 jest의 test env를 새로 작성하 테스트 파이프라인에서는 해당 env로 동작하도록 파이프라인을 수정했다. 3 - typedefs와 같은 gql문법을 조금 더 안전하게 보장 할 수 있지 않을까?\n기존에는 엄청난 길이의 typedefs를 거의 로우하게 텍스트로 관리하고 있다. 오타에 많이 취약한 구조였고, 더 좋게 관리할 방법이 있지 않을까 고민됐다.\nconst typeDefs = ` ${defaultTypeDefs} type Query { (많은 쿼리를 text로 정리한 내용 ..) } // 타입도 진짜 개많다. type BannerSchedule {} type Banner {} `; export const schema = makeExecutableSchema({ typeDefs, resolvers }); gql 관련해서 여기저기 찾아보니, makeExecutableSchema()함수에 정말 많은 기능이 있었다.\nrequireResolversForNonScalar, requireResolversForArgs와 같은 것들이 있는데, 이런 옵션은 기본값이 false로 되어있다. (관련된 사용 예시 레퍼런스들을 찾아 봤을 때, 실용적인 면에서 너무 보수적인 옵션값들이다.)\n각각 스칼라객체의 타입이 잘 구현되어있는지, 리졸버의 아규먼트가 전부 있는게 맞는건지 등을 검증하는데, true로 수정해도 커뮤니티쪽에서는 에러가 안잡혔다.\n마찬가지로 너무 가혹한 기준 같아서 내가 진행하는 테스트코드에만 적용을 했다.(before에서 한번 검증하고 시작)\nTO-BE 가장 큰 도메인이기는 하다고 짐작했지만, 정말로 5년 된 레거시코드의 커버리지를 10% 내외로 끌어올렸다.\n같이 진행한 리팩토링 덕분에 코드를 보기 훨씬 편해진 것 같다.\n트랜잭션과 관련해서 조금 더 안전한 코드가 된 것 같다.\n테스트코드 작성하다 알게된 미흡한 트랜잭션 처리 보완 외부 컴포넌트를 호출하는 함수들을 리팩토링하면서 확인한, 미흡한 트랜잭션 처리 보완 비즈니스 로직이 붙다 보니 아래와 같은 트랜잭션으로 엮여야 하는 부분들이 확인되었다.\n// 운영자 등록 예시 // 1. 커뮤니티 기가입 유저 여부 체크 someIsOutSiteUserQuestionToOurHasura(); // 2. role 테이블 권한 추가 someMutationForAddRoleToOurHasura(); // 3. 권한 매핑 someMutationForMapUserRoleToOurHasura(); // 4. 멀티프로필 계정 생성 someMutationForCreateMultiProfileToOurHasura(); // 5. 멀티프로필 계정 매핑 someMutationForMapMultiProfileToOurHasura(); 일단 Hasura 는 단일 요청 내에서 쿼리 결과를 기반으로 뮤테이션을 수행하는 기능은 제공하지 않는다.\n아예 지원이 없는건 아니고, db레벨에서 stored procedure를 사용하고, 해당 함수를 호출 할 수 있도록 generate해준다는걸 보니 정말 지원을 안하는 것 같다.\n관련해서 논의해봤을 때, 기본적으로 stored procedure를 레거시로 여기는 경향이 있어 해당 stored procedure 도입은 반려되었다.\n결국 위에서 진행하며 분리한 데이터 소스를 호출하는 함수들에 대해서, 멱등하게 관리 할 수 있는 부분에 대해서는 보상 트랙잭션성 함수들을 추가해서 보완했다.\ntry { // 1. 기가입 유저 체크 someIsOutSiteUserQuestionToOurHasura(); // 2. role 테이블 권한 추가 someMutationForAddRoleToOurHasura(); try { // 3. 권한 매핑 someMutationForMapUserRoleToOurHasura(); try { // 4. 멀티프로필 계정 생성 someMutationForCreateMultiProfileToOurHasura(); try { // 5. 멀티프로필 계정 매핑 someMutationForMapMultiProfileToOurHasura(); } catch (error) { // 기존 매핑을 확인하고 멱등하게 동작 someCompensatingMutationForDeleteMultiProfile(); throw error; } } catch (error) { // 이미 존재하는지 확인하는 로직 추가 someCompensatingMutationForUnmapUserRole(); throw error; } } catch (error) { someCompensatingMutationForRemoveRole(); throw error; } } catch (error) { throw error; } 잔여 프론트엔드 작업 빠르게 마무리하기 기존 커머스 플랫폼에 커뮤니티 기능을 도입하는 태스크였고, 내가 맡은 부분은 레거시 cms의 뷰 작업과 관련한 api작업, 그리고 프론트엔드 커뮤니티 인가 분리하는 태스크였다.\n레거시 cms라 사용성에서 일부 잘못된 부분이 있었다. 예를 들어 router에 검색 조건을 push하고 lazyQuery로 라우터의 변경이 감지되면 쿼리를 실행하는 로직이 있었는데, 이러한 부분들을 리팩토링 하면서 진행했다.\n상태값으로 관리해야 할 데이터들을 분리해서 상태값으로 관리하고, appoloClient의 refetch, invalidate query key를 이용해서 특정 상태값(주로 검색 조건)이 변경됨에 따라 다시 호출을 해야 하는 부분들을 정리했다.\n그리고 기존 인가 관련 로직이 커뮤니티 기능 안에서 파편화 작업되어 있어서, 별도의 인가를 관리하는 훅을 분리해서 처리했다.\n결론적으로 불필요한 깜빡임이나, 불필요한 다수의 쿼리파라미터로 지저분해지는 일을 개선했으며, 커뮤니티 기능 안에서의 인가관리를 한곳에서 처리 할 수 있도록 개선했다.\n","permalink":"http://localhost:1313/_wiki/%EC%A0%84%EC%8B%9C%EC%98%81%EC%97%AD-%EB%B0%B1%EC%97%94%EB%93%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%BD%94%EB%93%9C-%EB%8F%84%EC%9E%85%EA%B8%B0/","summary":"프론트엔드 잔여작업 마치기, 테스트코드 도입하기","title":"러너스 하이 1~2주차 회고"},{"content":"일단 너무 바쁘다.\n이달 말까지 잡힌 프론트업무를 다 쳐냈다.\n그리고 야근과 틈내나는대로 테스트코드도 도입중이다\nhasura 이부분은 정리해서 wil로 올릴 예정이다\n","permalink":"http://localhost:1313/_wiki/ldady-03/","summary":"일단 너무 바쁘다.\n이달 말까지 잡힌 프론트업무를 다 쳐냈다.\n그리고 야근과 틈내나는대로 테스트코드도 도입중이다\nhasura 이부분은 정리해서 wil로 올릴 예정이다","title":"Day-03, 대충 쓰고 wil 써야지 (뭔가 플래그 같지만)"},{"content":"커뮤니티 서비스 개발 ","permalink":"http://localhost:1313/_wiki/lday-02/","summary":"커뮤니티 서비스 개발 ","title":"프론트 업무이지만, 더 나은 방법을 고민하며"},{"content":"목표 설정 목표를 설정하려고 어제오늘 내내 고민했고 어느정도 윤곽이 잡힌 것 같다. 지금 작업과 관련해서 할 수 있는일과, 다음 작업을 통해서 개선 할 일 두가지의 꼭지로 되어있다.\n지금 작업 관련\nhasura, gql의 문서와 레퍼런스를 보고 전시영역 backend 개선 해당 backend 프로젝트에 테스트 코드 도입. 다음 작업 관련\n프로젝트가 리뉴얼 될 때 인증과 인가쪽의 리뉴얼(소셜로그인, 본인인증, 회원가입 등)도 담당했는데, 관련한 이슈가 나한테 들어온다. 문제는 이슈가 cs센터 통해서 들어오기 전에 이슈를 파악하지 못했고 엄청 레거시한 로깅 구조때문에 이슈를 파악하고 감지하는것도 늦었고, 실제 이슈를 해결하는데 도움을 받지 못한다. 매번 일회성 로그를 작성하고 일부남기는 등의일을 통해 개선되지 못하고 있다. 인증 인가쪽은 로그로 남기면 안되는 폭탄 천지라 더더욱 그런점이 심한 것 같다. 그래서 일단 우리 레거시가 사용하는 솔루션의 로그 관련 문서도 뒤져보고, 담당자한테 물어봐서 그라파나 환경을 물어봤는데, 로키 관련 설정은 있긴 하다고 한다. 명분도 있고 권한 관련 문제도 없어서 지금 있는 태스크를 쳐내고 여기부터 할 것 같다. 위 두가지는 다시 문제정의를 하고 작업을 진행할 예정\n그외에는 프론트작업은 빨리 쳐내려고 한다. 관련해서 레거시한 부분을 개선해가면서 하고있는데, 이것도 작성할지는 모르겠다\n","permalink":"http://localhost:1313/_wiki/lday-01/","summary":"목표 설정 목표를 설정하려고 어제오늘 내내 고민했고 어느정도 윤곽이 잡힌 것 같다. 지금 작업과 관련해서 할 수 있는일과, 다음 작업을 통해서 개선 할 일 두가지의 꼭지로 되어있다.\n지금 작업 관련\nhasura, gql의 문서와 레퍼런스를 보고 전시영역 backend 개선 해당 backend 프로젝트에 테스트 코드 도입. 다음 작업 관련\n프로젝트가 리뉴얼 될 때 인증과 인가쪽의 리뉴얼(소셜로그인, 본인인증, 회원가입 등)도 담당했는데, 관련한 이슈가 나한테 들어온다. 문제는 이슈가 cs센터 통해서 들어오기 전에 이슈를 파악하지 못했고 엄청 레거시한 로깅 구조때문에 이슈를 파악하고 감지하는것도 늦었고, 실제 이슈를 해결하는데 도움을 받지 못한다.","title":"Day-01, 목표 설정하기, 기존 프론트엔드 작업 쳐내기"},{"content":"들어가기 전에 일괄처리의 한계를 이야기하면서 시작한다.\n유한한 크기로 한정한다. 특히 정렬과 같은 것들은 전체 레코드를 읽어야 출력을 시작 할 수 있다. 실제로는 데이터는 시간이 지나면서 점진적으로 발생하기에 한정되지도 않고, 특정 기간씩 청크를 나눠야 한다.\n그러나 이러한 특정 기간(보통 일)에 처리가 된다는건 사용자 입장에서는 매우 느릴 수 있다. 결국 이벤트가 발생할 때마다 처리를 시작하는 아이디어가 나왔는데 이게 스트림 처리의 기본 개념이다.\n일반적으로 \u0026ldquo;스트림\u0026quot;은 시간 흐름에 따라 점진적으로 생산된 데이터를 일컫는다.\n이벤트 스트림 전송 스트림에서의 입출력은 레코드(이벤트)이고, 특정 시점에 일어난 사건에 대한 세부사항을 포함하는 작고 독립된 불변 객체이다.\n이벤트는 텍스트 문자열이나 json, 혹은 바이너리 형태로 부호화된다.\n일괄 처리에서 파일은 한 번 기록하면 여러 작업에서 읽을 수 있고, 스트리밍에서도 이와 비슷하다.\n생산자가 이벤트를 한 번 만들면 소비자가 처리 할 수있고, 파일시스템에서는 관련 레코드 집합을 파일 이름으로 식별하지만, 스트림에서는 토픽이나 스트림으로 관련 이벤트를 묶는다.\n이번 절의 핵심인 문제는 이러한 이벤트를 알아내기 위해서는 알림 혹은 폴링과 같은 방식이 필요하다 즉 이벤트 발생을 캐치하기 위해 알림을 받거나 폴링하면서 새로운 이벤트를 캐치해야하는데, 전통적인 데이터 베이스는 이러한 것들을 고려하지 않고 설계되었으며, 일부 지원되는 기능들도 설계 이후에 도입된 개념들이라서 좋진 않다.\n메시징 시스템 결론적으로 새로운 이벤트에 대해 소비자에게 알려주려고 쓰이는 일반적인 방법은 메시징 시스템을 사용하는 것이다.\n구축하는데 가장 간단하게는 유닉스 파이프처럼 구현하거나, TCP연결을 직접 열어버리는 방법이지만, 대부분 시스템은 이 기본 모델을 확장한다.\n원하는건 다수의 생산자가 같은 토픽으로 메시지를 전송하고, 다수의 소비자가 토픽하나에서 메시지를 받아가는 것이다.\n위와 같은 모델을 pub/sub 모델이라고 한다. 그리고 이러한 접근법을 가진 시스템을 구분하는데 도움이 되는 두 가지 질문이 있다.\n생산자가 소비자의 메시지를 처리하는 속도보다 빠르게 메세지를 전송한다면 어떻게 될까? 노드가 죽거나 일시적으로 오프라인이 된다면 어떻게 할까? 생산자에서 소비자로 메시지를 직접 전달하기 보통 udp 멀티캐스트와 같은 접근법을 사용한다. 일단 신뢰성 낮은 udp(일단 그냥 보내고 잘갔는지 맞게 왔는지 서로 확인 안함)를 쓰고, 애플리케이션 코드로 보완하는 방법들인것같다. 직접 메시징 시스템은 설계 상황에서는 잘 동작하지만, 유실에 대한 대응 코드가 어플리케이션에 들어가야 한다.\n메시지 브로커 메시지 브로커는 근본적으로 메시지 스트림을 처리하는데 최적화된 데이터베이스의 일종이다.\n생산자는 브로커로 소비자는 브로커에서 메시지를 전송하거나 전송받는다.\n데이터를 브로커에 모으기 때문에 아래와 같은 장점이 있다고 한다.\n클라이언트 상태 변경에 쉽게 대처 가능. 디스크에 저장하거나, 큐를 제한없이 늘어나게해서 유실에 대비한다. 그리고 큐대기를 하면 소비자는 일반적으로 비동기로 동작한다.\n복수 소비자 기본적으로는 두가지 방법\n로드밸런싱 - 메시지는 소비자중 하나로 전달 -\u0026gt; 병렬처리를 위해서 팬아웃 - 여러 독립적인 소비자가 동일한 메시지를 간섭없이 청취 할 수 있도록. 확인 응답과 재전송 소비자는 언제라도 장애가 발생할 수 있고, 소비자가 메세지를 처리하지 못하거나 부분적으로만 처리한 후 장애가 나는 상황이 생긴다. 그래서 브로커는 확인 응답을 사용한다. 클라이언트의 연결이 닫히거나 타임아웃이 나면 브로커는 다시 소비자에게 메세지를 전송한다.\n문제는 이렇게 장애가 나서 확인응답을 못받아서 다시 전송한다고 해도 소비자가 많은 상황에서는 문제가 생기는데,\n바로 메시지 순서가 유지되지 않는다는 것이다. (메시지간 인과성이 있다면 매우 중요한 문제다)\n","permalink":"http://localhost:1313/_wiki/11%EC%9E%A5/","summary":"스트림 처리","title":"데이터 중심 애플리케이션 설계 11장"},{"content":"들어가기 전에 지금까지는 요청과 응답, 질의와 결과에 관한 내용을 주로 다뤘다.\n온라인 시스템에 익숙해져있으면, 이러한 것들이 전부라고 착각하기 쉽지만 사실 그렇지 않다.\n시스템은 세가지 유형으로 나뉜다.\n서비스(온라인 시스템)\n서비스는 클라이언트로부터 요청이나 지시가 올 때 까지 기다린다. http/rest 기반 api덕분에 가장 익숙한 시스템이다. 응답시간과 가용성이 가장 주요한 성능 지표로 꼽힌다. 일괄 처리 시스템 (오프라인 시스템)\n매우 큰 입력데이터를 받아 데이터를 처리하는 작업을 수행하고 결과 데이터를 생산한다. 사용자가 대기를 하지는 않으며 그래서 시간당 처리량 같은 것들이 성능 지표로 꼽힌다. 스트림 처리 시스템\n준 실시간 처리라고 불린다. 서비스와 다르게 요청에 응답하지 않으며 입력 데이터를 소비하고 결과 데이터를 생산한다. 반대로 배치와는 다르게 특정한 시간이나 데이터 양까지 기다리지 않으며 처리를 시작한다. 결론은 지금까지 알아본 내용은 서비스 위주였고, 이번 장에서는 일괄 처리 시스템에 대해서 알아보고, 다음 장에서는 스트림 처리 시스템에 대해서 알아본다.\n유닉스 도구로 일괄 처리하기 cat /var/log/nginx/access.log awk \u0026#39;{print \u0026amp;7}\u0026#39; sort uniq -c sort -r -n head -n 5 로그를 읽고,주소를 뽑고, 주소를 기준으로 정렬하고, 중복 제거하면서 카운트를 붙이고, 카운트를 기준으로 정렬하고, 위에서 다섯개를 뽑기!\nfn main() -\u0026gt; io::Result\u0026lt;()\u0026gt; { let log_file_path = \u0026#34;/var/log/nginx/access.log\u0026#34;; let file = File::open(log_file_path)?; let reader = io::BufReader::new(file); let mut field_counts: HashMap\u0026lt;String, usize\u0026gt; = HashMap::new(); for line in reader.lines() { let line = line?; let fields: Vec\u0026lt;\u0026amp;str\u0026gt; = line.split_whitespace().collect(); if fields.len() \u0026gt;= 7 { let field = fields[6].to_string(); *field_counts.entry(field).or_insert(0) += 1; } } let mut sorted_counts: Vec\u0026lt;_\u0026gt; = field_counts.into_iter().collect(); sorted_counts.sort_by(|a, b| b.1.cmp(\u0026amp;a.1)); for (field, count) in sorted_counts.iter().take(5) { println!(\u0026#34;{}: {}\u0026#34;, field, count); } Ok(()) } 동일한 작업을 하지만, 인메모리 해쉬테이블을 유지하는 방법 2\n물론 두번째 방식이 더 익숙하기는 하고, 실제로는 대부분 잘 동작할 것이다.\n다만 만약 처리해야할 데이터의 양이 메모리보다 크다면 문제가 생긴다.\n두번째 방법은 처리가 불가능하고(추가적인 보완이 필요 하거나 의미없음), 첫번째 방법은 정렬을 기반으로 하기에 디스크를 효율적으로 사용할 수 있다. 청크를 메모리에서 정렬하고 청크를 세그먼트 파일로 디스크에 저장, 그 다음 각각 정렬된 세그먼트 파일 여러개를 한개의 큰 정렬 파일로 병합한다.\n실제로 GNU Coreutils에 포함된 sort는 메모리보다 큰 데이터셋을 자동으로 디스크로 보내고 자동으로 여러 코어에서 병렬로 정렬한다고 한다.\n디스크를 읽어들이는 병목을 감수하면 아주 잘 동작한다.\n가장 중요한 점은 이게 우연이 아니고, 유닉스 철학을 따르기 때문이라고 책에서는 이야기 한다.\n유닉스 철학 다른 방법으로 데이터 처리가 필요할 때 정원 호스와 같이 여러 다른 프로그램을 연결하는 방법이 필요하다. 이것은 I/O방식 이기도 하다.\n각 프로그램이 한 가지 일만 하도록 작성하라. 새 작업을 하려면 기존 프로그램을 고쳐 새로운 기능을 추가해 프로그램을 복잡하게 만들기보다는 새로운 프로그램을 작성하라. 모든 프로그램의 출력은 아직 알려지지않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 소프트웨어를 빠르게 써볼 수 있게 설계하고 구축하라. 심지어 운영체제도 마찬가지다. 수 주 안에 끝내는 것이 이상적이다. 프로그래밍 작업을 줄이려면 미숙한 도움보다는 도구를 사용하라. 애자일과 데브옵스와 같이 몇십년이 지나도 아이디어가 전혀 바뀌지 않은 탁월한 아이디어이다.\n그리고 책에서는 pipe 즉 모든 프로그램의 출력은 아직 알려지지 않은 다른 프로그램의 입력으로 쓰일 수 있다고 생각하라. 에 집중한다.\n동일 인터페이스 어떤 프로그램의 출력을 다른 프로그램의 입력으로 쓰고자 한다면 이들 프로그램은 같은 데이터 형식을 사용해야 한다. 즉 호환 가능한 인터페이스를 써야 한다.\n유닉스에서의 인터페이스는 파일(파일 디스크럽터)이다. 파일은 단지 순서대로 정렬된 바이트의 연속이다. 그리고 이렇게 단순한 인터페이스를 공유하기에 소켓과 표준 입출력, 드라이버 소켓에서도 다른 여러가지 것들을 표현 할 수 있다.\n이처럼 동일 인터페이스를 사용해서 상호 운용하는건 생각하는 것 이상으로 어렵다.\n그리고 이러한 프로그램들은 최근에도 많이 없으며 데이터베이스 역시 심지어는 같은 모델을 씀에도 데이터를 한쪽에서 다른 쪽으로 옮기는 것이 쉽지 않다.\n유닉스와 같은 통합이 부족했기 때문이다.\n로직과 연결의 분리 유닉스는 표준 입출력을 사용한다. stdin, stdout\n그리고 파이프는 다른 프로세스의 stdout을 stdin으로 연결한다.\n이 때 중간데이터를 디스크에 쓰지 않고 작은 인메모리 버퍼를 사용해 프로세스간 데이터를 전송한다.\n위의 것들이 지켜지면 프로그램은 어디서 입력을 받고 내 출력이 어디로 가는지 알 필요도, 알 방법도 없다. (loose coupling, late binding, inversion of control)\n투명성과 실험 또한 유닉스 도구가 성공적인 이유는 진행 사항을 파악하기가 쉽다는 점이 있다.\n입력이 불변으로 처리된다 -\u0026gt; 여러번 수행해도 ok!\n어느 시점이든 파이프라인을 중단하고 출력을 파이프를 통해 원하는 출력이 나오는지 확인 할 수 있다. -\u0026gt; 디버깅 용이\n특정 파이프라인 단계의 출력을 파일(디스크)에 쓰고 다음 단계의 입력으로 쓸 수 있다. -\u0026gt; 재실행에 용이\n문제는 유닉스도구 는 단일 장비에서만 실행이 가능하다는 것이고 책은 그래서 하둡과 같은 도구가 필요한 이유라고 이야기 한다.\n맵리듀스와 분산 파일 시스템 맵리듀스와 유닉스 도구의 공통점과 차이점\n공통점\n하나 이상의 입력을 받아 하나 이상의 출력을 만든다. 입력을 수정하지 않는다. 차이점\n맵리듀스는 수천대의 장비로 분산해서 실행이 가능하다. 분산 파일 시스템 상의 파일을 입력과 출력으로 사용한다. -\u0026gt; 잘 모르겠음 무튼 주요한 아이디어는 유닉스도구와 맵리듀스가 동일하고, 분산노드에서 병렬 처리가 가능하다는 이야기 인 것 같다.\n그리고 분산 처리를 보완한 내용은 아래와 같다.\n일단 데몬 프로세스를 통해 노드들끼리 공유가 가능하도록 해두었다. 네임노드라고 부르는 중앙 서버는 특정 파일 블록이 어디에 저장됐는지 추적한다. 맵리듀스 작업 실행하기 이것도 순서로 정리 할 수 밖에 없는 것 같다.\n레코드를 쪼갠다. 매퍼함수를 호출한다. 정렬한다. 리듀스함수를 호출한다. 즉 로그예시에서는 \u0026lsquo;\\n\u0026rsquo; 으로 로그함수를 쪼개고 , 매퍼함수로 url을 키 값 쌍으로 정리하고 , 정렬하고 , 리듀스 함수로 레코드 수를 읽어간다.\n추가적인 내용을 요약하면\n맵리듀스는 데이터를 파티셔닝하여 병렬로 처리하는데, 병렬처리를 위한 추가적인 로직은 필요없다. 입력 데이터는 맵 함수에서 키-값 쌍으로 변환된다. 같은 키를 가진 데이터는 항상 같은 리듀서에서 처리된다(해쉬 사용). 맵 태스크 수는 입력 파일 블록 수에 따라 결정되고, 리듀스 태스크 수는 사용자가 설정한다. 데이터베이스마다 다르기는 한데, 매퍼와 리듀서는 java, js등 어플리케이션 코드로 되어있는 경우가 많다고 한다. 맵리듀스 워크플로 맵리듀스 하나로 해결 할 수 있는 문제는 엄청 제한적이라서 여러 맵리듀스 작업을 연결해 워크플로우를 구성하기도 한다.\n다만 유닉스의 파이프라인과는 약간 다른게 실제 메모리 버퍼등을 이용하는것과는 다르게 중간출력파일이 다음 워크플로우의 입력이 되는 형식이라고 한다.\n리듀스 사이드 조인과 그룹화 일괄 처리 맥락에서 조인은 데이터셋 내의 모든 연관관계를 다룬다.\n그리고 인덱스를 사용하지않고 풀테이블 스캔을 하는 식이다.\n당연히 병렬처리로 보완하기도 하고, 애초에 일부 데이터와 그에 대한 처리가 필요하다면 일괄 처리가 아니라 인덱스를 타는 로직을 태우는게 현명하기 때문에 애초에 고려대상이 아니라고 이야기 하는 것 같다.\n결론적으로 일괄 처리중에는 실제 조인을 때리는데, 그 과정을 위해 매 데이터마다 필요한 데이터를 얻기 위해 db를 네트워크로 호출은 아니고 사본을 가져와 진행한다고 한다.\n(작성중)\n","permalink":"http://localhost:1313/_wiki/10%EC%9E%A5/","summary":"일괄 처리","title":"데이터 중심 애플리케이션 설계 10장"},{"content":"준비하기 전에 내가 아는 정보가 어느정도는 제한된 부분이 있다.\n멘토링 세션이 1회인지 피드백 혹은 평가를 위한 추가적인 일정이 있는지 구체적인 미션이 있는지 위와 같은 것들이 월요일이 되어야 구체적으로 알 수 있을 것 같다.\n원래 이직을 준비하면서 중간 목표로 잡았던 것들이 아래와 같다.\n레디스 만들기 (code-crafters) 송년회 사이드 프로젝트 서버작업 마무리하기 (취소됨) 필요한 책 새로 읽거나, 특히 도움이 되는 책들 리마인드하기 코딩테스트 준비 딱 여기까지가 1월 19일까지 목표였는데, 아마 이부분의 우선순위를 조정해야 할 것 같다.\n이후로는 카프카 만들기를 진행하면서 지원서를 내고 그 과정의 진척상황에 따라 우선순위등을 조정하려고 했다.\n일단 전형 일정상, 코딩테스트 준비는 완전히 스탑해야 할 것 같다.\n그리고 구체적으로 뭔가가 정해지지 않아서 이번 주말은 일단 최대한 책을 당겨 읽으면서 보내야 할 것 같다.\n그리고 만약 구체적인 미션이 정해지지 않는다면, 세션에서 배운것들을 기반으로 레디스 프로젝트 등을 기반으로 잡고 진행해도 될 것 같다.\n물론 구체적인 미션이 있다면 모든걸 멈추고 진행할 예정이다.\n그나마 코딩테스트 준비를 완전 스탑하는게 마음에 좀 걸려서 주말동안 코틀린 재활작업을 하고 코틀린정도나 더볼까 싶다.\n","permalink":"http://localhost:1313/_wiki/l-day-00/","summary":"준비!","title":"L-Day-00"},{"content":"Intro - 첫 번째 세션에서 모호한 과제가 아니다, 어려운 과제일뿐. 토스의 일하는 방식을 소개받으며, 다음과 같은 원칙들을 체감했다.\n• 배포한 것들의 임팩트를 측정하고,\n• 이를 위해 레퍼런스, 자료, 도구를 살피며,\n• 구체적인 데이터를 바탕으로 의사소통하고,\n• ROI(투자 대비 효과)를 고민하며 움직이는 방식\n이후 실습 과제를 받았을 때 처음에는 “이건 터무니없는 과제다”라는 생각이 들었지만, 실질적으로는 “명확한 과제”임을 깨닫게 되었다.\n토스가 기대하는 방식대로 일하려면,\n능동적으로 문제를 정의하고\n해결 방안을 찾아 구현하며\n정량적 데이터로 해결되었음을 증명하고\n이를 바탕으로 효율적인 커뮤니케이션을 수행하여\n내 코드의 비즈니스적 임팩트를 정의하고\n설득과 결과 도출까지 책임지는 것이 요구된다.\n이는 곧 기술, 운영, 제품, 커뮤니케이션 역량을 모두 검증할 수 있는 방식이며, 결국 명확한 과제였다.\nDays - 러너스 하이를 진행하면서 해왔던 것들 1주차, 2주차 작업내용 기존에 잡혀있던 프론트엔드 태스크 진행 기존 커머스 플랫폼에 커뮤니티 기능을 추가하는 작업 수행. 레거시 CMS의 뷰 및 관련 API 작업과 프론트엔드 페이지 개발 완료. 개선점 : 검색 조건을 router에 push하고 lazyQuery로 감지하는 기존 로직을 리팩토링. 상태값을 분리하여 Apollo Client의 refetch, invalidate query key를 활용해 불필요한 깜빡임 및 중복 요청 제거. 백엔드 테스트 코드 도입 및 커버리지 개선 (10%) 배경: 전시영역을 담당하는 Hasura 기반의 백엔드 프로젝트에 테스트 코드가 거의 없는 상태(0%대). 문제점 리졸버 핸들러가 여러 번 외부 컴포넌트를 호출하는 문제. 테스트 코드 작성 시 외부 API 요청을 적절히 모킹할 수 있도록 구조 개선 필요. Hasura가 기본적으로 트랜잭션을 지원하지 않아 데이터 정합성 이슈 발생. typedefs가 로우 텍스트로 관리되어 오타 및 구조적 오류 발생 가능성 높음. 개선사항 핸들러 구조 개선 : 리졸버 내부의 외부 요청을 별도 함수로 분리하여 모듈화 테스트 환경 보호 : jest설정을 변경하여 테스트 실행 시 운영 데이터에 영향이 없도록 방어로직 추가. 트랜잭션 처리 개선 : Hasura 트랜잭션 대신, 요청에 맞는 보상트랜잭션 추가 typedefs 관련 검증 옵션 추가 1주차, 2주차동안의 상세 작업 내용과 후기 링크 -\u0026gt; [[전시영역-백엔드-테스트코드-도입기]]\n2주차, 3주차 작업 내용 배경 : 인증관련 이슈 수정작업 진행 문제점 멀티스레드 환경에서 로그가 섞여 불편했었음 특정 사용자에 대한 연속성있는 로그를 보기 힘든 구조 빈약한 로깅 개선 개선사항 로그와 요청 식별값 추가 레거시 로그 라이브러리 버전에서 환경에서 로그 레아이웃 커스텀하기 PII를 고려한 식별값 추가 범용적으로 적용, 추가될 로그 관련 성능이슈 수정 전반적인 로깅 보완 2주차, 3주차동안의 상세 작업 내용과 후기 링크 -\u0026gt; [[레거시-프로젝트의-로깅-개선하기]]\n3주차, 4주차 작업 내용 배경 : 인사이동으로 인한 OJT 진행, 새로운 팀의 프로젝트를 공부하던 중 메인 프로젝트가 헥사고날 아키텍처로 구현되어있는 메세지 스트리밍 위주의 프로젝트인 것 을 확인 OJT 기간을 치열하게 보낼 수 있도록 온보딩 목적의 사이드 프로젝트 진행 카프카를 헥사고날 아키텍처로 클론코딩하기 Kraft metadata stroe, Handshake성 인터페이스들 프로토콜대로 구현 세그먼트 단위로, 로그기반 메세지 저장하는 로직 구현 producer api, consumer api 몇가지 구현 3주차, 4주차동안의 상세 작업 내용과 후기 링크 -\u0026gt; [[카프카를-헥사고날하게-클론코딩-해보기]]\n그 외 이슈들 단순 운영 작업, 혹은 빠른 시간내에 완수해야 하는 작업들도 병행하며 진행했습니다.\n커뮤니티 기능 개발 프론트엔드 인가 분리 작업 커뮤니티 기능 개발 기획 누락/변경 대응 사이트맵 현행화 작업 Outro - 후기 엄청나게 바쁘고 하드코어하게 달려왔다. 휴일 반납은 기본이었고, 매일 밤늦게까지 몰입했다.\n주차별 회고에는 정리되지 않았지만, 운영 이슈 대응, 기획 변경 및 누락 대응 등도 병행하면서 압도적인 몰입을 경험했다.\n물론, 여건이 따라주지 않는 순간도 있었다.\n예를 들어, 인사 이동으로 인한 업무 공백, 회사 내부 사정으로 인한 혼란 등 대응하기 어려운 상황이 많았지만,\n그럼에도 내가 처한 상황에서 최선의 선택을 했고, 최고의 노력을 기울였다고 자평할 수 있다.\n회사와 개인 목표를 같은 선상에서 바라보게 된 변화 이전까지는 회사 일과 개인적인 개발 목표가 분리되어 있었다.\n• “매일 프론트 업무가 섞여 들어오니까…”\n• “빨리 끝내면 다른 프론트 업무가 배정되겠지…”\n• “일정도 빠듯한데 무슨 고도화, 자동화야…”\n이러한 생각들이 많았지만, 이번 경험을 통해 사고의 흐름이 완전히 바뀌었다.\n나는 항상 퇴근 후 사이드 프로젝트를 하면서\n“회사에서 하는 일도 내가 원하는 방향과 일치했으면 좋겠다” 라고 막연히 생각했다.\n사이드 프로젝트가 더 재미있고 도움된다는 느낌에, 퇴근이후에만 하던 몰입이 출근하면 깨지는 것도 싫었기 때문이다.\n그런데 이번 러너스하이를 통해,\n내가 원래 하고 싶던 공부와 회사에서의 목표를 같은 선상에서 바라볼 수 있게 되었다.\n","permalink":"http://localhost:1313/_wiki/learners-high/","summary":"러너스 하이 계획 실행 문서","title":"Learner's high 🏃‍➡️"},{"content":"#[tokio::main] async fn main() { // 1. 필요한 설정, 데이터 등을 세팅함. let state = StateManager::new(); let config_handler = ConfigHandler::new(state.get_db(), state.get_config(), state.get_replication_config()); config_handler.load_config().await; config_handler.configure_db().await; config_handler.configure_replication().await; let port = config_handler.get_port().await; let listener = TcpListener::bind(format!(\u0026#34;127.0.0.1:{}\u0026#34;, port)).await.unwrap(); println!(\u0026#34;Listening on port {}\u0026#34;, port); loop { match listener.accept().await { // 2. 스트림을 따서, 스트림을 handle_client로 전달 Ok((stream, _)) =\u0026gt; { let db = state.get_db(); let config = state.get_config(); let replication_config = state.get_replication_config(); task::spawn(async move { // 3. 딱 봐도 알 수 있겠지만, 일단 경합자원이고 뭐고 다 넘겨버린다. handle_client(stream, db, config, replication_config).await; }); } Err(e) =\u0026gt; { println!(\u0026#34;Error accepting connection: {}\u0026#34;, e); } } } } // === 이하 handler.rs === pub async fn handle_client(mut stream: TcpStream, db: Db, config: Config, replication_config: ReplicationConfig) { let mut buffer = [0; 512]; loop { buffer.fill(0); // 1. (직접 받아온 스트림에서) 버퍼로 요청 메세지를 읽는다. match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; { let message = match std::str::from_utf8(\u0026amp;buffer[..n]) { Ok(msg) =\u0026gt; msg, Err(_) =\u0026gt; { println!(\u0026#34;Failed to parse message as UTF-8\u0026#34;); continue; } }; println!(\u0026#34;Received message: {:?}\u0026#34;, message); // 2. 메세지를 파싱해서, Command 객체를 (정확히는 enum)을 만들어준다. match CommandParser::parse_message(message) { Ok(command) =\u0026gt; { // 3. 커맨드를 실행하는, 메서드는 다음과 같이 경합자원들을 물고 들어간다(stream, db, 등등...) if let Err(e) = command.handle_command(\u0026amp;mut stream, Arc::clone(\u0026amp;db), Arc::clone(\u0026amp;config), replication_config.clone()).await { println!(\u0026#34;Failed to send response: {}\u0026#34;, e); } } Err(e) =\u0026gt; { println!(\u0026#34;Failed to parse command: {}\u0026#34;, e); } } } Err(e) =\u0026gt; { println!(\u0026#34;Error reading from stream: {}\u0026#34;, e); break; } } } } // === 이하 command.rs === pub async fn handle_command( \u0026amp;self, stream: \u0026amp;mut TcpStream, db: Db, config: Config, replication_config: ReplicationConfig, ) -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { let peer_addr = match stream.peer_addr() { Ok(addr) =\u0026gt; addr, Err(_) =\u0026gt; { let err_response = \u0026#34;-ERR Failed to retrieve client address\\r\\n\u0026#34;.to_string(); stream.write_all(err_response.as_bytes()).await?; return Ok(()); } }; // 1. 커맨드에서 받아온 처리 응답 결과를 경합자원인 stream에 직접 쓰는 문제. match self.execute(db, config, replication_config, peer_addr).await { Ok(responses) =\u0026gt; { for response in responses { match response { CommandResponse::Simple(response) =\u0026gt; { stream.write_all(response.as_bytes()).await?; } CommandResponse::Bulk(data) =\u0026gt; { let header = format!(\u0026#34;${}{}\u0026#34;, data.len(), CRLF); stream.write_all(header.as_bytes()).await?; stream.write_all(\u0026amp;data).await?; } CommandResponse::EndStream =\u0026gt; break, } } } Err(e) =\u0026gt; { let err_response = format!(\u0026#34;-ERR {}\\r\\n\u0026#34;, e); stream.write_all(err_response.as_bytes()).await?; } } Ok(()) } pub async fn execute( \u0026amp;self, db: Db, config: Config, replication_config: ReplicationConfig, peer_addr: SocketAddr, ) -\u0026gt; Result\u0026lt;Vec\u0026lt;CommandResponse\u0026gt;, String\u0026gt; { match self { // 각 커맨드에 해당하는 처리 함수를 호출한다. Command::SET { key, value, ex, px } =\u0026gt; Ok(vec![CommandResponse::Simple( Self::execute_set(key, value, *ex, *px, db).await, )]), // (중략 ... ) } } async fn execute_set(key: \u0026amp;String, value: \u0026amp;String, ex: Option\u0026lt;u64\u0026gt;, px: Option\u0026lt;u64\u0026gt;, db: Db) -\u0026gt; String { let expiration_ms = match (px, ex) { (Some(ms), _) =\u0026gt; Some(ms), (None, Some(s)) =\u0026gt; Some(s * 1000), _ =\u0026gt; None, }; // 2. 실제 스레드에서 경합자원을 직접적으로 이용한다. db.write().await.insert(key.clone(), ValueEntry::new_relative(value.clone(), expiration_ms)); // 3. 심지어 레플리케이션 전파와 같은 로직이 늘어난다면 또하나의 경합자원을 생성한다. format!(\u0026#34;{}OK{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF) } // ====== 이하 진행하고 있는 리팩토링 ======= #[tokio::main] async fn main() { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); let client_manager = ClientManager::new(); let (tx, mut rx) = mpsc::channel::\u0026lt;RedisEvent\u0026gt;(32); let db = Arc::new(tokio::sync::RwLock::new(Default::default())); let config = Arc::new(tokio::sync::RwLock::new(Default::default())); let replication_config = Arc::new(tokio::sync::RwLock::new(Default::default())); //# client manager 자체를 넘기고, 아래 spawn에서는 client manager를 사용하지 않고 //# client추가, 삭제를 RedisEvent에 더 추가해서 넘기기 (RedisEvent::AddClient(...), RemoveClient(...)) //# db, config, replication_config, cilent_manager는 모두 event handler에서만 사용하게 바뀌게 되어서 //# Arc, RwLock 등 삭제 let event_handler = EventHandler::new( db.clone(), config.clone(), replication_config.clone(), client_manager.clients.clone(), //# client_manager자체를 넘기고, ); let event_publisher = EventPublisher::new(tx); tokio::spawn(async move { while let Ok((stream, addr)) = listener.accept().await { //# id는 atomic같은것을 이용해서 unique함을 보장 let client_id = addr.port() as u64; //# AddClient event로 수정하면서 //# stream을 split 시켜서 읽는 쪽과 쓰는쪽을 분리. //# 읽는쪽은 아래spawn 내부에서 사용하고, 쓰는쪽은 client에서 사용 //# https://docs.rs/tokio/latest/tokio/net/struct.TcpStream.html#method.split client_manager.add_client(client_id, stream.try_clone().unwrap()).await; let publisher = event_publisher.clone(); //# 매니저는 event_handler에서만 존재 let manager = client_manager.clone(); tokio::spawn(async move { //# 분리한 sream중 reader 사용 let mut stream = manager.get_stream(client_id).await.unwrap().write().await; let mut buffer = [0; 1024]; loop { let bytes_read = match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; n, Err(_) =\u0026gt; { eprintln!(\u0026#34;Failed to read from client {}\u0026#34;, client_id); break; } }; //# 보낸 데이터를 한번에 다 읽는다는 보장이 없기 때문에 //# 보낼때도 byte len같은걸 해더에 담아 보내고 //# 읽을때도 해당 바이트를 다 읽을때까지 계속 돌면서 buffer를 채워야 함. let input = String::from_utf8_lossy(\u0026amp;buffer[..bytes_read]).to_string(); if let Err(e) = publisher.publish(client_id, input.clone()).await { eprintln!(\u0026#34;Error publishing event: {}\u0026#34;, e); } } manager.remove_client(client_id).await; }); } }); while let Some(event) = rx.recv().await { event_handler.handle_event(event).await; } } //# 아래에 각족 Lock, Arc는 필요성이 없다면 모두 삭제 pub type SharedClients = Arc\u0026lt;RwLock\u0026lt;HashMap\u0026lt;u64, Arc\u0026lt;Client\u0026gt;\u0026gt;\u0026gt;\u0026gt;; pub struct ClientManager { clients: SharedClients, } impl ClientManager { pub fn new() -\u0026gt; Self { Self { clients: Arc::new(RwLock::new(HashMap::new())), } } pub async fn add_client(\u0026amp;self, client_id: u64, client: Client) { let mut clients = self.clients.write().await; clients.insert(client_id, Arc::new(client)); } pub async fn remove_client(\u0026amp;self, client_id: u64) { let mut clients = self.clients.write().await; clients.remove(\u0026amp;client_id); } pub async fn get_client(\u0026amp;self, client_id: u64) -\u0026gt; Option\u0026lt;Arc\u0026lt;Client\u0026gt;\u0026gt; { let clients = self.clients.read().await; clients.get(\u0026amp;client_id).cloned() } } #[derive(Debug)] pub struct Client { pub id: u64, pub stream: Arc\u0026lt;RwLock\u0026lt;TcpStream\u0026gt;\u0026gt;, pub connected_at: Instant, pub request_count: RwLock\u0026lt;u64\u0026gt;, } impl Client { pub fn new(id: u64, stream: TcpStream) -\u0026gt; Self { Self { id, stream: Arc::new(RwLock::new(stream)), connected_at: Instant::now(), request_count: RwLock::new(0), } } pub async fn increment_request_count(\u0026amp;self) { let mut count = self.request_count.write().await; *count += 1; } pub async fn get_request_count(\u0026amp;self) -\u0026gt; u64 { *self.request_count.read().await } } ","permalink":"http://localhost:1313/_wiki/mpsc-%EC%A7%88%EB%AC%B8-%EB%8B%B5%EB%B3%80-%EB%B0%B1%EC%97%85/","summary":"#[tokio::main] async fn main() { // 1. 필요한 설정, 데이터 등을 세팅함. let state = StateManager::new(); let config_handler = ConfigHandler::new(state.get_db(), state.get_config(), state.get_replication_config()); config_handler.load_config().await; config_handler.configure_db().await; config_handler.configure_replication().await; let port = config_handler.get_port().await; let listener = TcpListener::bind(format!(\u0026#34;127.0.0.1:{}\u0026#34;, port)).await.unwrap(); println!(\u0026#34;Listening on port {}\u0026#34;, port); loop { match listener.accept().await { // 2. 스트림을 따서, 스트림을 handle_client로 전달 Ok((stream, _)) =\u0026gt; { let db = state.get_db(); let config = state.get_config(); let replication_config = state.get_replication_config(); task::spawn(async move { // 3.","title":"mpsc refactoring review 🦀"},{"content":"Prerequisite 내가 직면한 문제는 아래의 문서에 있다.\n👉 [[Redis-Stream-Issue]]\n아주 간단하게 요약하자면, 각 스레드가 스트림을 물고다니면서 태스크가 처리되고, 리소스들을 lock으로 관리한다.\n지금까지는 그나마 괜찮았는데, 레플리케이션의 쓰기 전파를 생각해봤을 때, 다수의 슬레이브 스트림을 락으로 관리하는 구조에서는 간단한 쓰기 요청에서도 슬레이브들의 스트림을 사용하는 쓰기 락 때문에 지나친 병목이 발생한 구조라는 것이다.\n원조 레디스는 싱글스레드와 이벤트루프로 구현된다.\n과정에서 좋은 방법이 없을까 하다가 찾게된건 mpsc이고 mpsc에 대한 간단한 조사를 아래의 문서에 정리했다.\n👉 [[rust-mpsc]]\n아주 좋은 구조이자 해결책이라는 생각이 들었지만, 동시에 스트레스가 차오른다. mpsc는 좋지만 도입을 위해 해결해야 할 문제들 지금까지는 상쾌하게, 아무런 설계에 대한 고민을 하지 않고 진행을 했고, 그게 내가 코드크래프터스에 돈을 지불하는 이유라고 생각했다. 스테이지별 처리해야할 요구사항만을 기준으로 생각하고 구현했고, 그 결과는 위와 같았던 것이다.\n지금까지의 나의 코드의 구조는 이렇다.\nmain.rs\n#[tokio::main] async fn main() { // 1. 필요한 설정, 데이터 등을 세팅함. let state = StateManager::new(); let config_handler = ConfigHandler::new(state.get_db(), state.get_config(), state.get_replication_config()); config_handler.load_config().await; config_handler.configure_db().await; config_handler.configure_replication().await; let port = config_handler.get_port().await; let listener = TcpListener::bind(format!(\u0026#34;127.0.0.1:{}\u0026#34;, port)).await.unwrap(); println!(\u0026#34;Listening on port {}\u0026#34;, port); loop { match listener.accept().await { // 2. 스트림을 따서, 스트림을 handle_client로 전달 Ok((stream, _)) =\u0026gt; { let db = state.get_db(); let config = state.get_config(); let replication_config = state.get_replication_config(); task::spawn(async move { // 3. 딱 봐도 알 수 있겠지만, 일단 경합자원이고 뭐고 다 넘겨버린다. handle_client(stream, db, config, replication_config).await; }); } Err(e) =\u0026gt; { println!(\u0026#34;Error accepting connection: {}\u0026#34;, e); } } } } main.rs에서 하는 일은 1,2,3으로 정리 될 수 있다. lock으로 관리하는 자원들을 넘기는게 일단 잘못되어있다. handle_client.rs\npub async fn handle_client(mut stream: TcpStream, db: Db, config: Config, replication_config: ReplicationConfig) { let mut buffer = [0; 512]; loop { buffer.fill(0); // 1. (직접 받아온 스트림에서) 버퍼로 요청 메세지를 읽는다. match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; { let message = match std::str::from_utf8(\u0026amp;buffer[..n]) { Ok(msg) =\u0026gt; msg, Err(_) =\u0026gt; { println!(\u0026#34;Failed to parse message as UTF-8\u0026#34;); continue; } }; println!(\u0026#34;Received message: {:?}\u0026#34;, message); // 2. 메세지를 파싱해서, Command 객체를 (정확히는 enum)을 만들어준다. match CommandParser::parse_message(message) { Ok(command) =\u0026gt; { // 3. 커맨드를 실행하는, 메서드는 다음과 같이 경합자원들을 물고 들어간다(stream, db, 등등...) if let Err(e) = command.handle_command(\u0026amp;mut stream, Arc::clone(\u0026amp;db), Arc::clone(\u0026amp;config), replication_config.clone()).await { println!(\u0026#34;Failed to send response: {}\u0026#34;, e); } } Err(e) =\u0026gt; { println!(\u0026#34;Failed to parse command: {}\u0026#34;, e); } } } Err(e) =\u0026gt; { println!(\u0026#34;Error reading from stream: {}\u0026#34;, e); break; } } } } 여기도 마찬가지로 1,2,3 순서로 주석을 작성했다. command.rs\npub async fn handle_command( \u0026amp;self, stream: \u0026amp;mut TcpStream, db: Db, config: Config, replication_config: ReplicationConfig, ) -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { let peer_addr = match stream.peer_addr() { Ok(addr) =\u0026gt; addr, Err(_) =\u0026gt; { let err_response = \u0026#34;-ERR Failed to retrieve client address\\r\\n\u0026#34;.to_string(); stream.write_all(err_response.as_bytes()).await?; return Ok(()); } }; // 1. 커맨드에서 받아온 처리 응답 결과를 경합자원인 stream에 직접 쓰는 문제. match self.execute(db, config, replication_config, peer_addr).await { Ok(responses) =\u0026gt; { for response in responses { match response { CommandResponse::Simple(response) =\u0026gt; { stream.write_all(response.as_bytes()).await?; } CommandResponse::Bulk(data) =\u0026gt; { let header = format!(\u0026#34;${}{}\u0026#34;, data.len(), CRLF); stream.write_all(header.as_bytes()).await?; stream.write_all(\u0026amp;data).await?; } CommandResponse::EndStream =\u0026gt; break, } } } Err(e) =\u0026gt; { let err_response = format!(\u0026#34;-ERR {}\\r\\n\u0026#34;, e); stream.write_all(err_response.as_bytes()).await?; } } Ok(()) } pub async fn execute( \u0026amp;self, db: Db, config: Config, replication_config: ReplicationConfig, peer_addr: SocketAddr, ) -\u0026gt; Result\u0026lt;Vec\u0026lt;CommandResponse\u0026gt;, String\u0026gt; { match self { // 각 커맨드에 해당하는 처리 함수를 호출한다. Command::SET { key, value, ex, px } =\u0026gt; Ok(vec![CommandResponse::Simple( Self::execute_set(key, value, *ex, *px, db).await, )]), // (중략 ... ) } } async fn execute_set(key: \u0026amp;String, value: \u0026amp;String, ex: Option\u0026lt;u64\u0026gt;, px: Option\u0026lt;u64\u0026gt;, db: Db) -\u0026gt; String { let expiration_ms = match (px, ex) { (Some(ms), _) =\u0026gt; Some(ms), (None, Some(s)) =\u0026gt; Some(s * 1000), _ =\u0026gt; None, }; // 2. 실제 스레드에서 경합자원을 직접적으로 이용한다. db.write().await.insert(key.clone(), ValueEntry::new_relative(value.clone(), expiration_ms)); // 3. 심지어 레플리케이션 전파와 같은 로직이 늘어난다면 또하나의 경합자원을 생성한다. format!(\u0026#34;{}OK{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF) } 마찬가지로 작성된, 나의 코드의 문제를 주석으로 작성했다.\n즉 이런 구조로는 스레드가 직접적으로 경합 자원을 가져다 쓴다는 이슈이다.\n더 어려운건 이 상태를 변경하려면 구조를 심각하게 변경해야 한다는 것이다.\n다시 설계를 진행해야 한다. 먼저 생각해본 개편 이후의 흐름. 먼저 새로 이벤트를 정의한다. 아래는 아직 간단하게 생각하는 redis_event.rs\n#[derive(Debug)] pub enum RedisEvent { ClientRequest { client: Client, command: Command, }, Replication { slave: Slave, data: Vec\u0026lt;u8\u0026gt;, }, PubSub { channel: String, message: String, }, ClientConnect { client: Client, }, ClientDisconnect { client: Client, }, } 참고, 원조 레디스는 클라이언트를 별도의 주소값만으로 식별한다.\nuse std::net::SocketAddr; #[derive(Debug)] pub struct Client { pub addr: SocketAddr, } 마찬가지로 이벤트 핸들러. event_handler.rs\npub struct EventHandler { // 아마도 여기에 경합 자원들을 전부 보관. // State 객체를 여기서 들고있어도 좋을 것 같다. // 거기에 추가적으로 Sender도 하나 들고 있어야 한다(아마도 replication_rx). // (이벤트를 처리하는 도중, 새로운 이벤트를 발행할수 있음. 예를들어 set을 처리하면서 db에 쓰고, 새로운 replication 전파 이벤트 발행) } impl EventHandler { pub async fn handle_event(event: RedisEvent) { match event { RedisEvent::ClientRequest { client, command, params } =\u0026gt; { // 명령 실행 로직 } RedisEvent::Replication { slave_id, data } =\u0026gt; { // 레플리케이션 로직 } RedisEvent::PubSub { channel, message } =\u0026gt; { // Pub/Sub 메시지 처리 } RedisEvent::ClientConnect { client } =\u0026gt; { // 클라이언트 연결 처리 } RedisEvent::ClientDisconnect { client } =\u0026gt; { // 클라이언트 해제 처리 } } } } 이부분까지 진행을 했을 때, 리팩토링을 하는 부분에 있어서 질문이 생겼고 커뮤니티에 질문을 올리고 답변을 받았다. [[mpsc-질문-답변-백업]]\n","permalink":"http://localhost:1313/_wiki/%EB%82%9C%EA%B0%9C%EB%B0%9C%EB%90%9C-%EB%A0%88%EB%94%94%EC%8A%A4%EB%A5%BC-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EB%A3%A8%ED%94%84-%EA%B8%B0%EB%B0%98%EC%9C%BC%EB%A1%9C-%EB%A6%AC%ED%8C%A9%ED%86%A0%EB%A7%81%ED%95%98%EA%B8%B0/","summary":"Prerequisite 내가 직면한 문제는 아래의 문서에 있다.\n👉 [[Redis-Stream-Issue]]\n아주 간단하게 요약하자면, 각 스레드가 스트림을 물고다니면서 태스크가 처리되고, 리소스들을 lock으로 관리한다.\n지금까지는 그나마 괜찮았는데, 레플리케이션의 쓰기 전파를 생각해봤을 때, 다수의 슬레이브 스트림을 락으로 관리하는 구조에서는 간단한 쓰기 요청에서도 슬레이브들의 스트림을 사용하는 쓰기 락 때문에 지나친 병목이 발생한 구조라는 것이다.\n원조 레디스는 싱글스레드와 이벤트루프로 구현된다.\n과정에서 좋은 방법이 없을까 하다가 찾게된건 mpsc이고 mpsc에 대한 간단한 조사를 아래의 문서에 정리했다.\n👉 [[rust-mpsc]]","title":"난개발된 레디스를 이벤트 루프 기반으로 리팩토링하기 🥶"},{"content":"mpsc란? Rust의 mpsc 채널은 \u0026ldquo;여러 생산자 (Multiple Producer)\u0026ldquo;와 \u0026ldquo;하나의 소비자 (Single Consumer)\u0026ldquo;로 메시지를 보내고 처리 할 수 있는 비동기 통신 도구이다. 아이디어도 아이디어지만, 기본적으로 설계와 동작이 Rust의 소유권과 동시성 모델에 기반을 두고 있다.\n기본적인 사용 방식은 아래와 같다.\nmpsc::channel\ntx (생산자), rx(소비자) 를 반환받는다. use tokio::sync::mpsc; #[tokio::main] async fn main() { // 채널 생성 (버퍼 크기: 32) let (tx, mut rx) = mpsc::channel(32); // 생산자 (Producer) tokio::spawn(async move { for i in 1..=5 { // tx.send()로 채널에 메세지를 보낸다. if let Err(_) = tx.send(format!(\u0026#34;Message {}\u0026#34;, i)).await { println!(\u0026#34;Receiver dropped\u0026#34;); return; } println!(\u0026#34;Sent: Message {}\u0026#34;, i); } }); // 소비자 (Consumer) : rx.recv()로 수신한 메세지를 처리한다. while let Some(message) = rx.recv().await { println!(\u0026#34;Received: {}\u0026#34;, message); } } Sent: Message 1 Received: Message 1 Sent: Message 2 Received: Message 2 ... Sender의 복제\ntx에는 clone()이 구현되어 있어, 여러 생산자를 복제할 수 있다. use tokio::sync::mpsc; #[tokio::main] async fn main() { let (tx, mut rx) = mpsc::channel(32); // Sender를 복제 let tx1 = tx.clone(); let tx2 = tx.clone(); // 첫 번째 생산자 tokio::spawn(async move { tx1.send(\u0026#34;From Producer 1\u0026#34;).await.unwrap(); }); // 두 번째 생산자 tokio::spawn(async move { tx2.send(\u0026#34;From Producer 2\u0026#34;).await.unwrap(); }); // 소비자 while let Some(message) = rx.recv().await { println!(\u0026#34;Received: {}\u0026#34;, message); } } Received: From Producer 1 Received: From Producer 2 그 외에도 버퍼의 크기를 설정할 수 있고, 버퍼가 가득 차면 send 호출이 블록상태가 된다.(즉 컨슈머의 처리 속도가 걱정된다면, 적당한 버퍼의 크기로 조절 할 수 있다.) 또한 루프의 상태를 보고 send를 하거나 대기를 하는것도 send, try_send와 같은 메서드들로 구분 할 수 있다. 그리고 매우 일반적인 방법인 것 같은데, 버퍼의 크기를 조절하기도 하지만 큐 자체를 나눠서 분배 할 수 도 있다.\nlet (client_tx, mut client_rx) = tokio::sync::mpsc::channel::\u0026lt;RedisEvent\u0026gt;(32); let (replication_tx, mut replication_rx) = tokio::sync::mpsc::channel::\u0026lt;RedisEvent\u0026gt;(32); tokio::spawn(async move { while let Some(event) = client_rx.recv().await { // 클라이언트 요청 처리 } }); tokio::spawn(async move { while let Some(event) = replication_rx.recv().await { // 레플리케이션 작업 처리 } }); mpsc의 장점 스레드 간 안전한 데이터 교환 mpsc 채널은 잘 설계하면 Rust의 소유권과 동시성 모델에 기반을 두고 있어, 생산자와 소비자가 다른 스레드에서 동작해도 데이터 경합 없이 안전하다. 심지어 내부적으로 Arc나 Mutex없이 설계되어 고성능을 보장한다고 한다. 생산자 확장성 mpsc의 Sender를 클론하여 여러 생산자를 생성 할 수 있다. 작업 디커플링 구조대로 작성한다면, 생산자와 소비자는 서로 독립적으로 동작한다. 생산자는 메세지를 보내놓고, 다음 작업으로 넘어갈 수 있고 소비자는 큐에서 데이터를 꺼내 처리 할 뿐이다. 백프레셔 관리 mpsc는 버퍼링기능을 자체적으로 지원하고, 관련한 인터페이스도 잘 빠져있다. 버퍼가 가득 차는 정도, 소비자의 처리속도를 고려해서 사용자가 유동적으로 조절 할 수 있고 반대로 여러 소비자를 둬서 분배를 할 수 있다. 결론 이상적으로 잘 설계만 한다면 멀티스레드의 장점과 (이벤트루프 기반의)싱글스레드 프로그램의 장점을 동시에 취할 수 있을 것 같다. 아마도 락같은 경합 자원들을 컨슈머쪽에 몰빵하는 구조가 될 것 같은데, 이와 같은 기반으로 설계를 처음부터 잘 하고 들어가야 사용 할 수 있을 것 같다. ","permalink":"http://localhost:1313/_wiki/rust-mpsc/","summary":"mpsc란? Rust의 mpsc 채널은 \u0026ldquo;여러 생산자 (Multiple Producer)\u0026ldquo;와 \u0026ldquo;하나의 소비자 (Single Consumer)\u0026ldquo;로 메시지를 보내고 처리 할 수 있는 비동기 통신 도구이다. 아이디어도 아이디어지만, 기본적으로 설계와 동작이 Rust의 소유권과 동시성 모델에 기반을 두고 있다.\n기본적인 사용 방식은 아래와 같다.\nmpsc::channel\ntx (생산자), rx(소비자) 를 반환받는다. use tokio::sync::mpsc; #[tokio::main] async fn main() { // 채널 생성 (버퍼 크기: 32) let (tx, mut rx) = mpsc::channel(32); // 생산자 (Producer) tokio::spawn(async move { for i in 1.","title":"러스트의 mpsc 🤔"},{"content":"Issue : 레디스 스트림과 락을 관리하는 이슈 \u0026hellip;😇 마스터와 슬레이브를 잘 등록했다고 생각했는데, 실제 쓰기 요청을 전파하다가 바로 이슈가 생겨버렸다.\n#[derive(Clone, Debug)] pub struct SlaveInfo { pub addr: SocketAddr, pub offset: i64, } 직전 포스팅에서 이야기 한 것 처럼, SlaveInfo는 위와 같이 관리하고 있었다.\nIP주소로 클라이언트를 식별해서, 잘Slave를 등록을 했고, 명령만 전파하면 될 일이었다.\n머리가 꽃밭이었던 나는 큰 고민 없이 작업에 착수했는데..\nasync fn execute_set(key: \u0026amp;String, value: \u0026amp;String, ex: Option\u0026lt;u64\u0026gt;, px: Option\u0026lt;u64\u0026gt;, db: Db) -\u0026gt; String { let expiration_ms = match (px, ex) { (Some(ms), _) =\u0026gt; Some(ms), (None, Some(s)) =\u0026gt; Some(s * 1000), _ =\u0026gt; None, }; db.write().await.insert(key.clone(), ValueEntry::new_relative(value.clone(), expiration_ms)); // 1. replconfig에서 슬레이브 목록을 받는다. // 2. 해당 슬레이브들에게 set과 커맨드를 전송한다. // 3. tcpstream::new()...? 응....? format!(\u0026#34;{}OK{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF) } 사실 위의 주석 내용도 멍청하게도 해보고 나서야 깨닫은 내용이다\n바로 실행한 결과는 내 쓰기 요청을 레플리카들이 못받았다고 test fail이 발생했다.\n나는 stateless 한 서버-클라이언트에만 절어있는사람.. 🤐 사실 이슈는 너무 당연했다.\n클라이언트(레플리카)가 syc-ack을 하러 스트림을 개설하면, 해당 스트림 내에서 이후 처리가 이뤄져야 하는데\n너무 요청을 단위로 로직을 끊어놓아서 그리고 그런 방식으로만 생각해서, 자연스럽게 생각을 하지 못한 것 같다\n레디스 자체가 서버처럼 응답을 하고, 아마도 대부분의 어플리케이션의 라이브러리에 스트림을 관리하게 되어있을거고,\n단건의 간단한 요청은 바로 스트림을 끊어버리도록 되어있을 것이다. (클라언트 사이드에서 명시적인 스트림 닫기)\n그게 아닌 상황에서는 오히려 디폴트는 개설한 스트림을 끊지 않는다는 것이다.\n그리고 특히나 레플리카와 마스터의 관계에서는 당연히 스트림을 끊을 이유가 없었다.\n너무 망상일 수 있겠지만, 제작자들이 지금 시점에서 해당 문제에 직면하도록 설계를 해 둔 것 같기도 하다. 여기가 아는 다른 부분에서는 스트림 개설이 자유로웠다.\n그러면 스트림을 보관하면 되잖아? #[derive(Clone, Debug)] pub struct SlaveInfo { pub addr: SocketAddr, pub offset: i64, pub 아까_열린_스트림: Arc\u0026lt;Lock\u0026lt;TcpStream\u0026gt;\u0026gt; } 일단 근데, 바로 시작하고 수정하려고 했더니 당연히 Lock을 걸어야 했다.\nLock 생각을 하자 마자 마음이 불안해지고 심사가 뒤틀렸다.\n아 맞다\n멀티스레드지..\n스트림이 락이네..\n그리고 난 쓰기요청을 전파해야 하네..\n당장 10건의 쓰기가 있을 때 레플리카가 두세개만 있는 상황만 생각해도..\n즉시 결합! 앞으로 모든 쓰기는 레플리카 스트림 락을 반환받기 전까지 응 못해~\n그러면 찐레디스는 어떻게 해? 응~ 레디스 형들은 이벤트루프 다 만들어 놨어~ \u0026lsquo;이벤트 루프 기반의 싱글 스레드 프로그램\u0026rsquo; 이라고 광고했는데, 그게 느껴져?\n여기서 솔직히 그냥 멘붕이 너무 심했다.\n지금까지 한 스테이지들을 다 갈아 엎..어도 토키오나 이런부분을 잘 모르는 내가 지금부터 이벤트 루프로직을 잘 찾아서 이용할 수 있는지도 모르겠고,\n사실 이미 어떠한 부분은 그렇게 되고 있나 싶기도 하고..\n결론? 을 고민하다가 아직 해결을 못했다.\n일단 스트림은 보관하되 명확하게 전파하는 부분을 잘 분리해서 비동기이면서 이벤트루프스럽게 구현 할 건덕지를 찾기는 했다. 바로 mpsc\n이걸 제대로 이용하려면 일단 더 찾아보기도 해야할 것 같고, 특히 토키오쪽도 더 뒤적여야 제대로 사용 할 수 있을 것 같다.\n아마도 내일 진행 할 듯 하다.\n","permalink":"http://localhost:1313/_wiki/redis-stream-issue/","summary":"산넘어 산..","title":"Lock과 Stream을 어떻게 접근 할 것인가.."},{"content":"레디스 레플리케이션을 위한 handshake는 간단하게 아래와 같은 순서로 이루어진다.\nslave가 마스터에 PING 호출 -\u0026gt; PONG slave가 마스터에 REPLCONF -\u0026gt; +OK\\r\\n : 포트정보 등을 인자로 전달하여 알려줌(ex. REPLCONF listening-port 6380) 몇차례의 REPLCONF 반복 PSYNC -\u0026gt; +FULLRESYNC \u0026lt;REPL_ID\u0026gt; 0\\r\\n 그리고 간단하게, 지금까지 나의 레디스 ReplicationConfig의 구조는 아래와 같다.\n#[derive(Clone)] pub struct ReplicationConfig { role: Arc\u0026lt;RwLock\u0026lt;String\u0026gt;\u0026gt;, master_host: Arc\u0026lt;RwLock\u0026lt;Option\u0026lt;String\u0026gt;\u0026gt;\u0026gt;, master_port: Arc\u0026lt;RwLock\u0026lt;Option\u0026lt;u16\u0026gt;\u0026gt;\u0026gt;, master_replid: Arc\u0026lt;RwLock\u0026lt;String\u0026gt;\u0026gt;, master_repl_offset: Arc\u0026lt;RwLock\u0026lt;u64\u0026gt;\u0026gt;, slaves: Arc\u0026lt;RwLock\u0026lt;Vec\u0026lt;SlaveInfo\u0026gt;\u0026gt;\u0026gt;, } #[derive(Clone, Debug)] pub struct SlaveInfo { pub addr: SocketAddr, pub offset: i64, } impl ReplicationConfig { pub fn new() -\u0026gt; Self { let replid = Self::generate_replication_id(); Self { role: Arc::new(RwLock::new(\u0026#34;master\u0026#34;.to_string())), master_host: Arc::new(RwLock::new(None)), master_port: Arc::new(RwLock::new(None)), master_replid: Arc::new(RwLock::new(replid)), master_repl_offset: Arc::new(RwLock::new(0)), slaves: Arc::new(RwLock::new(Vec::new())), } } ...(중략) 그리고 주요한 메서드는 아래와 같다.\nimpl ReplicationConfig { ...(중략) pub async fn register_slave(\u0026amp;self, addr: SocketAddr) { let mut slaves = self.slaves.write().await; if !slaves.iter().any(|slave| slave.addr == addr) { slaves.push(SlaveInfo { addr, offset: 0, }); println!(\u0026#34;Slave registered: {:?}\u0026#34;, addr); } } pub async fn update_slave_offset(\u0026amp;self, addr: SocketAddr, offset: i64) { let mut slaves = self.slaves.write().await; if let Some(slave) = slaves.iter_mut().find(|slave| slave.addr == addr) { slave.offset = offset; } } pub async fn update_slave_state(\u0026amp;self, addr: SocketAddr, offset: i64) { let mut slaves = self.slaves.write().await; if let Some(slave) = slaves.iter_mut().find(|slave| slave.addr == addr) { slave.offset = offset; } } pub async fn list_slaves(\u0026amp;self) -\u0026gt; Vec\u0026lt;SlaveInfo\u0026gt; { let slaves = self.slaves.read().await.clone(); println!(\u0026#34;Current slaves: {:?}\u0026#34;, slaves); slaves } } 마지막으로, 실제 커맨드를 실행시키는 부분은 아래와 같다.\npub async fn execute_replconf( args: \u0026amp;Vec\u0026lt;String\u0026gt;, peer_addr: SocketAddr, replication_config: ReplicationConfig, ) -\u0026gt; String { println!(\u0026#34;peer_addr on replconf : {:?}\u0026#34;, peer_addr); if args[0] == \u0026#34;listening-port\u0026#34; { if let Ok(port) = args[1].parse::\u0026lt;u16\u0026gt;() { let addr = SocketAddr::new(peer_addr.ip(), port); replication_config.register_slave(addr).await; return format!(\u0026#34;{}OK{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF); } } else if args[0] == \u0026#34;capa\u0026#34; { return format!(\u0026#34;{}OK{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF); } format!(\u0026#34;-ERR Invalid REPLCONF arguments{}\u0026#34;, CRLF) } async fn execute_psync( args: \u0026amp;Vec\u0026lt;String\u0026gt;, replication_config: ReplicationConfig, peer_addr: SocketAddr, ) -\u0026gt; Vec\u0026lt;CommandResponse\u0026gt; { println!(\u0026#34;peer_addr on psync : {:?}\u0026#34;, peer_addr); let slaves = replication_config.list_slaves().await; println!(\u0026#34;Slaves during PSYNC: {:?}\u0026#34;, slaves); if !slaves.iter().any(|slave| slave.addr == peer_addr) { println!( \u0026#34;-ERR Slave not registered: {}:{}{}\u0026#34;, peer_addr.ip(), peer_addr.port(), CRLF ); return vec![CommandResponse::Simple(format!( \u0026#34;-ERR Slave not registered: {}:{}{}\u0026#34;, peer_addr.ip(), peer_addr.port(), CRLF ))]; } let master_repl_id = replication_config.get_repl_id().await; let requested_offset: i64 = args .get(1) .and_then(|offset| offset.parse::\u0026lt;i64\u0026gt;().ok()) .unwrap_or(-1); let master_offset = 0; if requested_offset == -1 || requested_offset \u0026lt; master_offset { let full_resync_response = format!( \u0026#34;{}FULLRESYNC {} {}{}\u0026#34;, SIMPLE_STRING_PREFIX, master_repl_id, master_offset, CRLF ); // TODO : give real rdb file if needed const EMPTY_RDB_FILE: \u0026amp;[u8] = \u0026amp;[ 0x52, 0x45, 0x44, 0x49, 0x53, 0x30, 0x30, 0x30, 0x39, 0xFF, ]; vec![ CommandResponse::Simple(full_resync_response), CommandResponse::Bulk(EMPTY_RDB_FILE.to_vec()), ] } else { vec![CommandResponse::Simple(format!( \u0026#34;{}CONTINUE{}\u0026#34;, SIMPLE_STRING_PREFIX, CRLF ))] } } 즉 replconf으로 온 요청을 식볋해서, slave 목록을 저장하고, psync 요청때 해당 slave의 offset을 활성화 하는 방식으로 관리했다.\n그 과정에서 스트림에서 직접 ip와 port를 받아오는 걸로 처리를 했는데 (psync에는 slave에 대한 식별값이나, 호스트 관련 정보를 전달하지 않음)\n문제는 테스트 케이스에서 replconf를 등록한 요청과, 실제 스트림에서 추출한 peer_addr정보가 다르다는 것 이었다.\n디버그 로그\n[tester::#ZN8] Running tests for Stage #ZN8 (Replication - Single-replica propagation) [tester::#ZN8] $ ./your_program.sh --port 6379 [your_program] Configuration loaded. [your_program] Listening on port 6379 [tester::#ZN8] [handshake] replica: $ redis-cli PING [your_program] Received message: \u0026#34;*1\\r\\n$4\\r\\nPING\\r\\n\u0026#34; [tester::#ZN8] [handshake] Received \u0026#34;PONG\u0026#34; [tester::#ZN8] [handshake] replica: \u0026gt; REPLCONF listening-port 6380 [your_program] Received message: \u0026#34;*3\\r\\n$8\\r\\nREPLCONF\\r\\n$14\\r\\nlistening-port\\r\\n$4\\r\\n6380\\r\\n\u0026#34; [your_program] peer_addr on replconf : 127.0.0.1:38364 [your_program] Slave registered: 127.0.0.1:6380 [tester::#ZN8] [handshake] Received \u0026#34;OK\u0026#34; [tester::#ZN8] [handshake] replica: \u0026gt; REPLCONF capa psync2 [your_program] Received message: \u0026#34;*3\\r\\n$8\\r\\nREPLCONF\\r\\n$4\\r\\ncapa\\r\\n$6\\r\\npsync2\\r\\n\u0026#34; [your_program] peer_addr on replconf : 127.0.0.1:38364 [tester::#ZN8] [handshake] Received \u0026#34;OK\u0026#34; [tester::#ZN8] [handshake] replica: \u0026gt; PSYNC ? -1 [tester::#ZN8] Expected simple string or bulk string, got ERROR [tester::#ZN8] Test failed (try setting \u0026#39;debug: true\u0026#39; in your codecrafters.yml to see more details) [your_program] Received message: \u0026#34;*3\\r\\n$5\\r\\nPSYNC\\r\\n$1\\r\\n?\\r\\n$2\\r\\n-1\\r\\n\u0026#34; [your_program] peer_addr on psync : 127.0.0.1:38364 [your_program] Current slaves: [SlaveInfo { addr: 127.0.0.1:6380, offset: 0 }] [your_program] Slaves during PSYNC: [SlaveInfo { addr: 127.0.0.1:6380, offset: 0 }] [your_program] -ERR Slave not registered: 127.0.0.1:38364 [your_program] 그래서 실제로 레디스 관련 자료를 찾아봤는데, 딱히 도움이되는 내용은 없었다.\n일반적으로 docs는 slave기준으로 내려주는 커맨드에 대한 설명만 자세하게 나와있다.redis-docs\n그래서 직접 소스코드를 보는 수 밖에 없었다.\n먼저 replication.c 의 void syncCommand(client *c)를 보면 이처럼 이미 식별값을 가지고 있다.\nif (c-\u0026gt;flags \u0026amp; CLIENT_SLAVE) return; 그리고 여기가 해당 식별값을 설정하는 부분이고, 사실상 client 인스턴스에 식별값이 다 있다고 생각이 됐다.\nvoid replicationCreateSlave(client *c) { c-\u0026gt;flags |= CLIENT_SLAVE; c-\u0026gt;replstate = SLAVE_STATE_WAIT_BGSAVE_START; listAddNodeTail(server.slaves, c); } 그리고 여기가 REPLCONF, SYNC/PSYNC 같은 커맨드에서 호출되는건 확인하긴 했는데.. 그 클라이언트 초기화 하는 부분은 직접 찾기 너무 귀찮아서 gpt에게 물어봤다.\nvoid acceptCommonHandler(connection *conn, int flags, char *ip) { client *c = createClient(conn); // 새 클라이언트 생성 if (c == NULL) { serverLog(LL_WARNING, \u0026#34;Error creating client\u0026#34;); return; } if (connPeerToString(conn, c-\u0026gt;ip, sizeof(c-\u0026gt;ip), \u0026amp;c-\u0026gt;port) == -1) { serverLog(LL_WARNING, \u0026#34;Error identifying peer address\u0026#34;); freeClient(c); return; } serverLog(LL_VERBOSE, \u0026#34;Accepted %s:%d\u0026#34;, c-\u0026gt;ip, c-\u0026gt;port); } 그래서 찾은건 여기 코드고 클라이언트의 peer_addr을 스트림에서 추출하는것과 동일하다고 가정하면, 클라이언트에 대한 식별은 ip(replconf 커맨드로 바뀔 수 있는 호스트는 제외)라고 생각되어 수정했다.\n결론 어렵다. 힘들다. 생각보다 codecrafters의 설명이 자세하진 않다. 클라이언트로 추상화 미리 해둬야 하나? ","permalink":"http://localhost:1313/_wiki/redis-handshake-for-replicas/","summary":"레디스 레플리카를 등록하는 과정 중 replconf, psync를 처리하는 중 발생한 문제.","title":"레디스 HandShake중 이슈 처리하기😬"},{"content":"07장 트랜잭션 어떤 저자들은 2단계 커밋에서 유발되는 성능이나 가용성 문제 때문에 생기는 비용이 너무 커서 이를 지원할 수 없다고 주장했다. 우리는 항상 트랜잭션 없이 코딩하는 것보다 트랜잭션을 과용해서 병목지점이 생기는 성능 문제를 애플리케이션 프로그래머가 처리하는게 낫다고 생각한다.\n냉혹한 현실 세계에서 데이터 시스템은 여러 가지 문제가 생길 수 있다.\n데이터베이스 소프트웨어나 하드웨어는 언제라도 실패할 수 있다. 애플리케이션은 언제라도 죽을 수 있따. 네트워크가 끊기면 애플리케이션과 데이터베이스의 연결이 갑자기 끊기거나 데이터베이스 노드 사이의 통신이 안될 수 있다. 여러 클라이언트가 동시에 데이터베이스에 쓰기를 실행해서 다른 클라이언트가 쓴 내용을 덮어 쓸 수 있다. 클라이언트가 부분적으로만 갱신돼서 비정상적인 데이터를 읽을 수 있다. 클라이언트 사이의 경쟁 조건은 예측하지 못한 버그를 유발할 수 있다. 수십년동안 트랜잭션은 문제를 단순화하는 방식으로 해결해왔다. 몇개의 읽기와 쓰기를 하나의 논리적 단위로 묶는 방법이다. (하나의 쓰기가 실패하면 해당 논리적 단위가 전부 실패)\n트랜잭션은 항상 모든 애플리케이션에서 필요하지 않다. \u0026ldquo;그렇다면 트랜잭션이 필요한지 어떻게 알 수 있을까?\u0026rdquo; 이를 대답하려면 트랜잭션이 제공하는 안전성 보장에는 어떤 것이 있으며, 이와 관련된 비용은 무엇인지 정확히 이해해야 한다.\n이번 장에서는 문제가 생길 수 있는 여러 예를 조사하고 이런 문제를 방지하기 위해 데이터베이스에서 사용하는 알고리즘을 살펴본다.\n먼저 동시성 제어를 깊게 다루며 발생할 수 있는 다양한 종류의 경쟁 조건과 데이터베이스에서 커밋 후 읽기, 스냅샷 격리, 직렬성과 같은 격리 수준을 어떻게 구현하는지 설명한다.\n애매모호한 트랜잭션의 개념 분산 데이터베이스 vs 트랜잭션의 문제는 단순하지 않다. 트랜잭션도 이점과 한계가 있다.\nACID의 의미 저자는 지금의 ACID가 마케팅 용어로 변질되었다고 하고, ACID 표준을 따르지 않는 BASE는 더 모호하고 \u0026lsquo;ACID\u0026rsquo;가 아닌 뭔가 정도로 묘사한다고 되어있다.\n원자성\n일반적으로 원자적이란 더 작은 부분으로 쪼갤 수 없는 뭔가를 가리킨다.\n컴퓨터의 여러 분야에서 비슷한데 미묘한 차이가 있다.\n먼저 다중 스레드 프로그래밍에서 한 스레드가 원자적 연산을 실행한다면 다른 스레드에서 절반만 완료된 연산을 관찰할 수 없다. 시스템은 연산을 실행하기 전이나 실행한 후의 상태에만 있을 수 있으며 그 중간 상태에서 머물 수 없다.\n이러한 것들은, ACID의 맥락에서는 동시성과 관련이 없다.(보통 위와 같은 문제는 격리성에서 다룬다)\nACID에서는 \u0026lsquo;쓰기 작업 몇 개를 실행하려고 하는데, 그 중 일부만 처리된 후 결함이 생기면 무슨 일이 생기는지 설명한다\u0026rsquo;\n여러 쓰기 작업이 하나의 원자적 트랜잭션으로 묶여있는데, 결함 때문에 commit 될 수 없다면 abort되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소해야 한다.\n즉 어떠한 변경은 효과가 있고, 어떠한 것은 그렇지 않은지 알기 어려운 상태를 배제하려는 노력이고,\n책에서는 abortability가 원자성보다 더 나은 설명이라고 이야기한다.\n일관성 ACID의 맥락에서 일관성은 데이터베이스가 좋은 상태에 있어야 한다는 것의 애플리케이션에 특화된 개념을 가리킨다.\nACID의 일관성 아디어는 항상 진실이어야 하는, 데이터에 관한 어떤 선언 즉, 불변식(invariant)가 있다는 것이다.\n다만 이러한 것들은 어플리케이션의 논리에 기댈 수 밖에 없어서, 현실적으로는 C는 ACID에 속하지 않는다고 언급하고 있다.\n격리성 ACID에서 격리성은 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미한다.\n지속성 지속성은 트랜잭션이 성공적으로 커맷됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장이다.\n단일 객체 연산과 다중 객체 연산 요약하면 ACID에서 원자성과 격리성은 클라이언트가 한 트랝개션 내에서 여러번의 쓰기를 하면 데이터베이스가 어떻게 해야 하는지를 서술한다.\n원자성 : 쓰기를 이어서 실행하는 도중 오류가 발생하면 트랜잭션은 어보트돼야 하고 그때까지 쓰여진 내용은 폐기되어야 한다. (전부 반영되거나 아무것도 반영되지 않는 것을 보장)\n격리성 : 동시에 실행되는 트랜잭션들은 서로를 방해하지 말아야 한다. 한 트랜잭션이 여러번 쓴다면 다른 트랜잭션은 그 내용을 전부 볼 수 있든지 아무것도 볼 수 없든지 둘 중 하나여야한다.\n단일 객체 쓰기 다중 객체 트랜잭션의 필요성 오류와 어보트 처리 어보트의 취지는 안전하게 재시도를 하기 위함이다.\n완화된 격리 수준 ","permalink":"http://localhost:1313/_wiki/7%EC%9E%A5/","summary":"07장 트랜잭션 어떤 저자들은 2단계 커밋에서 유발되는 성능이나 가용성 문제 때문에 생기는 비용이 너무 커서 이를 지원할 수 없다고 주장했다. 우리는 항상 트랜잭션 없이 코딩하는 것보다 트랜잭션을 과용해서 병목지점이 생기는 성능 문제를 애플리케이션 프로그래머가 처리하는게 낫다고 생각한다.\n냉혹한 현실 세계에서 데이터 시스템은 여러 가지 문제가 생길 수 있다.\n데이터베이스 소프트웨어나 하드웨어는 언제라도 실패할 수 있다. 애플리케이션은 언제라도 죽을 수 있따. 네트워크가 끊기면 애플리케이션과 데이터베이스의 연결이 갑자기 끊기거나 데이터베이스 노드 사이의 통신이 안될 수 있다.","title":"데이터 중심 어플리케이션 설계 7장"},{"content":"파티셔닝 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고, 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라고 한다.\n데이터를 파티셔닝 하는 주된 이유는 확장성이다.\n파티셔닝과 복제 파티셔닝을 해도, 파티션 된 단위를 기준으로는 복제를 할 수 있다. 한 노드에 여러 파티션을 복제 할 수도 있어서, 노드 하나에 특정 파티션의 리더와 나머지 파티션의 복제를 가지는식으로 교차해 두기도 한다.\n키-값 데이터 파티셔닝 파티셔닝의 목적은 데이터와 질의 부하를 분산시키는 것이다. 이것이 달성되지 않았을 때 쏠렸다(skewed) 라고 한다. 이러한 쏠림이 발생하면, 특정 파티션에만 부하가 몰리게 되고, 다른 파티션은 거의 사용되지 않는 병목이 발생한다. 그 때 몰린 파티션을 핫스팟 이라고 한다.\n이게 싫어서 지금부터 전략을 세우는데, 가장 쉬운 방법은 랜덤하게 파티션을 나누는 것이다.\n그러면 데이터 분산은 매우 고르게 되지만, 데이터를 읽으려면 모든 파티션을 읽어야 하기 때문에, 이는 비효율적이다.\n키 범위 기준 파티셔닝\n그게 싫으면, 키 범위를 기준으로 파티션을 나누는 방법이 있다. 키를 특정 기준으로 정렬하는 방법은 앞에서 많이 다뤘고, 키값이 정렬되어있다면, 범위 기준으로 파티션을 나누는 것은 매우 쉽다. 심지어 각각의 범위를 재조정하는 것도 명확하다. 문제는 논리적인 정렬을 의존한다는 것인데, 만약 타임스탬프를 키로 사용한다면, 특정 날짜 혹신 시간대를 기준으로 유휴노드가 생기고 몰림이 발생할 수 있다.\n키의 해시값 기준 파티셔닝\n이런 논리적인 정렬을 피하기 위해서 해시값을 사용하는 방법이 있다. 해시값을 사용하면, 키의 해시값을 기준으로 파티션을 나누게 되고, 이는 랜덤하게 나누는 것과 같은 효과를 가진다. 또한, 해시값을 사용하면, 키의 범위가 어떻게 되든, 해시값은 항상 고르게 분포되기 때문에, 데이터를 고르게 분산시킬 수 있다. 그리고 간단한 해시함수를 사용하는 것으로도 충분하다. 물론 여기서도 문제가 생기는데, 바로 범위 기반의 질의에 약하다는 것이다. 범위와 같은 논리적인 내용에서는 인접해야할 키들이 다른 노드에 분산되어 있고, 결과적으로는 병렬적인 질의를 진행해야 한다.\n쏠린 작업부하와 핫스팟 완화\n해시를 해서 노드를 분산해도 핫스팟이 발생할 수 있다. sns의 유명 게시물이나, 특정 키워드로 검색된 결과물이나, 특정 사용자의 데이터와 같이, 특정 키에 대한 부하가 몰리는 경우가 있다. 이런경우 어플리케이션 로직으로 보완하는 경우도 있다. 예를 들어 특정 키에 대한 부하가 몰리면, 해당 키에 추가적인 식별값을 붙여서 해시를 분산하는 것이다. 물론 읽거나 다음 쓰기 등에 어플리케이션에서 처리해줘야 할 부분이 생기니 신중하게 필요한 부분만 적용해야 한다.\n파티셔닝과 보조 인덱스 지금까지 설명한 파티셔닝 방식은 키-값 데이터 모델에 의존한다. 레코드를 기본키를 통해서만 접근하다면 키로부터 파티션을 결정하고 이를 사용해 해당 키를 담당하는 파티션으로 읽기 쓰기 요청을 전달 할 수 있다. 보조 인덱스가 연관되면 상황은 복잡해진다. 보조 인덱스 는 보통 레코드를 유일하게 식별하는 용도가 아니라 특정한 값이 발생한 항목을 검색하는 수단이다. 사용자 123이 실행한 액션을 모두 찾거나 빨간색 자동차를 모두 찾는 등의 작업에 쓰인다.\n문서 기준 보조 인덱스 파티셔닝\n뭔가 보조인덱스를 기준으로 파티셔닝을 하는 것처럼 보이지만, 사실 그건 아니고, 기본키와 같은 것들로 파티셔닝을 해두고 해당 노드에서 보조인덱스를 유지하는 것이다. 즉 쓰기 등에서 파티션된 노드의 보조인덱스만 업데이트 하는 방식이다. 다만 내가 오해한 것처럼 특정 보조인덱스를 기준으로 파티셔닝을 하는것은 아니라서, 병렬적인 요청과 취합이 필요하다. 이걸 스캐터/게더라고 하고, 꼬리지연시간이 발생할 수 있다. 그래서 전역 인덱스가 아닌 로컬 인덱스로 불리는 것이다.\n용어 기준 보조 인덱스 파티셔닝\n이건 반대로 전역인덱스를 두는 방식이다. 그리고 전역 보조 인덱스대로 파티셔닝까지 진행한다. 예를들어 색상이라는 보조인덱스가 잇다면, 노드별로 특정 색상을 담당해서 파티셔닝을 한다. 전역적으로 인덱스가 유지되기 때문에 읽기가 효율적이다.(모든 노드에 질의하고 취합하는 과정이 필요없다, 어디에 질의해야할지 알 수 있기 때문이다.) 반대로는 쓰기가 느려질 수 있다는 점이다.\n파티션 재균형화 증설, 장애, 등의 이유로 파티션을 재배치해야할 때가 있다. 그리고 이러한 재배치를 진행 할 때, 최소한 만족해야하는 기준이 있다.\n재균형화 이수 부하가 클러스터 내의 노드에 균등하게 분배되어야 한다. 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 계속 처리해야 한다. 재균형화가 빨리 실행되고 네트워크와 디스크 부하를 최소하 할 수 있도록 데이터가 필요 이상으로 옮겨져서는 안된다. 파티션 개수 고정\n가장 간단한 해결책이다, 파티션 갯수를 훨씬 널널하게 만들고, 노드들이 나눠가지게 하는 것이다. 노드가 추가되거나 삭제 될 때, 파티션 단위로 이동시키는 것이다.\n이 방법은 간단하고, 빠르게 실행되지만, 파티션의 갯수가 고정되어 있어야 한다. (이론적으로는 변경이 가능하지만, 실제로는 어렵다.) 또 파티션 갯수에도 트레이드오프가 있어, 너무 많아지면 관리 오버헤드가 발생하고, 또 너무 적으면 증설이나 재배치가 필요한 경우 대응이 어렵다.\n동적 파티셔닝\n말 그대로 동적으로 파티션을 추가하는 방법이다. 특정 임계값을 넘어가면, 파티션을 추가하고, 데이터를 재배치하는 방법이다. 이 방법은 파티션의 갯수를 유연하게 관리할 수 있지만, 재배치가 빈번하게 일어나는 경우, 네트워크와 디스크 부하가 발생할 수 있다. 또 처음 시작할 때 하나의 파티션으로 시작해야 하기도 한다.(사전 분할 방식으로 보완하기도 한다)\n운영: 자동 재균형화와 수동 재균형화 자동은 편리하지만, 예기치 못한 일이 발생 할 수 있고, 수동은 더 많은 제어권을 가지지만, 더 많은 노력이 필요하다.\n요청 라우팅 병렬 요청을 보내지 않는 한, 파티션을 나눴으면 어디로 요청을 보내야할지 알아야 한다. 이를 위해 라우팅을 하는 방법중 몇가지 접근법이 있다.\n아무 노드나 선택 -\u0026gt; 해당 노드에 파티션이 있는지 확인 -\u0026gt; 없으면 올바른 노드를 지정해서 이동시킴 모든 요청을 라우팅 계층으로 보냄 -\u0026gt; 그리고 라우팅 계층에서 올바른 노드로 보냄 클라이언트가 이미 파티션을 알고 있도록 세가지 방법 모두 짐작가는 장단점이 있어 보인다. 다만 문제는 노드의 파티션 변경을 어떻게 알아야 하는지에 대한 문제가 있다.\n결론은 주키퍼 같은 코디네이터를 사용하는 것과, 특정 프로토콜을 통해 노드의 파티션 관련 정보를 서로 전파하는 것이다.\n","permalink":"http://localhost:1313/_wiki/6%EC%9E%A5/","summary":"파티셔닝 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고, 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라고 한다.\n데이터를 파티셔닝 하는 주된 이유는 확장성이다.\n파티셔닝과 복제 파티셔닝을 해도, 파티션 된 단위를 기준으로는 복제를 할 수 있다. 한 노드에 여러 파티션을 복제 할 수도 있어서, 노드 하나에 특정 파티션의 리더와 나머지 파티션의 복제를 가지는식으로 교차해 두기도 한다.\n키-값 데이터 파티셔닝 파티셔닝의 목적은 데이터와 질의 부하를 분산시키는 것이다. 이것이 달성되지 않았을 때 쏠렸다(skewed) 라고 한다.","title":"데이터 중심 어플리케이션 설계 6장"},{"content":"Rust-Redis-D4 Code 🥸 use crate::protocol_constants::{MAGIC_NUMBER, OPCODE_EOF, OPCODE_META, OPCODE_START_DB}; use crate::{Config, Db, ValueEntry}; use byteorder::{LittleEndian, ReadBytesExt}; use crc::{Crc, CRC_64_ECMA_182}; use std::fs::File; use std::io::{self, BufReader, Read, Seek, SeekFrom}; fn bytes_to_hex(bytes: \u0026amp;[u8]) -\u0026gt; String { bytes.iter().map(|b| format!(\u0026#34;{:02X}\u0026#34;, b)).collect::\u0026lt;Vec\u0026lt;String\u0026gt;\u0026gt;().join(\u0026#34; \u0026#34;) } fn read_length_or_integer\u0026lt;R: Read\u0026gt;(reader: \u0026amp;mut R, first_byte: u8) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { match first_byte \u0026gt;\u0026gt; 6 { 0b00 =\u0026gt; Ok((first_byte \u0026amp; 0x3F) as usize), 0b01 =\u0026gt; { let second_byte = reader.read_u8()?; Ok((((first_byte \u0026amp; 0x3F) as usize) \u0026lt;\u0026lt; 8) | (second_byte as usize)) } 0b10 =\u0026gt; reader.read_u32::\u0026lt;LittleEndian\u0026gt;().map(|len| len as usize), 0b11 =\u0026gt; match first_byte \u0026amp; 0x3F { 0 =\u0026gt; Ok(reader.read_u8()? as usize), 1 =\u0026gt; Ok(reader.read_u16::\u0026lt;LittleEndian\u0026gt;()? as usize), 2 =\u0026gt; Ok(reader.read_u32::\u0026lt;LittleEndian\u0026gt;()? as usize), _ =\u0026gt; Err(io::Error::new(io::ErrorKind::InvalidData, \u0026#34;Unsupported encoding type\u0026#34;)), }, _ =\u0026gt; Err(io::Error::new(io::ErrorKind::InvalidData, \u0026#34;Invalid length encoding\u0026#34;)), } } pub async fn run(db: Db, config: Config) -\u0026gt; io::Result\u0026lt;()\u0026gt; { let config_read = config.read().await; let dir = config_read.get(\u0026#34;dir\u0026#34;).cloned().unwrap_or_else(|| \u0026#34;\u0026#34;.to_string()); let db_file_name = config_read.get(\u0026#34;dbfilename\u0026#34;).cloned().unwrap_or_else(|| \u0026#34;\u0026#34;.to_string()); let mut path = \u0026#34;\u0026#34;.to_string(); if !dir.is_empty() \u0026amp;\u0026amp; !db_file_name.is_empty() { println!(\u0026#34;Initiating Redis with Data File\u0026#34;); path = format!(\u0026#34;{}/{}\u0026#34;, dir, db_file_name); } else { println!(\u0026#34;Initiating Redis without Data File\u0026#34;); return Ok(()); } let file = File::open(\u0026amp;path)?; let mut reader = BufReader::new(file); let mut magic = [0; 5]; reader.read_exact(\u0026amp;mut magic)?; if \u0026amp;magic != MAGIC_NUMBER { eprintln!(\u0026#34;Invalid RDB file format.\u0026#34;); return Ok(()); } println!(\u0026#34;Valid Redis RDB file detected.\u0026#34;); let mut version = [0; 4]; reader.read_exact(\u0026amp;mut version)?; println!(\u0026#34;RDB Version: {}\u0026#34;, String::from_utf8_lossy(\u0026amp;version)); loop { let mut marker = [0; 1]; if reader.read_exact(\u0026amp;mut marker).is_err() { println!(\u0026#34;Reached the end of file.\u0026#34;); break; } match marker[0] { OPCODE_META =\u0026gt; { let first_key_byte = reader.read_u8()?; let key_length = read_length_or_integer(\u0026amp;mut reader, first_key_byte)?; let mut key_bytes = vec![0; key_length]; reader.read_exact(\u0026amp;mut key_bytes)?; let key = String::from_utf8_lossy(\u0026amp;key_bytes); println!(\u0026#34;Metadata key: {}\u0026#34;, key); let first_value_byte = reader.read_u8()?; if first_value_byte \u0026gt;\u0026gt; 6 == 0b11 { let value = read_length_or_integer(\u0026amp;mut reader, first_value_byte)?; println!(\u0026#34;Metadata value : {}\u0026#34;, value); } else { let value_length = read_length_or_integer(\u0026amp;mut reader, first_value_byte)?; let mut value_bytes = vec![0; value_length]; reader.read_exact(\u0026amp;mut value_bytes)?; match String::from_utf8(value_bytes.clone()) { Ok(value) =\u0026gt; println!(\u0026#34;Metadata value: {}\u0026#34;, value), Err(_) =\u0026gt; { let hex_value = bytes_to_hex(\u0026amp;value_bytes); println!(\u0026#34;Invalid UTF-8 in metadata value, raw HEX bytes: {}\u0026#34;, hex_value); } } } continue; } OPCODE_START_DB =\u0026gt; { println!(\u0026#34;Detected start of new database.\u0026#34;); let db_index = reader.read_u8()?; println!(\u0026#34;Database index: {}\u0026#34;, db_index); continue; } 0xFB =\u0026gt; { println!(\u0026#34;Resizedb field detected.\u0026#34;); let total_size = reader.read_u8()?; let expires_size = reader.read_u8()?; println!(\u0026#34;Hash table size: {}, Expires table size: {}\u0026#34;, total_size, expires_size); continue; } 0xFD | 0xFC =\u0026gt; { let expiry_type = if marker[0] == 0xFD { \u0026#34;seconds\u0026#34; } else { \u0026#34;milliseconds\u0026#34; }; let expiration = if expiry_type == \u0026#34;seconds\u0026#34; { Some(reader.read_u32::\u0026lt;LittleEndian\u0026gt;()? as u64) } else { Some(reader.read_u64::\u0026lt;LittleEndian\u0026gt;()?) }; let value_type = reader.read_u8()?; println!(\u0026#34;Value type ::::: {}\u0026#34;, value_type); let key_length = reader.read_u8()? as usize; let mut key = vec![0; key_length]; reader.read_exact(\u0026amp;mut key)?; let key_str = String::from_utf8_lossy(\u0026amp;key).to_string(); let value_length = reader.read_u8()? as usize; let mut value = vec![0; value_length]; reader.read_exact(\u0026amp;mut value)?; let value_str = String::from_utf8_lossy(\u0026amp;value).to_string(); let entry = ValueEntry::new( value_str.clone(), if marker[0] == 0xFD { expiration } else { None }, if marker[0] == 0xFC { expiration } else { None }, ); db.write().await.insert(key_str.clone(), entry); println!(\u0026#34;Inserted key: {} with value: {}\u0026#34;, key_str, value_str); continue; } 0x00 =\u0026gt; { println!(\u0026#34;Processing key-value pair without expiration.\u0026#34;); let key_length = reader.read_u8()? as usize; let mut key = vec![0; key_length]; reader.read_exact(\u0026amp;mut key)?; let key_str = String::from_utf8_lossy(\u0026amp;key).to_string(); let value_length = reader.read_u8()? as usize; let mut value = vec![0; value_length]; reader.read_exact(\u0026amp;mut value)?; let value_str = String::from_utf8_lossy(\u0026amp;value).to_string(); let entry = ValueEntry::new(value_str.clone(), None, None); db.write().await.insert(key_str.clone(), entry); println!(\u0026#34;Inserted key: {} with value: {}\u0026#34;, key_str, value_str); } OPCODE_EOF =\u0026gt; { println!(\u0026#34;Reached end of RDB file.\u0026#34;); let mut checksum_bytes = [0; 8]; reader.read_exact(\u0026amp;mut checksum_bytes)?; let read_checksum = u64::from_le_bytes(checksum_bytes); println!(\u0026#34;Read checksum (Little-Endian): {:X}\u0026#34;, read_checksum); reader.seek(SeekFrom::Start(0))?; let mut buffer = Vec::new(); reader.read_to_end(\u0026amp;mut buffer)?; let data_to_hash = \u0026amp;buffer[..buffer.len() - 8]; println!(\u0026#34;Data length for checksum calculation: {}\u0026#34;, data_to_hash.len()); println!(\u0026#34;Data (first 64 bytes for check): {}\u0026#34;, bytes_to_hex(\u0026amp;data_to_hash[..64.min(data_to_hash.len())])); let crc = Crc::\u0026lt;u64\u0026gt;::new(\u0026amp;CRC_64_ECMA_182); let calculated_checksum = crc.checksum(data_to_hash); println!(\u0026#34;Calculated checksum: {:X}\u0026#34;, calculated_checksum); if calculated_checksum == read_checksum { println!(\u0026#34;Checksum valid.\u0026#34;); } else { eprintln!(\u0026#34;Checksum invalid! Expected: {:X}, Got: {:X}\u0026#34;, read_checksum, calculated_checksum); } break; } _ =\u0026gt; { eprintln!(\u0026#34;Unknown or unsupported marker: 0x{:02X}\u0026#34;, marker[0]); break; } } } Ok(()) } 일단 레포를 따로 올릴 수 있다는걸 알아서 주요한 부분만 올려놓았다. 오래걸리긴 했는데, 그게 내가 스테이지과제가 저rdb(redis database) 파일을 읽어야 하는 부분을 전부 구현해야 한다고 생각해서 그런 것 같다. 코드를 submit하니까 4단계가 clear 되어 뛰어넘었다. 말하는중에 생각이나서 조금 더 하고 와야겠다. ","permalink":"http://localhost:1313/_wiki/rust-redis-d4/","summary":"Rust-Redis-D4 Code 🥸 use crate::protocol_constants::{MAGIC_NUMBER, OPCODE_EOF, OPCODE_META, OPCODE_START_DB}; use crate::{Config, Db, ValueEntry}; use byteorder::{LittleEndian, ReadBytesExt}; use crc::{Crc, CRC_64_ECMA_182}; use std::fs::File; use std::io::{self, BufReader, Read, Seek, SeekFrom}; fn bytes_to_hex(bytes: \u0026amp;[u8]) -\u0026gt; String { bytes.iter().map(|b| format!(\u0026#34;{:02X}\u0026#34;, b)).collect::\u0026lt;Vec\u0026lt;String\u0026gt;\u0026gt;().join(\u0026#34; \u0026#34;) } fn read_length_or_integer\u0026lt;R: Read\u0026gt;(reader: \u0026amp;mut R, first_byte: u8) -\u0026gt; io::Result\u0026lt;usize\u0026gt; { match first_byte \u0026gt;\u0026gt; 6 { 0b00 =\u0026gt; Ok((first_byte \u0026amp; 0x3F) as usize), 0b01 =\u0026gt; { let second_byte = reader.read_u8()?; Ok((((first_byte \u0026amp; 0x3F) as usize) \u0026lt;\u0026lt; 8) | (second_byte as usize)) } 0b10 =\u0026gt; reader.","title":""},{"content":"Day 3 코드 command.rs\nuse crate::{Config, Db, ValueEntry}; use tokio::io::AsyncWriteExt; use tokio::net::TcpStream; pub enum Command { PING, ECHO(String), GET(String), SET { key: String, value: String, px: Option\u0026lt;u64\u0026gt;, ex: Option\u0026lt;u64\u0026gt; }, CONFIG(ConfigCommand), } pub enum ConfigCommand { GET(String), } impl Command { pub fn parse_message(message: \u0026amp;str) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { let mut lines = message.lines(); let first_line = lines.next().ok_or(\u0026#34;Argument Error : Empty message\u0026#34;)?; if first_line.starts_with(\u0026#39;*\u0026#39;) { let num_args: usize = first_line[1..].parse().map_err(|_| \u0026#34;Invalid array size\u0026#34;)?; let mut args = Vec::new(); for _ in 0..num_args { let bulk_len_line = lines.next().ok_or(\u0026#34;Missing bulk length\u0026#34;)?; if !bulk_len_line.starts_with(\u0026#39;$\u0026#39;) { return Err(\u0026#34;Invalid bulk string format\u0026#34;.into()); } let bulk_len: usize = bulk_len_line[1..].parse().map_err(|_| \u0026#34;Invalid bulk length\u0026#34;)?; let bulk_string = lines.next().ok_or(\u0026#34;Missing bulk string\u0026#34;)?; if bulk_string.len() != bulk_len { return Err(\u0026#34;Bulk string length mismatch\u0026#34;.into()); } args.push(bulk_string.to_string()); } if let Some(command_name) = args.get(0).map(|s| s.as_str()) { match command_name { \u0026#34;PING\u0026#34; =\u0026gt; Command::parse_ping(\u0026amp;args), \u0026#34;ECHO\u0026#34; =\u0026gt; Command::parse_echo(\u0026amp;args), \u0026#34;GET\u0026#34; =\u0026gt; Command::parse_get(\u0026amp;args), \u0026#34;SET\u0026#34; =\u0026gt; Command::parse_set(\u0026amp;args), \u0026#34;CONFIG\u0026#34; =\u0026gt; Command::parse_config(\u0026amp;args), _ =\u0026gt; Err(format!(\u0026#34;Unknown command: {}\u0026#34;, command_name)), } } else { Err(\u0026#34;Empty command\u0026#34;.into()) } } else { Err(\u0026#34;Unsupported protocol type\u0026#34;.into()) } } pub async fn handle_command(\u0026amp;self, stream: \u0026amp;mut TcpStream, db: Db, config: Config) -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { let response = self.execute(db, config).await; stream.write_all(response.as_bytes()).await?; Ok(()) } pub async fn execute(\u0026amp;self, db: Db, config: Config) -\u0026gt; String { match self { Command::PING =\u0026gt; \u0026#34;+PONG\\r\\n\u0026#34;.to_string(), Command::ECHO(echo_message) =\u0026gt; format!(\u0026#34;${}\\r\\n{}\\r\\n\u0026#34;, echo_message.len(), echo_message), Command::GET(key) =\u0026gt; Self::execute_get(\u0026amp;key, db).await, Command::SET { key, value, ex, px } =\u0026gt; Self::execute_set(key, value, *ex, *px, db).await, Command::CONFIG(command) =\u0026gt; Self::execute_config(command, config).await, } } async fn execute_get(key: \u0026amp;String, db: Db) -\u0026gt; String { match db.read().await.get(key) { Some(value_entry) =\u0026gt; { if value_entry.is_expired() { \u0026#34;$-1\\r\\n\u0026#34;.to_string() } else { format!(\u0026#34;${}\\r\\n{}\\r\\n\u0026#34;, value_entry.value.len(), value_entry.value.clone()) } } None =\u0026gt; \u0026#34;$-1\\r\\n\u0026#34;.to_string(), } } async fn execute_set(key: \u0026amp;String, value: \u0026amp;String, ex: Option\u0026lt;u64\u0026gt;, px: Option\u0026lt;u64\u0026gt;, db: Db) -\u0026gt; String { db.write().await.insert(key.clone(), ValueEntry::new(value.clone(), ex, px)); \u0026#34;+OK\\r\\n\u0026#34;.to_string() } async fn execute_config(command: \u0026amp;ConfigCommand, config: Config) -\u0026gt; String { match command { ConfigCommand::GET(key) =\u0026gt; { match config.read().await.get(key.as_str()) { Some(value) =\u0026gt; { format!(\u0026#34;*2\\r\\n${}\\r\\n{}\\r\\n${}\\r\\n{}\\r\\n\u0026#34;, key.len(), key, value.len(), value) } None =\u0026gt; \u0026#34;$-1\\r\\n\u0026#34;.to_string(), } } } } fn parse_ping(args: \u0026amp;[String]) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { if !(args.len() == 1) { return Err(\u0026#34;Argument Error : PING command takes no arguments\u0026#34;.into()); } Ok(Command::PING) } fn parse_echo(args: \u0026amp;[String]) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { if !(args.len() == 2) { return Err(\u0026#34;Argument Error : ECHO command takes only one argument\u0026#34;.into()); } Ok(Command::ECHO(args[1].clone())) } fn parse_get(args: \u0026amp;[String]) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { if !(args.len() == 2) { return Err(\u0026#34;Argument Error : GET command takes only one argument\u0026#34;.into()); } Ok(Command::GET(args[1].clone())) } fn parse_set(args: \u0026amp;[String]) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { if args.len() \u0026lt; 3 { return Err(\u0026#34;Argument Error : SET requires at least key value argument\u0026#34;.into()); } let key = args[1].clone(); let value = args[2].clone(); let mut ex = None; let mut px = None; let mut arg_index = 3; while arg_index \u0026lt; args.len() { match args[arg_index].to_uppercase().as_str() { \u0026#34;PX\u0026#34; =\u0026gt; { if arg_index + 1 \u0026lt; args.len() { px = Some(args[arg_index + 1].parse::\u0026lt;u64\u0026gt;().map_err(|_| \u0026#34;Argument Error : Invalid px value\u0026#34;)?); arg_index += 2; } else { return Err(\u0026#34;Argument Error : Px option argument err\u0026#34;.into()); } } \u0026#34;EX\u0026#34; =\u0026gt; { if arg_index + 1 \u0026lt; args.len() { ex = Some(args[arg_index + 1].parse::\u0026lt;u64\u0026gt;().map_err(|_| \u0026#34;Argument Error : Invalid ex value\u0026#34;)?); arg_index += 2; } else { return Err(\u0026#34;Argument Error : Ex option argument err\u0026#34;.into()); } } _ =\u0026gt; return Err(format!(\u0026#34;Argument Error: {} unknown option\u0026#34;, args[arg_index])) } } Ok(Command::SET { key, value, ex, px }) } fn parse_config(args: \u0026amp;[String]) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { match args[1].to_uppercase().as_str() { \u0026#34;GET\u0026#34; =\u0026gt; { Ok(Command::CONFIG(ConfigCommand::GET(args[2].clone()))) } _ =\u0026gt; Err(\u0026#34;Argument Error : Unsupported CONFIG subcommand!\u0026#34;.into()), } } } handler.rs\nuse crate::command::Command; use crate::{Config, Db}; use std::sync::Arc; use tokio::io::AsyncReadExt; use tokio::net::TcpStream; pub async fn handle_client(mut stream: TcpStream, db: Db, config: Config) { let mut buffer = [0; 512]; loop { buffer.fill(0); match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; { let message = match std::str::from_utf8(\u0026amp;buffer[..n]) { Ok(msg) =\u0026gt; msg, Err(_) =\u0026gt; { println!(\u0026#34;Failed to parse message as UTF-8\u0026#34;); continue; } }; println!(\u0026#34;Received message: {:?}\u0026#34;, message); match Command::parse_message(message) { Ok(command) =\u0026gt; { if let Err(e) = command.handle_command(\u0026amp;mut stream, Arc::clone(\u0026amp;db), Arc::clone(\u0026amp;config)).await { println!(\u0026#34;Failed to send response: {}\u0026#34;, e); } } Err(e) =\u0026gt; { println!(\u0026#34;Failed to parse command: {}\u0026#34;, e); } } } Err(e) =\u0026gt; { println!(\u0026#34;Error reading from stream: {}\u0026#34;, e); break; } } } } pub async fn handle_env(args: Vec\u0026lt;String\u0026gt;, config: Config) -\u0026gt; Result\u0026lt;(), String\u0026gt; { if args.len() \u0026lt;= 1 { println!(\u0026#34;No configuration arguments provided. Using default settings.\u0026#34;); return Ok(()); } let mut dir: Option\u0026lt;String\u0026gt; = None; let mut path_name: Option\u0026lt;String\u0026gt; = None; let mut arg_index = 1; while arg_index \u0026lt; args.len() { match args[arg_index].as_str() { \u0026#34;--dir\u0026#34; =\u0026gt; { if arg_index + 1 \u0026lt; args.len() { dir = Some(args[arg_index + 1].clone()); arg_index += 2; } else { return Err(\u0026#34;Argument Error: --dir option requires an argument\u0026#34;.into()); } } \u0026#34;--dbfilename\u0026#34; =\u0026gt; { if arg_index + 1 \u0026lt; args.len() { path_name = Some(args[arg_index + 1].clone()); arg_index += 2; } else { return Err(\u0026#34;Argument Error: --dbfilename option requires an argument\u0026#34;.into()); } } _ =\u0026gt; return Err(format!(\u0026#34;Argument Error: \u0026#39;{}\u0026#39; is an unknown option\u0026#34;, args[arg_index])), } } match (dir, path_name) { (Some(dir), Some(path_name)) =\u0026gt; { let mut config_guard = config.write().await; config_guard.insert(\u0026#34;dir\u0026#34;.to_string(), dir); config_guard.insert(\u0026#34;dbfilename\u0026#34;.to_string(), path_name); println!(\u0026#34;Environment configuration applied.\u0026#34;); } (None, None) =\u0026gt; { println!(\u0026#34;No configuration arguments provided. Using default settings.\u0026#34;); } _ =\u0026gt; { return Err(\u0026#34;Argument Error: Both --dir and --dbfilename must be provided together.\u0026#34;.into()); } } Ok(()) } value_entry.rs\nuse std::time::{Duration, Instant}; #[derive(Clone)] pub struct ValueEntry { pub(crate) value: String, expiration: Option\u0026lt;Instant\u0026gt;, } impl ValueEntry { pub fn new(value: String, ex: Option\u0026lt;u64\u0026gt;, px: Option\u0026lt;u64\u0026gt;) -\u0026gt; ValueEntry { let expiration = match (px, ex) { (Some(ms), _) =\u0026gt; Some(Instant::now() + Duration::from_millis(ms)), (_, Some(s)) =\u0026gt; Some(Instant::now() + Duration::from_secs(s)), _ =\u0026gt; None, }; ValueEntry { value, expiration } } pub fn is_expired(\u0026amp;self) -\u0026gt; bool { if let Some(expiration) = self.expiration { Instant::now() \u0026gt; expiration } else { false } } } main.rs\nmod command; mod value_entry; mod handler; use crate::handler::{handle_client, handle_env}; use crate::value_entry::ValueEntry; use std::collections::HashMap; use std::env; use std::sync::Arc; use tokio::net::TcpListener; use tokio::sync::RwLock; use tokio::task; type Db = Arc\u0026lt;RwLock\u0026lt;HashMap\u0026lt;String, ValueEntry\u0026gt;\u0026gt;\u0026gt;; type Config = Arc\u0026lt;RwLock\u0026lt;HashMap\u0026lt;String, String\u0026gt;\u0026gt;\u0026gt;; #[tokio::main] async fn main() { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); let db = Arc::new(RwLock::new(HashMap::new())); let config = Arc::new(RwLock::new(HashMap::new())); let args: Vec\u0026lt;String\u0026gt; = env::args().collect(); if let Err(e) = handle_env(args.clone(), Arc::clone(\u0026amp;config)).await { eprintln!(\u0026#34;Failed to handle environment configuration: {}\u0026#34;, e); return; } loop { match listener.accept().await { Ok((stream, _)) =\u0026gt; { let db_clone = Arc::clone(\u0026amp;db); let config_clone = Arc::clone(\u0026amp;config); task::spawn(async move { handle_client(stream, db_clone, config_clone).await; }); } Err(e) =\u0026gt; { println!(\u0026#34;Error accepting connection : {}\u0026#34;, e); } } } } Day 3 정리 최소한의 리팩토링을 하려고 했다. 정규식 부분을 싹 걷어내고, 일부 모듈을 분리했다. 작성하고 보니 Command쪽이 계속 비대해지고, parser 부분 로직이 충분히 분리할 수 있을 것 같다. enum을 조금 더 예쁘게 표현 할 수 있을 것 같다. (구조는 마음에 드는데 들고 다니는 데이터가 만족스럽지 않다.) 서브커맨드들이 많아지면 지금의 구조가 구릴 것 같다 특히 인덱스를 전진시키며 파싱하는 부분은 조금 더 잘 추상화해면 빼둘 수 있을 것 같다. ","permalink":"http://localhost:1313/_wiki/rust-redis-d3/","summary":"Day 3 코드 command.rs\nuse crate::{Config, Db, ValueEntry}; use tokio::io::AsyncWriteExt; use tokio::net::TcpStream; pub enum Command { PING, ECHO(String), GET(String), SET { key: String, value: String, px: Option\u0026lt;u64\u0026gt;, ex: Option\u0026lt;u64\u0026gt; }, CONFIG(ConfigCommand), } pub enum ConfigCommand { GET(String), } impl Command { pub fn parse_message(message: \u0026amp;str) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { let mut lines = message.lines(); let first_line = lines.next().ok_or(\u0026#34;Argument Error : Empty message\u0026#34;)?; if first_line.starts_with(\u0026#39;*\u0026#39;) { let num_args: usize = first_line[1..].parse().map_err(|_| \u0026#34;Invalid array size\u0026#34;)?","title":"Build Redis With Rust 🦀"},{"content":"About Part 2 저장소와 데이터 검색에 여러 장비가 관여한다면 어떻게 될까? 이번 장에서는 분산 데이터에 대해 다룬다.\n여러 장비가 필요한 이유\n확장성 : 부하를 분산시킬수 있다. 내결함성/고가용성 : 장애가 발생해도 시스템이 계속 동작할 수 있다. 지연시간 : 사용자 가까이 데이터를 분산시킬 수 있다. 공유 메모리 아키텍처, 공유 디스크 아키텍처\n많은 CPU, 메모리, 디스크를 하나의 운영체제로 합친다. 단순한 구조에 어느정도 내결함성을 가진다. 선형적이지 않은 비용증가, 제한적인 내결함성이 단점이다. 비공유 아키텍처\n각 장비를 노드로 분류하고, 각각의 컴퓨팅 자원을 독립적으로 사용한다. 노드간 통신을 위한 네트워크가 필요하며, 소프트웨어 레벨에서 coordination 한다. 훨씬 유연한 내결함성과, 나름 일관적인 비용증가가 장점이다.(디스크를 더 달기 위해서, RAM을 더 넣기 위해서 필요한 부가적인 하드웨어가 없을것이다) 물론 추가적인 복잡성이라는 단점이 있다. 데이터 분산은 주로 복제와 파티셔닝으로 이루어진다.\n복제 \u0026ldquo;복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미이다.\u0026rdquo; 복제가 필요한 이유는 다음과 같다. 첫 번째, 지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다. 두 번째, 내결함성을 높인다. 세 번째, 읽기 처리량을 높인다.\n참고로 이번장은 데이터셋이 작아서 모든 장비에 복제본 전부를 넣을 수 있는 상황을 가정한다. 이러한 제약조건은 주제를 단순화하고, 해당 개념에 집중할 수 있게 한다.\n복제가 진짜 어려운 이유는 데이터가 변경되기 때문이다. 그리고 그러한 어려움을 해결하기 위해 이번장에서는 가장 인기있는 세가지 알고리즘을 다룬다.(single-leader, multi-leader, leaderless)\n리더와 팔로워 데이터베이스의 복사본을 저장하는 각 노드를 replica라고 한다. 그리고 다중 복제 서버를 사용할 때, 가장 중요한 문제와 맞닥뜨리게 된다.\n\u0026ldquo;모든 복제 서버에 모든 데이터가 있다는 것을 어떻게 보장할 수 있을까?\u0026rdquo;\n가장 먼저 생각해야 할 것은, 모든 쓰기는 모든 복제 서버에 각각 적용되어야 한다는 것이다. 이걸 달성하기 위해 리더와 팔로워라는 개념을 사용한다. (복제 서버중 하나를 리더로 지정, 리더에만 쓰기를 허용하고, 리더는 팔로워에게 본인의 쓰기 로그 또는 변경 스트림을 전달한다.)\n동기식 복제와 비동기식 복제 복제는 동기식과 비동기식으로 나뉘어지고, 대부분의 rdb에서 설정 할 수 있다. 동기식은 리더가 보낸 스트림 또는 쓰기로그의 처리가 완료된걸 확인하고 응답을 보내는 방식이고, 비동기식은 전송을 하고 쓰기 완료는 따로 확인하지 않는 방식이다.\n리더 기반의 복제는 보통 반동기식, 혹은 비동기식으로 구성한다. (현실적으로 모든 복제를 동기식으로 처리하는건 불가능하다. 왜냐하면 네트워크 지연이나 장애로 인해 리더가 쓰기를 처리하지 못할 수 있기 때문이다.)\n새로운 팔로워 설정 새로운 팔로워를 설정할 때 도 데이터가 지금 변경되고 있는중이라는 것이 중요하다. 데이터베이스를 잠궈서 새로운 팔로워를 설정하는건, 고가용성이라는 목표에 반대되는 행동이다. 그래서 새로운 팔로워설정은 아래와 같은 방식으로 이루어진다.\n리더의 스냅샷을 가져온다. 스냅샷을 복사 완료 한 이후 리더의 변경 스트림을 이어받는다. 어디서부터 이어받을지는 로그 일련번호나 이진로그 좌표등으로 결정한다. 이어받은 이후 변경 스트림을 적용받는다. 노드 중단처리 팔로워의 중단처리\n중단 지점의 트랜잭션을 알아내고, 팔로워는 중단 지점 이후의 변경 스트림을 요청한다. 리더의 중단처리\n리더가 중단되면 중단을 감지한다(대부분 그냥 타임아웃 설정) 새로운 리더를 선출한다.(보통은 팔로워중 가장 높은 로그번호를 가진 노드를 선출하는데, 이 경합에 대해서는 9장에서.) 새로운 리더 사용을 위해 시스템을 재설정한다.(라우팅, 새로운 리더로부터 변경 스트림을 받기 등) 문제는 다음과 같은 복구과정을 거쳐도 잘못될 수 있는것 투성이라는 것이다.\n비동기식 복제 상황에서 이전 리더가 실패하기 전에 이전 리더의 쓰기를 일부 수신하지 못할 수 있다. 그리고 만약 이전 리더가 복구될 때 충돌이 발생할 수 있다. 만약 특정 구간 쓰기를 폐기한다면 내구성에 심각한 의문이 제기된다 예전에 잘못된 노드가 리더로 승격되었고, db의 기본키를 레디스에서 사용해서, 뒤쳐진 리더가 기본키를 중복으로 사용하고 그대로 일부 정보가 레디스를 통해 노출되었던 사례가 있다.\n스플릿 브레인 문제가 발생할 수 있다. (리더가 여러개 생기는 문제) 타임아웃도 까다로운 문제이다. (네트워크 지연이나 장애로 인해 리더가 쓰기를 처리하지 못할 수 있기 때문이다.) 복제 로그 구현 구문 기반 복제\n가장 간단한 방법으로 요청 statement를 기반으로 한다. 팔로워도 저걸 전달받아서 실행하면 된다. 문제는 복제가 깨질 수 있는 여러 사례가 있다는 것이다.\nNOW(), RAND() 같은 함수를 사용하면 리더와 팔로워의 결과가 다를 수 있다. 자동증가 칼럼, 혹은 데이터베이스의 데이터를 의존하는 경우 부수효과 (트리거, 스토어드 프로시저, 사용자 정의 함수) 물론 간편하기 때문에 위의 문제들을 적절히 보완하고 사용하는 경우도 있다.\n쓰기 전 로그 배송\n3장에서 본 것처럼, 모든 쓰기는 로그에 남는다. 그리고 이 로그를 팔로워에게 전달하면 된다.\n문제는 제일 저수준에서 기록된다는 것이고, 특정 바이트를 변경했는지 수준으로 관리된다는 것이다. 그래서 엔진과 밀접하게 엮이고, 버전이 변경되거나 하는 엔진과 관련된 변경이 생길 때 문제가 발생할 수 있다는 것이다. (실제로 리더와 팔로워의 소프트웨어 버전을 다르게 실행 할 수 없다.)\n논리적(로우기반) 로그 복제\n복제를 위한 별도의 로그를 만들어서 진행한다.\n삽입된 로우의 로그는 모든 칼럼의 값을 포함한다. 삭제된 로우의 로그는 로우를 식별하는 키를 포함한다.(기본키, 없으면 모든값 기록) 갱신된 로우는 고유값과 모든 칼럼의 새로운값을 포함한다. -- users 테이블 생성 CREATE TABLE users ( id INT PRIMARY KEY, name VARCHAR(50), age INT ); -- INSERT 예시 -- 원본 쿼리 INSERT INTO users (id, name, age) VALUES (1, \u0026#39;Alice\u0026#39;, 30); -- 복제 로그 INSERT LOG Table: users Columns: id, name, age Values: 1, \u0026#39;Alice\u0026#39;, 30 -- DELETE 예시 -- 원본 쿼리 DELETE FROM users WHERE id = 1; -- 복제 로그 DELETE LOG Table: users Condition: id = 1 -- UPDATE 예시 -- 원본 쿼리 UPDATE users SET age = 31 WHERE id = 1; -- 복제 로그 UPDATE LOG Table: users Columns: age Values: 31 Condition: id = 1 트리거 기반 복제\n어플리케이션에서 변경이 발생하면, 트리거가 발동되어 복제 로그를 생성한다고 한다. 요건 설명이 자세하지 않고 잘 사용되지 않는것같아서 생략한다. 복제 지연 문제 지금까지 설명한 내용은 확장성이나, 지연시간 측면에서 매우 유용하게 사용될 수 있다. 특히 읽기 비중이 높은 웹환경에서 매우 유용한 옵션이다. 하지만 대부분은 비동기적인 복제를 사용하고, 이 방식은 복제 지연 문제를 가지고 있다.\n자신이 쓴 내용 읽기\n리더한테 쓰고, 가까운 팔로워 노드한테 읽는다고 했을 때 발생 할 수 있다. 이것 때문에 쓰기 후 읽기 일관성을 지키기 위해서 여러가지 방법이 쓰인다.\n논리적인 규칙을 통해서 (사용자의 프로필은 리더에서 읽고, 다른 사용자의 프로필은 팔로워에서 읽는다) 특정한 기준으로 (최근 5분 이내의 데이터는 리더에서 읽는다) 클라이언트에 기억된 타임스탬프를 통해서(리더에 쓰고, 팔로워에 읽을 때 타임스탬프를 비교해서 읽는다) 단조 읽기\n두번째 이슈는 시간이 거꾸로 흐르는 현상을 클라이언트가 볼 수 있다는 것이다. (더 빠른 팔로워에서 읽고, 다음 요청이 느린 팔로워에서 읽는다면, 특정 데이터가 이전 요청에는 포함이 되었지만, 다음 요청에는 포함이 안될 수 있다.) 단조 읽기는 이러한 문제를 해결하는 것인데, 새로운 데이터를 읽은 이후에는 이전 데이터를 읽지 않는다는 것이다.\n가장 쉽게 달성하는 법은 한 사용자가 계속 같은 팔로워를 사용하게 하는 것이다.(다른 사용자는 다른 팔로워를 사용해도 된다.)\n일관된 순서로 읽기\n사실 이건 뒤에서 더 자세히 나올 것 같은게 파티션에 의해 발생하는 문제이다.\n\u0026ldquo;네\u0026rdquo; \u0026ldquo;당신은 미래를 볼 수 있나요?\u0026rdquo;\n다중 리더 복제 다중 리더 복제에 대한 니즈도 당연히 존재한다. 쓰기 요청에 대한 내결함성 등 여러가지 사유가 있을 수 있다.\n다중 리더 복제의 사용 사례 다중 데이터 센터 운영\n일단 복잡도는 굉장히 많이 올라간다. 하지만 성능(쓰기를 위해 리더에게 가야만 하는 시간), 내결함성(리더가 죽어도 다른 리더가 있어서 쓰기를 계속할 수 있다.), 등의 이점이 있다.\n문제는 쓰기에 충돌이 발생할 여지가 많다는 것인데, auto increment key, unique key, trigger 등을 미묘하게 신경쓰며 관리해야 한다.\n클라이언트의 오프라인 작업\n클라이언트가 오프라인이 된 경우 디바이스의 저장소에 데이터를 보관하는데, 이러한 경우 다중 리더 복제의 \u0026lsquo;로직\u0026rsquo;을 적용할 수 있다. 다만 클라이언트 만큼 많은 리더와 믿을 수 없는 네트워크가 있는 만큼 매우 어렵고 복잡한 이슈이다.\n협업 편집\n노션이나 구글닥스를 생각하면 된다. 물론 다른 알고리즘이나 솔루션을 사용하지만, 몇몇부분은 다중 리더 복제와 비슷한 개념을 사용한다. 예를들어 충돌을 없애기 위해 lock을 걸수도 있지만, 사용성을 위해 락을 매우 쪼개고 충돌을 해결해주는 방식을 사용할 수도 있다.\n쓰기 충돌 다루기 동기 대 비동기 충돌 감지 동기식으로 할 수 있기는 하지만, 사실 의미가 없다(다중 쓰기가 무효화됨) 비동기식으로 풀 수 있는 여지는 없다\n충돌 회피 충돌을 회피하는 가장 간단한 전략이다. 그리고 이건 특히 레코드를 기준으로 쓰기를 나누면 회피를 할 수 있다. 물론 이와 같은 방식은 역할을 나누는 방식이기 때문에 내결함성에는 취약하다. (리더가 변경되는 상황이나, 리더가 고장나는 상황에 취약)\n일관된 상태 수렴 모든 복제 서버는 최종적으로 동일하다는 사실을 보장해야 한다 즉 중간에 데이터 반영의 속도차이때문에 다른 경우는 있을 수 있어도 최종적으로는 동일해야한다. 문제는 다중리더에서는 쓰기 순서가 정해지지 않아 최종적으로 동일하다는 것을 보장 할 수 없다.\n그래서 아래와 같은 방법을 둔다.\n각 쓰기에 고유ID를 부여하고, 해당 값이 가장 높은 경우를 반영한다. 각 복제 서버에 고유ID를 부여하고 낮은 숫자의 복제서버에서 생긴 쓰기보다 항상 우선적으로 선택한다. 명시적인 충돌 해소 로직을 애플리케이션 코드로 작성한다. 사용자 정의 충돌 해소 로직 여기서는 간단한 충돌로직을 언급하는데, 구체적이지 않다.\n충돌은 무엇인가? 마찬가지로 12장에서 설명할 내용을 소개하고 간단하게 갈무리한다.\n다중 리더 복제 토폴로지 복제 토폴로지는 쓰기를 한 노드에서 다른 노드 전달하는 통신 경로를 설명한다. 이부분에서는 리더의 쓰기 요청이 다른 노드에 전달될 수 있도록 구성한 토폴로지를 설명한다. 그래프로 갈음 할 수 있는 별모양 토폴로지와, 복제의 순서를 지정 할 수 있는 원모양 토폴로지, 마지막으로 전체 연결 토폴로지이다.\n물론 여기서도 다양한 위험에 빠지게 된다(읽기 요청의 경우, 읽기는 직전 삽입에 종속적이다. 다만 그러한 것들이 충돌로 인식되지 못하고 진행되는 경우가 있고, 다양한 충돌이 발생한다.)\n리더 없는 복제 리더 없는 복제에서는 모두가 리더이다. 모든 노드가 쓰기 요청을 허락받는다 물론 그많은 충돌을 해결하는 것은 아니고, 클라이언트가 여러 복제서버에 쓰기를 직접 전송하거나 이러한일을 담당하는 코디네이터 노드를 두기도 한다.\n리더 없는 복제에서 노드가 다운됐을 때 데이터베이스에 쓰기 이러한 방식에서는, 노드 하나가 죽어도 상관이 없다. 클라이언트는 쓰기요청과 읽기 요청을 병렬로 보내기 때문이다. 죽어있던 기간에 생긴 누락된 데이터는 더 정확한 노드를 판별하여 알아서 사용한다.\n읽기 복구와 안티 엔트로피 물론 클라이언트는 문제가 없지만, 노드 입장에서는 다운타임동안 발생한 데이터를 따라잡아야 한다. 읽기 복구 : 클라이언트가 오래된 버전의 데이터를 감지하면, 해당 노드의 데이터를 직접 업데이트한다.(읽기 요청이 많아야 기능함) 안티 엔트로피 처리 : 별도의 백그라운드 프로세스가 계속 감시해준다..(짐작이 가능하듯 감지되어 쓰기가 되기 까지 매우 오래걸릴 수 있다.)\n개인적으로 여기도 \u0026lsquo;최종적으로 동일하다는 사실을 보장한다\u0026rsquo;고 봐야하는지 의문이 든다.\n읽기와 쓰기를 위한 정족수\n어느 범위까지 유효한 쓰기이고, 유효한 읽기로 간주 할 수 있을까?\nn : 복제 노드의 수 w : 쓰기 성공 카운트 r : 질의하는 노드의 수\nw + r \u0026gt; n 이면 보통은 최신 데이터를 읽을 것 이라고 간주한다.\n위의 값들은 파라미터로 각각 설정이 가능한데, 일반적인 선택은 w = r = (n + 1)/2 이다.\n동시 쓰기 감지 일단 다이나모 스타일 데이터베이스도 여러 클라이언트가 동시에 같은 키를 쓰는것을 허용하기에 정족수를 엄격하게 조절해도 충돌이 발생한다.\n당장 네트워크 상황만 생각해봐도 클라이언트 A, B가 동시에 세개의 노드로 X키를 기록하는 상황을 생각해볼 수 있다.\n노드1, 2 번이 각각 다른 순서로 A,B의 요청을 받을 수 있기에 충돌을 감지해야 한다.\n최종 쓰기 승리(동시 쓰기 버리기) 첫번째 접근 방식은 각 복제본이 가진 예전 값을 버리가 가장 최신 값으로 덮어쓰는 것이다. 어떤 쓰기가 최신인지 명확하게 결정할 수 있어야 한다. 문제는 클라이언트의 상태가 없는 노드의 입장에서 어떠한 값이 최신인지 식별할 방법은 사실상 없고, 이 순서가 정해지지 않았다고 생각해야 하니까 결국 동시 쓰리가로 해야한다. 결국 타임스탬프같은 값들을 기준으로 최종 승리 쓰기를 기술한다.\n(이건 지속성을 침해하므로 사실 키로 UUID를 사용해서 모든 쓰기 작업에 고유키를 부여하는 방식이 일반적이다)\n이전 발생 관계와 동시성 이건 충돌을 완벽하게 해결하는 방식은 아니고, 이전 발생을 식별하는 경우 처리를 단순화 하는 것에 가깝다. 예를들어 A라는 값을 생성하는 쓰기와, 해당 값을 변경하는 쓰기처럼 인과성이 있는 경우 이전 작업을 식별 할 수 있어 별도의 충돌 해결이 필요 없다.\n이전 발생 관계 파악하기\n","permalink":"http://localhost:1313/_wiki/5%EC%9E%A5/","summary":"About Part 2 저장소와 데이터 검색에 여러 장비가 관여한다면 어떻게 될까? 이번 장에서는 분산 데이터에 대해 다룬다.\n여러 장비가 필요한 이유\n확장성 : 부하를 분산시킬수 있다. 내결함성/고가용성 : 장애가 발생해도 시스템이 계속 동작할 수 있다. 지연시간 : 사용자 가까이 데이터를 분산시킬 수 있다. 공유 메모리 아키텍처, 공유 디스크 아키텍처\n많은 CPU, 메모리, 디스크를 하나의 운영체제로 합친다. 단순한 구조에 어느정도 내결함성을 가진다. 선형적이지 않은 비용증가, 제한적인 내결함성이 단점이다. 비공유 아키텍처\n각 장비를 노드로 분류하고, 각각의 컴퓨팅 자원을 독립적으로 사용한다.","title":"데이터 중심 애플리케이션 설계 5장"},{"content":"1. Code use regex::Regex; use std::collections::HashMap; use std::sync::Arc; use tokio::io::{AsyncReadExt, AsyncWriteExt}; use tokio::net::{TcpListener, TcpStream}; use tokio::sync::RwLock; use tokio::task; type Db = Arc\u0026lt;RwLock\u0026lt;HashMap\u0026lt;String, String\u0026gt;\u0026gt;\u0026gt;; enum Command { PING, ECHO(String), GET(String), SET(String, String), } impl Command { fn parse_message(message: \u0026amp;str) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { let re_ping = Regex::new(r\u0026#34;^\\*1\\r\\n\\$4\\r\\nPING\\r\\n$\u0026#34;).unwrap(); let re_echo = Regex::new(r\u0026#34;^\\*2\\r\\n\\$4\\r\\nECHO\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); let re_get = Regex::new(r\u0026#34;^\\*2\\r\\n\\$3\\r\\nGET\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); let re_set = Regex::new(r\u0026#34;^\\*3\\r\\n\\$3\\r\\nSET\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); if re_ping.is_match(message) { Ok(Command::PING) } else if let Some(captures) = re_echo.captures(message) { let length: usize = captures[1].parse().unwrap_or(0); let echo_message = \u0026amp;captures[2]; if echo_message.len() == length { Ok(Command::ECHO(echo_message.to_string())) } else { Err(\u0026#34;Invalid ECHO command format: length mismatch\u0026#34;.to_string()) } } else if let Some(captures) = re_get.captures(message) { let key = captures[2].to_string(); Ok(Command::GET(key)) } else if let Some(captures) = re_set.captures(message) { let key = captures[2].to_string(); let value = captures[4].to_string(); Ok(Command::SET(key, value)) } else { Err(\u0026#34;Unknown command\u0026#34;.to_string()) } } async fn handle_command(\u0026amp;self, stream: \u0026amp;mut TcpStream, db: Db) -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { let response = self.execute(db).await; stream.write_all(response.as_bytes()).await?; Ok(()) } async fn execute(\u0026amp;self, db: Db) -\u0026gt; String { match self { Command::PING =\u0026gt; \u0026#34;+PONG\\r\\n\u0026#34;.to_string(), Command::ECHO(echo_message) =\u0026gt; format!(\u0026#34;${}\\r\\n{}\\r\\n\u0026#34;, echo_message.len(), echo_message), Command::GET(key) =\u0026gt; Self::execute_get(\u0026amp;key, db).await, Command::SET(key, value) =\u0026gt; Self::execute_set(key, value, db).await, } } async fn execute_get(key: \u0026amp;String, db: Db) -\u0026gt; String { match db.read().await.get(key) { Some(value) =\u0026gt; format!(\u0026#34;${}\\r\\n{}\\r\\n\u0026#34;, value.len(), value), None =\u0026gt; \u0026#34;$-1\\r\\n\u0026#34;.to_string() } } async fn execute_set(key: \u0026amp;String, value: \u0026amp;String, db: Db) -\u0026gt; String { db.write().await.insert(key.clone(), value.clone()); \u0026#34;+OK\\r\\n\u0026#34;.to_string() } } #[tokio::main] async fn main() { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); let db = Arc::new(RwLock::new(HashMap::new())); loop { match listener.accept().await { Ok((stream, _)) =\u0026gt; { let db_clone = Arc::clone(\u0026amp;db); task::spawn(async move { handle_client(stream, db_clone).await; }); } Err(e) =\u0026gt; { println!(\u0026#34;Error accepting connection : {}\u0026#34;, e); } } } } async fn handle_client(mut stream: TcpStream, db: Db) { let mut buffer = [0; 512]; loop { buffer.fill(0); match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; { let message = match std::str::from_utf8(\u0026amp;buffer[..n]) { Ok(msg) =\u0026gt; msg, Err(_) =\u0026gt; { println!(\u0026#34;Failed to parse message as UTF-8\u0026#34;); continue; } }; println!(\u0026#34;Received message: {:?}\u0026#34;, message); match Command::parse_message(message) { Ok(command) =\u0026gt; { if let Err(e) = command.handle_command(\u0026amp;mut stream, Arc::clone(\u0026amp;db)).await { println!(\u0026#34;Failed to send response: {}\u0026#34;, e); } } Err(e) =\u0026gt; { println!(\u0026#34;Failed to parse command: {}\u0026#34;, e); } } } Err(e) =\u0026gt; { println!(\u0026#34;Error reading from stream: {}\u0026#34;, e); break; } } } } 2. Review 정말 간단한 리팩토링을 진행했다, 정말 보기 싫은 것들만 정리했고, 모듈 분리는 일단 계속 해보다가 할 것 같다.(포스팅 하기 편하고, 사이트에서 리뷰받기가 수월한 것 같다) Tokio의 RwLock을 사용했는데, 이것은 Mutex와 비슷하지만 읽기 전용 락을 여러 스레드가 가질 수 있다. 그리고 SET, GET을 추가했다. 명령을 파싱하는 부분이 정규식 쓰는것도 그렇고 너무 마음에 안들고 더럽다, 레디스 프로토콜이 있다는걸 생각하면 좋은 방법이 있을것같아서 생각해봐야겠다. 생각해본 절차는 명령어를 먼저 뽑고, 그 다음을 프로토콜대로 파싱하면 key-val 혹은 match하는 구조로 만들 수 있을 것 같다. 일단 빨리 프로토콜을 봐야지.. ","permalink":"http://localhost:1313/_wiki/rust-redis-d2/","summary":"1. Code use regex::Regex; use std::collections::HashMap; use std::sync::Arc; use tokio::io::{AsyncReadExt, AsyncWriteExt}; use tokio::net::{TcpListener, TcpStream}; use tokio::sync::RwLock; use tokio::task; type Db = Arc\u0026lt;RwLock\u0026lt;HashMap\u0026lt;String, String\u0026gt;\u0026gt;\u0026gt;; enum Command { PING, ECHO(String), GET(String), SET(String, String), } impl Command { fn parse_message(message: \u0026amp;str) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { let re_ping = Regex::new(r\u0026#34;^\\*1\\r\\n\\$4\\r\\nPING\\r\\n$\u0026#34;).unwrap(); let re_echo = Regex::new(r\u0026#34;^\\*2\\r\\n\\$4\\r\\nECHO\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); let re_get = Regex::new(r\u0026#34;^\\*2\\r\\n\\$3\\r\\nGET\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); let re_set = Regex::new(r\u0026#34;^\\*3\\r\\n\\$3\\r\\nSET\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); if re_ping.is_match(message) { Ok(Command::PING) } else if let Some(captures) = re_echo.captures(message) { let length: usize = captures[1].","title":"Rust-Redis-D2"},{"content":"0. PreRequisite 해당 문서의 참고입니다! https://app.codecrafters.io/concepts/rust-tcp-server\nstd::net 모듈은 TCP 서버를 만들기 위한 모듈이다. 그리고 아래의 다섯가지 메셔드를 주요하게 이용한다. TcpListener::bind : pub fn bind\u0026lt;A: ToSocketAddrs\u0026gt;(addr: A) -\u0026gt; Result\u0026lt;TcpListener\u0026gt; - 주어진 주소에 바인딩된 새로운 TcpListener 인스턴스를 반환한다 TcpListener::incoming : pub fn incoming(\u0026amp;self) -\u0026gt; Incoming - 이 리스너로 들어오는 coneection에 대한 iterator를 반환한다. TcpStream::connect : pub fn connect\u0026lt;A: ToSocketAddrs\u0026gt;(addr: A) -\u0026gt; Result\u0026lt;TcpStream\u0026gt; - 주어진 주소로 연결된 새로운 TcpStream 인스턴스를 반환한다. TcpStream::read : pub fn read(\u0026amp;mut self, buf: \u0026amp;mut [u8]) -\u0026gt; Result\u0026lt;usize\u0026gt; - 스트림에서 데이터를 읽어서 주어진 버퍼에 저장한다. TcpStream::write_all : pub fn write_all(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; Result\u0026lt;()\u0026gt; - 스트림에 주어진 버퍼의 모든 데이터를 쓴다. TcpLister Struct는 아래와 같이 구성되어 있다.\nimpl TcpListener { // accept는 대기 중인 연결을 수락하고, connection을 반환한다. pub fn accept(\u0026amp;self) -\u0026gt; Result\u0026lt;(TcpStream, SocketAddr)\u0026gt;; // incoming은 이 listener로 들어오는 connection에 대한 iterator를 반환한다. pub fn incoming(\u0026amp;self) -\u0026gt; Incoming\u0026lt;TcpStream\u0026gt;; // local_addr는 이 listener가 바인딩된 주소를 반환한다. pub fn local_addr(\u0026amp;self) -\u0026gt; Result\u0026lt;SocketAddr\u0026gt;; } TcpStream Struct는 아래와 같이 구성되어 있다.\nimpl TcpStream { pub fn read(\u0026amp;mut self, buf: \u0026amp;mut [u8]) -\u0026gt; Result\u0026lt;usize\u0026gt;; pub fn write(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; Result\u0026lt;usize\u0026gt;; pub fn write_all(\u0026amp;mut self, buf: \u0026amp;[u8]) -\u0026gt; Result\u0026lt;()\u0026gt;; } 참고하자면, write_all은 아래처럼 버퍼의 모든 데이터를 쓰는걸 보장해주기 때문에, 간단하게 사용할 수 있다.\nfn write_all(\u0026amp;mut self, mut buf: \u0026amp;[u8]) -\u0026gt; io::Result\u0026lt;()\u0026gt; { while !buf.is_empty() { match self.write(buf) { Ok(0) =\u0026gt; { return Err(io::Error::new( io::ErrorKind::WriteZero, \u0026#34;failed to write whole buffer\u0026#34;, )); } Ok(n) =\u0026gt; buf = \u0026amp;buf[n..], Err(ref e) if e.kind() == io::ErrorKind::Interrupted =\u0026gt; {} Err(e) =\u0026gt; return Err(e), } } Ok(()) } fn handle_client(mut stream: TcpStream) { let mut buffer = [0; 512]; loop { let byte_read = stream.read(\u0026amp;mut buffer).expect(\u0026#34;Failed to read\u0026#34;); if byte_read == 0 { return; } stream.write_all(\u0026amp;buffer[0..byte_read]).expect(\u0026#34;Feil to write\u0026#34;); } } fn main() { let listener = TcpListener::bind(\u0026#34;localhost:8080\u0026#34;).expect(\u0026#34;Could not bind\u0026#34;); for stream in listener.incoming() { match stream { Ok(stream) =\u0026gt; { handle_client(stream); } Err(e) =\u0026gt; { eprintln!(\u0026#34;Failed: {}\u0026#34;, e); } } } } 참고 : 한번에 하나의 커넥션만 처리가 가능하고, 다른 커넥션은 blocked된다.\n1. Day 1 Code Day 1에서는 기본적인 TcbServer 바인딩과, 메세지를 읽어서 다시 클라이언트에게 보내는 기능을 구현한다.\nuse regex::Regex; use tokio::io::{AsyncReadExt, AsyncWriteExt}; use tokio::net::{TcpListener, TcpStream}; use tokio::task; enum Command { PING, ECHO(String), } #[tokio::main] async fn main() { let listener = TcpListener::bind(\u0026#34;127.0.0.1:6379\u0026#34;).await.unwrap(); loop { match listener.accept().await { Ok((stream, _)) =\u0026gt; { task::spawn(async move { handle_client(stream).await; }); } Err(e) =\u0026gt; { println!(\u0026#34;Error accepting connection : {}\u0026#34;, e); } } } } async fn handle_client(mut stream: TcpStream) { let mut buffer = [0; 512]; loop { buffer.fill(0); match stream.read(\u0026amp;mut buffer).await { Ok(0) =\u0026gt; break, Ok(n) =\u0026gt; { let message = match std::str::from_utf8(\u0026amp;buffer[..n]) { Ok(msg) =\u0026gt; msg, Err(_) =\u0026gt; { println!(\u0026#34;Failed to parse message as UTF-8\u0026#34;); continue; } }; println!(\u0026#34;Received message: {:?}\u0026#34;, message); match parse_message(message) { Ok(command) =\u0026gt; { if let Err(e) = handle_command(command, \u0026amp;mut stream).await { println!(\u0026#34;Failed to send response: {}\u0026#34;, e); } } Err(e) =\u0026gt; { println!(\u0026#34;Failed to parse command: {}\u0026#34;, e); } } } Err(e) =\u0026gt; { println!(\u0026#34;Error reading from stream: {}\u0026#34;, e); break; } } } } fn parse_message(message: \u0026amp;str) -\u0026gt; Result\u0026lt;Command, String\u0026gt; { let re_ping = Regex::new(r\u0026#34;^\\*1\\r\\n\\$4\\r\\nPING\\r\\n$\u0026#34;).unwrap(); let re_echo = Regex::new(r\u0026#34;^\\*2\\r\\n\\$4\\r\\nECHO\\r\\n\\$(\\d+)\\r\\n(.+)\\r\\n$\u0026#34;).unwrap(); if re_ping.is_match(message) { Ok(Command::PING) } else if let Some(captures) = re_echo.captures(message) { let length: usize = captures[1].parse().unwrap_or(0); let echo_message = \u0026amp;captures[2]; if echo_message.len() == length { Ok(Command::ECHO(echo_message.to_string())) } else { Err(\u0026#34;Invalid ECHO command format: length mismatch\u0026#34;.to_string()) } } else { Err(\u0026#34;Unknown command\u0026#34;.to_string()) } } async fn handle_command(command: Command, stream: \u0026amp;mut TcpStream) -\u0026gt; std::io::Result\u0026lt;()\u0026gt; { match command { Command::PING =\u0026gt; { stream.write_all(b\u0026#34;+PONG\\r\\n\u0026#34;).await?; } Command::ECHO(echo_message) =\u0026gt; { let response_message = format!(\u0026#34;${}\\r\\n{}\\r\\n\u0026#34;, echo_message.len(), echo_message); stream.write_all(response_message.as_bytes()).await?; } } Ok(()) } 2. Day 1 Review Trouble Shooting 먼저 tokio를 써도 되는지 모르고, std::net으로 비동기와 이벤트루프를 구현하려고 했다. 중간에 이게 맞나 싶어서 정답지를 봤는데, 다른사람들은 그냥 tokio 쓰더라.. 정규식은 어렵고 귀찮다 + 레디스 프로토콜을 모르고 비비려다가 더 고생했고, 정규식 부분은 그냥 검색해서 긁어왔다. ","permalink":"http://localhost:1313/_wiki/rust-redis-d1/","summary":"0. PreRequisite 해당 문서의 참고입니다! https://app.codecrafters.io/concepts/rust-tcp-server\nstd::net 모듈은 TCP 서버를 만들기 위한 모듈이다. 그리고 아래의 다섯가지 메셔드를 주요하게 이용한다. TcpListener::bind : pub fn bind\u0026lt;A: ToSocketAddrs\u0026gt;(addr: A) -\u0026gt; Result\u0026lt;TcpListener\u0026gt; - 주어진 주소에 바인딩된 새로운 TcpListener 인스턴스를 반환한다 TcpListener::incoming : pub fn incoming(\u0026amp;self) -\u0026gt; Incoming - 이 리스너로 들어오는 coneection에 대한 iterator를 반환한다. TcpStream::connect : pub fn connect\u0026lt;A: ToSocketAddrs\u0026gt;(addr: A) -\u0026gt; Result\u0026lt;TcpStream\u0026gt; - 주어진 주소로 연결된 새로운 TcpStream 인스턴스를 반환한다. TcpStream::read : pub fn read(\u0026amp;mut self, buf: \u0026amp;mut [u8]) -\u0026gt; Result\u0026lt;usize\u0026gt; - 스트림에서 데이터를 읽어서 주어진 버퍼에 저장한다.","title":"Rust-Redis-D1"},{"content":"Build Redis With Rust 🦀 이건 코드크래프터스 에서 진행하는 프로젝트를 따라하면서 작성한 문서입니다. 전적으로 제가 작성한 코드와 저의 생각만 포스팅을 할 예정입니다. 주요한 가이드는 직접 위 사이트에서 확인해주세요.\nGithub-Repo\nRedis-Protocol\n[[Rust-Redis-D1]]\n[[Rust-Redis-D2]]\n[[Rust-Redis-D3]]\n[[Rust-Redis-D4]]\nTrouble Shootings [[Redis-Handshake-For-Replicas]] : 레플리카(슬레이브) 등록을 위한 HandShake중 클라이언트를 식별하는 이슈 [[Redis-Stream-Issue]] ","permalink":"http://localhost:1313/_wiki/build-redis-with-rust/","summary":"Build Redis With Rust 🦀 이건 코드크래프터스 에서 진행하는 프로젝트를 따라하면서 작성한 문서입니다. 전적으로 제가 작성한 코드와 저의 생각만 포스팅을 할 예정입니다. 주요한 가이드는 직접 위 사이트에서 확인해주세요.\nGithub-Repo\nRedis-Protocol\n[[Rust-Redis-D1]]\n[[Rust-Redis-D2]]\n[[Rust-Redis-D3]]\n[[Rust-Redis-D4]]\nTrouble Shootings [[Redis-Handshake-For-Replicas]] : 레플리카(슬레이브) 등록을 위한 HandShake중 클라이언트를 식별하는 이슈 [[Redis-Stream-Issue]] ","title":"Build Redis With Rust 🦀"},{"content":"4장 부호화와 발전 어플리케이션의 변경과 변화에 대응하는 방법을 소개하는 장. 일단 먼저 대규모 어플리케이션 변화에 있어 장애물이 되는 부분은 크게 아래와같다.\n데이터타입이나 스키마가 변경되는 경우 서버측에서는 순회식 업그레이드를 진행한다. 클라이언트측 어플리케이션은 사용자에 전적으로 좌우된다. 어떤 사용자는 한동안 업그레이드를 하지 않을 수도 있다. 즉 예전버전의 코드와 새로운 버전의 코드, 이전의 데이터타입과 새로운 데이터타입 이 시스템에 공존 할 수 있다는 것이다. 그래서 시스템에는 양방향의 호환성이 필요하다.\n하위 호환성 : 새로운 코드는 이전 코드가 기록한 데이터를 읽을 수 있어야 한다. 상위 호환성 : 이전 코드는 새로운 코드가 기록한 데이터를 읽을 수 있어야 한다. 데이터 부호화 형식 데이터는 크게 두가지 형식으로 다뤄진다.\n메모리에서 : 데이터는 메모리 위에서 표현되며, CPU가 효율적으로 읽고 처리할 수 있도록 구조화되고 최적화된다. 디스크나 네트워크에서 : 데이터는 바이트 스트림으로 저장되며, 이는 다양한 시스템에서 호환되도록 한다. 그래서 이 두가지 형식에서 일련의 전환이 필요한데 그것을 부호화라고 한다. (일반적으로 직렬화라고 더 많이 하지만 트랜잭션에서 동일한 용어가 사용되어 부호화로 표현)\n언어별 부호화 형식 기본적으로 언어별로 부호화 하는 기능들이 존재한다. 다만 이러한 부호화 형식은 언어별로 다르기 때문에 서로 호환되지 않고, 보안 이슈가 발생 할 수 있으며, 특정 언어는 성능이슈도 있다 (Java의 직렬화) JSON, XML, 그리고 이진 변형 JSON, XML은 가장 많이 사용되는 부호화 형식이다. 싫어하는 사람만큼 좋아하는 사람도 많다. 텍스트 형식이기 때문에 사람이 어느 정도 읽을 수 있고, JSON같은경우는 사용처가 압도적으로 많으며 쉽다는 장점이 있다. 다만 아쉬운점도 여러가지가 있는데, 대표적으로 수와 숫자로 구성된 문자열을 구분 할 수 없으며, 부동소수점의 정확도가 떨어진다. 유니코드 문자열은 지원하지만, 이진 문자열은 지원하지 않는다. 이진 부호화 형식 이러한 단점을 보완하기 위해 이진 부호화 형식이 등장했다. { \u0026#34;userName\u0026#34;: \u0026#34;Martin\u0026#34;, \u0026#34;favoriteNumber\u0026#34;: 1337, \u0026#34;interests\u0026#34;: [\u0026#34;daydreaming\u0026#34;, \u0026#34;hacking\u0026#34;] } 위와 같은 JSON(81바이트)을 이진 부호화 형식으로 변환하면 아래와 같다. 03 A8 75 73 65 72 4E 61 6D 65 06 4D 61 72 74 69 6E 0D 66 61 76 6F 72 69 74 65 4E 75 6D 62 65 72 04 0D 간단하게 타입 정의로 데이터를 표현해서 15 바이트를 줄였다.\n스리프트와 프로토콜 버퍼 스리프트와 프로토컬 버퍼는 기본적으로 스키마를 정의한다.\nmessage Person { 1: required string userName; 2: optional i32 favoriteNumber; 3: repeated string interests; } 이 상태로 데이터를 직렬화 하는데, 방식이 두가지가 있다. (바이너리 프로토콜, 컴팩트 프로토콜)\n단순히 스키마를 기반으로 필드 이름을 태그로 표현해서 절약하는 방식.\n여기서 컴팩트 프로토콜은 필드태그나 숫자 데이터 형식까지 단일 바이트 가변길이 정수로 인코딩한다.\n필드 태그와 스키마 발전 그렇다면 스키마가 변경되는 경우에 어떻게 상위호환성과 하위호환성을 유지할 수 있을까? 결론은 문제가 없다. 부호화된 레코드는 부호화된 필드의 연결일 뿐이다. 새로운 필드가 추가되면 이전 버전의 코드는 새로운 필드를 무시하고, 버퍼를 건너뛰면 된다. 반대로 새로운 코드가 이전 버전의 레코드를 읽을 때는 태그 번호가 같은 의미를 유지하기 때문에 문제가 없다. 다만 추가되는 필드가 required인 경우에는 문제가 발생하기에 이런 경우에는 optional 또는 default 값을 사용해야 한다. 필드를 삭제하는 경우도 마찬가지인데, 이 경우에는 optional필드만 삭제가 가능하고, 기존 태그번호는 변경하지 않는다. 데이터 타입과 스키마 발전 이건 그냥 32비트 정수를 64비트 정수로 바꾸는 경우를 생각해보면 간단한데, 이 경우에는 하위호환성이 보장되지 않는다. (새로운 코드는 이전 버전의 데이터를 읽지만, 이전 버전의 코드는 새로운 데이터를 읽을 수 없다.) 아브로 아브로는 스리프트와 다른 하둡의 부호화 형식이다.\n아브로의 예제 스키마는 아래와 같다.\n{ \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Person\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;userName\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;favoriteNumber\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;int\u0026#34;, \u0026#34;null\u0026#34;]}, {\u0026#34;name\u0026#34;: \u0026#34;interests\u0026#34;, \u0026#34;type\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: \u0026#34;string\u0026#34;}} ] } 아브로는 태그 번호를 사용하지 않고, 스키마의 순서에 의존한다. 이러한 방식의 문제점은 읽는코드와 쓰는 코드가 정확히 같은 스키마를 사용해야만 복호화 할 수 있다는 것이다. 이러한 문제점을 아브로는 Avro Reader라는 계층을 두고 쓰기와 읽기 스키마를 분리해서 Avro Reader가 읽기스키마에 맞게 데이터를 변환해준다. 더 정확히는 Avro Reader는 쓰기 스키마와 읽기 스키마를 비교해서 변환을 해준다. 먼저 쓰기 스키마에 있는데 읽기 스키마에는 없는 필드는 무시한다. 반대로 쓰기 스키마에 없는데 읽기 스키마에 있는 필드는 기본값을 사용한다. 스키마 발전 규칙 아브로에서 상위 호환성은 새로운 버전의 쓰기 스키마와 예전 버전의 읽기 스키마를 가질 수 있음을 의미하고, 하위 호환성은 예전 버전의 쓰기 스키마와 새로운 버전의 읽기 스키마를 가질 수 있음을 의미한다.\n기본값이 있는 필드만 추가하거나 삭제 할 수 있다. (새로운 필드를 가진 읽기스키마는 예전 데이터를 만나면 기본값으로 채워넣으면 그만) 기본값이 없는 필드를 추가하면 새로운 읽기는 예전 쓰기가 기록한 데이터를 읽을 수 없다. 기본값이 없는 필드를 삭제하면 예전 읽기 스키마는 새로운 쓰기 스키마가 기록한 데이터를 읽을 수 없다. null 대신 union을 이용한다 () 필드의 타입을 변경할 수 있다. (int -\u0026gt; long) (스키마의 타입 변경을 지원) 필드의 이름을 변경할 수 있다. (근데 별칭을 통해서 하위 호환성을 유지할 수 있는 방식으로 지원하기에, 상위 호환성은 없다) 그러면 쓰기 스키마는 무엇인가? 근데 대충 얼버무렸지만, 쓰기 스키마를 언제 제공할건데?\n먼저 모든 레코드에 쓰기 스키마를 포함하는건 말이 안된다. 그래서 사실 방법에 따라서 다르게 제공한다. 많은 레코드가 있는 대용량 파일 -\u0026gt; 파일의 시작에 쓰기 스키마를 저장한다. 개별적으로 기록된 레코드를 가진 데이터베이스 -\u0026gt; 데이터베이스에 스키마 버전 목록을 저장한다, 그리고 레코드마다 스키마 버전을 저장한다. 네트워크 연결 -\u0026gt; 클라이언트와 서버가 합의해서 스키마를 공유한다. (진짜 프로토콜이네!) 동적 생성 스키마 프로토콜 버퍼와 스리프트에 비해 아브로 방식은 한 가지 장점이 있따. 스키마에 태그번호가 포함돼 있지 않다는 것이다. 이 차이는 아브로가 동적 생성 스키마에 더 친숙하다는 것을 의미한다.\n아브로에서는 스키마가 변경되면, 갱신된 새로운 아브로 스키마를 생성하고 새로운 아브로 스키마로 데이터를 내보낸다. 데이터 내보내는 과정은 스키마 변경에 신경 쓸 필요가 없다. 그리고 이렇게 나온 데이터는 필드가 이름으로 식별되기 때문에, 여전히 이전 읽기 스키마로 읽을 수 있다. 스리프트나 프로토콜 버퍼는 관리자가 스키마 변경될 때마다 태그의 매핑을 수동으로 갱신해야 한다. 코드 생성과 동적 타입 언어 스리프트와 프로토콜 버퍼는 코드 생성에 의존한다. (코드 생성을 통해 스키마를 사용하는 코드를 생성한다.) 정적 타입 언어에서는 코드 생성이 매우 효과적이다. 문제는 동적 타입언어는 타입체크가 안되기도 하고 명시적 컴파일 단계가 없기 때문에 코드 생성이 어렵다. 아브로에서는 코드생성을 선택적으로 사용한다. 아브로에서는 쓰기 스키마를 포함한 객체 컨테이너 파일이 있다면 아브로 라이브러리를 사용해 간단히 열어 JSON파일을 보는 것 과 같이 데이터를 볼 수 있지만, 메타 데이터를 요구하기 때문에 자기 기술적이다.\n스키마의 장점 요약하자면 장점은 부호화를 통한 데이터 절약과 호환성이다. 많은 데이터 베이스 시스템은 이진 부호화를 독자적으로 구현하기도 한다. 예를 들어 대부분의 관계형 데이터베이스에는 질의를 데이터베이스로 보내고 응답을 받을 수 있는 네트워크 프로토콜이 이따. 이 프로토콜은 일반적으로 특정 데이터베이스에 특화되고 데이터베이스 벤더는 데이터베이스 네트워크 프로토콜로부터 응답을 받아 인메모리 데이터 구조로 복호화 하는 드라이버를 제공한다.(JDBC, ODBC)\n데이터 플로 모드 데이터 플로우는 매우 추상적인 개념으로서 하나의 프로세스에서 다른 프로세스로 데이터를 전달하는 방법은 아주 많다. 누가 데이터를 부호화하고 누가 그것을 복호화 할까? 이번장의 나머지 부분에서는 프로세스간 데이터를 전달하는 가장 보편적인 방법을 살펴본다.\n데이터베이스를 통해 RPC를 통해(서비스 호출을 통해) 비동기 메세지 전달을 통해 ","permalink":"http://localhost:1313/_wiki/4%EC%9E%A5/","summary":"4장 부호화와 발전 어플리케이션의 변경과 변화에 대응하는 방법을 소개하는 장. 일단 먼저 대규모 어플리케이션 변화에 있어 장애물이 되는 부분은 크게 아래와같다.\n데이터타입이나 스키마가 변경되는 경우 서버측에서는 순회식 업그레이드를 진행한다. 클라이언트측 어플리케이션은 사용자에 전적으로 좌우된다. 어떤 사용자는 한동안 업그레이드를 하지 않을 수도 있다. 즉 예전버전의 코드와 새로운 버전의 코드, 이전의 데이터타입과 새로운 데이터타입 이 시스템에 공존 할 수 있다는 것이다. 그래서 시스템에는 양방향의 호환성이 필요하다.\n하위 호환성 : 새로운 코드는 이전 코드가 기록한 데이터를 읽을 수 있어야 한다.","title":"데이저 중심 애플리케이션 4장 스터디"},{"content":"Rust 관련 정보 모음 Docker 이미지 만들기 Compile ","permalink":"http://localhost:1313/_wiki/rust-main/","summary":"Rust 관련 정보 모음 Docker 이미지 만들기 Compile ","title":"Rust 🦀"},{"content":"저장소와 검색 데이터베이스의 가장 중요한 두가지 추상화는 쓰기/읽기이다. 그리고 이 두가지 성능은 항상 Trade-off 관계에 있다. 그 Trade-off 관계를 이해하는 것과, 가장 대표적인 저장소 엔진인 로그구조(Log-Structured) 저장소 엔진과 B-트리 같은 페이지지향(page-oriented) 저장소 엔진을 비교하는 것이 이 장의 목표이다.\n데이터베이스를 강력하게 만드는 데이터 구조 #!/bin/bash db_set () { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get () { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 // 특정 키에 대한 마지막 값을 가져온다. } 가장 간단한 데이터 베이스의 구조 \u0026gt; db_set \u0026#34;small\u0026#34; \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;helloWorld@helloWorld.com\u0026#34;}\u0026#39; \u0026gt; db set \u0026#34;big\u0026#34; \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;BigzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;helloWorld2@helloWorld.com\u0026#34;}\u0026#39; \u0026gt; db set \u0026#34;small\u0026#34; \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;foo@bar.com\u0026#34;}\u0026#39; \u0026gt; cat database \u0026#34;small\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;helloWorld@helloWorld.com\u0026#39;}\u0026#34; \u0026#34;big\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;BigzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;hellowWorld@helloWorld.com\u0026#34;}\u0026#34; \u0026#34;small\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;foo@bar.com\u0026#34;}\u0026#34; 언뜻 장난같지만 이 데이터베이스는 실제로 매우 강력하다.\n쓰기 작업은 성능이 특히 뛰어나다. (그냥 파일에 append만 하면 되기 때문)\n읽기 작업은 키를 찾아서 파일을 끝까지 읽어야 하기 때문에 성능이 좋지 않다.(O(n))\n좋은 쓰기 성능 대비 나쁜 읽기성능을 보완하기 위해 다른 데이터 구조를 추가하는데, 바로 Index이다.\n색인은 기본ㄷ 데이터에서 파생된 추가적인 구조다. 많은 데이터베이스는 색인의 추가오 삭제를 허용한다. 이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다. 단지 질의 성능에만 영향을 준다. 특히 쓰기 과정에서의 오버헤드가 발생한다. 쓰는 시점에 인덱스를 갱신하기 때문이다.\n해시 색인\n먼저 키-값 데이터를 색인하는 가장 간단한 방법은 해시 테이블을 사용하는 것이다. 실제로 인메모리에 해시테이블을 사용하는건 굉장히 흔한 방식이고, 비트캐스크(Riak의 엔진)도 이 방식을 사용한다고 한다. (newline은 없고 디스크 상에 일렬로 저장된다고 가정한다.) \u0026#34;small\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;helloWorld@helloWorld.com\u0026#39;}\u0026#34; \u0026#34;big\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;BigzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;hellowWorld@helloWorld.com\u0026#34;}\u0026#34; \u0026#34;small\u0026#34;,\u0026#34;{\u0026#34;name\u0026#34;: \u0026#34;SmallzooDev\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;foo@bar.com\u0026#34;}\u0026#34; // key : value small : (가장 최근에 추가된 small이 시작되는 위치) big : (가장 최근에 추가된 big이 시작되는 위치) 이렇게 빠르게 조회를 달성하고 나면 위의 구조(모든 추가 데이터를 파일에 append, 해시테이블에 키-값을 저장)는 여러가지 장점을 가진다. 첫 번째로 아직 쓰기 성능이 뛰어나다. (파일에 append만 하면 되기 때문) 두 번째로 해시테이블을 사용하면 키를 찾는데 O(1)의 시간이 걸린다.\n하지만 한가지 문제가 있는데, 바로 디스크의 용량이 결국 부족해진다는 것이다. 위의 예시에서, 계속 append된 데이터를 실제로 데이터베이스에서도 매우 유용하게 사용하며, 이를 database 로그라고 일컫는다. 지금 상황은 로그 자체를 데이터베이스로 사용하고 있는 것이다.\n이 문제를 해결하기 위해 컴팩션이라는 개념이 등장한다. 먼제 세그먼트를 도입해서 로그가 특정 크기에 도달하면 이를 나눠담는다. 그리고 이 세그먼트를 더 작게 만들기 위해서 하는 작업이 컴팩션 이다. 사실 컴팩션 자체는 매우 간단한데, 세그먼트를 읽어서 중복된 키를 제거하고, 가장 최근의 값을 유지하는 것이다. 컴팩션은 다른 쓰레드에서 진행해도 무방하고, 아직도 안전한 append 로그 작업을 계속할 수 있다. (append 로그 방식이 얼마나 안전한지 모르겠다면, 값을 갱신하는 방식으로 db를 구현했을때 갱신중 꺼지는 상황을 떠울리면 된다) 하지만 해시 테이블 역시 제약 사항이 있다.\n메모리에 키를 저장해야 하기 때문에, 키가 매우 많아지면 메모리가 부족해진다. 범의 질의를 지원하지 않는다. ##SS테이블과 LSM트리 먼지 키를 특정 기준으로 정렬한다. 정렬을 위해서 merge-sort를 사용하는데, (세그먼트로 나누어서 정렬하고, 이를 합치는 방식) 메모리보다 파일이 커도 정렬이 가능하다. 이렇게 키로 정렬된 테이블을 SS테이블(sorted string table)이라고 한다. 이렇게 SS테이블을 만들면 해당 테이블을 이용해 범위 질의도 할 수 있고, 모든 키를 메모리에 저장하지 않아도 된다(정렬의 특성상, 없으면 범위를 찾을 수 있기 때문) 여기까지는 괜찮은데 그렇다면 데이터를 정렬하려면 어떻게 해야할까? 일단 이것도 디스크에 정렬을 유지하는것은 쉽지않다. 유입되는 쓰기는 임의 순서로 발생하기 때문이다. (B트리를 이용하면 가능하지만, 이는 다음에 설명) 그래서 메모리에 AVL트리나 레드블랙트리를 사용해서 정렬을 유지한다. 이런 구조들로 임의 순서로 키를 삽입하고, 정렬된 순서로 키를 읽는다. 쓰기가 들어오면 인메모리 균형 트리 데이터구조(레드블랙트리나 AVL트리)에 추가한다. 이걸 멤테이블(memtable)이라고 부른다. 멤테이블이 일정 크기에 도달하면 SS테이블로 변환하고, 디스크에 기록한다. 새로운 SS테이블파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 쓰는동한 새로운 쓰기는 멤테이블 인스턴스에 기록한다. 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야한다. 그리고 그 다음에는 가장 최신의 SS테이블부터 가장 오래된 SS테이블까지 차례로 검색한다. 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 작업을 수행한다.(이 작업은 백그라운드에서 수행된다.) (데이터베이스가 고장난경우 쓰기중인 데이터가 날아갈 수 있지만, 로그를 유지하고 있기 때문에 복구가 가능하다.) SS테이블에서 LSM트리 만들기\nLSM트리는 Log-Structured Merge-Tree의 약자로, SS테이블을 이용해서 만들어진다. 이러한 방식은 구글의 빅테이블 논문에서 처음 소개되었다. 루신과 같은 검색엔진에서도 사용되는 방식인데, 용어 사전(term dictionary)을 만들때 사용한다. (검색 질의가 들어오면, 단어가 언급된 모든 문서를 찾는데, 이 접근법을 키를 단어로 값은 단어를 포함한 모든 문서의 포스팅 목록으로하는 키-값구조로 저장하게된다.)\nLSM트리는 블룸필터등을 사용해서 키 존재 여부를 빠르게 확인하며 최적화하고 SS테이블 병합도 크기 계층, 레벨 컴팩션을 통해 최적화한다. ##B트리 지금까지 설명한 로그 구조화 색인이 점점 보편화되고 있지만 가장 일반적인 색인 유형은 아니다. 가장 널리 사용되는 색인 구조는 B트리이다. 알에서 살펴본 로그 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다. 반면 B트리는 데이터베이스를 고정 크기의 페이지로 나누고(전통적으로 4KB) 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 수행한다. 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근분족으로 하드웨어와 조금 더 밀접한 관련이 있다.\n기본적인 b트리로직과 똑같다. 루트 페이지에 여러 키와 하위페이지의 참조를 저장하고, 이어서 두 번째 페이지에도 키와 참조를 저장한다.\n그러다 리프페이지에 도달하면, 값의 참조를 저장한다.\nB트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기계수라고 부른다.\n갱신과 추가는 쉽지만 삭제는 조금 복잡하다.\n삭제시에는 키를 삭제하고, 빈 공간을 채우기 위해 인접한 키를 이동시키거나, 인접한 페이지와 병합하는 작업을 수행한다.\n신뢰 할 수 있는 B트리 구현하기\n로그 구조화 색인과 달리 B트리는 쓰기작업시 데이터를 디스크상의 페이지에 덮어쓴다. 이 동작이 덮어쓰기가 페이지 위치를 변경하지 않는다고 가정한다. 즉 페이지를 덮어써도 참조는 온전히 남는다. 이런 이유로 동시성 제어가 필요하고, 트랜잭션 로그를 사용해서 데이터베이스를 복구할 수 있어야 한다. B트리는 여러가지 최적화 기법이 있다.\n페이지 덮어쓰기와 WAL유지 대신 변경된 페이지는 다른위치에 기록하고, 변경된 페이지를 가리키는 로그를 유지한다. 전체키를 쓰는게 아니라, 키의 일부만 쓰는 방식을 사용한다. 디스크에 순서대로 저장할 제약을 두지 않는다. 여기저기 포인터로 최적화(리프노드에 양쪽 페이지의 포인터를 저장하는 방식)를 사용한다. 기타 색인 구조 키-값 색인에 대해서 살펴봤고, 번역이 이상한지 해당 인덱스를 사용하는 사용예시를 보여준다.\n다중 칼럼 색인\nSELECT * FROM restaurans WHERE latitute BETWEEN 37.0 AND 37.1 AND longitude BETWEEN -122.0 AND -121.9; 위와 같은 쿼리가 있을 때 지금까지 언급된 인덱스는 효율적으로 응답 할 수 없다. 이런 경우 2차원 채움 곡선과 같이 단일 숫자로 변환하는 방법이 있다고 한다. 그외에 R트리 색인 같은게 있고 postgresql에서는 구현되어있다고 하는데 설명은 없다. ","permalink":"http://localhost:1313/_wiki/3%EC%9E%A5/","summary":"저장소와 검색 데이터베이스의 가장 중요한 두가지 추상화는 쓰기/읽기이다. 그리고 이 두가지 성능은 항상 Trade-off 관계에 있다. 그 Trade-off 관계를 이해하는 것과, 가장 대표적인 저장소 엔진인 로그구조(Log-Structured) 저장소 엔진과 B-트리 같은 페이지지향(page-oriented) 저장소 엔진을 비교하는 것이 이 장의 목표이다.\n데이터베이스를 강력하게 만드는 데이터 구조 #!/bin/bash db_set () { echo \u0026#34;$1,$2\u0026#34; \u0026gt;\u0026gt; database } db_get () { grep \u0026#34;^$1,\u0026#34; database | sed -e \u0026#34;s/^$1,//\u0026#34; | tail -n 1 // 특정 키에 대한 마지막 값을 가져온다.","title":"데이터 중심 애플리케이션 설계 스터디3장"},{"content":"13.0.0 Functional Languages Features: Iterators and Closures Rust’s design has taken inspiration from many existing languages and techniques, and one significant influence is functional programming. Programming in a functional style often includes using functions as values by passing them in arguments, returning them from other functions, assigning them to variables for later execution, and so forth. In this chapter, we won’t debate the issue of what functional programming is or isn’t but will instead discuss some features of Rust that are similar to features in many languages often referred to as functional.\n요약하자면 러스트의 디자인과 기능은 함수형 프로그래밍에서도 영감을 받았다. 하지만 뭐가 함수형인지 논의하는것보다는 많은 언어들에서 함수형 언어로 일컫어지는 기능들이 러스트에서 어떻게 사용할 수 있는지 알아본다고 한다.\n구체적으로는\nClosures : 안에 변수를 캡쳐할 수 있는 function-like construct Iterators : series of elements를 처리하는 방법들 위 두가지의 성능 에 대해서 알아본다. 13.1 Closures: Anonymous Functions that Can Capture Their Environment 러스트의 클로져는 변수를 저장하거나, 다른 함수에 아규먼트로 넘길 수 있는 익명 함수이다. 특점 시점에 클로저를 생성하고, 다른 어딘가 다른 컨택스트에서 실행할 수 있다. 다만 일반 함수들과는 다르게 그들이 정의된 시점과 스코프의 값을 캡쳐할 수 있다.\n13.1.1 Captureing the Environment with Closures Scenario : 티셔츠 회사에서는 프로모션으로 메일링 리스트에 등록된 사람에게 한정판 티셔츠를 무료로 증정한다. 메일링 리스트에 등록된 사람들은 선택적으로 프로필에 자신의 좋아하는 색상을 추가할 수 있다. 만약 무료 티셔츠를 받게 된 사람이 좋아하는 색상을 설정해 놓았다면, 그 색상으로 티셔츠를 받는다. 만약 좋아하는 색상을 지정하지 않았다면, 회사에서 현재 가장 많이 보유하고 있는 색상의 티셔츠를 받게 된다.\n#[derive(Debug, PartialEq, Copy, Clone)] enum ShirtColor { Red, Blue, } struct Inventory { shirts: Vec\u0026lt;ShirtColor\u0026gt;, } impl Inventory { fn giveaway(\u0026amp;self, user_preference: Option\u0026lt;ShirtColor\u0026gt;) -\u0026gt; ShirtColor { user_preference.unwrap_or_else(|| self.most_stocked()) } fn most_stocked(\u0026amp;self) -\u0026gt; ShirtColor { let mut num_red = 0; let mut num_blue = 0; for color in \u0026amp;self.shirts { match color { ShirtColor::Red =\u0026gt; num_red += 1, ShirtColor::Blue =\u0026gt; num_blue += 1, } } if num_red \u0026gt; num_blue { ShirtColor::Red } else { ShirtColor::Blue } } } fn main() { let store = Inventory { shirts: vec![ShirtColor::Blue, ShirtColor::Red, ShirtColor::Blue], }; let user_pref1 = Some(ShirtColor::Red); let giveaway1 = store.giveaway(user_pref1); println!( \u0026#34;The user with preference {:?} gets {:?}\u0026#34;, user_pref1, giveaway1 ); let user_pref2 = None; let giveaway2 = store.giveaway(user_pref2); println!( \u0026#34;The user with preference {:?} gets {:?}\u0026#34;, user_pref2, giveaway2 ); } user_preference.unwrap_or_else(|| self.most_stocked()) : 여기서 클로저가 사용되었다. 먼저 Option\u0026lt;T\u0026gt;의 unwrap_or_else 메소드는 Option\u0026lt;T\u0026gt;가 Some이면 T를 반환하고, None이면 클로저를 실행한다. impl\u0026lt;T\u0026gt; Option\u0026lt;T\u0026gt; { pub fn unwrap_or_else\u0026lt;F\u0026gt;(self, f: F) -\u0026gt; T where F: FnOnce() -\u0026gt; T, // 이때 F는 T를 반환하는 클로저 타입, 이외에도 FnMut, Fn 트레이트도 있다. { match self { Some(value) =\u0026gt; value, None =\u0026gt; f(), // None이면 클로저 f를 실행해 그 결과를 반환 } } } || self.most_stocked() : 즉 여기서는 ||로 시작하고, self.most_stocked()를 본문으로 가지는 클로저를 넘긴 것이다. 결과값이 필요해진 경우 (unwrap_or_else가 호출되는 경우) 클로저가 실행되어 most_stocked 메소드를 호출한다. 이 부분이 헷갈리는 이유는 함수로도 구현할 수 있어보이기 때문인데 (함수를 파라미터로 넘기면), 사실 가장중요한건 외부 환경(여기서는 self)을 캡처할 수 있다는 것이다. 즉, 클로저는 self를 따로 매개변수로 넘기지 않아도 내부에서 접근할 수 있다. 반례 (함수 포인터를 넘기는 경우)를 생각하려 한다면, Option\u0026lt;T\u0026gt;의 unwrap_or_else 메소드가 Inventory, ShirtColor 타입을 알아야 한다.. 함수 포인터를 넘기는 경우 필요한 데이터를 명시적으로 매개변수로 전달해야 하거나 별도로 래핑을 해서 전달해야 한다.\n13.1.2 Closure Type Inference and Annotation 클로저는 대부분의 상황에서 타입을 명시적으로 지정할 필요가 없다. 반면 함수는 하나의 인터페이스 노출되기 때문에 명시적으로 (모두가 동의하는) 타입을 지정해야 한다. 클로저는 노출된 인터페이스처럼 사용되지 않기 때문에 그렇다. 당연히 컴파일러의 타입추론에 의존하고, 꼭 필요한 경우에 타입을 명시적으로 지정하기도 한다.\nfn add_one_v1 (x: u32) -\u0026gt; u32 { x + 1 } let add_one_v2 = |x: u32| -\u0026gt; u32 { x + 1 }; let add_one_v3 = |x| { x + 1 }; let add_one_v4 = |x| x + 1 ; 넷 다 가능하고, 타입을 지정하지 않으면 평가시점에 타입을 추론한다. let example_closure = |x| x; let s = example_closure(String::from(\u0026#34;hello\u0026#34;)); let n = example_closure(5); $ cargo run Compiling closure-example v0.1.0 (file:///projects/closure-example) error[E0308]: mismatched types --\u0026gt; src/main.rs:5:29 | 5 | let n = example_closure(5); | --------------- ^- help: try using a conversion method: `.to_string()` | | | | | expected struct `String`, found integer | arguments to this function are incorrect | note: closure parameter defined here --\u0026gt; src/main.rs:2:28 | 2 | let example_closure = |x| x; | ^ For more information about this error, try `rustc --explain E0308`. error: could not compile `closure-example` due to previous error example_closure는 처음 평가시 String을 받았기 때문에 String으로 타입이 결정되었다. 클로저의 소유권은 함수와 대응된다(동일하다) fn main() { let list = vec![1, 2, 3]; println!(\u0026#34;Before defining closure: {:?}\u0026#34;, list); let only_borrows = || println!(\u0026#34;From closure: {:?}\u0026#34;, list); println!(\u0026#34;Before calling closure: {:?}\u0026#34;, list); only_borrows(); println!(\u0026#34;After calling closure: {:?}\u0026#34;, list); } 위의 경우 불변 참조를 사용했기 때문에 컴파일이 된다. fn main() { let mut list = vec![1, 2, 3]; println!(\u0026#34;Before defining closure: {:?}\u0026#34;, list); let mut borrows_mutably = || list.push(7); // println!(\u0026#34;Before calling closure: {:?}\u0026#34;, list); borrows_mutably(); println!(\u0026#34;After calling closure: {:?}\u0026#34;, list); } 위의 경우 가변 참조를 이용해서 벡터를 수장 할 수 있다. 만약 주석을 해제하면 컴파일 에러가 발생한다. 만약 소유권 이전을 하고 싶다면 move 키워드를 사용한다. use std::thread; fn main() { let list = vec![1, 2, 3]; println!(\u0026#34;Before defining closure: {:?}\u0026#34;, list); thread::spawn(move || println!(\u0026#34;From thread: {:?}\u0026#34;, list)) .join() .unwrap(); } move 키워드를 사용하면 클로저는 소유권을 이전받는다. 이 예제는 새로운 쓰레드에서 클로저를 실행하는데 클로저 본문이 immutable 참조만 필요하기에 기본적으로는 immutable 참조를 사용한다. 그런데 소유권은 아직 메인 쓰레드에 있기 때문에 불변참조가 유지되는동안 list가 drop될 가능성이 있다. 그래서 move 키워드를 사용해서 소유권을 이전하도록 강제되어있다. 13.1.3 Moving Captured Values Out of Closures and the Fn Traits 클로저가 외부 환경으로부터 변수를 캡처하는 방식은 Rust에서 Fn, FnMut, FnOnce 트레이트에 영향을 준다.\n클로저는 외부 환경에서 변수를 캡처할 수 있으며, 이를 처리하는 방식은 크게 세 가지로 나뉜다:\n값을 클로저 내부로 이동시키기: 외부 변수의 소유권을 가져오는 경우. 값을 변경하기: 외부 변수의 값을 변경할 수 있는 경우. 값을 읽기만 하기: 외부 변수의 값을 읽기만 하고, 변경하지 않는 경우. Rust에서는 클로저가 외부 변수를 어떻게 캡처하느냐에 따라 Fn, FnMut, FnOnce 트레이트 중 하나가 자동으로 구현된다.\nFnOnce: 클로저가 외부 변수의 소유권을 가져가면 한 번만 호출될 수 있다.\nFnMut: 클로저가 외부 변수의 값을 변경할 수 있는 경우, 여러 번 호출 가능하다.\nFn: 외부 변수를 읽기만 할 때는 여러 번 호출 가능하다.\nfn consume_with_fn_once\u0026lt;F\u0026gt;(f: F) where F: FnOnce(), { f(); // 한 번만 호출 가능 } fn main() { let name = String::from(\u0026#34;Rust\u0026#34;); let introduce = || { // name의 소유권을 가져가서 이동시킴 println!(\u0026#34;Hello, {}!\u0026#34;, name); }; consume_with_fn_once(introduce); // OK // introduce(); // 에러 발생! introduce는 이미 소유권을 이동시켜 한 번만 호출 가능 } 클로저가 외부 변수의 소유권을 가져가기 때문에, FnOnce 트레이트가 적용된다. 소유권이 이동되었으므로 클로저는 한 번만 호출 가능하다.\nfn consume_with_fn_mut\u0026lt;F\u0026gt;(mut f: F) where F: FnMut(), { f(); // 여러 번 호출 가능 f(); } fn main() { let mut count = 0; let mut increment = || { count += 1; // 외부 변수 count를 변경 println!(\u0026#34;Count: {}\u0026#34;, count); }; consume_with_fn_mut(increment); // OK } 클로저가 외부 변수를 가변 참조로 캡처하여 값을 변경하므로 FnMut 트레이트가 적용된다. 클로저는 여러 번 호출 가능하다.\nfn consume_with_fn\u0026lt;F\u0026gt;(f: F) where F: Fn(), { f(); // 여러 번 호출 가능 f(); } fn main() { let greeting = String::from(\u0026#34;Hello\u0026#34;); let say_hello = || { println!(\u0026#34;{}\u0026#34;, greeting); // greeting을 읽기만 함 }; consume_with_fn(say_hello); // OK } 클로저가 외부 변수를 읽기만 하므로 Fn 트레이트가 적용된다. 변수를 변경하지 않기 때문에 여러 번 호출이 가능하다.\n클로저가 외부 변수를 어떻게 캡처하느냐에 따라 Rust는 자동으로 Fn, FnMut, FnOnce 트레이트를 구현한다.\nFnOnce: 클로저가 외부 변수의 소유권을 가져갈 때. FnMut: 클로저가 외부 변수를 변경할 때. Fn: 클로저가 외부 변수를 읽기만 할 때. 이러한 방식으로 Rust는 클로저가 외부 변수와 어떻게 상호작용하는지에 따라 자동으로 적절한 트레이트를 적용해준다.\n","permalink":"http://localhost:1313/_wiki/funcional-langauges-features/","summary":"13.0.0 Functional Languages Features: Iterators and Closures Rust’s design has taken inspiration from many existing languages and techniques, and one significant influence is functional programming. Programming in a functional style often includes using functions as values by passing them in arguments, returning them from other functions, assigning them to variables for later execution, and so forth. In this chapter, we won’t debate the issue of what functional programming is or isn’t but will instead discuss some features of Rust that are similar to features in many languages often referred to as functional.","title":"러스트의 함수영 언어 특징"},{"content":"공통 종작은 타입 시스템으로 표현하라 ","permalink":"http://localhost:1313/_wiki/item-2/","summary":"공통 종작은 타입 시스템으로 표현하라 ","title":"Effective Rust Item 2  공통 종작은 타입 시스템으로 표현하라"},{"content":"데이터 구조를 타입 시스템으로 표현하라 복잡한 데이터 구조를 구성하는 방법을 배운다. 이 과정에서 enum은 핵심적인 역할을 한다. 러스트의 enum은 기본적으로 다른 언어와 같지만, 배리언트에 직접 데이터 필드를 넣을 수 있다는 점에서 다른 언어보다 훨씬 유연하고 표현력이 높다.\n기본 타입\ni8 i16 i32 i64 i128 : 부호 있는 정수 u8 u16 u32 u64 u128 : 부호 없는 정수 isize usize : 시스템 아키텍처에 따라 크키가 변하는 정수, 포인터와 인덱스 연산에 사용 f32 f64 : 부동 소수점 bool : 참/거짓 char : 유니코드 문자 () : 유닛타입, c언어의 void와 비슷한 역할\n특징적일것은 없지만 컴파일러가 조금 더 빡빡하게 체크해준다. let x: i32 = 42; let y: i16 = x; // error[E0308]: mismatched types, let y: i16 = x.try_into().unwrap(); let x = 42i32; let y: i64 = x; // error[E0308]: mismatched types, let y: i64 = x.try_into(); ** 묶음 타입 (arggregates) **\n튜플 : 고정된 크기의 묶음, 각 요소의 타입은 다를 수 있다. 배열 : 고정된 크기의 묶음, 모든 요소의 타입은 같아야 한다. 구조체 : 이름이 붙은 필드를 가지는 묶음, 각 필드의 타입은 다를 수 있다. 튜플 구조체 : 이름이 붙지 않은 필드를 가지는 묶음, 각 필드의 타입은 다를 수 있다. // 튜플 구조체 struct TextMatch(usize, String); let m = TextMatch(42, \u0026#34;hello\u0026#34;.to_string()); assert_eq!(m.0, 42); ** 열거 타입 (enum) **\n기본적으로는 상호 배타적인 값들의 집합을 나타낸다. enum Direction { Up = \u0026#39;h\u0026#39;, Down = \u0026#39;j\u0026#39;, Left = \u0026#39;k\u0026#39;, Right = \u0026#39;l\u0026#39;, } assert_eq!(Direction::Up as char, \u0026#39;h\u0026#39;); 단순히 bool타입을 사용하는 것보다는 열거 타입을 사용하는 것이 더 가독성이 좋고, 유지보수하기 쉽다.\npub fn print_page(is_both_side: bool, is_color: bool) { /* ... */ } // this better pub fn print_page(side: Sides, color: Color) { /* ... */ } pub enum Sides { Both, One, } pub enum Color { Color, BlackAndWhite, } 사실 더 나은 방법은 뉴타입 패턴을 이용해 래핑하는 것이지만, 많약 옵션이 추가될 여지가 있다면 위처럼 열거 타입을 사용하는 것이 좋다.\nenum의 타입안정성은 mathch표현식을 통해 보장 할 수 있다. let direction = match input { \u0026#39;h\u0026#39; =\u0026gt; Direction::Up, \u0026#39;j\u0026#39; =\u0026gt; Direction::Down, \u0026#39;k\u0026#39; =\u0026gt; Direction::Left, }; // error[E0004]: non-exhaustive patterns 모든 variant를 다루지 않으면 컴파일러가 에러를 발생시킨다. 물론 \u0026lsquo;_\u0026lsquo;를 사용해 모든 variant를 다루지 않도록 할 수 있긴 하지만, 그렇게 하면 새로운 variant가 추가되었을 때 컴파일러가 알려주지 않기 때문에 조심해서 사용해야 한다.\n필드가 있는 enum\nC/C++에서 enum과 union을 조합한것에 타입 안정성이 보장되는 것을 그냥 enum으로 표현할 수 있다. 즉, 프로그램 데이터 구조의 불변성을 러스트의 타입 시스템으로 인코딩할 수 있으며, 이러한 불현성을 어기면 컴파일이 되지 않는다.\nc언어와 union을 사용한 예제 enum State { INT, FLOAT }; union Value { int i; float f; }; struct Data { enum State state; union Value value; }; void print_value(struct Data* data) { if (data-\u0026gt;state == FLOAT) { printf(\u0026#34;%f\\n\u0026#34;, data-\u0026gt;value.f); } } 러스트의 enum의 기능을 활용한 예제 enum Value { Int(i32), Float(f32), } fn print_value(value: Value) { match value { Value::Int(i) =\u0026gt; println!(\u0026#34;{}\u0026#34;, i), Value::Float(f) =\u0026gt; println!(\u0026#34;{}\u0026#34;, f), } } 그리고, 작성자의 의도가 컴파일러뿐만 아니라 사람에게도 명확하게 드러나는 enum이야 말로 제대로 설계된 enum이라 할 수 있다. 이런식의 (아래의 예시처럼) 구성이야 말로 바로 이번 아이템의 핵심 주제인 \u0026lsquo;러스트는 어떻게 타입 시스템을 통해 프로그램 컨셉을 디자인하는가\u0026rsquo;를 보여주는 좋은 예시라 할 수 있다.\nuse std::collections::{HashMap, HashSet}; pub enum SchedulerState { Insirt, Pending(HashSet\u0026lt;Job\u0026gt;), Running(HashMap\u0026lt;Job, Worker\u0026gt;), } 유효하지 못한 상태가 타입에 표현 될 수 없도록 설계를 제대로 해야한다. 필드나 매개변수의 유효성 조건에 대한 주석이 달린다면, 개념을 타입 시스팀에 제대로 표현하지 못했다는 뜻이다.\npub struct Car { pub is_parked: bool, // 주차 중이면 speed는 반드시 0이어야 한다. pub speed: u32, } pub enum CarState { Parked, Driving(u32), } pub struct Car { pub state: CarState, } 흔히 사용하는 enum 타입\nOption\u0026lt;T\u0026gt; : 값이 있을 수도 있고 없을 수도 있는 타입\nSome(T) : 값이 있는 경우 None : 값이 없는 경우 컬렉션과 관련해서는 조금 더 생각해볼 부분이 있다. (Vec\u0026lt;Thing\u0026gt; vs Option\u0026lt;Vec\u0026lt;Thing\u0026gt;\u0026gt;) 값이 없는 스트링에서는 \u0026ldquo;\u0026ldquo;와 None중에 어떠한것이 좋을지에 대해서는 Option이 좋다. Result\u0026lt;T, E\u0026gt; : 성공할 수도 있고 실패할 수도 있는 타입\nOk(T) : 성공한 경우 Err(E) : 실패한 경우 실패할 수 있는 모든 연산에 사용해야 한다. ? 연산자를 사용하면 에러를 반환하고, 함수의 반환 타입이 Result인 경우에는 자동으로 에러를 반환한다. fn read_file_basic() -\u0026gt; Result\u0026lt;String, io::Error\u0026gt; { let mut file = match File::open(\u0026#34;test.txt\u0026#34;) { Ok(file) =\u0026gt; file, Err(e) =\u0026gt; return Err(e), }; let mut contents = String::new(); match file.read_to_string(\u0026amp;mut contents) { Ok(_) =\u0026gt; Ok(contents), Err(e) =\u0026gt; Err(e), } } fn main() { match read_file_basic() { Ok(contents) =\u0026gt; println!(\u0026#34;File contents: {}\u0026#34;, contents), Err(e) =\u0026gt; eprintln!(\u0026#34;Error reading file: {}\u0026#34;, e), } } fn read_file_chain() -\u0026gt; Result\u0026lt;String, io::Error\u0026gt; { let mut contents = String::new(); File::open(\u0026#34;test.txt\u0026#34;)?.read_to_string(\u0026amp;mut contents)?; Ok(contents) } fn main() { match read_file_chain() { Ok(contents) =\u0026gt; println!(\u0026#34;File contents: {}\u0026#34;, contents), Err(e) =\u0026gt; eprintln!(\u0026#34;Error reading file: {}\u0026#34;, e), } } ","permalink":"http://localhost:1313/_wiki/item-1/","summary":"데이터 구조를 타입 시스템으로 표현하라 복잡한 데이터 구조를 구성하는 방법을 배운다. 이 과정에서 enum은 핵심적인 역할을 한다. 러스트의 enum은 기본적으로 다른 언어와 같지만, 배리언트에 직접 데이터 필드를 넣을 수 있다는 점에서 다른 언어보다 훨씬 유연하고 표현력이 높다.\n기본 타입\ni8 i16 i32 i64 i128 : 부호 있는 정수 u8 u16 u32 u64 u128 : 부호 없는 정수 isize usize : 시스템 아키텍처에 따라 크키가 변하는 정수, 포인터와 인덱스 연산에 사용 f32 f64 : 부동 소수점 bool : 참/거짓 char : 유니코드 문자 () : 유닛타입, c언어의 void와 비슷한 역할","title":"Effective Rust Item 1  데이터 구조를 타입 시스템으로 표현하라"},{"content":"Effective Rust 🦀 Effective Rust를 읽고 기억할만한 내용을 정리하는 문서입니다.\nChapter 1 : Type [[Item-1]] : 데이터 구조를 타입 시스템으로 표현하라 [[Item-2]] : 공통 동작은 타입 시스템으로 표현하라 ","permalink":"http://localhost:1313/_wiki/effective-rust/","summary":"Effective Rust 🦀 Effective Rust를 읽고 기억할만한 내용을 정리하는 문서입니다.\nChapter 1 : Type [[Item-1]] : 데이터 구조를 타입 시스템으로 표현하라 [[Item-2]] : 공통 동작은 타입 시스템으로 표현하라 ","title":"Effective Rust 🦀"},{"content":" 데이터 모델은 아마도 소프트웨어 개발에서 제일 중요한 부분일 것이다. 왜냐하면 데이터 모델은 소프트웨어가 어떻게 작성됐는지 뿐만 아니라, 문제를 어떻게 생각해야 하는지에 지대한 영향을 미치기 때문이다.\n대부분의 애플리케이션은 하나의 데이터 모델을 다른 데이터 모델 위에 계층을 둬서 만든다. 각 계층의 핵심적인 문제는 다음 하위 계층 관점에서 데이터 모델을 표현하는 것이다. 참고로 레이어 패턴은 하나의 레이어가 직전 레이어의 성립을 전제로 존재하고, 그러한 레이어들로 이루어진 구조를 말한다.\n무튼 이번 장에서는 아래와 같은 것들을 살펴본다.\n다양한 범용 데이터 모델들에 대한 소개 다양한 질의 언어와 사용 사례 관계형 모델과 문서 모델 관계형 모델과 문서 모델, 그리고 아주 약간의 그래프 모델에 대해 그리고 이들의 역사에 대해 살펴본다.\n가장 중요하게 생각한건 어떠한 요구를 처리하다가 어떠한 db가 우위를 점했는지에 대한 내용이다.\n관계형 모델\n관계형 모델은 1970년대에 제안된 모델로, 상당 기간 우위를 점했다. 테이블과 관계를 튜플로 표현한 데이터의 모음으로 관리한다. 트랜잭션 처리와 일괄 처리에 대한 지원을 강점으로 내세워 우위를 점했다. NoSQL\nNoSQL은 관계형 모델의 우위를 뒤집기 위한 가장 최근의 시도이다. 처음에는 커뮤니티 밋업을 위한 해쉬태그였지만 점점 용어가 확산되어 Not Only SQL로 재해석됐다. 주로 아래와 같은 이유로 사용된다. 대규모 데이터 셋이나 매우 높은 쓰기 처리량을 필요로 하는 경우 오픈소스 소프트웨어를 사용하고자 하는 경우 동적이고 표현력이 풍부한 모델에 대한 바램 객체 관계 불일치\n객체 관계 불일치는 객체지향 프로그래밍 언어와 관계형 데이터베이스 간의 불일치를 의미한다. 요즘은 가장 대중적으로 객체지향 프로그래밍 언어를 사용하는데, 이로 인해 객체지향 프로그래밍 언어와 관계형 데이터베이스 간의 불일치가 발생한다. 이런 모델 사이의 불일치를 임피던스 불일치라고 한다. 아래의 예시 json 데이터는 객체 지향 프로그램의 데이터 모델과 아주 유사하다.\n{ \u0026#34;profile\u0026#34;: { \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34;, \u0026#34;headline\u0026#34;: \u0026#34;Software Engineer at TechCorp\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;city\u0026#34;: \u0026#34;San Francisco\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;California\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;United States\u0026#34; }, \u0026#34;summary\u0026#34;: \u0026#34;Experienced software engineer with a passion for developing scalable web applications and working across the full stack.\u0026#34;, \u0026#34;profilePictureUrl\u0026#34;: \u0026#34;https://example.com/profile/johndoe.jpg\u0026#34;, \u0026#34;contactInfo\u0026#34;: { \u0026#34;email\u0026#34;: \u0026#34;john.doe@example.com\u0026#34;, \u0026#34;phone\u0026#34;: \u0026#34;+1-123-456-7890\u0026#34;, \u0026#34;linkedinUrl\u0026#34;: \u0026#34;https://www.linkedin.com/in/johndoe\u0026#34; } }, \u0026#34;experience\u0026#34;: [ { \u0026#34;title\u0026#34;: \u0026#34;Senior Software Engineer\u0026#34;, \u0026#34;company\u0026#34;: \u0026#34;TechCorp\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;startDate\u0026#34;: \u0026#34;2019-06\u0026#34;, \u0026#34;endDate\u0026#34;: \u0026#34;Present\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Leading the development of microservices architecture and improving CI/CD pipelines.\u0026#34; }, { \u0026#34;title\u0026#34;: \u0026#34;Software Engineer\u0026#34;, \u0026#34;company\u0026#34;: \u0026#34;Web Solutions Inc.\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;New York, NY\u0026#34;, \u0026#34;startDate\u0026#34;: \u0026#34;2016-01\u0026#34;, \u0026#34;endDate\u0026#34;: \u0026#34;2019-05\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Developed web applications using modern JavaScript frameworks.\u0026#34; } ], \u0026#34;education\u0026#34;: [ { \u0026#34;school\u0026#34;: \u0026#34;University of California, Berkeley\u0026#34;, \u0026#34;degree\u0026#34;: \u0026#34;Bachelor of Science\u0026#34;, \u0026#34;fieldOfStudy\u0026#34;: \u0026#34;Computer Science\u0026#34;, \u0026#34;startDate\u0026#34;: \u0026#34;2012-09\u0026#34;, \u0026#34;endDate\u0026#34;: \u0026#34;2016-05\u0026#34; } ], \u0026#34;skills\u0026#34;: [ \u0026#34;JavaScript\u0026#34;, \u0026#34;React\u0026#34;, \u0026#34;Node.js\u0026#34;, \u0026#34;Microservices\u0026#34;, \u0026#34;Docker\u0026#34; ], \u0026#34;certifications\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;AWS Certified Solutions Architect\u0026#34;, \u0026#34;authority\u0026#34;: \u0026#34;Amazon Web Services\u0026#34;, \u0026#34;issueDate\u0026#34;: \u0026#34;2021-03\u0026#34;, \u0026#34;expirationDate\u0026#34;: \u0026#34;2024-03\u0026#34; } ], \u0026#34;recommendations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Jane Smith\u0026#34;, \u0026#34;relationship\u0026#34;: \u0026#34;Former Manager\u0026#34;, \u0026#34;recommendationText\u0026#34;: \u0026#34;John is an outstanding software engineer with exceptional leadership skills.\u0026#34; } ] } 그러나 이런 데이터를 관계형 데이터베이스에 저장하려면, 객체를 테이블로 변환해야 한다. 이러인해 많은 테이블, 스키마 들이 생기게 되고 이로 인해 지역성(locality)이 떨어지게 된다. 예를들어 profile, experience 등의 테이블이 생겨나게 되고 조회를 위해서 매번 조인해야 한다. 물론 이렇게 저장하고 관리하는게 모든 면에서 훌륭하지는 않다. 다대일이나 다대다 관계를 표현하는 부분에서는 관계형 데이터베이스가 더 효율적이다. id를 통해 참조하는 방식은 모호함을 회피하는데 좋다. (이름 같은 다른 도시가 있을 경우) 갱신을 위한 비용이 적다. 역조건으로 검색하는 경우 인덱스와 조인을 통해 빠르게 검색할 수 있다. 관계형 데이터베이스와 오늘날의 문서 데이터베이스 바로 위에 다뤘던 내용과 관련된 내용이다. 요약하면 문서 데이터 모델은 스키마 유연성, 지역성이 높고 그부분에 대한 성능으로 어필하고 관계형 데이터베이스는 다대일, 다대다 관계를 표현하는데 효율적이다.\n그래도 일반적으로는 관계형 데이터베이스가 \u0026lsquo;최근\u0026rsquo; 어플리케이션들의 코드를 복잡하게 만드는 경향이 있다 기본적으로 매번 데이터를 조인해야 어플리케이션 모델을 생성 할 수 있기 때문이다. 책도 이부분에 대한 내용에 어느 정도 동의를 하고 있다. 물론 ORM들이 아마도 최근에 더 활발하게 사용되고 있는 부분을 고려해야 할 수 있기는 한 것 같다.\n반대로 문서형 데이터베이스 모델들은 상대적으로 rdb보다 코드를 간단하게 만들어 주는 것은 사실인 것 같다. 그러나 이러한 모델들은 다대일, 다대다 관계를 표현하는데 비효율적이다. 비정규화된 데이터로 중북을 감수해야 하고 데이터 일관성을 위한 추가적인 코드 작업이 필요하다. 추가적으로 문서모델은 스키마유연성이 높다. 그렇다고 schemaless하다고 표현하기에는 오해의 소지가 있을 수 있다. \u0026lsquo;읽는\u0026rsquo; 작업에서는 그래도 어느정도의 스키마를 가정한다. (암묵적으로) 그러나 \u0026lsquo;쓰는\u0026rsquo; 작업에서는 스키마가 유연하다. (쓰기 스키마를 가진다고 표현했다.) 마지막으로 지역성에 대한 고려는 조회 한번에 거의 모든 데이터를 사용하는 경우는 지역성이 높은 모델이 훨씬 더 효율적이다. 데이터베이스 질의 선언형 질의와 명령형 질의, 그리고 맵리듀스 질의에 대한 내용이 나온다. 선언형 질의와 명령형 질의에 대한 내용이 이해가 잘 되지 않아서 좀 더 공부가 필요할 것 같다. (선언형 질의와 명령형 질의에 대한 내용 추후 작성 예정)\n맵리듀스 질의\n함수형 프로그래밍에서 나온 아이디어이며 함수형 프로그래밍의 맵, 리듀스를 알아야 한다.\n함수형 프로그래밍에서 map은 컬렉션의 각 요소에 동일한 함수를 적용하여 새로운 컬렉션을 생성하는 함수이다. 각 요소가 독립적으로 처리되기 때문에 병렬 처리에도 용의하다. reduce는 컬렉션의 모든 요소를 하나의 값으로 결합하는 함수이다. 여러개의 값을 결합해서 최종 결과를 도출한다. ","permalink":"http://localhost:1313/_wiki/2%EC%9E%A5/","summary":"데이터 모델은 아마도 소프트웨어 개발에서 제일 중요한 부분일 것이다. 왜냐하면 데이터 모델은 소프트웨어가 어떻게 작성됐는지 뿐만 아니라, 문제를 어떻게 생각해야 하는지에 지대한 영향을 미치기 때문이다.\n대부분의 애플리케이션은 하나의 데이터 모델을 다른 데이터 모델 위에 계층을 둬서 만든다. 각 계층의 핵심적인 문제는 다음 하위 계층 관점에서 데이터 모델을 표현하는 것이다. 참고로 레이어 패턴은 하나의 레이어가 직전 레이어의 성립을 전제로 존재하고, 그러한 레이어들로 이루어진 구조를 말한다.\n무튼 이번 장에서는 아래와 같은 것들을 살펴본다.","title":"데이터 모델과 질의 언어 📚"},{"content":"블로그를 유지보수하며 블로그를 유지보수(?)하면서 참 css도 css인데 글을 너무 두서없이 쓰기도 하고, 레이아웃도 너무 두서없이 바꾸기도 하고, 무튼 참 난잡하다는 생각이 들었다. 그래서 약간 스스로와의 약속처럼 가이드라인을 작성해보려고 한다. 글 작성 관련 h1과 타이틀 둘 다 나오면 뭔가 헤딩이 너무 많아 보여서 별로라서 지나치게 아랫 번호의 헤딩을 쓰는 습관 고치기.(h2로 글을 잘 나눠 쓴다를 전제로 해야겠다.) 백틱과 코드블럭을 너무 많이 쓴다. 꼭 필요한 경우에만 써야겠다. hr 라인을 h2마다 붙이자 \u0026ldquo;내가 다시 볼 만 한 글을 쓰기\u0026rdquo; vs \u0026ldquo;읽거나 공부하는데 정리하느라 너무 많은 시간을 쏟지 않기\u0026rdquo; 중에서 중심잡기가 어렵다. 글 내용 관련 목적이 분명한 글쓰기를 해야겠다. 모르는 부분에 대해서 뭉게는 습관을 고치자. (모르면 모른다고 모르는대로 쓰기) 그냥 다시 볼 사람은 나밖에 없는데, 이해가 안된부분을 제대로 명시하지 않거나, 내가 이걸 모르고 있었다거나 하는 부분을 괜히 공개하는 것 같아서 뭉개는 습관을 고치자. 내가 다시 볼 때 보기 좋은 글을 쓰자. (이 블로그의 목적은 개인 아카이브용이다.) ","permalink":"http://localhost:1313/_wiki/%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%9E%91%EC%84%B1-%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8/","summary":"사실 그냥 나 혼자 지켜야 할 가이드라인 🤔","title":"블로그 작성 가이드라인(지속적으로 보충할 문서!) 📝"},{"content":"데이터 중심 애플리케이션 설계 1장 00 머리말 환경에 대한 이야기를 한다. 머리말에서는 최근 사업적으로는 클라우드와 saas 환경, 하드웨어 적으로는 cpu클럭이 더이상 오르지 않고 멀티코어가 표준이 된 환경을 이야기하며 병렬 처리에 대한 환경을 강조한다. 위의 예시를 데이터 중심적 이라고 정의하며 반대로 cpu사이클이 병목인경우를 계산 중심적이라고 정의한다 이 책은 (\u0026hellip;) 데이터 시스템의 기초가 되는 다양한 원리와 트레이드오프에 대해 논의한다. 데이터 시스템 아키텍처와 데이터 중심 애플리케이션으로 데이터 시스템을 통합하는 방법을 주로 다룬다.\n이 책의 개요\n이책은 크게 3부로 구성되어 있다.\n1부에서는 데이터 중심 애플리케이션 설계를 뒷받침하는 금본 개념을 설명한다. 2부에서는 여러 장비에 데이터를 분산하여 저장하는 부분을 설명하다. 3부에서는 특정 데이터셋에서 다른 데이터셋을 파생하는 시스템을 설명한다. 01 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션 오늘날 많은 어플리케이션은 계선중심적이 아니라 데이터 중심적이라서, 데이터의 양, 데이터의 복잡도, 데이터의 변화 속도 등이 주요 해결해야할 이슈이다.\n데이터 시스템이 어플리케이션의 요구에 따라 제공해야할 핵심 기능은 아래와 같이 추상화 되어 있다.\nDatabase Cache Seach Index Stream processing Batch processing 데이터 시스템에 대한 생각 일반적으로 db와 큐, 캐시와 같은 것들은 다른 범주에 속하는 단일 도구들로 생각한다. 하지만 표면적으로 비슷하더라도 각각은 매우 다른 접근 패턴을 가지고 있고, 최근에 만들어졌는데 심지어 특정한 유즈케이스에 특화된 컴포넌트들이기 때문에 전통적인 데이터 시스템 분류로 접근하면 안된다. 그리고 점점 더 많은 애플리케이션들이 단일도구로는 핸들링 할 수 없는 복잡한 요구사항을 가지고 있다. 요구사항을 태스크로 나누고 해당 태스크들에 위에 설명한 각각의 단일 도구들에 맡기고 전체적인 실행 흐름을 애플리케이션 코드로 제어한다. 그래서 위의 각각의 단일 도구들을 애플리케이션 코드로 제어하는 개발자는 데이터 시스템 설계자이기도 하며, 각각의 단일 도구들 역시 데이터 시스템으로 봐야 한다.\n그리고, 이러한 데이터시스템의 가장 주요한 관심사는 세가지로 분류된다.\n신뢰성 (Reliability) 하드웨어나 소프트웨어 결함, 심지어 인적오류같은 역경에 직면하더라도, 시스템은 지속적으로 올바르게 동작한다.\n소프트웨어의 경우 신뢰 할 수 있다라는 언사에 대한 일반적인 기대치는 아래와 같다.\n애플리케이션은 사용자가 기대한 기능을 수행한다. 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다. 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다. 시스템은 허가되지 않은 접근과 오남용을 방지한다. 결함(fault) 에 대해서.\n결함과 장애 그리고 내결함성에 대해서 이해해야 한다. 먼저 결함과 장애는 동일하지 않다. 결함은 사양에서 벗어난 시스템의 한 구성요소로 정의되지만, 장에는 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 상황을 이야기한다.\n그리고 결함은 모든 시스템에 필연적으로 존재한다. 예를들어 지진과 홍수와 같은 자연재해로 인해 서버가 파괴되었을 때 웹 호스팅을 이어나갈 수 없다. 결론적으로는 결함이 장애로 이어지지 않도록 내결함성(fault-tolerent), 탄력성(resilient)를 갖춰야 한다.\n그 이유는 모든 결함을 예방할 수 없기 때문인데, 그래서 보통은 모든것을 예방한다기 보단 내결함성을 갖는것을 추구한다. (물론 한번의 결함으로 인해 복구가 불가능한 피해를 입을 수 있는 보안같은 것들은 예방이 중요하다.)\n하드웨어 결함\n하드웨어 평균 장애시간(mean time to faillure, MTTF)는 평균적으로 10~50년으로 보고됐다. 따라서 10,000개의 디스크로 구성된 저장 클러스터는 평균적으로 하루에 한개의 디스크가 죽는다고 예상해야한다.\n첫 번째 대응으로 하드웨어 컴포넌트에 중복을 추가하는 방법이 일반적이다.\n전원 컴포넌트라면 발전기와 건전지가 있고, 네트워크 컴포넌트라면 다중화된 네트워크 인터페이스가 있다.\n당연히 비용이 엄청나게 들어가는 일이라, 고가용성을 위한 비용을 지불할 수 있는 소프트웨어에 사용됐었다.\n하지만 클라우드가 보편화 되었고, AWS와 같은 클라우드 서비스들은 단일 장비의 신뢰성보다 유연성과 탄력성을 주요 관심사로 삼는다.\n즉 AWS의 단일 인스턴스는 쉽게 죽지만, 다른 인스턴스로 쉽게 대체할 수 있다.\n소프트웨어 오류\n하드웨어 결함은 보통 무작위적이고, 서로 독립적이다. 즉 특정 한 장비의 디스크에 장애가 있다고 해서 다른 장비의 디스크에 장애가 발생하지 않는다는 뜻이다. 반면 소프트웨어 결함은 보통 시스템 전체에 영향을 미친다.\n소프트웨어 결함은 보통 무작위적이지 않다. 즉, 특정한 조건에서만 발생한다.\n소프트웨어 결함은 보통 신속한 해결책이 없다. (주의깊게 생각하기, 빈틈없는 테스트, 프로세스 격리와 죽은 프로세스의 재시작 허용, 모니터링 \u0026hellip;)\n인적 오류\n장비의 결함으로 인한 장애율은 보통 10~25% 선이다. 반면 사람은 최선의 의도를 갖고 있어도 미덥지 않다.\n신뢰성은 얼마나 중요할까? \u0026ldquo;원자력 발전소\u0026rdquo;, \u0026ldquo;항공 관제 시스템\u0026rdquo;, \u0026ldquo;몇만명의 몇년치 추억을 보관한 저장소 서비스\u0026rdquo; 만큼\u0026hellip;\n확장성 시스템이 현재 안정적으로 동작한다고 해서 미래에도 안정적으로 동작한다는 보장은 없다. 확장성은 증가한 부하에 대처하는 시스템 능력을 설명하는 데 사용하는 용어지만, 시스템에 부여하는 일차원적인 표식이 아니다.\n\u0026ldquo;X는 확장 가능하다\u0026rdquo;, \u0026ldquo;Y는 확장성이 없다\u0026rdquo; - (X)\n\u0026ldquo;시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가\u0026rdquo; - (O) \u0026ldquo;추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?\u0026rdquo; - (O)\n부하 기술하기\n먼저 부하를 정의하고 파악하기 위해서 load parameter를 기술해야 한다.\n대표적인 예시로, 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률 등이 될 수 있다.\n병목이 있다면 특정 하나의 파라미터가, 그게 아니라면 해당 값들의 평균이 중요 할 수 있다.\n부하 기술하기 tweeter 예제\n# 트위터의 주요 두가지 동작 트윗 작성 - 평균 초당 4.6k, 피크 초당 12k 홈 타임라인 - 초당 300k 트윗 작성은 핸들링 하기 쉽지만, 팬아웃이 문제였다고 한다.\n1번 방식 - 간단히 트윗을 전역 컬렉션에 삽입 (타임라인 조회시 팔로우하는 모든 사람을 찾고, 이사람들의 모든 트윗을 찾아 시간순으로 정렬해서 합치기)\nSELECT tweets.*, users.* FROM tweets JOIN users ON tweets.sender_id = users.id JOIN follows ON follows.followee_id = users.id WHERE follows.follower_id = current_user 엄청난 부하가 예상되는 쿼리!\n2번 방식 - 개별 사용자의 홈 타임라인 캐시를 유지하는 방식. (사용자가 트윗을 작성하면 해당 사용자를 팔로우하는 모든 사람을 찾고 각자의 홈 타임라인 캐시에 새 트윗 삽입)\n쓰기 시점에 작업을 부가적으로 하면서 조회 부담을 극단적으로 줄이는 방식!\n결론적으로 트위터는 타임라인 조회 건수가 압도적으로 많기 때문에, 후자가 맞는 설계였다 문제는 2번 방식은 작성에 부하가 매우 커진다는 것 이었는데, 평균값은 75명 정도의 팔로워가 있어 4.6k의 쓰기가 345k 건의 쓰기로 이어지는데다가 진짜 문제는 분포였다. 특정 사용자의 경우 3천만이 넘는 팔로워를 가지고 있었다.\n트위터 결론 1번과 2번의 혼합 방식을 사용한다. 다만 2번방식에서 유명한 사용자의 트윗은 팬아웃에서 빠지고, 1번 방식으로 데이터를 로드하는 시점에 가져온다고 한다.\n성능 기술하기 부하 매게변수를 잘 기술해두면 아래와 같은 테스트들이 가능하다.\n부하 매개변수를 증가시키고, 시스템 자원을 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까? 부하 매개변수를 증가시켰을 때 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까? 두 질문 모두 성능 수치가 필요한데, 하둡과 같은 일괄 처리 시스템은 처리량이 관심사일것이고, 온라인 시스템의 중요한 사항은 응답 시간일 것이다. 책에서는 응답 시간에 대한 이야기를 위주로 한다.\n먼저 응답시간은 측정 가능한 값의 분포로 생각해야 한다.\n응답 시간에 대한 이 책의 주요한 관점\n보통 평균 시간을 참고하는건 좋은 생각이 아니다. 그보다는 중앙값과 같은 백분위값을 이용하는게 좋다. (예를 들어 가장 중간값의 요청이 200ms 가 걸렸다면, 절반의 사용자는 200ms이내에 응답을 받았고, 반대도 마찬가지이다.) 상위 하위 백분위값으로 주요 지표를 추려갈 수 있다. 꼬리 지연시간 (tail latency)는 생각보다 중요한 지표이다. 가장 비싼 요청을 보낸 사용자는 가장 주요한 고객일 확률이 높다. 그렇다고 최상위의 백분위를 참고하는것은 최적화에 너무 큰 비용이 들거나 임의 이벤트의 영향을 받을 수 있기에 참고하기에는 너무 지엽적인 지표이다. 큐 대기 지연은 느리게 응답받은 요청건의 상당수를 차지한다. (오래걸리는 요청이 먼저 온 케이스) 6번과 같은 이유로 클라이언트사이드의 응답시간 측정이 주요하다. 부하 대응 접근 방식 다수의 장비에 stateless한 서비스를 배포하는일은 상당히 간단한다. 하지만 단일 노드에 상태 유지 데이터 시스템을 분산 설치하는일은 아주 많은 복잡도가 추가적으로 발생한다. 이런 이유로 데이터 시스템을 분산 설치하는 일은 아주 많은 복잡도가 추가적으로 발생한다. 이런 이유로 확장 비용이나 데이터베이스를 분산으로 만들어야 하는 고가용성 요구가 있을 때 까지 단일 노드에 데이터베이스를 유지하는것이 최근까지의 통념이다.\n특정 애플리케이션에 적합한 확장성을 갖춘 아키텍처는 주요 동작이 무없이고 잘 하지 않는 동작이 무엇인지에 대한 가정을 바탕으로 구축한다. 이 가정이 잘못되면 확장에 대한 엔지니어링 노력은 헛수고가 되고 최악의 경우 역효과를 낳는다.\n유지보수성 운용성: 운영의 편리함 만들기\n좋은 운영은 종종 나쁜 소프트웨어의 제약을 피하는 대안이 될 수 있다. 하지만 좋은 소프트웨어라도 나쁘게 운영할 경우 작동을 신뢰할 수 없다.\n좋은 운영성이란 동일하게 반복되는 태스크를 쉽게 수행하게끔 만들어 운영팀이 고부가가치 활동에 노력을 집중한다는 의미이다.\n이해하기 어려운 내용은 없고 기술적인 면이 있는 챕터라 책의 디테일한 부분을 발췌하지는 않았다.\n단순성: 복잡도 관리\n최상의 도구는 추상화다. 깔끔하고 직관적인 외관 아래로 많은 세부 구현을 숨길수 있다. 예를 들어, 고수준 프로그래밍 언어는 기계언어, cpu 레지스터, 시스템콜을 숨긴 추상화다. SQL은 디스크에 기록하고 메모리에 저장한 복잡한 데이터 구조와 다른 클라이언트의 동시 요청과 고장 후 불일치를 숨긴 추상화다.\n발전성 : 변화를 쉽게 만들기\n애자일과 TDD와 같은 좋은 이야기들..\n정리 데이터 시스템을 컴포넌트로 나누고 그 흐름을 어플리케이션의 흐름으로 제어하기 때문에 어플리케이션 설계는 데이터 시스템 설계와 같다 가 주요한 내용인것 같은데 아직 구체적인 이야기는 나오지 않았다. 확장성을 설명하는 접근 방식이 좋았다. 주요 지표를 설정하고 그 지표에 따라서 확장에 대응하는 실제 예시를 통해 실전적인 고민을 하는 부분이 좋았다. ","permalink":"http://localhost:1313/_wiki/1%EC%9E%A5/","summary":"데이터 중심 애플리케이션 설계 1장 00 머리말 환경에 대한 이야기를 한다. 머리말에서는 최근 사업적으로는 클라우드와 saas 환경, 하드웨어 적으로는 cpu클럭이 더이상 오르지 않고 멀티코어가 표준이 된 환경을 이야기하며 병렬 처리에 대한 환경을 강조한다. 위의 예시를 데이터 중심적 이라고 정의하며 반대로 cpu사이클이 병목인경우를 계산 중심적이라고 정의한다 이 책은 (\u0026hellip;) 데이터 시스템의 기초가 되는 다양한 원리와 트레이드오프에 대해 논의한다. 데이터 시스템 아키텍처와 데이터 중심 애플리케이션으로 데이터 시스템을 통합하는 방법을 주로 다룬다.\n이 책의 개요","title":"데이터 중심 애플리케이션 설계 1장"},{"content":"데이터 중심 애플리케이션 설계 1부 데이터 시스템의 기초\n처음 4개의 장에서는 데이터 시스템이 잔일 장비거나 여러 클러스터 장비에 분산됐거나 상관없이 모든 상황에서 적용되는 기본 개념을 알아본다.\n[[1장]] : 신뢰성, 확장성, 유지보수성같은 단어의 실제 의미와 이같은 목표를 달성하기 위해 어떻게 해야하는지 [[2장]] : 데이터 모델과 질의 언어, 데이터 모델의 종류와 각 모델이 어떤 상황에 적합한지 [[3장]] : 저장소와 검색 [[4장]] : 부호화와 발전 [[5장]] : 분산 데이터 [[6장]] : 파티셔닝 [[7장]] : 트랜잭션 [[10장]] : 일괄 처리 [[11장]] : 스트림 처리 보조 인덱스는 데이터 레코드를 직접 가리키거나 해당 레코드의 기본 키를 저장한다. 데이터 레코드 포인터는 힘파일 또는 iot의 오프셋이다. 여러 보조 인덱스가 같은 레코드를 가리킬 수 있으며, 하나의 레코드는 여러 다른 필드로 식별될 수 있고 다양한 인덱스를 사용해 검색할 수 있다. 기본 인덱스 파일은 키별로 하나의 레코드만 가리키는 반면, 보조 인덱스는 키별로 여러 레코드를 가리킬 수도 있다.\n","permalink":"http://localhost:1313/_wiki/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%91%EC%8B%AC-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EC%84%A4%EA%B3%84/","summary":"데이터 중심 애플리케이션 설계 1부 데이터 시스템의 기초\n처음 4개의 장에서는 데이터 시스템이 잔일 장비거나 여러 클러스터 장비에 분산됐거나 상관없이 모든 상황에서 적용되는 기본 개념을 알아본다.\n[[1장]] : 신뢰성, 확장성, 유지보수성같은 단어의 실제 의미와 이같은 목표를 달성하기 위해 어떻게 해야하는지 [[2장]] : 데이터 모델과 질의 언어, 데이터 모델의 종류와 각 모델이 어떤 상황에 적합한지 [[3장]] : 저장소와 검색 [[4장]] : 부호화와 발전 [[5장]] : 분산 데이터 [[6장]] : 파티셔닝 [[7장]] : 트랜잭션 [[10장]] : 일괄 처리 [[11장]] : 스트림 처리 보조 인덱스는 데이터 레코드를 직접 가리키거나 해당 레코드의 기본 키를 저장한다.","title":"데이터 중심 애플리케이션 설계 스터디"},{"content":"AeroSpace Cheat Sheet 🧊️ https://www.josean.com/posts/how-to-setup-aerospace-tiling-window-manager https://nikitabobko.github.io/AeroSpace/commands\noption + , : 타일링 레이아웃/아코디언 레이아웃 전환 option + q : 터미닐 워크스페이스로 이동 option + w : 웹 브라우저 워크스페이스로 이동 option + e : gpt 워크스페이스로 이동 option + r : 채팅앱을 위한 워크스페이스로 이동 ","permalink":"http://localhost:1313/_wiki/aerospace-macos/","summary":"i3 like tiling tool for macos","title":"AeroSpace Cheat Sheet"},{"content":"Settings for AeroSpace 🧊️ # Place a copy of this config to ~/.aerospace.toml # After that, you can edit ~/.aerospace.toml to your liking # It\u0026#39;s not necessary to copy all keys to your config. # If the key is missing in your config, \u0026#34;default-config.toml\u0026#34; will serve as a fallback # You can use it to add commands that run after login to macOS user session. # \u0026#39;start-at-login\u0026#39; needs to be \u0026#39;true\u0026#39; for \u0026#39;after-login-command\u0026#39; to work # Available commands: https://nikitabobko.github.io/AeroSpace/commands after-login-command = [] # You can use it to add commands that run after AeroSpace startup. # \u0026#39;after-startup-command\u0026#39; is run after \u0026#39;after-login-command\u0026#39; # Available commands : https://nikitabobko.github.io/AeroSpace/commands after-startup-command = [] # Start AeroSpace at login start-at-login = true # Normalizations. See: https://nikitabobko.github.io/AeroSpace/guide#normalization enable-normalization-flatten-containers = true enable-normalization-opposite-orientation-for-nested-containers = true # See: https://nikitabobko.github.io/AeroSpace/guide#layouts # The \u0026#39;accordion-padding\u0026#39; specifies the size of accordion padding # You can set 0 to disable the padding feature accordion-padding = 30 # Possible values: tiles|accordion default-root-container-layout = \u0026#39;tiles\u0026#39; # Possible values: horizontal|vertical|auto # \u0026#39;auto\u0026#39; means: wide monitor (anything wider than high) gets horizontal orientation, # tall monitor (anything higher than wide) gets vertical orientation default-root-container-orientation = \u0026#39;auto\u0026#39; # Possible values: (qwerty|dvorak) # See https://nikitabobko.github.io/AeroSpace/guide#key-mapping key-mapping.preset = \u0026#39;qwerty\u0026#39; # Mouse follows focus when focused monitor changes # Drop it from your config, if you don\u0026#39;t like this behavior # See https://nikitabobko.github.io/AeroSpace/guide#on-focus-changed-callbacks # See https://nikitabobko.github.io/AeroSpace/commands#move-mouse on-focused-monitor-changed = [\u0026#39;move-mouse monitor-lazy-center\u0026#39;] on-focus-changed = \u0026#34;move-mouse window-lazy-center\u0026#34; # Gaps between windows (inner-*) and between monitor edges (outer-*). # Possible values: # - Constant: gaps.outer.top = 8 # - Per monitor: gaps.outer.top = [{ monitor.main = 16 }, { monitor.\u0026#34;some-pattern\u0026#34; = 32 }, 24] # In this example, 24 is a default value when there is no match. # Monitor pattern is the same as for \u0026#39;workspace-to-monitor-force-assignment\u0026#39;. # See: https://nikitabobko.github.io/AeroSpace/guide#assign-workspaces-to-monitors [gaps] inner.horizontal = 10 inner.vertical = 10 outer.left = 10 outer.bottom = 10 outer.top = 10 outer.right = 10 # \u0026#39;main\u0026#39; binding mode declaration # See: https://nikitabobko.github.io/AeroSpace/guide#binding-modes # \u0026#39;main\u0026#39; binding mode must be always presented [mode.main.binding] # All possible keys: # - Letters. a, b, c, ..., z # - Numbers. 0, 1, 2, ..., 9 # - Keypad numbers. keypad0, keypad1, keypad2, ..., keypad9 # - F-keys. f1, f2, ..., f20 # - Special keys. minus, equal, period, comma, slash, backslash, quote, semicolon, backtick, # leftSquareBracket, rightSquareBracket, space, enter, esc, backspace, tab # - Keypad special. keypadClear, keypadDecimalMark, keypadDivide, keypadEnter, keypadEqual, # keypadMinus, keypadMultiply, keypadPlus # - Arrows. left, down, up, right # All possible modifiers: cmd, alt, ctrl, shift # All possible commands: https://nikitabobko.github.io/AeroSpace/commands # You can uncomment this line to open up terminal with alt + enter shortcut # See: https://nikitabobko.github.io/AeroSpace/commands#exec-and-forget # alt-enter = \u0026#39;exec-and-forget open -n /System/Applications/Utilities/Terminal.app\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#layout alt-slash = \u0026#39;layout tiles horizontal vertical\u0026#39; alt-comma = \u0026#39;layout accordion horizontal vertical\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#focus alt-h = \u0026#39;focus left\u0026#39; alt-j = \u0026#39;focus down\u0026#39; alt-k = \u0026#39;focus up\u0026#39; alt-l = \u0026#39;focus right\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#move alt-shift-h = \u0026#39;move left\u0026#39; alt-shift-j = \u0026#39;move down\u0026#39; alt-shift-k = \u0026#39;move up\u0026#39; alt-shift-l = \u0026#39;move right\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#resize alt-shift-minus = \u0026#39;resize smart -50\u0026#39; alt-shift-equal = \u0026#39;resize smart +50\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#workspace alt-1 = \u0026#39;workspace 1\u0026#39; alt-2 = \u0026#39;workspace 2\u0026#39; alt-3 = \u0026#39;workspace 3\u0026#39; alt-4 = \u0026#39;workspace 4\u0026#39; alt-5 = \u0026#39;workspace 5\u0026#39; alt-q = \u0026#39;workspace T\u0026#39; # for Terminal alt-w = \u0026#39;workspace B\u0026#39; # for Browsers alt-e = \u0026#39;workspace G\u0026#39; # for GPT alt-r = \u0026#39;workspace C\u0026#39; # for Chat alt-m = \u0026#39;workspace M\u0026#39; # for Music alt-n = \u0026#39;workspace N\u0026#39; # for Notes # See: https://nikitabobko.github.io/AeroSpace/commands#move-node-to-workspace alt-shift-1 = \u0026#39;move-node-to-workspace 1\u0026#39; alt-shift-2 = \u0026#39;move-node-to-workspace 2\u0026#39; alt-shift-3 = \u0026#39;move-node-to-workspace 3\u0026#39; alt-shift-4 = \u0026#39;move-node-to-workspace 4\u0026#39; alt-shift-5 = \u0026#39;move-node-to-workspace 5\u0026#39; alt-shift-q = \u0026#39;move-node-to-workspace T\u0026#39; alt-shift-w = \u0026#39;move-node-to-workspace B\u0026#39; alt-shift-e = \u0026#39;move-node-to-workspace G\u0026#39; alt-shift-r = \u0026#39;move-node-to-workspace C\u0026#39; alt-shift-m = \u0026#39;move-node-to-workspace M\u0026#39; alt-shift-n = \u0026#39;move-node-to-workspace N\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#workspace-back-and-forth alt-tab = \u0026#39;workspace-back-and-forth\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#move-workspace-to-monitor alt-shift-tab = \u0026#39;move-workspace-to-monitor --wrap-around next\u0026#39; # See: https://nikitabobko.github.io/AeroSpace/commands#mode alt-shift-semicolon = \u0026#39;mode service\u0026#39; alt-shift-f = \u0026#39;fullscreen\u0026#39; # \u0026#39;service\u0026#39; binding mode declaration. # See: https://nikitabobko.github.io/AeroSpace/guide#binding-modes [mode.service.binding] esc = [\u0026#39;reload-config\u0026#39;, \u0026#39;mode main\u0026#39;] r = [\u0026#39;flatten-workspace-tree\u0026#39;, \u0026#39;mode main\u0026#39;] # reset layout #s = [\u0026#39;layout sticky tiling\u0026#39;, \u0026#39;mode main\u0026#39;] # sticky is not yet supported https://github.com/nikitabobko/AeroSpace/issues/2 f = [\u0026#39;layout floating tiling\u0026#39;, \u0026#39;mode main\u0026#39;] # Toggle between floating and tiling layout backspace = [\u0026#39;close-all-windows-but-current\u0026#39;, \u0026#39;mode main\u0026#39;] alt-shift-h = [\u0026#39;join-with left\u0026#39;, \u0026#39;mode main\u0026#39;] alt-shift-j = [\u0026#39;join-with down\u0026#39;, \u0026#39;mode main\u0026#39;] alt-shift-k = [\u0026#39;join-with up\u0026#39;, \u0026#39;mode main\u0026#39;] alt-shift-l = [\u0026#39;join-with right\u0026#39;, \u0026#39;mode main\u0026#39;] [[on-window-detected]] if.app-id = \u0026#39;com.googlecode.iterm2\u0026#39; run = \u0026#39;move-node-to-workspace T\u0026#39; [[on-window-detected]] if.app-id = \u0026#39;com.google.Chrome\u0026#39; run = \u0026#39;move-node-to-workspace B\u0026#39; [[on-window-detected]] if.app-id = \u0026#39;com.kakao.KakaoTalkMac\u0026#39; run = \u0026#39;move-node-to-workspace C\u0026#39; [[on-window-detected]] if.app-id = \u0026#39;com.tinyspeck.slackmacgap\u0026#39; run = \u0026#39;move-node-to-workspace C\u0026#39; [[on-window-detected]] if.app-id = \u0026#39;com.openai.chat\u0026#39; run = \u0026#39;move-node-to-workspace G\u0026#39; ","permalink":"http://localhost:1313/_wiki/aerospace/","summary":"Settings for AeroSpace 🧊️ # Place a copy of this config to ~/.aerospace.toml # After that, you can edit ~/.aerospace.toml to your liking # It\u0026#39;s not necessary to copy all keys to your config. # If the key is missing in your config, \u0026#34;default-config.toml\u0026#34; will serve as a fallback # You can use it to add commands that run after login to macOS user session. # \u0026#39;start-at-login\u0026#39; needs to be \u0026#39;true\u0026#39; for \u0026#39;after-login-command\u0026#39; to work # Available commands: https://nikitabobko.","title":"AeroSpace Toml"},{"content":"Settings 🧊️ TODO : dotfiles 레포를 만들자!\n[[AeroSpace]] ","permalink":"http://localhost:1313/_wiki/settings/","summary":"Settings 🧊️ TODO : dotfiles 레포를 만들자!\n[[AeroSpace]] ","title":"Settings 🧊️"},{"content":"9.0.0 Error Handling Error는 소프트웨어의 한 요소이다. 당연히 러스트에서도 다양한 방식으로 에러를 핸들링 할 수 있도록 지원한다. 러스트 역시 에러의 가능성과 그에대한 대응을 컴파일 시점에 체크해준다. 러스트는 에러를 두가지로 그룹화한다. recoverable과 unrecoverable 에러로 나누어진다. 다른 언어에서는 해당 에러들을 굳이 구분하지 않고, 모두 exception과 같은 시스템으로 처리한다. 러스트는 이러한 에러를 Result\u0026lt;T, E\u0026gt;와 panic! 매크로를 통해 나눠서 처리한다.\n9.1.0 Unrecoverable Errors with panic! 가끔 우리의 코드에는 안좋은 일들이 일어나고, 그 부분에 대해서 더이상 뭔가를 할 수 없는 경우가 있다. 이러한 경우를 unrecoverable 에러라고 하며, 러스트는 이러한 에러를 처리하기 위해 panic! 매크로를 제공한다.\nfn main() { panic!(\u0026#34;crash and burn\u0026#34;); } panic! 매크로는 프로그램을 즉시 종료하고, 스택을 걷어내고, 부모 프로세스에게 알린다. RUSST_BACKTRACE=1 환경변수를 사용하여 백트레이스를 출력할 수 있다. 9.2.0 Recoverable Errors with Result enum Result\u0026lt;T, E\u0026gt; { Ok(T), Err(E), } Result는 Ok와 Err 두 가지의 열거형을 가지고 있다. Result는 recoverable 에러를 나타내는데 사용된다. use std::fs::File; fn main() { let greeting_file_result = File::open(\u0026#34;hello.txt\u0026#34;); let greeting_file = match greeting_file_result { Ok(file) =\u0026gt; file, Err(error) =\u0026gt; panic!(\u0026#34;Problem opening the file: {error:?}\u0026#34;), }; } ","permalink":"http://localhost:1313/_wiki/error-handling/","summary":"9.0.0 Error Handling Error는 소프트웨어의 한 요소이다. 당연히 러스트에서도 다양한 방식으로 에러를 핸들링 할 수 있도록 지원한다. 러스트 역시 에러의 가능성과 그에대한 대응을 컴파일 시점에 체크해준다. 러스트는 에러를 두가지로 그룹화한다. recoverable과 unrecoverable 에러로 나누어진다. 다른 언어에서는 해당 에러들을 굳이 구분하지 않고, 모두 exception과 같은 시스템으로 처리한다. 러스트는 이러한 에러를 Result\u0026lt;T, E\u0026gt;와 panic! 매크로를 통해 나눠서 처리한다.\n9.1.0 Unrecoverable Errors with panic! 가끔 우리의 코드에는 안좋은 일들이 일어나고, 그 부분에 대해서 더이상 뭔가를 할 수 없는 경우가 있다.","title":"러스트 에러 처리하기"},{"content":"burrow-checker에 대해 도움이 될 만 한 내용을 정리한 문서, rust-in-action 내용을 참고하여 작성하였습니다. 대여 검사는 서로 연결된 세 가지 개념인 수명, 소유권, 대여에 의존한다.\n소유권 : 러스트에서 소유권은 해당 값이 더 이상 필요 없을 때 깨끗이 지우는 것 과 관련이 있다. 수명 : 값에 접근해도 문제없는 기간을 의미한다. 대여 : 값에 접근함을 의미한다. 원래 소유자에게 값을 되돌려 주지 않아도 된다는 점에서 현실의 대여와 헷갈린다. \u0026ldquo;값의 소유자는 하나이며, 프로그램의 많은 다른 부분에서 이 값을 접근하기 위한 장치\u0026quot;를 생각하면 조금 더 편하다. 01. Preriquisite #[derive(Debug)] struct SomeStruct { some_field: u64, } fn do_not_take_ownership(primitive_type_case_param: u64) { println!(\u0026#34;do nothing!\u0026#34;); } fn take_ownership(some_struct: SomeStruct) { println!(\u0026#34;do nothing!\u0026#34;); } fn main() { let fine_case: u64 = 1; let ownership_error_case: SomeStruct = SomeStruct { some_field: 1 }; do_not_take_ownership(fine_case); take_ownership(ownership_error_case); println!(\u0026#34;fine_case: {}\u0026#34;, fine_case); println!(\u0026#34;ownership_error_case: {:?}\u0026#34;, ownership_error_case); } error[E0382]: borrow of moved value: `ownership_error_case` --\u0026gt; src/main.rs:22:44 | 16 | let ownership_error_case: SomeStruct = SomeStruct { some_field: 1 }; | -------------------- move occurs because `ownership_error_case` has type `SomeStruct`, which does not implement the `Copy` trait ... 19 | take_ownership(ownership_error_case); | -------------------- value moved here ... 22 | println!(\u0026#34;ownership_error_case: {:?}\u0026#34;, ownership_error_case); | ^^^^^^^^^^^^^^^^^^^^ value borrowed here after move | note: consider changing this parameter type in function `take_ownership` to borrow instead if owning the value isn\u0026#39;t necessary --\u0026gt; src/main.rs:10:32 | 10 | fn take_ownership(some_struct: SomeStruct) { | -------------- ^^^^^^^^^^ this parameter takes ownership of the value | | | in this function = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) fine_case는 u64 타입이기 때문에 Copy 트레이트를 구현하고 있어서 do_not_take_ownership 함수에 값을 전달해도 문제가 없다. ownership_error_case는 SomeStruct 타입이기 때문에 Copy 트레이트를 구현하고 있지 않아서 take_ownership 함수에 값을 전달하면 소유권이 이동하게 된다. 그래서 ownership_error_case를 사용하려고 하면 컴파일 에러가 발생한다. 여기까지는 rust 기본 문접 가이드에서 나온 내용이라 어렵지는 않다. } 를 만나면 스코프의 종료와 함께 해당 스코프에 있는 변수(정확히는 스코프 내에서 생성된, 아규먼트를 포함한)들을 drop한다. 값이 범위를 넘어가거나 다른 어떤 이유로 수명이 끝난다면, 파괴자가 호출된다. 파괴자는 값에 대한 참조를 지우고 메모리를 해제함으로써 프로그램으로부터 값의 흔적을 지우는 함다. \u0026hellip; (중략) 이 시스템에 함축된 한 가지 의미는 \u0026ldquo;값은 절대로 소유자보다 오래 지속될 수 없다\u0026rdquo; 는 것이다.\n시스템은 아이디어를 함의하기 때문에 단순히 일어나는 일보다 왜 이렇게 되었을까를 이해하는게 더 중요하다고 생각한다. 개인적인 생각으로는 언어가 아무것도 안하거나 (c/cpp) 가비지 컬렉션같이 성능을 깎아먹는 것 대신, 소유권 시스템을 만들고 컴파일러가 이를 체크하도록 하는 것 자체가 아이디어인 것 같다.(하나의 시스템을 컴파일러가 검사한다면 사용자는 알아서 잘 하겠지!) 02. 소유권 문제 해결하기 러스트의 소유권 시스템은 훌륭하지만, 시스템을 이해하기 전에는 실수하기 십상이다. 그래서 처음 시작할 때 도움되는 네가지 전략은 아래와 같다.\n완전한 소유권이 필요하지 않은 경우에는 참조를 사용한다. 값을 복제한다. 이동 문제를 보조하기 위해 설계된 타입으로 데이터를 감싼다. 사실 \u0026lsquo;장기간 유지되어야 하는 객체 수를 줄일 수 있도록 코드를 리팩토링 한다.\u0026rsquo; 와 같은 해결책도 책에서는 소개하고 있지만, 일반적인 내용이며 예시를 직접 보는게 도움이 될 것 같아 정리하지는 않았다.\n완전한 소유권이 필요하지 않은 경우에는 참조를 사용한다.\n가장 직접적이며 단순한 해결방법이다. \u0026amp; T, \u0026amp; mut T 를 사용한다. 기존에 다른 언어를 배운 사람들에게 익숙한 방법이면서도 러스트 소유권 시스템 룰을 따를 수 있다. 다만 트리나 그래프같은 상황에서 소유권으로 인해 생기는 이슈에는 대응하지 못한다. 값을 복제한다.\n소유권 이전이 문제가 되는 상황에 대해서 또 하나의 간단한 해결책은 값을 복제하는 것이고 크게 두가지 방법이 있다. std::marker::Copy 트레이트를 구현하고 있는 타입은 값이 복사되어 전달된다. 원시 타입과 같은 경우는 CPU 입장에서는 부하가 덜하다는 장점이 있어 보통 Copy 트레이트를 구현하고 있다. 그래서 때로 몇몇 상황에서는 암묵적으로 수행된다는 특징이 있다. 비트 대 비트 사본을 만들기 때문에, 비용이 싸고 값이 동일하다. std::clone::Clone 절대 암묵적일 수 없다. clone() 메서드를 호출해야 한다. 느리고 비쌀 수 있으며, 정의하는 것에 따라서 원래 값과 달라질 수 있다. 데이터를 특별한 타입으로 감싸기.\nRc\u0026lt;T\u0026gt;는 기본적으로 아래와 같이 구현되어 있다. (가장 핵심적인 부분과 그부분을 보기위해 필요한 부분만 정리했다.)\npub struct Rc\u0026lt;T\u0026gt; { ptr: NonNull\u0026lt;RcBox\u0026lt;T\u0026gt;\u0026gt;, // 실제 데이터에 대한 포인터, NonNull은 null이 아닌 포인터를 보장한다. } struct RcBox\u0026lt;T\u0026gt; { strong: Cell\u0026lt;usize\u0026gt;, // Strong 참조 count weak: Cell\u0026lt;usize\u0026gt;, // Weak 참조 count value: T, // 실제 데이터 } impl\u0026lt;T\u0026gt; Rc\u0026lt;T\u0026gt; { // RcBox\u0026lt;T\u0026gt;의 value를 가리키는 포인터를 반환 fn inner(\u0026amp;self) -\u0026gt; \u0026amp;RcBox\u0026lt;T\u0026gt; { unsafe { self.ptr.as_ref() } } } impl\u0026lt;T\u0026gt; Clone for Rc\u0026lt;T\u0026gt; { #[inline] fn clone(\u0026amp;self) -\u0026gt; Rc\u0026lt;T\u0026gt; { unsafe { // strong 카운트 증가 self.inner().inc_strong(); Rc { ptr: self.ptr, } } } } impl\u0026lt;T\u0026gt; Drop for Rc\u0026lt;T\u0026gt; { fn drop(\u0026amp;mut self) { unsafe { if self.inner().dec_strong() == 0 { // strong 카운트가 0이 되면 value를 드롭 ptr::drop_in_place(self.inner_mut().value_mut()); // weak 카운트도 0이면, 메모리를 해제 if self.inner().weak() == 0 { deallocate(self.ptr.as_ptr() as *mut u8); } } } } } 간단하게, Rc\u0026lt;T\u0026gt;는 RcBox\u0026lt;T\u0026gt;를 가리키는 포인터를 가지고 있고, RcBox\u0026lt;T\u0026gt;는 실제 데이터와 참조 카운트를 가지고 있다 Rc\u0026lt;T\u0026gt;는 Clone 트레이트를 구현하고 있어서 clone() 메서드를 호출하면 참조 카운트를 증가시킨다. 그리고 Drop 트레이트를 구현하고 있어서 참조 카운트가 0이 되면 메모리를 해제한다. RefCell\u0026lt;T\u0026gt;도 마찬가지로, 가장 핵심적인 부분과 그부분을 보기위해 필요한 부분만 정리했다.\npub struct RefCell\u0026lt;T: ?Sized\u0026gt; { value: UnsafeCell\u0026lt;T\u0026gt;, // 내부 데이터 (UnsafeCell로 내부 변경 가능) borrow: Cell\u0026lt;isize\u0026gt;, // 현재의 빌림 상태 (불변 빌림: 양수, 가변 빌림: -1) } ","permalink":"http://localhost:1313/_wiki/burrow-checker/","summary":"burrow-checker에 대해 도움이 될 만 한 내용을 정리한 문서, rust-in-action 내용을 참고하여 작성하였습니다. 대여 검사는 서로 연결된 세 가지 개념인 수명, 소유권, 대여에 의존한다.\n소유권 : 러스트에서 소유권은 해당 값이 더 이상 필요 없을 때 깨끗이 지우는 것 과 관련이 있다. 수명 : 값에 접근해도 문제없는 기간을 의미한다. 대여 : 값에 접근함을 의미한다. 원래 소유자에게 값을 되돌려 주지 않아도 된다는 점에서 현실의 대여와 헷갈린다. \u0026ldquo;값의 소유자는 하나이며, 프로그램의 많은 다른 부분에서 이 값을 접근하기 위한 장치\u0026quot;를 생각하면 조금 더 편하다.","title":"burrow-checker에 대한 추가 정리자료"},{"content":"Daily-Log 📝 2024-09-24\n가장 큰 프로젝트가 오픈했고, 오픈 직후의 이슈들도 정리되어 가고 있다. 밀렸던 포스팅들을 하나씩 올리려고 한다. 프로젝트 때문에 몇날 밤을 새웠는데, 몇일 쉬었다고 정신 못차리고 스터디와 사이드 프로젝트를 진행하려고 한다. 그 때문에 러스트 공부를 시급하게 해야한다. 당장 오늘 Rust In Action 복습을 시작했다. 2024-09-25\n러스트 사이드 프로젝트의 교모와 시기가 상당히 타이트 할 것 같다. 10월 초 긴 연휴 내에 각자 필요한 것들을 준비하기로 했다. 최소 서버는 러스트로 구현 할 것 같다 (actix-web) 러스트 문법에 대한 복습을 짧게 마치고, 프레임워크에 대한 공부와 러스트 웹소켓 관련 코드들을 찾아보려고 한다. -09-26\n공부 할 때 알고 있었던 내용에 대한 더 명쾌한 정의가 나오면 쾌감이 쩐다. 해피해킹 키보드를 선물받았다. 나도 일본을 다녀왔는데 구매하지 못했고 선물도 딱히 준비하지 못했는데 미안했다. 키보드에 대한 적응은 사실 필요없었음(카라비너를 이용해서 이미 미니배열에 최적화 되도록 설정들을 사용하고 있었는데 관련해서 해피해킹 사용자들이 어떻게 하나 많이 찾아보고 있었음) 2024-10-07\n키보드의 2번 레이어의 스페이스바를 option키로 바꾸기 2024-10-11\n이펙티브 러스트가 출시됐다, 아마 이 책도 읽으며 포스팅을 작성할까 한다. 이 탬플릿이 좋을 것 같다. Kotlin-in-Action aerospace config 에 아래 설정 추가하기 블로그를 조금 유지보수 했다, 좀 보기 싫었던 css를 수정했다. 새로운 취미? 혹은 목표로 매일 수학 1시간 공부하기를 해볼 예정이다, 그 이유는 아래와 같다. 학창시절에는 수학을 그나마 좋아했지만, 어느 순간 이후로 담을 쌓고 있었고 필요 할 때 마다 필요한부분을 보는정도로 때워왔다. 경제학을 공부할때 미분 조금 뭐 이런식으로.. 그러다가 수학이 꼭 필요한 시점이 금방 오지 않을까? 라는 생각을 해왔는데, 뭔가 진짜 와가는 것 도 같고, 오늘은 특히 하스켈 관련한 포스팅을 보다가 수학이 필요하다는 생각이 들었다.(항상 뭔가를 볼 때 수학적인 내용이 나올 때 마다 가슴한켠을 찌르는데 바빠서 외면해왔다. ) 급한건 선형대수, 이산수학 (그리고 그걸 위한 미적분)이고, 개인적으로 빨리 보고싶은건 수리논리학이다. 그래도 지금은 재활이 필요한 시점이라 마침 적절한 인프런 강의도 있기에 기초대수학으로 시작해보려고 한다. 취미라고 한 이유는 지금 당장 할 일이 많아 죽겠고, 공부할것도 많아 죽겠어서 당장 이게 먼저가 아닌건 분명히 아는데 막연한 불안감과 양심때문에 굳이 하는거라서 그렇다. 선형대수학은 학부때 c를 받았고 그만큼 지루했는데 잘 해내길 바래야겠다. 2024-10-14\n이펙티브 러스트트를 시작하려고한다. 이번 주 수요일까지 간단하게 초기세팅을 완료한 러스트 서버를 띄워야한다. 아마도 axum + mongodb + jwt관련 세팅 추가하고 띄울 것 같다. .ideavimrc 파일 을 만들고 관리해야 겠다, 점점더 dotfiles에 대한 요구가 많아져서 둘 다 같이 빨리 작업해야겠다 2024-10-17\n러스트 axum 서버를 이용한 서버 초기 구현을 끝냈다. 생각보다 훨씬 오래걸렸다. 처음에는 axum관련 코드에 익숙하지 않았고, 이슈 해결하는게 오래걸렸다. 너무 복잡한 boiler_plate template을 선택해서 조금 더 해맸던 것 같다. 마침 layered architecture 패턴으로 된 템플릿 찾아서 그냥 해당 탬플릿으로 바꾸고 나아졌다. model과 model_controller를 기준으로 하고 라우팅 핸들러가 직접 참조하는식으로 하려고 했는데, 잘 안됐다 뭔가 코드가 애매하게 나온다. 기본적으로 아직 상태관리가 익숙하지 않아서 그런 것 같긴 하다 의존성주입 덕분에 편했던 부분을 직접 관리하려고 하니 생각보다 예쁘게 안나와서 일단 기본적으로 구현했다. AppState, Axum의 State 부분을 잘 관리하는 best case코드를 실제로 좀 보고싶은데 아무래도 자료가 조금 부족하다 2024-10-18\n\u0026lsquo;올바른 문제\u0026rsquo;를 \u0026lsquo;올바른 때\u0026rsquo;에 \u0026lsquo;제대로된 방법\u0026rsquo;으로 풀어 가는 사람이 결국 이깁니다\n이번 주말의 목표로는 수학공부를 시작하는것과, dotfiles 레포 만들기가 있다 기대된다. 확장성은 증가한 부하에 대처하는 시스템 능력을 설명하는데 사용하는 용어지만 시스템에 부여하는 일차원적인 표식이 아님을 주의하자. \u0026ldquo;X는 확장 가능하다\u0026rdquo; 또는 \u0026ldquo;Y는 확장성이 없다\u0026rdquo; 같은 말은 의미가 없다. 오히려 확장성을 논한다는 것은 \u0026ldquo;시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?\u0026ldquo;와 \u0026ldquo;추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?\u0026rdquo; 같은 질문을 고려한다는 의미다.\n아주 좋은 관점이자 좋은 문구인 것 같다. (심지어 튜터링중에 써먹기도 너무 좋다) 가끔패턴이나 방법론책(이펙티브 시리즈, 클린코드, 클린아키텍처)나, 특정 패러다임등을 처음 공부하시는 분들이 너무 심취하셔서 \u0026ldquo;~ 패턴을 사용하지 않았으니 안좋은 코드다\u0026rdquo; 라는 식으로 생각하시는 경우가 있는데, 소개해주기 좋은 관점인 것 같다. 2024-10-21\n주말에 수학공부를 시작하지 못했다! \u0026ldquo;내일부터 해야지\u0026rdquo; dotfile은 만들고 있고 만들던 와중에 ideavim도 결국 만져야 할 것 같아서 조금 걸리고 있다. Wezterm으로 갈아타는거에 한눈이 팔렸다. 2024-10-23\n용기를 내서 질문했는데, 너무 따뜻한 답변을 받았다. 뭔가 내가 질문에 생략했던것들에 대해서도 알고 계신 듯 한 느낌을 받았다. 질문의 결과로 머리가 명확해지는 경우가 생각보다 일하면서도 흔치 않은데, 이번에는 그런 느낌을 받았다. 나중에 누군가를 도울 일이 있다면 꼭 오늘을 기억하고 싶다. 2024-10-24\nideavimrc를 만들고, dotfiles 작업을 마무리하려고 한다. 2024-10-26\n내 인생에 가장 위대한 영화로 꼽힐 영화를 봤다. The Wild Robot 그래도 프로그래밍을 하는 사람으로써 절대 일어날 일 없는 일을 이 영화에서 단 한번만 일어나게 해달라고 때 쓰는 애처럼 봤다. 또 한 번 내 인생에서 가장 기억에 남을 순간을 같이해준, 그리고 기꺼이 그러자고 해준 아내에게 감사하다. 인생은 알 수 없는 일이지!\n2024-10-29\nideavim에 익숙해지기 위해서 여러 설정을 들춰보고 좋은쪽으로 수정도 해보고 있고, 와중에 더 좋아보이는 단축키로 원래 nvim 키매핑도 변경해가면서 하고 있다. 두 가지 이슈가 있는데, 블로그의 최근 변경된 문서 항목이 지나치게 늘어지는거랑, 로컬 빔위키가 느려지고 있다는 점이다(프로파일 해봐도 이유가 잘 안잡힌다.) 2024-10-30\n어제 코드크래프터스를 알게되었는데, rust로 redis 구현해보는 가이드가 있어서 그냥 시작했다. 수학공부도 해야하고, 사이드도 해야하는데 일단 덜컥 시작해버렸다. 2024-11-01\nintellij, rustrover, webstorm -\u0026gt; \u0026ldquo;Hide All Tool Windows\u0026rdquo; -\u0026gt; shift + space 2024-11-04\ndotfiles를 만들었다, 단순하게 시작했다(편하더라, 진작할걸!) 이번주는 데일리로그를 다 써 봐야겠다 2024-11-05\n길을 잃은 것 같을 때는, 조금 더 구체적인걸 하는게 나은 것 같다. 이번주 혹은 이번달은 정말 최소한의 스터디와 codecrafters, 코테준비만 하려고 한다. 타임테이블을 조금 만들어야 겠다. 2024-11-06\n레디스 프로젝트가 갈수로 어려워진다, 버퍼로 뭔가를 하는게 오랫만이라 많이 절고있다 2024-11-08\n코테준비는 그냥저냥, 레디스는 재미있게 하고있다. 러스트로 코테준비는 악평이 자자한데 안심심하게 하려면 그렇게라도 해야할까 싶다. 2024-11-16\n2024-11-17\n블로그 글로써의 의의는 달성 하면서도, 내가 공부하거나 책을 읽는 속도에 지장을 주지 않는 정도의 포스팅을 가늠하는게 어려운 것 같다. 2024-11-18\nvimwiki가 느려졌는데, log로는 이유가 잘 확인이 안된다 최악의 경우 하나씩 플러그인들을 내려보며 확인해야 할 것 같은데, 언제하지.. 2024-11-22\n레디스와 코테\u0026hellip; 2024-11-25\n사이드프로젝트는 잊고살면 해커톤이 되어 돌아온다. 코드크래프터스는 교수님같다. 더미응답을 내라며 스테이지를 통과시켜주더니, 진짜 래플리케이션과 데이터 전파를 요구한다. 2024-11-27\nvimwiki 성능이 늦어지는 이슈는 뭔가 태그를 기준으로 발생하는 것 같다. 2024-11-28\n러스트 한국 사용자모임 디코에 올린 질문에 정성스러운 답변을 받았다, 마찬가지로 도움이 받을 때 마다 나도 도움을 줄 수 있는 사람이 되고싶다라는 생각을 하게 된다. 아마 위의 답변을 검토하고 러스트를 진행 할 것 같다. 2024-12-01\n레디스 리팩토링중 푸시를 한번에 하다보면 당일 잔디를 못심는 경우가 있는데, 이거에 연연하는게 참 별로라고 생각도 했다가도 또 이걸 관리하기위해서 하는 부분이 있었어서 뭐라고도 하기 애매한것같기도 오늘 푸시한 커밋이 없어서 데일리로그를 작성한다는 이야기를 길게 하고있는거다. 2024-12-09\n작업을 많이해서 블로그 글을 못올렸다. 이번주 할일은 송년회 프로젝트 sse 구현하기 + 레디스 레플리케이션 끝내기 2024-12-10\n정시에 엔터를 치는 기계와, 인간 캐시 생성기, 디비 백업을 위해 테이프를 감는 사람 등 무서운 이야기를 많이 들었다. 앞으로 월요일에 주간회고를 쓰려고 한다. 주말에도 뭘 하다보니 월요일은 정말 퇴근하면 녹초가 되고, 그래도 커밋을 채우고 싶기 때문이다. 2024-12-11\n쉽지 않은 일은 항상 일어난다. 기대치를 낮춰도 기대치가 높은 종류의 일인 것 같다. 2024-12-13\n정말 크게 감사하게도 다시 달릴 기회를 얻었다. 연말 워크샵에 개인 프로젝트에 개인 공부까지 너무 힘들었고 워크샵 끝난 오늘은 정말 힘들었는데 쉬다가 좋은 결과 문자메세지가 피로를 씻어줬다 앞으로 한달간 정말 정말 열심히 준비해봐야겠다. 2024-12-18\n진짜 싫다 빠르게 떠나야 할 것 같다 2024-12-20\n힘든데 그래도 길이 보이고 있다. 2024-12-24\n퇴근이 안끝나는 느낌이다 2024-12-29\n누적된 피로가 가시질 않는데 이래저래 이직이 끝나면 꼭 한동안 쉬어야 할 것 같다 2024-12-31\n새해복많이 받으세요 ","permalink":"http://localhost:1313/_wiki/daily-log-2024/","summary":"Daily-Log 📝 2024-09-24\n가장 큰 프로젝트가 오픈했고, 오픈 직후의 이슈들도 정리되어 가고 있다. 밀렸던 포스팅들을 하나씩 올리려고 한다. 프로젝트 때문에 몇날 밤을 새웠는데, 몇일 쉬었다고 정신 못차리고 스터디와 사이드 프로젝트를 진행하려고 한다. 그 때문에 러스트 공부를 시급하게 해야한다. 당장 오늘 Rust In Action 복습을 시작했다. 2024-09-25\n러스트 사이드 프로젝트의 교모와 시기가 상당히 타이트 할 것 같다. 10월 초 긴 연휴 내에 각자 필요한 것들을 준비하기로 했다. 최소 서버는 러스트로 구현 할 것 같다 (actix-web) 러스트 문법에 대한 복습을 짧게 마치고, 프레임워크에 대한 공부와 러스트 웹소켓 관련 코드들을 찾아보려고 한다.","title":"Daily-Log 2024 (Daily 아님주의) 🙈"},{"content":"16. 세그멘테이션 16.1 베이스 바운드의 일반화 지금 가정의 단계에서 내부단편화가 발생하는 요인은 스택과 힙 사이에 사용하지 않는 메모리가 존재하는 것이다.\n세그멘테이션은 60년대에 이미 사용되던 메모리 관리 기법이다. 기본적으로 세그멘테이션은 세그먼트마다 베이스와 바운드를 가지고 있다. 세그먼트란 논리적인 단위로, 프로그램이나 데이터를 담고 있는 논리적인 단위이다. (스택, 힙, 데이터영역, 코드영역 등) 즉 논리적인 단위로 나누어진 세그먼트(논리적 단위)에 각각 베이스와 바운드를 주는 것이다. 그외에는 베이스 바운드 기법을 사용한다. 예를들어 가상주소가 100, 베이스가 50, 바운드가 110이라면, 베이스 주소인 50으로 가서 100을 더하면 150이 되는데, 이는 바운드보다 크기 때문에 오류가 발생한다. (똑같음) 그리고 그 세그먼트 종류마다 주소를 세그먼트 레지스터에 저장한다. 참고로 베이스 + 오프셋(가상주소)이 바운드보다 크면 오류가 발생하는데, 이걸 Segment Fault라고 한다.\n\u0026lsquo;일반화\u0026rsquo; 라는 단어가 뭔가 묘하게 어울리지 않는 것 같아서 약간 헷갈릴 수 있지만 어려운 내용은 아니다.\n16.2 세그먼트 종류에 대한 파악 당연하게도 뭐하나 자동으로 되는건 없다. 세그먼트를 베이스를 기반으로 참조했을때 이 세그먼트가 어떤 종류인지도 알 수 있도록 조치해야한다.\n처음에는 네트워크에서 헤더 붙이는 것처럼 주소값에 최상위 몇 비트를 이용해서 구분했다. Segment = (VirtualAddress \u0026amp; SEGMENT_MASK) \u0026gt;\u0026gt; SEGMENT_SHIFT Offset = VirtualAddress \u0026amp; OFFSET_MASK if Offset \u0026gt; SegmentSize[Segment] then Raise Exception(SEGMENTATION_FAULT) else PhysicalAddress = Base[Segment] + Offset Register = Memory[PhysicalAddress] 해석 여기서 목표는 아래와 같음\n가상 주소: 1100 0101 0010 1101 1010 1111 0001 0011 (32비트) 세그먼트 번호: 1100 (상위 4비트) 오프셋: 0101 0010 1101 1010 1111 0001 0011 (하위 28비트) 첫줄은 이렇게 나누려고 SEGMENT_MASK로 \u0026amp;연산을 해서 세그먼트 번호를 구하는 코드 SEGMENT_MASK: 1111 0000 0000 0000 0000 0000 0000 0000 (32비트) VirtualAddress: 1100 0101 0010 1101 1010 1111 0001 0011 SEGMENT_MASK: 1111 0000 0000 0000 0000 0000 0000 0000 결과: 1100 0000 0000 0000 0000 0000 0000 0000 여기서 결과값에 쉬프트 연산으로 다 밀어버리면 세그먼트 번호가 나온다. 비슷한 과정을 거쳐 오프셋을 구한다. Base[Segment] : 해당하는 세그먼트의 베이스 주소, 여기다 오프셋을 더하면 물리주소가 나온다. 그리고 해당 주소값을 참조하기! 문제점\n문제는 이러한 방식은 최대 세그먼트의 크기와 같은 것들이 \u0026lsquo;고정\u0026rsquo;이고, \u0026lsquo;약속\u0026rsquo;이 되어 있다는 것! 또한 위에 주소 비트를 이용해서 세그먼트를 구분하는데 쓰는것도 생각보다 더 비용이 많이 든다. 예를들어 앞에 네 비트를 사용하면 실제 offset으로 사용할 수 있는 비트가 2^4만큼 줄어든다. 16억개의 메모리 주소를 사용할 수 있었을건데 비트 네개를 까버리면 1억개만 사용할 수 있게 된다. 16.3 스택 스택이라고 소개를 하지만, 사실 세그먼트의 특성에 따라 관리와 행동이 달라진다는 것을 보여주는 예시\n스택이라는 세그먼트는 주소가 음의 성장을 한다. 이거 cpp보면 진짜 그럼 이젠 순방향으로 증가하는지 여부를 어딘가에 저장해야한다. 그래서 스택 세그먼트에는 방향 비트를 추가해서 어느 방향으로 증가하는지를 표시한다. 16.4 공유 지원(Support for Sharing) 결론적으로는 일단, 특정 세그먼트를 공유하는게 메모리 공간상 효율적일 수 있는데, 바로 \u0026lsquo;code\u0026rsquo;를 공유하는 것이다. 가장 직관적으로 비유하면 라이브러리 같은 것을 공유하는 것이다.(정확하지는 않지만 c로 작성된 프로그램이 여럿인데, stl을 여러개 메모리에 올릴 이유가 없음!) 이건 진짜 좋긴 하지만 위험하니까, 공유를 위해 보호 비트를 추가해서 공유한다는게 주요 내용이다. 여기까지 세그먼트 레지스터에 저장해야할 데이터는 아래와 같다. 16.5 소단위대 대단위 세그멘테이션 지금은 대단위 세그멘테이션을 한다. (스택, 힙, 코드, 데이터) 요정도로만 크게크게 나눠서 대단위라고함 그런데 필요성에 따라서, 더 작은 단위로 나누어서 세그멘테이션을 할 수도 있다. 이렇게 세그먼트를 줄이고 많이 가지고 있으면 세그멘트 테이블 같은 새로운 하드웨어 지원이 필요하다. 16.6 운영체제의 지원 세그멘테이션 덕분에 낭비되는 \u0026lsquo;물리\u0026rsquo;메모리 없이 메모리를 효율적으로 사용할 수 있게 되었다. 근데 당연하게도 세그먼트가 야기하는 문제가 있고, 세그먼트가 아직 해결 못한 문제도 있다. 세그먼트가 야기하는 문제와 세그먼트로 해결 못한 문제 마지막으로 그걸 운영체제가 어떻게 해결 할 수 있는지 알아본다.\n세그먼트가 야기하는 문제 컨텍스트 스위치 시 세그먼트 레지스터 관리 문제 각 프로세스는 자신의 가상 주소 공간을 가지고 있어, 컨텍스트 스위치 시 운영체제가 세그먼트 레지스터를 저장하고 복원해야 한다.(오버헤드가 커지겠지!) 세그먼트 크기 변경 시의 문제 프로그램이 malloc()을 호출할 때, 기존 힙에서 요청을 처리할 수 없으면 힙 세그먼트가 커져야 한다. 메모리 할당 라이브러리가 시스템 호출을 통해 힙을 확장하고, 운영체제는 힙을 확장하여 세그먼트 크기 레지스터를 업데이트하고, 라이브러리에 성공을 알린다. 운영체제는 물리 메모리가 부족하거나 호출된 프로세스가 이미 너무 많은 메모리를 사용하고 있다고 판단하면 요청을 거부할 수 있다. 물리 메모리의 빈 공간 관리 문제 새로운 주소 공간을 생성할 때 운영체제는 세그먼트에 대한 물리 메모리 공간을 찾아야 한다. 물리 메모리가 작은 빈 공간들로 나뉘어 새로운 세그먼트를 할당하거나 기존 세그먼트를 확장하기 어려워진다. 이를 외부 단편화(external fragmentation)라고 한다. 세그먼트가 아직 해결 못한 문제 외부 단편화 문제 세그먼트가 가변 크기이기 때문에 빈 메모리가 작은 조각들로 나뉘어져 메모리 할당 요청을 충족하기 어렵게 된다. 완전히 일반화된 희박한 주소 공간 지원 부족 문제 큰 논리적 세그먼트(예: 희박한 힙)가 메모리에 완전히 상주해야 한다. 주소 공간 사용 모델이 세그멘테이션 설계 방식과 일치하지 않으면 세그멘테이션이 잘 작동하지 않는다. 운영체제가 세그멘테이션 문제를 해결하는 방법 메모리 압축 방법 운영체제는 프로세스를 멈추고 데이터를 연속된 메모리 영역으로 복사하고, 세그먼트 레지스터 값을 새로운 물리적 위치로 변경하여 큰 빈 메모리 공간을 확보한다. 그러나 메모리 압축은 비용이 많이 든다. 자유 리스트 관리 알고리즘 사용 큰 메모리 공간을 유지하려고 시도하는 자유 리스트 관리 알고리즘을 사용한다. 대표적인 알고리즘으로는 best-fit, worst-fit, first-fit, buddy algorithm 등이 있다. 이러한 알고리즘은 외부 단편화를 최소화하려고 시도한다. 세그멘테이션은 메모리 가상화에서 여러 문제를 해결하지만, 여전히 외부 단편화와 희박한 주소 공간 지원 부족 문제를 가지고 있다. 운영체제는 메모리 압축과 다양한 자유 리스트 관리 알고리즘을 통해 이러한 문제를 해결하려고 노력하지만, 근본적인 문제는 여전히 존재하므로 더 나은 솔루션이 필요하다.\n17. 빈 공간 관리 앞에서 세그먼트로 나눔으로써, 내부 단편화를 해결했지만 외부 단편화 문제가 주요하게 남아있다. 즉 고정 메모리 범위를 사용하면서 발생하는 문제를 세그먼트 단위로 적재하면서 해결했지만, 세그먼트를 메모리에 적재하는데 발생하는 문제가 외부 단편화이다.\n문제를 너무 잘 요약해서 책을 발췌하면, 관리해야 하는 공간이 가변 크기의 빈 공간으로 나뉘어져 있는 이슈를 해결해야한다. 위의 예시처럼, 빈공간은 20바이트나 있는데, 15바이트 할당에 실패한다. 17.1 가정 이 논의의 대부분은 사용자 수준의 메모리 할당 라이브러리의 발전 역사를 중심으로 한다. (malloc()과 free()는 실시간으로 힙 세그먼트 내부의 빈 공간을 조정해야 하는 역할을 필연적으로 가지게 된다.)\n외부 단편화를 해결하는데 초점을 맞춘다. 할당된 메모리는 다른 위치로 이동할 수 없다. 17.2 저 수준의 기법들 빈공간 list 만들기 빈 공간을 관리하기 위해 위처럼 말 그대로 빈 공간의 리스트를 만들어서 관리한다. 분할 빈 공간을 나누어서 할당하는 방법이다. 일단 요청이 청크보다 작으면, 청크를 나누어 사용자에게 할당하고, 남은 부분은 리스트에 남긴다. 병합 반환받은 메모리를 병합시키는 방법이다. 문제는 여기서 발생한다. 위의 사진에서 10을 사용하던 두 메모리가 반환됐을때, 10을 의미하는 빈공간 리스트의 세개의 노드가 존재하게 되고, 사실상 30이 연달아 있어 사용할 수 있는 메모리가 30이 되어야 하는데, list를 순회하며 10이 넘는 요청에 대한 메모리를 할당하지 못하도록 되어있다. 사실 병합의 문제는 간단히 해결 할 수 있다, 메모리가 반환되는 \u0026lsquo;시점\u0026rsquo;에 빈공간 리스트의 인접한 노드를 검사하고 병합시키면 된다. 참고로 포인터는 헤더가 있어서 실제 할당하려고 하면, 요청한 메모리 + 헤더 크기만큼 할당한다.\n빈 공간 리스트 내장 새로운 노드를 위한 공간이 필요할 때 malloc()을 호출함 메모리 할당 라이브러리 루틴에서는 이게 불가능하고, 대신 빈 공간 내에 리스트를 구축해야함 typdef struct __node_t { int size; struct __node_t *next } node_t ... node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_ANON|MAP_PRIVATE, -1, 0); head-\u0026gt;size = 4096 - sizeof(node_t); head-\u0026gt;next = NULL; 이렇게 초기화는 해두고, 메모리 청크 (예시 100바이트)가 요청되면 먼저 충분한 크기의 청크를 찾는다. 지금은 4088의 하나의 청크만이 존재하니까 여기가 선택된다. 그 후 헤더를 포인터 앞에 적고, 100바이트를 할당하고 스플릣한다. 지금까지의 과정 그리고 세개의 100바이트 청크가 있다가 가운데 하나가 해제되는 상황을 가정한다. 그러면 라이브러리는 빈공간리스트에 해당 반환된 공간을 삽입한다. (단편화 발생) 그리고 나머지가 반환되면 여러개의 빈공간 리스트가 생긴다. 요걸 다시 리스트순회해서 인접한 리스트끼리 합쳐서 하나의 빈공간으로 만든다. #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; typedef struct __node_t { int size; struct __node_t *next; } node_t; #define MAGIC 1234567 typedef struct { int size; int magic; } header_t; node_t *head = NULL; // 힙 초기화 함수 void init_heap(int size) { head = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_ANON | MAP_PRIVATE, -1, 0); if (head == MAP_FAILED) { perror(\u0026#34;mmap\u0026#34;); exit(1); } head-\u0026gt;size = size - sizeof(node_t); head-\u0026gt;next = NULL; } // 메모리 할당 함수 void *my_malloc(int size) { node_t *current = head; node_t *prev = NULL; while (current != NULL) { if (current-\u0026gt;size \u0026gt;= size + sizeof(header_t)) { header_t *hptr = (header_t *)((char *)current + sizeof(node_t)); hptr-\u0026gt;size = size; hptr-\u0026gt;magic = MAGIC; node_t *new_free = (node_t *)((char *)hptr + sizeof(header_t) + size); new_free-\u0026gt;size = current-\u0026gt;size - sizeof(header_t) - size - sizeof(node_t); new_free-\u0026gt;next = current-\u0026gt;next; if (prev == NULL) { head = new_free; } else { prev-\u0026gt;next = new_free; } return (void *)(hptr + 1); } prev = current; current = current-\u0026gt;next; } return NULL; // 할당 실패 } // 메모리 해제 함수 void my_free(void *ptr) { header_t *hptr = (header_t *)ptr - 1; assert(hptr-\u0026gt;magic == MAGIC); node_t *free_block = (node_t *)hptr; free_block-\u0026gt;size = hptr-\u0026gt;size + sizeof(header_t); node_t *current = head; node_t *prev = NULL; while (current != NULL \u0026amp;\u0026amp; current \u0026lt; free_block) { prev = current; current = current-\u0026gt;next; } free_block-\u0026gt;next = current; if (prev == NULL) { head = free_block; } else { prev-\u0026gt;next = free_block; } // 병합 if (free_block-\u0026gt;next != NULL \u0026amp;\u0026amp; (char *)free_block + free_block-\u0026gt;size + sizeof(node_t) == (char *)free_block-\u0026gt;next) { free_block-\u0026gt;size += free_block-\u0026gt;next-\u0026gt;size + sizeof(node_t); free_block-\u0026gt;next = free_block-\u0026gt;next-\u0026gt;next; } if (prev != NULL \u0026amp;\u0026amp; (char *)prev + prev-\u0026gt;size + sizeof(node_t) == (char *)free_block) { prev-\u0026gt;size += free_block-\u0026gt;size + sizeof(node_t); prev-\u0026gt;next = free_block-\u0026gt;next; } } // 힙 상태 출력 함수 void print_heap() { node_t *current = head; printf(\u0026#34;Free list:\\n\u0026#34;); while (current != NULL) { printf(\u0026#34;Address: %p, Size: %d\\n\u0026#34;, current, current-\u0026gt;size); current = current-\u0026gt;next; } } int main() { init_heap(4096); // 4KB 힙 초기화 void *a = my_malloc(100); void *b = my_malloc(100); void *c = my_malloc(100); print_heap(); my_free(b); print_heap(); my_free(a); my_free(c); print_heap(); return 0; } 17.3 힙의 확장 기본 전략 힙의 확장은 빈 공간이 부족할 때, 더 큰 메모리 공간을 할당하는 것을 의미한다. 없으면 NULL을 반환한다 -끝- 이 아니고\n아래와 같은 기본 전략들이 있다. 1. 최적 적합 (Best-Fit) 동작 방식: 메모리 할당 요청 시, 전체 자유 리스트를 탐색하여 요청된 크기에 가장 가까운(즉, 요청 크기에 가장 적게 남는) 자유 블록을 선택하는 방식이다. 선택된 블록을 할당하고 남은 부분을 다시 자유 리스트에 추가하는 방식이다. 장점: 메모리 공간을 최소한으로 낭비하게 하여 외부 단편화를 줄이는 데 도움이 된다. 단점: 전체 자유 리스트를 탐색해야 하므로 탐색 시간이 오래 걸릴 수 있다. 작은 조각들이 많이 남아 내부 단편화가 증가할 수 있다. 2. 최초 적합 (First-Fit) 동작 방식: 메모리 할당 요청 시, 자유 리스트의 첫 번째부터 시작하여 요청된 크기를 만족하는 첫 번째 블록을 선택하는 방식이다. 선택된 블록을 할당하고 남은 부분을 다시 자유 리스트에 추가하는 방식이다. 장점: 탐색 시간이 짧아 효율적이다. 대체로 빠른 할당이 가능하다. 단점: 초기 부분에 작은 조각들이 많이 남아 외부 단편화가 발생할 수 있다. 자주 사용되는 영역에 단편화가 발생할 가능성이 있다. 3. 최악 적합 (Worst-Fit) 동작 방식: 메모리 할당 요청 시, 전체 자유 리스트를 탐색하여 가장 큰 자유 블록을 선택하는 방식이다. 선택된 블록을 할당하고 남은 부분을 다시 자유 리스트에 추가하는 방식이다. 장점: 큰 블록을 분할하여 큰 조각들이 남아 큰 메모리 요청을 처리하기 쉽다. 단점: 큰 블록을 분할하면서 작은 조각들이 많이 남아 외부 단편화가 증가할 수 있다. 4. 다음 적합 (Next-Fit) 동작 방식: 메모리 할당 요청 시, 이전 할당이 끝난 위치부터 시작하여 요청된 크기를 만족하는 첫 번째 블록을 선택하는 방식이다. 선택된 블록을 할당하고 남은 부분을 다시 자유 리스트에 추가하는 방식이다. 장점: 최초 적합과 유사한 성능을 가지며, 자주 사용되는 영역에 단편화가 덜 발생한다. 단점: 자유 리스트가 순환 구조를 가지므로 리스트의 끝에서 다시 시작해야 할 경우 탐색 시간이 길어질 수 있다. 5. 개별 리스트 (Segregated List) 동작 방식: 크기별로 여러 개의 자유 블록 리스트를 따로 관리하는 방식이다. 요청된 크기에 맞는 리스트에서 블록을 할당하고, 필요 시 더 큰 블록을 분할하여 할당한다. 장점: 특정 크기의 블록을 빠르게 찾을 수 있어 탐색 시간이 짧다. 크기별로 관리하므로 특정 크기의 블록들이 적절히 분리되어 단편화를 줄이는 데 도움이 된다. 단점: 여러 리스트를 관리해야 하므로 구현이 복잡할 수 있다. 크기별 리스트에 따라 메모리 낭비가 발생할 수 있다. 6. 버디 할당기 (Buddy Allocation) 동작 방식: 메모리를 2의 거듭제곱 크기로 분할하여 관리하는 방식이다. 요청된 크기에 가장 적합한 크기의 블록을 할당하며, 필요 시 블록을 분할한다. 장점: 메모리 병합이 쉽고 빠르며, 내부 단편화가 적다. 단점: 항상 2의 거듭제곱 크기로 할당하므로, 일부 경우 외부 단편화가 발생할 수 있다. 18. 페이징: 개요 가변 크기의 조각은 청크로 분할 할 때 공간자체가 단편화되고, 할당은 점점 더 어려워진다. 두 번째 방법인 공간을 동일한 조각으로 분할하는 것을 고려해볼 필요가 있다. 논리적 단위가 아닌 고정크기로 나누는 방법이고 그 크기 단위를 Page 메모리도 Page frame이라고 불리는 고정 크기의 슬롯의 배열로 바라본다.\n핵심 질문 : 페이지를 사용하여 어떻게 메모리를 가상화 할 수 있을까?\n18.1 간단한 예제 및 개요 128 바이트의 (비현실적으로 작은) 물리 메모리의 예시 가상 주소 공간의 페이지들은 물리메모리 전체에 분산 배치되어있다. 이전 방식에 비해 다양한 장점을 가지고 있다. 일단 먼저 유연하다. 힙과 스택이 어떠한 방식으로 커지는가, 어떻게 사용되는가에 대한 가정이 필요 없다. 다음으로 단순하다. 64바이트 주소공간을 8페이지 물리메모리에 배치한다고 했을 때, 4개의 비어있는 페이지만 찾으면 된다. 주소공간의 각 가상 페이지에 대한 물리 메모리 위치 기록을 위하여 운영체제는 프로세스마다 페이지 테이블이라는 자료 구조를 유지한다. 주소공간의 가상페이지 주서 변환 정보를 저장하는것이다. (virtual page 1 -\u0026gt; physical page 7) \u0026hellip; 페이지 테이블은 프로세스마다 존재한다. 프로세스가 생성한 가상 주소의 변환을 위해 먼저 가상 주소를 가상 페이지 번호(Virtual Page Number)와 페이지 내의 오프셋 2개의 구성 요소로 분할한다. 가상 페이지 번호(VPN) 계산 • 0x1C34A8 = 0001 1100 0011 0100 1010 1000₂ • 상위 20비트가 VPN: 0001 1100 0011 0₂ = 0x1C3 • VPN = 0x1C3 (10진수: 451)\n페이지 오프셋 계산 • 하위 12비트: 0100 1010 1000₂ = 0x4A8 • 오프셋 = 0x4A8 (10진수: 1192)\n테이블에서 물리 페이지 주소 얻기\n0x1C3 -\u0026gt; 0x2F5 물리 주소 계산\n물리 주소 = (PFN \u0026laquo; 12) | Offset = (0x2F5 \u0026laquo; 12) | 0x4A8 = 0x2F5000 + 0x4A8 = 0x2F54A8 (10진수: 3099432)\n18.2 페이지 테이블은 어디에 저장되는가 기본적으로 추정하면 페이지 테이블의 용량은 산술적으로 엄청 큼 각 프로세스의 페이지 테이블을 메모리에 저장하는데, 당분간은 운영체제가 관리하는 물리 메모리에 상주한다고 가정하자. 18.3 페이지 테이블에는 실제 무엇이 있는가 가장 간단한 형태는 선형 페이지 테이블이고 단순한 배열이다. VPN으로 배열의 항목에 접근하고, 그항목의 페이지 테이블 항목(PTE)를 검색한다. (고 가정) Valid bit : 특정 변환의 유효 여부를 나타내기 위해서 포함 (모든 미사용 공간은 invalid) 만약 거기 접근하면 운영체제에 트랩을 발생시킨다. 또한 할당하지 않은 주소공간이라는 표식으로써 기능하 실제 물리 프레임을 할당할 필요을 없애 대량의 메모리를 절약한다. Protection bit : 읽기, 쓰기, 실행 가능 여부를 포함하는 비트이다. 허용되지 않은 방식의 접근은 트랩을 생성한다. Present bit : 페이지가 물리 메모리에 있는지, (혹은 스왑아웃 되었는지) 확인한다. Dirty bit : 페이지가 메모리에 적재된 이후 변경되었는지를 추적한다. reference bit : 페이지가 접근되었는지를 추적한다, 어떤 페이지가 인기있는지 확인하고 페이지 교체 알고리즘에 사용된다. 18.4 페이징: 너무 느림 movl 2l, %eax 가상주소 (21)을 정확한 물리적 주소 (117)로 변환해야한다. 117에서 데이터를 반입하기 전에 시스템은 프로세스의 페이지 테이블에서 적절한 페이지 테이블 항목을 가져와야하고, 변환을 수행한 후, 물리메모리에서 데이터를 탑재한다. 하드웨어는 현재 실행중인 프로세스의 페이지 테이블의 위치를 알아야 한다. 당분간 하나의 페이지 테이블 베이스 레지스터가 페이지 테이블의 시작 주소(물리주소)를 저장한다고 가정한다. (위의 물리 주소 계산 이후의 계산을 진행해야함) ","permalink":"http://localhost:1313/_wiki/segmentation-paging/","summary":"16. 세그멘테이션 16.1 베이스 바운드의 일반화 지금 가정의 단계에서 내부단편화가 발생하는 요인은 스택과 힙 사이에 사용하지 않는 메모리가 존재하는 것이다.\n세그멘테이션은 60년대에 이미 사용되던 메모리 관리 기법이다. 기본적으로 세그멘테이션은 세그먼트마다 베이스와 바운드를 가지고 있다. 세그먼트란 논리적인 단위로, 프로그램이나 데이터를 담고 있는 논리적인 단위이다. (스택, 힙, 데이터영역, 코드영역 등) 즉 논리적인 단위로 나누어진 세그먼트(논리적 단위)에 각각 베이스와 바운드를 주는 것이다. 그외에는 베이스 바운드 기법을 사용한다. 예를들어 가상주소가 100, 베이스가 50, 바운드가 110이라면, 베이스 주소인 50으로 가서 100을 더하면 150이 되는데, 이는 바운드보다 크기 때문에 오류가 발생한다.","title":"Week-06"},{"content":" static_cast static_cast는 가장 기본적인 형태의 캐스팅이다. 컴파일 시간에 타입 변환을 수행하며, 컴파일러가 타입 안전성을 어느 정도 보장해 준다. 주로 기본 타입 간의 변환, 명시적 생성자를 사용한 객체 생성, 상속 관계에 있는 클래스 간의 변환 등에 사용된다. Copy code int a = 10; double b = static_cast\u0026lt;double\u0026gt;(a); // int를 double로 변환 dynamic_cast dynamic_cast는 주로 다형성(polymorphism)을 사용하는 클래스 계층에서의 포인터 또는 참조 타입 변환에 사용된다. 실행 시간에 타입 검사를 수행하여 안전한 타입 변환을 보장해 준다. dynamic_cast는 주로 상속 관계에서 부모 클래스 포인터를 자식 클래스 포인터로 변환할 때 사용되며, 변환이 실패하면 nullptr을 반환한다. RTTI(Runtime Type Information)를 사용하여 실행 시간에 타입 정보를 확인하므로, dynamic_cast를 사용하려면 반드시 가상 함수(virtual function)가 정의된 클래스여야 한다. Copy code class Base { virtual void foo() {} }; class Derived : public Base { void foo() override {} }; Base* basePtr = new Derived; Derived* derivedPtr = dynamic_cast\u0026lt;Derived*\u0026gt;(basePtr); // 성공하면 derivedPtr이 유효한 포인터가 된다 const_cast const_cast는 변수의 const 또는 volatile 속성을 제거하거나 추가할 때 사용된다. 주로 기존의 const 객체를 변경해야 할 때 사용되며, 이는 안전하게 사용해야 한다. 비유하자면, const_cast는 책을 읽기 전용으로 두었다가 다시 수정 가능하도록 설정하는 것과 비슷하다. Copy code const int a = 10; int* b = const_cast\u0026lt;int*\u0026gt;(\u0026amp;a); // const를 제거하여 a를 수정 가능하게 만든다 reinterpret_cast reinterpret_cast는 가장 강력하고 위험한 형태의 캐스팅이다. 포인터나 데이터의 비트 패턴을 단순히 다른 타입으로 해석한다. 주로 포인터 타입 간의 변환이나 비트 패턴을 그대로 유지한 채 다른 타입으로 해석하고자 할 때 사용된다. Copy code int a = 65; char* b = reinterpret_cast\u0026lt;char*\u0026gt;(\u0026amp;a); // int 포인터를 char 포인터로 변환 ","permalink":"http://localhost:1313/_wiki/cpp-casting/","summary":"static_cast static_cast는 가장 기본적인 형태의 캐스팅이다. 컴파일 시간에 타입 변환을 수행하며, 컴파일러가 타입 안전성을 어느 정도 보장해 준다. 주로 기본 타입 간의 변환, 명시적 생성자를 사용한 객체 생성, 상속 관계에 있는 클래스 간의 변환 등에 사용된다. Copy code int a = 10; double b = static_cast\u0026lt;double\u0026gt;(a); // int를 double로 변환 dynamic_cast dynamic_cast는 주로 다형성(polymorphism)을 사용하는 클래스 계층에서의 포인터 또는 참조 타입 변환에 사용된다. 실행 시간에 타입 검사를 수행하여 안전한 타입 변환을 보장해 준다.","title":"cpp-casting 🐋"},{"content":"C++ 타입 변환 int main() { // -------비트열 재구성 여부에 따른 분류 -------- { // 1. 값 타입 변환(implicit conversion) // 특징) 의미를 유지하기 위해서, 원본 객체와 다른 비트열 재구성 // 실제로 메모리를 까보면, 원본 데이터와 다른 비트열로 재구성되어있는 부분을 확인할 수 있다. int a = 123456789; float b = (float)a; } { // 2. 참조 타입 변환 // 특징) 참조 타입 변환은 참조 타입을 이용해서, 원본 객체의 비트열을 그대로 참조 (보는 관점만 변화) // 실제로 메모리를 까보면, 원본 데이터와 같은 비트열로 재구성되어있는 부분을 확인할 수 있지만, 실제 값을 출력시 원본 객체와 다른 값을 출력한다. int a = 123456789; float b = (float\u0026amp;)a; } // -------안전도 분류(데이터 손실) -------- { // 3. 안전한 타입 변환 // 업캐스팅 하는 경우 (char -\u0026gt; short -\u0026gt; int) int a = 123456789; __int64 b = a; } { // 4. 안전하지 않은 타입 변환 // 의미가 항상 100% 보장되지 않는 경우 // 타입이 다르거나, 다운캐스팅 하는 경우 int a = 123456789; float b = a; short c = a; } // -------의도에 따른 분류 -------- { // 5. 암시적 타입 변환 // 타입 반환 규칙에 따라서 자동 타입 변환 int a = 123456789; float b = a; } { // 6. 명시적 타입 변환 int a = 123456789; float b = (float)a; } return 0; } ","permalink":"http://localhost:1313/_wiki/%ED%83%80%EC%9E%85-%EB%B3%80%ED%99%98/","summary":"멀끔한 정리는 항상 좋다.","title":"cpp 타입 변환"},{"content":"malloc()이 반환하는 값은 void* 타입이다. 사실 할당하고 데이터의 시작 주소를 반환하긴 하지만, 사실은 내부적으로 헤더값이 있어, 방금 할당한 메모리 공간에 대한 메타 정보를 가지고 있다. ","permalink":"http://localhost:1313/_wiki/free%EB%8A%94-%EC%96%B4%EB%96%BB%EA%B2%8C-%ED%95%A0%EB%8B%B9%EC%9D%84-%ED%95%B4%EC%A0%9C%ED%95%98%EB%8A%94%EA%B0%80/","summary":"malloc()이 반환하는 값은 void* 타입이다. 사실 할당하고 데이터의 시작 주소를 반환하긴 하지만, 사실은 내부적으로 헤더값이 있어, 방금 할당한 메모리 공간에 대한 메타 정보를 가지고 있다. ","title":"c/cpp free는 어떻게 할당을 해제하는가"},{"content":"Post 엔티티 @Entity public class Post { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String title; private String content; @OneToMany(mappedBy = \u0026#34;post\u0026#34;, fetch = FetchType.LAZY, cascade = CascadeType.ALL) private List\u0026lt;Comment\u0026gt; comments = new ArrayList\u0026lt;\u0026gt;(); } Comment 엔티티 @Entity public class Comment { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String content; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;post_id\u0026#34;) private Post post; } 일반적으로 이렇게 작성하셨으면, 실제 데이터베이스에는 아래처럼 테이블이 생성됩니다.\nPost 테이블 컬럼 이름 데이터 타입 제약 조건 id BIGINT PRIMARY KEY, AUTO_INCREMENT title VARCHAR(255) NOT NULL content TEXT Comment 테이블 컬럼 이름 데이터 타입 제약 조건 id BIGINT PRIMARY KEY, AUTO_INCREMENT content TEXT post_id BIGINT FOREIGN KEY, NOT NULL 연관관계의 주인 연관관계 주인을 설정한다는건 외래키를 어디에 두는지 설정하는거고. mappedBy를 설정한다는건 외래키를 가지고 있는 쪽이 아니라, 반대쪽(코멘트쪽!)에 있는 엔티티가 주인이라는 것입니다. DB관점에서 생각해보면,\npost_id가 3번인 코멘트를 찾아라! 와 같이 질문하는 상황이 맞겠죠? (여기를 가장 헷갈려하시는 것 같아요)\n예를들어 만약 그럴일 없겠지만, Post에 Comment의 외래키를 일대다로 가지고 싶다면, 외래키의 배열을 가지고 있어야 하는 겁니다.\n1번 포스트에 [3번코멘트, 4번코멘트, 5번 코멘트] 이런식으로요.\n이러한 경우 post를 온전히 조회하려면, 3번 4번 5번 코멘트를 각각 조회해야합니다.(물론 in 쿼리로 한번에 조회할 수 있지만, 비유적인 상황이니까 ..)\n결론적으로 1번 코멘트 찾아라!, 2번 코멘트 찾아라!, 3번 코멘트를 찾아라! 와 같은 어색한 상황이 생기게 됩니다.\n그래서 일반적으로 연관관계의 주인, 즉 외래키를 위와 같이 정하는 것 입니다.\nN + 1 문제 그렇다면, 기본적으로 연관관계를 설정해두면 조회가 두번 발생한다는게 자연스럽게 이해가 되실겁니다.\n\u0026ldquo;1번 Post를 찾아줘!\u0026rdquo;, \u0026ldquo;1번 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo; 이렇게 두번의 쿼리가 발생하게 되는데요.\n여기서 문제는 여러건의 Post를 조회할 때 발생합니다.\n\u0026ldquo;Post 5개 찾아줘!\u0026rdquo;\n\u0026ldquo;첫 번째 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo;\n\u0026ldquo;두 번째 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo;\n\u0026ldquo;세 번째 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo;\n\u0026ldquo;네 번째 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo;\n\u0026ldquo;다섯 번째 Post의 id를 외래키로 가지고 있는 Comment를 찾아줘!\u0026rdquo;\n이렇게 총 (5 + 1) 번의 쿼리가 발생하게 됩니다.\nSELECT c.id, c.content, c.post_id FROM Comment c WHERE c.post_id = 1; SELECT c.id, c.content, c.post_id FROM Comment c WHERE c.post_id = 2; ... SELECT c.id, c.content, c.post_id FROM Comment c WHERE c.post_id = 5; 해결방법 1. fetchType.LAZY 사실 이러한 상황은 fetchType의 기본값인 EAGER 때문에 발생합니다.\nEAGER는 즉시로딩이라는 뜻으로, Post를 조회할 때 Comment도 같이 조회하겠다는 의미입니다. (정확하게는 연관된 엔티티를 같이)\n반면에 LAZY는 지연로딩이라는 뜻으로, Post를 조회할 때 Comment는 조회하지 않겠다는 의미입니다.\n여기서 프록시 객체가 사용되는데요, 프록시는 \u0026ldquo;우회한다\u0026quot;는 뜻으로, 디비에서 바로 조회하는 대신 프록시 객체를 먼저 조회하고, 실제로 사용할 때 디비에서 조회하는 방식입니다.\n조금 더 직관적으로는 \u0026ldquo;가짜 객체를 만들어두고, 실제로 사용할 때 디비에서 조회한다\u0026rdquo; 라고 생각하시면 됩니다.\n조금 과격한 비유이지만, 가짜 코멘트들을 만들어두고 포스트에 점찍어서 코멘트를 쓸때 실제 디비에서 조회하는 방식이라고 생각하시면 됩니다.\n물론 이건 근본적인 해결책은 아니지만, 정말 필요할 경우에만 디비로 쿼리가 나가니 실제로는 N + 1번 쿼리가 발생하지 않는 정도로 퉁칠수 있는 상황이 있습니다.\n\u0026lsquo;의도치 않게\u0026rsquo; N+1로 쿼리가 발생하는 \u0026lsquo;상황\u0026rsquo;이 문제라면, FetchType.LAZY로 설정하는 것도 하나의 해결책이 될 수 있습니다.\n물론 근본적인 이야기를 하자면, 실제로 \u0026lsquo;모든 연관된 엔티티에 대한 참조가 일어난다면\u0026rsquo; FetchType.LAZY는 절대 해결책이 될 수 없습니다. 다만, 이건 Big O 표기법과 마찬가지로, 최악의 경우를 가정했을때 N + 1 문제가 발생한다는 것 입니다. 그래서 많이들 하시는 실수가, 해당 엔티티의 참조가 충분히 간헐적이고 유동적일 수 있는데 모두 Fetch Join을 사용해버리면 오히려 리소스의 낭비가 발생할 수 있습니다. 이러한 경우 실제 연관 엔티티의 참조가 필요한 경우가, 한 번 더 쿼리가 필요한 시점이라고 인지한다면 Fetch join을 사용하는 것 보다 훨씬 효율적일 수 있습니다.\n해결방법 2. fetch join 사실 이게 근본적인 해결책인데, 여기서부터는 조금 더 정확한 쿼리를 작성해서 해결하는 방법입니다.\npublic interface PostRepository extends JpaRepository\u0026lt;Post, Long\u0026gt; { @Query(\u0026#34;SELECT p FROM Post p JOIN FETCH p.comments WHERE p.id = :postId\u0026#34;) Post findPostWithComments(@Param(\u0026#34;postId\u0026#34;) Long postId); } 쿼리를 아까처럼 풀면, (다소 의역) \u0026ldquo;Post를 조회하면서, Post테이블과 Comment을 붙여서 코멘트도 같이 조회해줘!\u0026rdquo; 라고 요청하는 쿼리입니다.\nPost 테이블 id title content 1 First Post This is the first post. 2 Second Post This is the second post. 3 Third Post This is the third post. Comment 테이블 id content post_id 1 First comment 1 2 Second comment 1 3 Third comment 2 조인된 결과 Post.id Post.title Post.content Comment.id Comment.content 1 First Post This is the first post. 1 First comment 1 First Post This is the first post. 2 Second comment 2 Second Post This is the second post. 3 Third comment 이렇게 쿼리를 작성하면, Post와 Comment를 조인해서 조회하게 되므로, N + 1 문제가 발생하지 않고 단건의 쿼리로 조회가 가능합니다.\n","permalink":"http://localhost:1313/_wiki/jpa-%EC%97%94%EC%81%A0%EB%9F%AC%EC%8A%A4%EC%9D%BC/","summary":"Post 엔티티 @Entity public class Post { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String title; private String content; @OneToMany(mappedBy = \u0026#34;post\u0026#34;, fetch = FetchType.LAZY, cascade = CascadeType.ALL) private List\u0026lt;Comment\u0026gt; comments = new ArrayList\u0026lt;\u0026gt;(); } Comment 엔티티 @Entity public class Comment { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String content; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;post_id\u0026#34;) private Post post; } 일반적으로 이렇게 작성하셨으면, 실제 데이터베이스에는 아래처럼 테이블이 생성됩니다.","title":"N + 1 문제와 해결방법 🧊️"},{"content":"블로그 글을 퉁치려는 얄팍한 시도 근데 진짜 바쁘니까.. [[JPA-엔쁠러스일]]\n","permalink":"http://localhost:1313/_wiki/%ED%8A%9C%ED%84%B0%EB%A7%81-%EC%A7%88%EC%9D%98-%EC%9D%91%EB%8B%B5-%EB%AA%A8%EC%9D%8C/","summary":"블로그 글을 퉁치려는 얄팍한 시도 근데 진짜 바쁘니까.. [[JPA-엔쁠러스일]]","title":"튜터링 질의 응답 모음 🧊️"},{"content":"Intro 😃 프로토콜의 집합을 프로토콜 스위트라고 합니다. 프로토콜 스위트의 다양한 프로토콜이 서로 어떻게 연관되어 있으며 수행할 작업을 어떻게 나누는지 명시하는 설계를 아키텍처 또는 참조 모델이라고 합니다. TCP/IP는 인터넷 아키텍처를 구현하는 프로토콜 스위트이며, ARPANET 참조 모델(ARM)에서 유래했습니다.\nClark는 인터엣 아키텍처의 주된 목표가 \u0026ldquo;기존 상호 연결된 네트워크의 다중화된 활용을 위한 효과적인 기술을 개발하는 것\u0026quot;이라고 설명한다. 즉 이 진술의 핵심은 인터넷 아키텍처가 여러 개별 네트워크를 상호 연결할 수 있어야 하고, 그 결과 생성된 상호 연결된 네트워크에서 여러 활동이 동시에 실행될 수 있어야 한다는 것이다.\n네트워크 또는 게이트웨이 손실에도 불구하고 인터넷 통신은 계속되어야 합니다. 인터넷은 여러 유형의 통신 서비스를 지원해야 합니다. 인터넷 아키텍처는 다양한 네트워크를 수용해야 합니다. 인터넷 아키텍처는 자원의 분산 관리가 가능해야 합니다. 인터넷 아키텍처는 비용 효율적이어야 합니다. 인터넷 아키텍처는 호스트 연결을 쉽게 허용해야 합니다. 인터넷 아키텍처에서 사용되는 자원은 책임져야 합니다. ","permalink":"http://localhost:1313/_wiki/introduction/","summary":"Intro 😃 프로토콜의 집합을 프로토콜 스위트라고 합니다. 프로토콜 스위트의 다양한 프로토콜이 서로 어떻게 연관되어 있으며 수행할 작업을 어떻게 나누는지 명시하는 설계를 아키텍처 또는 참조 모델이라고 합니다. TCP/IP는 인터넷 아키텍처를 구현하는 프로토콜 스위트이며, ARPANET 참조 모델(ARM)에서 유래했습니다.\nClark는 인터엣 아키텍처의 주된 목표가 \u0026ldquo;기존 상호 연결된 네트워크의 다중화된 활용을 위한 효과적인 기술을 개발하는 것\u0026quot;이라고 설명한다. 즉 이 진술의 핵심은 인터넷 아키텍처가 여러 개별 네트워크를 상호 연결할 수 있어야 하고, 그 결과 생성된 상호 연결된 네트워크에서 여러 활동이 동시에 실행될 수 있어야 한다는 것이다.","title":"TCP/IP Illustrated 📚"},{"content":"14. 막간 : 메모리 관리 API stack : 프로그래머를 위해, 컴파일러에 의해 자동으로 할당과 해제가 이루어진다(automatic). void func() { int x; } func()가 호출되면 스택에 공간을 확보하고, func()가 종료되면 스택에서 공간을 해제한다. heap : 프로그래머가 직접 할당과 해제를 해야한다. void func() { int *x = (int *) malloc(sizeof(int)); free(x); } malloc()을 통해 메모리를 할당하고, free()를 통해 메모리를 해제한다. heap에 데이터를 저장하고, func()의 스택에는 heap에 저장된 데이터의 주소를 저장한다. stack만큼 명시적이고 단순하기는 하지만, 쓰임새가 다양하고 실수를 할 여지가 많다.\n14.2 malloc()함수 malloc()은 메모리를 할당하는 함수이다. 약간 더 자세하게 설명하면, malloc()은 힙에 요청할 공간의 크기를 받아 성공하면 할당한 메모리의 주소를 반환하고, 실패하면 NULL을 반환한다. 참고로 sizeof()는 연산자의 관점에서 바라보면 조금 더 적절한 부분이 있다. sizeof()는 컴파일 시간에 계산되는 연산자이다. 예를들어 int *x = malloc(sizeof(int) * 10); printf(sizeof(x)). 이 코드에서는 4 또는 8값이 반환된다. 즉 동적으로 할당된 메모리의 크기가 아닌, 포인터의 크기를 반환하기 때문이다. 컴파일 타임에 실행되기에 함수가 아니다! 14.3 free()함수 free()는 malloc()을 통해 할당된 메모리를 해제하는 함수이다. free()를 통해 메모리를 해제 할 때 할당된 영역의 크기를 알 필요가 없다. (라이브러리가 알아서 처리한다.) 14.4 흔한 오류 | 기본적으로 malloc()과 free()를 사용할 때 자주 오류가 발생하는데, 특히 가비지컬렉터가 없는 경우에 더욱 신경써야 한다.\n메모리 할당 잊어버리기 많은 루틴은 자신이 호출되기 전에 필요한 메모리가 이미 할당되었다고 가정한다. 이런 경우 메모리를 할당하지 않고 사용하려고 할 때, 프로그램은 세그멘테이션 폴트를 발생하고 종료된다.\n| 사실 이러한 경우는 너무 흔해서 조금 더 안전한 루틴이나 라이브러리를 사용하는 것이 좋다.\n버퍼 오버플로우 : 충분하지 않은 메모리 할당 프로그램이 할당된 메모리보다 더 많은 데이터를 쓰려고 할 때, 문제 없이 동작하는 것 처럼 보이지만, 실제로는 할당받지 않은 메모리를 사용하게 된다. 다른 변수나 중요한 데이터를 덮어쓰는 경우가 발생할 수 있고, 보안적으로 매우 위험하다.\n할당받은 메모리 초기화 하지 않기 malloc()을 통해 할당받은 메모리는 초기화되지 않는다. 나중에 uninitialized read가 발생할 수 있다. 마찬가지로 공격자의 데이터를 읽을 수 있게 되는 보안적인 문제가 발생할 수 있다.\n할당받은 메모리 해제하지 않기 free()를 호출하지 않으면, 메모리 누수가 발생한다. 이는 프로그램이 실행되는 동안 메모리 사용량이 계속 증가하게 되고, 결국 프로그램이 더 이상 실행되지 않게 된다.\n메모리 사용이 끝나기 전에 메모리 해제하기 dangling pointer는 이미 해제된 메모리를 사용하려고 할 때 발생한다. 이는 프로그램이 종료되거나, 다른 메모리를 할당받을 때 발생할 수 있다.\n두 번 해제하기 double free는 이미 해제된 메모리를 다시 해제하려고 할 때 발생한다. 이는 프로그램이 종료되거나, 다른 메모리를 할당받을 때 발생할 수 있다.\nfree() 잘못 호출하기 14.5 운영체제의 지원 malloc()과 free()는 라이브러리 함수이기 때문에, 시스템콜을 직접적으로 언급하지는 않았지만, 라이브러리 자체는 당연히 시스템콜을 사용한다.\nbrk, sbrk 시스템콜을 사용하고 있지만, 직접적으로 사용하지는 않는다.\n15. 주소 변환의 원리 LDE에서 프로그램이 하드웨어에 의해 직접 실행되면서도, 약간의 하드웨어 지원을 받은 운영체제의 개입으로 어떻게 가상화를 제공하면서도, 프로그램을 방해하지 않는지에 대해서 알아봤다, 메모리 가상화에도 마찬가지로, 비슷한 동작을 알아본다.\n메모리 가상화에서도 제어와 효율성을 동시에 추구한다. 제어 : 프로그램이 자기 자신의 메모리 이외에 다른 메모리에 접근하지 못하는것을 운영체제가 보장한다. 효율성 : 하드웨어의 지원으로 하여금, 다양한 자원을 사용하여 가상화를 효율적으로 수행할 수 있도록 한다. 여기서 다룰 기법은 hardware-based address translation, 짧게는 address translation이다. address translation은 프로그램이 메모리에 접근할 때, 가상 주소를 물리 주소로 변환하는 기법이다. 그리고 해당 기법을 다루며 달성하고자 하는 목표는 프로그램이 자신의 전용 메모리 공간을 가지고 있다고 믿게 하면서도, 실제로는 물리 메모리를 공유하도록 하는 것이다. 15.1 가정 CPU 가상화 부분에서 LDE에 대한 이야기를 했었는데, 요약하자면 대부분의 프로그램은 하드웨어에서 직접 실행되면서, 프로세스가 시스템콜을 호출하거나 타이머 인터럽트가 발생하면, 하드웨어는 커널로 제어권을 넘기고, 운영체제가 적절한 작업을 수행한다. 즉 실행 프로그램에 문제가 발생하지 않도록 적절한 시점에 개입해서 하드웨어 지원을 받아 역할을 수행한다는 것이다.\nLDE에서 위와 같은 것들을 달성하기 위해서, 중요한 포인트를 효율성과 제어라고 할 수 있었다. 메모리 가상화도 마찬가지로, 가상화를 제공하는 목표는 효울성과 제어를 달성하기 위함이다. 물론 이런것들을 달성하려면 적절한 하드웨어의 지원이 필요하다. 이전 장에서와 마찬가지로, 처음에는 단순 하드웨어의 지원(레지스터만 사용하는 정도)에서 TLB, 페이지 테이블등 점차 복잡한 하드웨어 지원을 공부하는 방식으로 진행한다. 마지막으로 메모리 가상화 관점에서 효율성과 제어의 목표를 각각 알아보면 다음과 같다. 효율성 : 메모리 가상화는 물리적 메모리를 효율적으로 사용할 수 있도록 해야한다. 제어 : 메모리 가상화는 프로세스가 다른 프로세스의 메모리에 접근하지 못하도록 해야한다. 결론, 핵심 질문 메모리 가상화를 배우는 시작 장에서 핵심 질문은 다음과 같다. 어떻게 효율적이고 유연하게 메모리를 가상화할 수 있을까?\n먼저 다룰 기법은 하드웨어 기반 주소 변환(hardware-based address translation), 그냥 짧게 주소 변환(address translation)이라고도 한다. 핵심은 그냥 프로그램의 모든 메모리 참조를 실제 메모리 주소로 재지정하기 위해서 하드웨어가 주소를 변환하는 것이다. 하드웨어만으로는 메모리 가상화를 제공 할 수 없다. 운영체제가 실제로 메모리의 빈공간과 사용중인 공간을 알고 관리해야 하며, 메모리 사용을 제공해야한다. 그리고 모든 프로그램이 자신의 전용 메모리 공간을 가지고 있다는 환상을 제공해야 한다. 15.1 가정 스케줄링을 배울 때 문제를 쉽게 이해하기 위해서 가정을 통해 고려 요인을 단순화 했듯이, 여기서도 가정을 통해 많은 제한사항을 두고 시작한다.\n먼저 사용자 주소 공간은 물리 메모리에 연속적으로 배치되어야 한다고 가정한다. 그리고 주소 공간의 크기가 너무 크지 않다고 가정한다. 마지막으로, 각 주소공간의 크기가 같다고 가정한다. 쉬워보이지만, 가정을 완화하는 과정에서 머리가 깨질 예정! 🤪\n15.2 사례 void func() { int x = 3000; x = x + 3; } 위 코드를 x86 어셈블리로 변환하면 다음과 같다. movl 0x0(%ebx), %eax; // 0 + ebx를 eax에 저장 addl $3, %eax; // eax에 3을 더한다. movl %eax, 0x0(%ebx); // eax를 ebx에 저장 이 명령어가 실행되면 프로세스 관점에서 아래와 같은 메모리 접근이 발생한다.\n(출처 : OSTEP)\n주소 128의 명령어를 반입\n이 명령어 실행(주소 15kb에서 탑재)\n주소 132의 명령어를 반입\n이 명령어 실행 (메모리 참조 없음)\n주소 135의 명령어를 반입\n이 명령어 실행 (주소 15kb에 저장)\n지금 시점의 프로그램 관점에서 주소공간은 0부터 16kb까지의 주소공간을 가지고 있다.\n(프로그램이 생성하는 모든 메모리 참조는 이 범위 내에 있어야 한다.)\n그러나 우리는 메모리 가상화를 위해 물리 메모리 주소 0이 아닌 다른곳에 위치시키고 싶다.\n이걸 실제로 프로세스 모르게 어떻게 재배치 하냐가 메모리 가상화의 핵심이다.\n일단 위의 그림처럼 간단한 상황이 있을 수 있다.\n15.3 동적 재배치 이 문제에 대한 첫 번째 해결 사례는 동적 재배치(dynamic relocation), 또는 base and bounds로 불리는 방법이. 이 방법은 프로세스가 시작될 때, 운영체제가 프로세스의 주소 공간을 위한 두 가지 레지스터(base, bounds)를 설정한다. base : 프로세스에 할당된 메모리의 시작 주소를 가리키는 레지스터 bounds : 프로세스에 할당된 마지막 주소를 가리키는 레지스터 그리고 아주 간단한 가상화 공식을 얻을 수 있다! physical address = virtual address + base 그러면 자연스럽게 bounds는 보호를 위해 쓰이며, 이 메모리 주소에 대한 참조가 유효한지 확인한다. 결론적으로아래와 같은 간단한 로직으로 동작한다.\nif (virtual address \u0026lt; 0 || virtual address \u0026gt; bounds) { raise an error(fault); } else { physical address = virtual address + base; } 15.4 하드웨어 지원 : 요약 위의 로직을 달성하기 위해서 필요한 하드웨어 지원은 다음과 같다.\n커널 모드 : 유저모드의 프로세스가 특권 연산을 수행할 수 없도록 한다. base, bounds 레지스터 : 주소 변환과, 번위 검사를 위해 CPU당 두 개의 레지스터가 필요하다. 가상 주소를 변환하고 범위 안에 있는지 확인하는 능력 : 주소 변환과 검사를 위한 회로가 필요하다. 베이스/바운드를 갱신하기 위한 privileged instruction : 프로그램 시작 전에 이를 설정할 수 있어야 한다. 예외 핸들러 등록을 위한 privileged instruction : 범위를 벗어난 주소에 접근할 때, 예외 처리 코드를 하드웨어에 등록할 수 있어야 한다. 예외 발생 기능 : 범위를 벗어난 주소에 접근할 때, 예외를 발생시킬 수 있어야 한다. 15.5 운영체제 이슈 위와 같은 하드웨어 지원을 받는다고 하더라도, 운영체제는 여전히 몇 가지 문제를 해결해야 한다.\n먼저 베이스-바운드를 구현하기 위해서 운영체제가 반드시 개입해야하는 시점이 세가지가 있다.\n프로그램이 시작될 때 : 운영체제는 주소 공간이 저장될 메모리 공간을 찾아야 한다. 프로그램이 종료될 때 : 운영체제는 사용된 메모리를 회수해야 한다. 컨텍스트 스위칭 : 컨텍스트 스위칭이 일어날 때, 프로세스별 자료구조에 베이스-바운드 레지스터 값을 저장해야 한다. (참고로 이 프로세스별 자료구조를 PCB라고 한다.) 당연히 새로 실행되는 프로세스의 베이스-바운드 레지스터 값을 로드해야 한다. 부팅시 LDE + 동적 재배치\n프로세스 실행중 15.6 정리 여기서 생겨난 문제를 알아본다. 기본적으로 동적 재배치는 비효율적이다. 예를들어 힙이 아주 작은 프로세스라도 동일한 크기의 베이스-바운드를 가지고 있어야 한다. 그렇게 낭비되는 메모리를 내부 단편화라고 한다. 메모리의 실제 이용률을 높이기 위해서 더 나은 방법이 필요한데, 첫 번째는 base and bounds를 일반화 하는 것인데 이것을 segmentation이라고 한다. ","permalink":"http://localhost:1313/_wiki/memory-virtualization/","summary":"14. 막간 : 메모리 관리 API stack : 프로그래머를 위해, 컴파일러에 의해 자동으로 할당과 해제가 이루어진다(automatic). void func() { int x; } func()가 호출되면 스택에 공간을 확보하고, func()가 종료되면 스택에서 공간을 해제한다. heap : 프로그래머가 직접 할당과 해제를 해야한다. void func() { int *x = (int *) malloc(sizeof(int)); free(x); } malloc()을 통해 메모리를 할당하고, free()를 통해 메모리를 해제한다. heap에 데이터를 저장하고, func()의 스택에는 heap에 저장된 데이터의 주소를 저장한다. stack만큼 명시적이고 단순하기는 하지만, 쓰임새가 다양하고 실수를 할 여지가 많다.","title":"Week-05"},{"content":"이사 후 사고싶은 물품 정리 커튼이랑 블라인드를 사기로 한 생각은 맞는 것 같다 책상방에 등에 거치용 행거를 사면 알맞을것 같다(등쪽에) 👉 클릭 아직은 냄세가 익숙치 않아서 초반 사용을 위한 디퓨저를 두고싶다. (이건 민숙이랑 같이 고르고 싶다) 러그는 있으면 좋을 것 같다, 조금 큰사이즈에 나무색깔을 거실에, 적당한 사이즈의 남색 러그를 침실에. 리노는 벌써 가스쪽을 돌아다니는데, 우리가 없어도 완전 안심할 수 있게 뭔가 안전장치가 필요하다. 밤에 형광등인게 생각보다 분위기가 별로인 것 같다, 따뜻한 색 조명을 침실과 거실에 두고싶다.(가능하면 벽걸이로) 👉 이런거 여러개? 팬트리를 잘 활용해야 할 것 같다 (공구, 리노음식-우리음식, 청소도구, 세탁도구) 수납함은 가능하면 책상방에 행거 아래에 두면 좋을 것 같다. 화장대는 여기 클릭 조금 더 돈을 쓴다면 이게 참 예쁘네 👉 클릭 ","permalink":"http://localhost:1313/_wiki/%EC%9D%B4%EC%82%AC/","summary":"이사 후 사고싶은 물품 정리 커튼이랑 블라인드를 사기로 한 생각은 맞는 것 같다 책상방에 등에 거치용 행거를 사면 알맞을것 같다(등쪽에) 👉 클릭 아직은 냄세가 익숙치 않아서 초반 사용을 위한 디퓨저를 두고싶다. (이건 민숙이랑 같이 고르고 싶다) 러그는 있으면 좋을 것 같다, 조금 큰사이즈에 나무색깔을 거실에, 적당한 사이즈의 남색 러그를 침실에. 리노는 벌써 가스쪽을 돌아다니는데, 우리가 없어도 완전 안심할 수 있게 뭔가 안전장치가 필요하다. 밤에 형광등인게 생각보다 분위기가 별로인 것 같다, 따뜻한 색 조명을 침실과 거실에 두고싶다.","title":""},{"content":"int arr[10] = {1,2,3,4,5,6,7,8,9,10}; int *p = arr; cout \u0026lt;\u0026lt; p[0] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; arr[0] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; p[5] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; arr[5] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *arr \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *(p+5) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *(arr+5) \u0026lt;\u0026lt; endl; int arr2[2][2] = {{1,2},{3,4}}; int** pp = (int**)arr2; // error : 2차원 배열은 다중 포인터와 다름 int** pp = (int**)arr2; // error : 2차원 배열은 다중 포인터와 다름 : 이 부분에서 에러가 나는 이유.\n첫 *(포인터 연산)은 arr2[0]의 주소값을 가리킨다.\n두번째 *(포인터 연산)은 arr2[0][0]의 value를 가리킨다.\n포인터 연산은 해당 메모리 주소로 가서 값을 참조하는것이다.\n위의 예시에서 다중 포인터의 의도에서는 첫번째 포인터 연산을 끝냈을 때, 포인터형 변수의 값이라 인지하고 값을 참조한다. 즉 첫 포인터 연산 이후 참조한 값은 int형 변수의 주소값이다.\n하지만 실제로 해당 주소칸에 존재하는 값은 int형 변수의 값이다.\n여기서 해당 값을 주소로 생각하고 참조하려다 보니 에러가 발생한다.\nPointerCheatSheat\n","permalink":"http://localhost:1313/_wiki/pointer-%EC%A7%80%EC%98%A5/","summary":"int arr[10] = {1,2,3,4,5,6,7,8,9,10}; int *p = arr; cout \u0026lt;\u0026lt; p[0] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; arr[0] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; p[5] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; arr[5] \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *p \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *arr \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *(p+5) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; *(arr+5) \u0026lt;\u0026lt; endl; int arr2[2][2] = {{1,2},{3,4}}; int** pp = (int**)arr2; // error : 2차원 배열은 다중 포인터와 다름 int** pp = (int**)arr2; // error : 2차원 배열은 다중 포인터와 다름 : 이 부분에서 에러가 나는 이유.","title":"포인터 지옥😢"},{"content":" int main() { const char* test1 = \u0026#34;Hello World\u0026#34;; // test1[0] = \u0026#39;A\u0026#39;; // error: assignment of read-only location \u0026#39;*(test1 + 0)\u0026#39; const char test2[] = \u0026#34;Hello World\u0026#34;; test2[0] = \u0026#39;A\u0026#39;; // ok } 배열 이름은 배열의 시작 주소를 가리키는 상수 포인터이다.\n인덱스 연산자 []는 배열 요소에 접근할 때 사용되며, 이는 사실 포인터 연산으로 구현된다.\ntest1[i]는 내부적으로 *(test1 + i)로 변환된다.\n여기서 arr은 배열의 첫 번째 요소의 주소를 가리키는 포인터로 간주되며, i는 인덱스이다.\n","permalink":"http://localhost:1313/_wiki/pointer-array-%ED%97%B7%EA%B0%88%EB%A6%B4%EB%95%8C-%ED%8C%81/","summary":"int main() { const char* test1 = \u0026#34;Hello World\u0026#34;; // test1[0] = \u0026#39;A\u0026#39;; // error: assignment of read-only location \u0026#39;*(test1 + 0)\u0026#39; const char test2[] = \u0026#34;Hello World\u0026#34;; test2[0] = \u0026#39;A\u0026#39;; // ok } 배열 이름은 배열의 시작 주소를 가리키는 상수 포인터이다.\n인덱스 연산자 []는 배열 요소에 접근할 때 사용되며, 이는 사실 포인터 연산으로 구현된다.\ntest1[i]는 내부적으로 *(test1 + i)로 변환된다.\n여기서 arr은 배열의 첫 번째 요소의 주소를 가리키는 포인터로 간주되며, i는 인덱스이다.","title":""},{"content":"int value = 10; int\u0026amp; reference = value; int* pointer = \u0026amp;value; PrintInfoByRef(*pointer); PrintInfoByPointer(\u0026amp;reference); ","permalink":"http://localhost:1313/_wiki/pointer-reference-%ED%97%B7%EA%B0%88%EB%A6%B4%EB%95%8C-%ED%8C%81/","summary":"int value = 10; int\u0026amp; reference = value; int* pointer = \u0026amp;value; PrintInfoByRef(*pointer); PrintInfoByPointer(\u0026amp;reference); ","title":"아주 간단한 팁!"},{"content":"11. CPU 가상화에 대한 마무리 대화 간단한 Wrapup 대화를 진행한다. 이 정책 전쟁은 영원히 계속 될 것처럼 보이네요.\n공학은 원래 그런거라네, 그리고 그것은 또한 권장 사항이야! 관점의 차이지, 나는 개인적으로 실용적인 것이 좋다고 생각하네. 실용주의자들은 모든 문제가 깔끔하고 쉬운 해결책이 있다고 생각하지 않아.\n12. 메모리 가상화에 관한 대화 수면 부족, 그것은 간단하게 해결할 수 있지. 좀 덜 놀고 더 자도록 하게. 가상 메모리를 이해하기 위해서는 여기서 부터 시작해야 하네. 사용자 프로그램이 생성하는 모든 주소는 가상주소이지. 운영체제는 각 프로세스에게 단지 환상을 제공하지. 구체적으로 프로세스가 자신만의 커다란 전용 메모리를 가진다는 환상 을 제공하는 것이지. 하드웨어로부터 약간의 도움을 얻어 운영체제는 이 가장된 가상 주소를 실제 물리 주소로 변환하고 원하는 정보의 위치를 찾을 수 있네.\n사용하기 쉬운 시스템을 제공하기 위하여 일세, 운영체제는 각 프로세스에게 코드와 데이터를 저장할 수 있는 대용량의 연속된 주소 공간(address space) 을 가지고 있다는 시각을 제공하고자 하는거지, 프로그래머는 이 변수를 어디에 저장해야 하는 거지?\u0026ldquo;와 같은 걱정은 하지 않아도 된다는 거야. 프로그램의 가상 주소 공간이 크고 변수 등을 위한 많은 공간을 가지고 있기 때문이지. 만일 코드 와 데이터를 작고 붐비는 공간에 넣을 걱정을 해야만 했다면 프로그래머로서의 인생은 더 힘들어졌을 거야.\n13. 주소 공간의 개념 13.1. 초기 시스템 메모리 관점에서, 초기 컴퓨터는 많은 개념을 가지고 있지 않았다. 운영체제는 메모리에 상주하는 프로그램(당시의 운영체제)를 올리고, 남은 메모리를 사용자 프로그램에게 할당했다. 13.2 멀티프로그래밍과 시분할 멀티프로그래밍이란, CPU가 프로그램을 번갈아가며 실행하는 것을 의미한다. 그리고 특히 대화식(interactive) 개념이 중요한 요구 사항이 되었다. 초기에는 엉성하게도, 프로세스에게 모든 메모리 접근 권한을 주고 실행하다가 중지하면, 다른 프로그램을 메모리에 올리는 방식으로 운영체제가 동작했다. 당연히 느리다 그래서 메모리에 여러 프로세스를 올리면, 보호의 문제가 대두되게 된다. 특히나 현대의 프로그램을 생각해보면 힙과 같이 동적으로 메모리를 할당하는데, 이러한 상태로 해당 프로그램을 두게 하면 너무 위험하다. 13.3 주소 공간 이러한 문제를 해결하기위해, 여러 프로세스가 메모리에 올라갔음에도, 사용하기 쉬운 메모리 개념을 만들어야 했고, 그것이 바로 주소 공간이다. 결론적으로 운영체제는 가상 주소 공간을 제공하고, 프로세스는 이 가상 주소 공간을 사용한다. 이렇게 하는것을 virtualizing memory라고 한다. 13.4 목표 가상화를 통해 얻고 싶은 목표는 다시 다음과 같다.\n투명성(transparency) : 사용자는 가상화를 인지하지 않아야 한다. 효율성(efficiency) : 가상화는 비용이 적어야 한다. 보호(protection) : 프로세스는 서로의 메모리에 접근할 수 없어야 한다. ","permalink":"http://localhost:1313/_wiki/memory-virtual-intro/","summary":"11. CPU 가상화에 대한 마무리 대화 간단한 Wrapup 대화를 진행한다. 이 정책 전쟁은 영원히 계속 될 것처럼 보이네요.\n공학은 원래 그런거라네, 그리고 그것은 또한 권장 사항이야! 관점의 차이지, 나는 개인적으로 실용적인 것이 좋다고 생각하네. 실용주의자들은 모든 문제가 깔끔하고 쉬운 해결책이 있다고 생각하지 않아.\n12. 메모리 가상화에 관한 대화 수면 부족, 그것은 간단하게 해결할 수 있지. 좀 덜 놀고 더 자도록 하게. 가상 메모리를 이해하기 위해서는 여기서 부터 시작해야 하네. 사용자 프로그램이 생성하는 모든 주소는 가상주소이지.","title":"Week-04 📚"},{"content":"네트워크 기본 개념Cheatsheet 🦉 from 외워서 끝내는 네트워크 핵심이론 OSI 7 Layer : 의존적 관계가 성립하는 (Layered, 상위 계층이 하위 계층에 의존) 프로토콜을 계층적으로 나열한 것 Protocol suite, Protocol Stack Protocol Suite, Protocol Stack : 여러 프로토콜의 집합 Network 성능 지표 throughput : 처리율 (bps, Mbps, Gbps 등), 실시간성을 띄며, 평균값을 보통 지표로 사용\nbandwidth : 대역폭, 통신망이 전송할 수 있는 데이터의 양, 단위는 bps\npacket loss : 패킷 손실률, 패킷이 전송 중 소멸되는 비율\nOSI \u0026amp; Layer와 식별자 알기쉽게 Bottom-up으로 다룬다. 개인적으로 개발 네트워크 서적이 Top-down으로 설정되어있는데, 개발자입장에서는 편하지만, 그냥 네트워크를 처음 배우는 입장에서는 이해가 힘든 것 같다. 요즘 네트워크 서적이나 강의는 보통 그래서 Bottom-up식으로 앞부분은 교양처럼 듣고, 뒤에 힘을 주는 방식으로 되어 있는 것 같다.\nHost Host : Computer + Network End-point : 네트워크의 이용 주체 (server, client 는 네트워크 이용 주체의 역할 구분, 구분하지 않으면 peer) Switch : 네트워크 자체를 이루는 host (Infra) Router : l3 스위치 IPS : 보안 Switch가 하는 일 네트워크를 고속도로로 비유하면, 고속도로망을 지나가다 교차로를 마주하고 경로를 선택하게 되는데 그 근거는 이정표이다.\n자동차를 패킷으로 비유 경로 선택의 근거인 이정표가 IP주소이면 L3 스위칭(라우터, 라우팅 테이블), 다른 계층도 마찬가지 스위칭에서 경로별 비용을 Matric에 비유 L2 NIC : Network Interface Card, H/W, MAC주소를 갖는다. (기본적으로는 신호를 프레임으로, 프레임을 신호로 변환)\n프레임을 검출해서 폐기하거나 전달하는 역할도 여기서 다나와 : 남자들의 쇼핑몰 😏\nPacket : 데이터 단위(사실 L2에서는 Frame을 씀 10kb 내외)\nMAC : Ethernet 계층의 48bit 식별자\nL2 Access switch : End-point와 직접 연결되는 스위치(MAC) 주소를 근거로 스위칭\n물리적인 단자 하나당 하나의 인터페이스 그냥 포트라고도 함 Link-up, Link-down : 연결 상태 (와이어샤크 수업이 생각난다..) L2 Distribution switch : L2 스위치를 위한 스위치(VLAN 기능을 제공)\n규모를 감잡기 위해서 l2스위치는 방하나, l2d 스위치는 층하나, 라우터는 건물 하나\nBroadcast : Unicast와는 반대, Broadcast주소라는 매우 특별한 주소가 존재(111111111111111111)\n목적지 주소가 Broadcast 주소이면, 전체 네트워크 모두로 전송 Broadcast이 발생하면, 다른 네트워크가 통신을 못함 Ethernet 프레임 헤더 구조\nPreamble : 7byte, 10101010, 10101010, 10101010, 10101011 : 전송 시작을 알리는 신호 SFD : 1byte, 10101011 : 프레임의 시작을 알리는 신호 Destination MAC Address : 6byte : 목적지 MAC 주소 Source MAC Address : 6byte : 출발지 MAC 주소 Type : 2byte, IP, ARP, RARP, etc (Ethernet Type) Data : 46 ~ 1500byte : 실제 데이터 FCS : 4byte, CRC : 오류 검출을 위한 계산값, 틀리면 버림 L3 IP Address : l3 식별자, 32bit(8bit * 4) 즉 (0 ~ 255).(0 ~ 255).(0 ~ 255).(0 ~ 255)\n. 으로 구분되며 앞의 세개의 숫자는 Network Id, 뒤의 하나의 숫자는 Host Id Packet : L3 IP Packet\nHeader, Payload로 나뉘는데, 이건 상대적인 분류 최대 크기는 MTU (Maximum Transmission Unit) : 특별한 이유가 없다면 1500bytes Encapsulation, Decapsulation\n패킷의 생성, 전달, 소멸\n계층별 데이터 단위 정리 Frame : l1 ~ l2\nPacket : IP에서(~ MTU)\nSegment : TCP에서(~ MSS)\nStream : 소켓에서 (연속적으로 이루어져 있으며, 크기를 정확히 알 수 없음)\nIPv4 Header 형식과 구성요소\nVersion : 버전 IHL : Header Length Type of Service : 서비스의 종류 Total Length : 전체 길이 Identification : 패킷의 식별자 Flags : Fragmentation Fragment Offset : Fragmentation Time to Live : 패킷의 수명 Protocol : 상위 계층 프로토콜 Header Checksum : 헤더의 체크섬 Source Address : 출발지 주소 Destination Address : 목적지 주소 Subnet Mask : 네트워크 주소와 호스트 주소를 구분하는데 사용되는 32bit 값 (1111 1111. 1111 1111. 1111 1111. 0000 0000)\n기본적으로 원래는 클래스를 나눠서 호스트 주소와 네트워크 주소를 구분했었음 a클래스면 앞에 8bit, b클래스면 16bit, c클래스면 24bit 와 같이 사용했는데, 이제는 서브넷 마스크로 구분 비트 and 연산을 통해 네트워크 주소와 호스트 주소를 구분 CIDR : Classless Inter-Domain Routing, 서브넷 마스크를 표기하는 방법\n192.168.0.10/24 와 같이 표기 호스트 주소와 네트워크 주소를 가르는 1의 개수를 표기 클래스 구분은 없지만 예를들어 a클래스면 /8, b클래스면 /16, c클래스면 /24 즉 앞에 n개의 비트만 and 연산을 해서 네트워크 주소를 추출하겠다는 의미 Broadcast IP Address : 네트워크의 모든 호스트에게 데이터를 전송하는데 사용되는 특별한 주소\n네트워크 주소의 마지막 호스트 주소를 Broadcast 주소로 사용 Multicast IP Address : 특정 그룹에 속한 호스트에게 데이터를 전송하는데 사용되는 특별한 주소\nHost 주소로 사용할 수 없는 주소\n0 : 서브넷 주소 255 : Broadcast 주소 1 : Default Gateway 주소(보통은) 참고 : 127.0.0.1 (localhost, loopback 주소) 인터넷 사용 전에 해야 할 설정\nIP 주소 설정 서브넷 마스크 설정 Gateway IP 설정 DNS 설정 귀찮으니까 DHCP를 사용한다.\nDHCP : Dynamic Host Configuration Protocol, 호스트에게 IP 주소를 동적으로 할당하는 프로토콜 (Broadcast로 요청하고, DHCP 서버가 응답, 즉 Broadcast domain에 묶여있어야함)\nDHCP Discover (client to dhcp server) : 클라이언트가 DHCP 서버를 찾는 과정 DHCP Offer (dhcp server to client) : DHCP 서버가 클라이언트에게 IP 주소를 제안 DHCP Request (client to dhcp server) : 클라이언트가 IP 주소를 요청 DHCP Ack (dhcp server to client) : DHCP 서버가 IP 주소를 할당 ARP : Address Resolution Protocol, IP 주소를 MAC 주소로 변환하는 프로토콜\nNAT : Network Address Translation, 사설 IP 주소를 공인 IP 주소로 변환하는 프로토콜\n| 참고로 공유기는 라우터 + 스위치 + DHCP Server + NAT 기능을 가지고 있음\nPing과 RTT\nICMP : Internet Control Message Protocol, 네트워크 장비 간에 메시지를 주고받는 프로토콜 Echo Request : Ping Echo Reply : Ping에 대한 응답 Time Exceeded : TTL이 0이 되어서 패킷이 소멸될 때 Destination Unreachable : 목적지에 도달할 수 없을 때 L4 TCP, UDP : 둘을 구분하는 가장 큰 차이는 Connection이다.\n문제는 연결이 Virtual이라는 것 (Virtual Circuit) 연결은 결과적으로 순서 번호로 구현 (Sequence Number) 연결은 상태 기반 (Stateful) TCP : Transmission Control Protocol, 신뢰성 있는 데이터 전송을 보장하는 프로토콜\nClient-Server 모델 클라이언트가 소켓을 열면, OS가 TCP 포트를 부여함 3-way Handshake : TCP 연결 설정 과정\nSYN : 클라이언트가 서버에게 연결을 요청\nSYN-ACK : 서버가 클라이언트에게 응답\nACK : 클라이언트가 서버에게 응답\nHandshake 과정에서 Sequence Number와 Acknowledgement Number가 사용됨, 그리고 정책을 교환함 (MSS, Window Size 등)\n4-way Handshake : TCP 연결 해제 과정\nFIN : 클라이언트가 연결 종료 요청 ACK : 서버가 응답 FIN : 서버가 연결 종료 요청 ACK : 클라이언트가 응답 TCP Header 형식과 구성요소\nSource Port : 출발지 포트 Destination Port : 목적지 포트 Sequence Number : 순서 번호 Acknowledgement Number : 확인 번호 Data Offset : 데이터 오프셋 Reserved : 예약 필드 Flags : 플래그 필드 Window Size : 윈도우 크기 Checksum : 체크섬 Urgent Pointer : 긴급 포인터 Options : 옵션 필드 Padding : 패딩 필드 UDP : User Datagram Protocol, 신뢰성 없는 데이터 전송을 보장하는 프로토콜\nConnectionless : 연결 설정 과정이 없음\nStateless : 상태를 유지하지 않음\nBest Effort : 최선을 다하지만, 데이터 손실이 발생할 수 있음\n혼잡제어, 버퍼 관리, 흐름제어가 없음\n클라이언트를 배려하지 않음\n그런데도 쓰는 이유\nIPTV의 경우, 실시간 스트리밍을 하는데, 사용자마다 네트워크 속도가 다르면 하향 평준화 밖에 답이 없음 게임서버의 경우 마찬가지로 TCP를 사용하면 하향 평준화가 발생함, UDP + 혼잡제어를 직접 구현해서 사용하는 것이 더 효율적 UDP Header 형식과 구성요소\nSource Port : 출발지 포트 Destination Port : 목적지 포트 Length : 길이 Checksum : 체크섬 세 가지 네트워크 장치 구조 Inline, 대표 장치 Packet + Drop/Bypass + Filtering Out-of-path Packet + Read only, Sensor Proxy Socket stream + Filtering ","permalink":"http://localhost:1313/_wiki/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/","summary":"네트워크 기본 개념Cheatsheet 🦉 from 외워서 끝내는 네트워크 핵심이론 OSI 7 Layer : 의존적 관계가 성립하는 (Layered, 상위 계층이 하위 계층에 의존) 프로토콜을 계층적으로 나열한 것 Protocol suite, Protocol Stack Protocol Suite, Protocol Stack : 여러 프로토콜의 집합 Network 성능 지표 throughput : 처리율 (bps, Mbps, Gbps 등), 실시간성을 띄며, 평균값을 보통 지표로 사용\nbandwidth : 대역폭, 통신망이 전송할 수 있는 데이터의 양, 단위는 bps\npacket loss : 패킷 손실률, 패킷이 전송 중 소멸되는 비율","title":"네트워크 기본 개념 Cheatsheet 🦉"},{"content":"Intro 😃 게임 서버 프로그래밍을 보는데, 소켓등 네트워크 관련 지식이 부족하다고 느껴서 마찬가지로 책을 한권 읽어보려고 하는데, TCP/IP Illustrated로 정했다. 워낙 네트워크를 싫어하고 귀찮아하는데, 이번에는 좀 더 깊게 이해하고 싶고, 쉬운 개념부터 복습해두고 책을 시작해보려고 한다. Warm-up 👋 [[네트워크-기본-개념]] TCP/IP Illustrated 📚 Chapter 1 : [[Introduction]] ","permalink":"http://localhost:1313/_wiki/network/","summary":"Intro 😃 게임 서버 프로그래밍을 보는데, 소켓등 네트워크 관련 지식이 부족하다고 느껴서 마찬가지로 책을 한권 읽어보려고 하는데, TCP/IP Illustrated로 정했다. 워낙 네트워크를 싫어하고 귀찮아하는데, 이번에는 좀 더 깊게 이해하고 싶고, 쉬운 개념부터 복습해두고 책을 시작해보려고 한다. Warm-up 👋 [[네트워크-기본-개념]] TCP/IP Illustrated 📚 Chapter 1 : [[Introduction]] ","title":"Network 🦉"},{"content":"8.0 스케줄링 : 멀티 레벨 피드백 큐 MLFQ가 해결하려고 하는 기본적인 문제는 두 가지 이다. 짧은 작업을 먼저 실행시켜 반환 시간을 최적화 하는 것. 대화형 사용자에게 빠른 시스템이라는 느낌을 주기 위해서 응답 시간을 최적화 하는 것. 그러나 1번은 작업수행시간을 모르기에, 2번은 rr과 같은 방식은 반환시간이 최악이기에 어렵다. 그래서 핵심 질문 \u0026gt; 정보 없이 스케줄 하는 방법은 무엇인가?\n8.1 MLFQ: 기본 규칙 MLFQ는 여러개의 큐로 구성되며, 각각 다른 우선순위를 가진다. 실행 준비가 된 프로세스는 이 중 하나의 큐에 존재한다. MLFQ는 프로세스 실행을 결정할 때 우선순위를 사용한다. 물론 하나의 큐에 여러개의 작업이 들어갈 수 있지만, 이 경우 RR을 사용한다. 여기까지는 쉬운데 어려운건 우선순위를 어떻게 정할 것인가이다.\nMLFQ는 각 작업에 고정된 우선순위를 부여하는 것이 아니라, 작업의 특성에 따라 우선순위를 동적으로 조절한다. 어떤 작업이 키보드 입력을 기다리며 반복적으로 cpu를 양보하면 -\u0026gt; 우선순위를 높게 유지! 한 작업이 길게 점유한다 -\u0026gt; 우선순위를 낮게 조정! MLFQ의 두 가지 규칙은 다음과 같다. 규칙 1 : Priority A \u0026gt; Priority B 이면, A의 프로세스는 B의 프로세스보다 먼저 실행된다. 규칙 2 : Priority A = Priority B 이면, A와 B는 RR을 사용하여 실행된다. 당장은 위의 그림과 같이 작업이 구성된다고 했을 때, A B가 RR으로 처리되면 CD는 실행되지도 않는 문제가 발생한다. 아래의 목차에서 작업 수선순위자체가 변경되는 방법에 대해 알아보자. 8.2 MLFQ: 우선순위의 변경 첫번째 변경은 다음과 같은데 주로 대화형 프로세스와 cpu bound 프로세스를 구분하는 방법이다.\n대화형 프로세스는 짧은 시간동안 CPU를 사용하고, 자주 양보한다. CPU bound 프로세스는 긴 시간동안 CPU를 사용하고, 응답시간이 짧다. MLFQ에 추가된 규칙\n규칙 3 : 작업이 시스템에 들어오면, 우선순위는 가장 높은 큐에 할당된다. 규칙 4-a : 작업이 타임슬라이스를 전부 사용하면, 우선순위는 낮은 큐로 이동된다. 규칙 4-b : 타음 슬라이스를 사용하지 않고 CPU를 양도하면, 우선순위는 유지된다. 이 규칙의 의의는 일단 전부 짧은 시간을 사용하는 프로세스라 가정하고, 실제로 실행시간이 짧다면 위에 두거나 우선순위가 하락하는 동안 끝내는 것이고, 그림에서 회색은 실제로 짧은 작업인데, 우선순위가 하락하기전에 종료, 더높은 우선순위가 없는동안은 검은색작업이 잘 수행된다. 실행시간이 길다면 우선순위가 하락하면서 아래로 내려가게 된다. 대화형 프로그램에서는 굳이 살피지 않아도 잘 동작함을 알 수 있다. (타임슬라이스 내의 반환으로 인한 우선순위 유지) 현재 MLFQ의 문제점 일견 완벽해 보이지만, MLFQ에도 문제점이 존재한다. 기아 상태(starvation)가 발생할 수 있다. (예를 들어 대화형 프로세스가 너무 많은 경우) 지금 상태를 알 수 있다면, CPU를 독점 하는 프로세스를 만들 수 있다. (예를 들어 악의적으로 아무 입출력을 타임슬라이스 내에 내서, 우선순위를 유지하는 프로그램) 프로그램의 구분이 바뀔 수 있다 (cpu bound 작업이 대화형 입출력을 요구받을 수 있다). 8.3 우선순위의 상향 조정 당연히 기본적인 아이디어는 우선순위를 상향 조정하는 것이다. 이를 위해 다음과 같은 규칙을 추가한다. 규칙 5 : 일정 기간 S가 지나면, 모든 프로세스의 우선순위를 최상위 큐로 이동시킨다. 이 규칙을 통해 기아 상태와 프로그램의 구분이 바뀔 수 있는 문제를 해결할 수 있다. 물론 여기에도 많은 고민이 남아있는데, 바로 S의 값을 어떻게 설정할 것인가이다. S의 값이 너무 작으면, 대화형 작업이 적절한 시간동안 실행되지 않을 수 있고, 너무 크면 기아 상태가 발생할 수 있다. 8.4 우선순위의 하향 조정 나머지 문제(스케줄러를 독점하는 이슈)도 하나의 규칙을 재정립해서 해결한다. 규칙 6 : 우선 순위 단계에서 시간 할당량을 소진하면, 우선 순위를 하향 조정한다. 8.5 MLFQ조정과 다른 이슈들 MLFQ의 아이디어는 위와 같지만, 아직 실제 구현에는 많은 문제가 남아있다. 타임슬라이스의 길이를 어떻게 설정할 것인가? 보통은 높은 우선순위의 큐일수록 타임슬라이스를 짧게 가져가긴 한다. S의 값을 어떻게 설정할 것인가? 9.0 스케줄링 : 비례 배분 이번 장에서는 스케줄러의 또 다른 방법인 비례 배분에 대해 알아본다.\n비례 배분의 목표는 간단한데, 반환시간이나 응답시간을 최적화 하는 대신 스케줄러가 각 프로세스에 CPU 시간을 공평하게 분배하는 것이다.\n가장 좋은 예시는 Waldspurger와 Weihl의 연구인 lottery scheduling이다. (간단하게 말하면, 각 프로세스에 티켓을 부여하고, 스케줄러가 랜덤하게 티켓을 뽑아서 실행하는 방식 더 중요한 프로세스에 더 많은 티켓을 준다)\n9.1 기본 개념 : 추첨권이 당신의 지분이다 추첨권이라는 기본적인 개념이 추천 스케줄링의 근간을 이룬다. 기본적인 아이디어는 위와 같고, 장점은 무작위성이다. 무작위성이 장점인 이유\n기본적으로 기존의 문제를 해결한다 (LRU의 예시를 생각해보자) 가볍다 (관리해야 할 정보가 거의 없다) 빠르다 (로직이 덜 붙어 난수생성 시간정도에 불과하다) 9.2 추첨 기법 추첨권을 다루는 다양한 기법이 있는데, 그 중 가장 먼저 고려할 것 은 추첨권 화폐이다. 이 개념은 사용자가 추첨권을 자신의 화폐 가치로 추첨권을 자유롭게 할당 할 수 있게 한다. (시스템은 자동적으로 화폐 가치를 변환한다) 이건 다른 사용자와 다른 프로세스가 할당한 추첨권의 가치를 비교할 수 있게 해준다. 그리고 추첨권 양도라는 개념도 있는데, 이는 다른 프로세스에게 추첨권을 양도할 수 있게 해준다. 이를 통해 사용자는 자신의 추첨권을 다른 프로세스에게 양도할 수 있고, 이는 다른 프로세스가 더 많은 추첨권을 가지게 해준다. 마지막으로 추첨권 팽창라는 개념도 있는데, 이는 시스템이 특정 이벤트가 발생할 때 추첨권을 증가시키는 것이다. 9.3 구현 // counter : 당첨자를 발견했는지 확인하는 변수 int counter = 0; // winner : 0부터 총 추첨권의 수까지 랜덤하게 추첨된 당첨자 int winner = getRandom(0, total_tickets); // 추첨권을 가진 프로세스를 찾는다. node_t *current = head; while (current) { counter += current-\u0026gt;tickets; if (counter \u0026gt; winner) { // 당첨자를 발견했으므로 프로세스를 실행한다. run(current-\u0026gt;process); break; } current = current-\u0026gt;next; } 위의 코드는 추첨권을 가진 프로세스를 찾아 실행하는 코드이다. 9.4 추첨권 시스템 예제 기본적으로 불공정 지표 U를 정의한다.(U = 1 - (첫 작업 종료 시간 / 두 번째 작업 종료 시간))\n기본적으로는 1(가장 공정함)으로 수렴하긴 하지만 랜덤의 특성상 초반에는 불공정함이 발생할 수 있다.\n다만 추첨권 시스템에서 가장 큰 문제는 추첨권을 어떻게 할당할 것인가이다.\n이는 추첨권을 어떻게 할당할 것인가에 따라 성능이 달라질 수 있고 아직 미해결 상태이다.\n보통은 아래와 같은 형식으로 한다고 함 정적(Static) 방식: 프로세스 유형과 우선순위를 기반으로 초기에 티켓을 할당.\n프로세스 우선순위 티켓 개수 (초기) CPU 사용량 (%) P1 (커널) 높음 (100) 100 30% P2 (브라우저) 중간 (50) 50 40% P3 (백그라운드) 낮음 (10) 10 20% P4 (영상 편집) 높음 (80) 80 90% 동적(Dynamic) 방식: CPU 사용량, I/O 대기 시간 등을 모니터링하며 티켓 개수를 실시간으로 조정. 프로세스 초기 티켓 조정 후 티켓 (CPU 사용 반영) P1 (커널) 100 110 (중요도가 높고 CPU 사용 적절) P2 (브라우저) 50 60 (인터랙티브 앱이므로 약간 증가) P3 (백그라운드) 10 20 (사용량이 낮아 티켓 증가) P4 (영상 편집) 80 60 (CPU 사용량이 너무 높아 감소) 9.6 결정론적 스케줄링 결정론적 스케줄링은 랜덤성을 제거하고, 스케줄링을 결정론적으로 만드는 것이다. 대표적으로 보폭 스케줄링(stride scheduling)이 있다. 보폭 스케줄링은 각 프로세스에 보폭을 할당하고, 스케줄러는 가장 작은 보폭을 가진 프로세스를 실행한다. 이를 통해 랜덤성을 제거하고, 스케줄링을 결정론적으로 만들 수 있다. curr = remove_min(queue); schedule(curr); curr-\u0026gt;pass += curr-\u0026gt;stride; insert(queue, curr); 처음부터 U가 1에 수렴하는 것을 볼 수 있다. 그렇다면 왜 결정론적 스케줄링을 사용하지 않을까? 이유는 단순한데, 새로운 프로세스가 들어오면, 스케줄러는 새로운 보폭을 할당해야 하는데, 이것이 결정론적 스케줄링의 단점이다.(랜덤 추첨권 방식에서 훨씬 쉽다) 9.7 리눅스 CFS(Completely Fair Scheduler) 리눅스는 기존과 다른 방식으로 공정 배분 스케줄링을 구현한다. 이 스케줄러의 장점은 효율성과 확장성이다. 효율성을 위해 CFS는 최적의 내부 설계와 자료구조를 사용한다. 일단 기본적으로 virtual runtime이라는 counting 기반 방식을 사용한다. 프로세스 실행시 virtual runtime이 증가하고, 스케줄러는 가장 작은 virtual runtime을 가진 프로세스를 실행한다. 이 역시 아이디어는 간단하지만, 스케줄러가 어느 시점에 멈출지를 결정하는 것이 중요하다. 너무 자주 스케줄러를 호출하면 오버헤드가 발생하고, 너무 늦게 호출하면 공정성이 떨어진다. 이를 위해 다양한 통제 변수를 사용한다. 첫 번째 변수로 sced_latency가 있다. 이 변수는 스케줄러가 얼마나 자주 호출되는지를 결정한다(보통 48ms). 예를 들어 네개의 프로세스가 있다면, CFS는 sced_latency를 1/4로 나누고 프로세스당 타임슬라이스를 해당 값으로 설정한다. 문제는 너무 많은 프로세스가 있다면 너무 많은 context switching이 발생할 수 있다. 이를 해결하기 위해 min_granularity라는 변수를 사용한다. (보통 최솟값은 6ms) 예를들어 10개의 프로세스가 있다면, 원래는 sced_latency에 따라 4.8ms로 나누어진다. 하지만 min_granularity가 6ms이므로, 6ms로 설정된다. 스케줄링의 효울성은 이렇게 보호된다. 이러한 방식으로 CFS는 공정성과 효율성을 모두 확보한다. 추가적인 기능으로 가중치(Niceness)를 사용한다. 이는 프로세스의 우선순위를 보정한다. 수식은 다음과 같다. time_slice = (weight_of_task / weight_of_all_tasks) * sced_latency (가중치 표는 -20 ~ 19까지에 해당하는 값을 대응 시킨다) 이런 수식을 도입하면 가중치에 따라서 프로세스의 타임슬라이스(재조정 시간)이 달라지게 된다. vruntime도 가중치에 따라서 고도화 되어있다. 고도화 수식은 다음과 같다. vruntime = vruntime + (weight_of_all_tasks / weight_of_task) * time_slice (가중치가 높을수록 vruntime이 느리게 증가한다) RedBlack Tree의 활용\nCFS는 효율적인 알고리즘이 꼭 필요하다. (다음 실행할 프로세스를 빠르게 찾아야 하기 때문) 예를들어 대기중인 프로세스를 LinkedList로 관려하면, 검색에 너무 많은 시간이 소요된다. 커질수록 O(n)의 시간복잡도를 가지기 때문인데, 아주 작은 타임슬라이스 시간 안에 수천개의 프로세스가 대기할 수 있는데, 이는 매우 큰 문제이다. I/O와 잠자는 프로세스 다루기\nCFS는 I/O와 잠자는 프로세스를 어떻게 다루는지에 대한 문제도 있다. 이를 위해 CFS는 vruntime을 사용한다. 정확히는 잠자는 프로세스가 깨어났을 때 vruntime을 업데이트한다(트리에서 찾을 수 있는 가장 작은 vruntime을 찾아서 업데이트한다) 10.0 멀티프로세서 스케줄링 이번 장에서는 멀티프로세서 스케줄링에 대해 알아본다. 원래는 병행성을 다루고 보는 것이 중요하지만, 이번 장에서는 멀티프로세서 스케줄링에 대해 알아본다. 다만 기존의 프로그램들(하나의 코어만 사용하도록 설계된)을 멀티프로세서에서 실행시키는 것에 대해서 알아본다. 10.1 배경: 멀티프로세서 구조 기본적으로 멀티 프로세서 하드웨어는 두가지 문제를 야기한다.\n다수의 프로세서 간의 데이터 공유 문제 하드웨어 캐시의 사용방식 문제 캐시는 지영성에 기반한다. 지역성에는 시간 지역성과 공간 지역성이 있다.\n시간 지역성 : 최근에 접근한 데이터는 다시 접근할 확률이 높다. 공간 지역성 : 최근에 접근한 데이터와 인접한 데이터에 다시 접근할 확률이 높다. 이러한 특징에서, 캐시 일관성 문제가 발생한다.\n캐시 일관성 문제를 요약하면, 캐시된 데이터를 다른 프로세서가 변경했을 때, 어떻게 처리할 것인가이다.\n기본적인 해결책은 하드웨어에서 제공된다, 하드웨어는 메모리 주소를 계속 감시하고, 항상 올바른 순서로 처리되도록 시스템을 관리한다.\n여러개의 프로세서가 하나의 메모리를 갱실할때는 항상 공유도되록한다.\n버스 기반 시스템에서는 버스 스누핑이라는 기술을 사용한다. (캐시가 자신과 메모리를 연경하는 버스의 통신 내용을 감시하는 것)\n10.2 동기화를 잊지 마시오 멀티프로세서에서는 동기화가 더욱 중요하다. 이건 병행성에서 다룰 것 같고, 간단히 요약하면, 동기화 문제가 발생하는 경우를 간단히 설명하는 장이다. lock이 대안이지만, lock을 사용하면 성능이 떨어지는 trade-off가 발생한다. 10.3 캐시 친화성 캐시 친화성도 문제를 야기한다 (CPU가 번갈아가며 캐시에 데이터를 올리면서 오는 지연과 낭비)\n멀티프로세서는 이런점을 고려해서 프로세서를 스케줄링 해야 한다.\n결론적으로 사실 병행성에서 나와야 하는 주제이고, 앞의 설명이 부족해서 단번에 이해가 어렵고 혼동스러울 수 있다. 멀티 프로세서 환경에서 스케줄링을 하기 위해서 고려해야할 것들에 대한 언급정도로 이해하면 될 것 같다.\n10.4 단일 큐 스케줄링 결국 다시 스케줄링으로 돌아와서 이야기해보면, 멀티프로세서 스케줄링에서 가장 간단한 방법은 단일 큐 스케줄링이다. 단일 큐 멀티프로세서 스케줄링(Single Queue Multiprocessor Scheduling)은 모든 프로세서가 하나의 큐를 공유하고, 스케줄러는 가장 높은 우선순위를 가진 프로세스를 실행한다. 간단히 말하면, 큐에 넣고 비어있는 프로세서에게 할당하는 방식이다. (작업이 두개고 프로세서가 두개면, 두개의 프로세서에게 각각 할당하는 방식) 이 방식은 대부분의 단점을 무시하기도 하고, 간단하지만, 확장성이 결여되어있다. 이 방식은 락을 사용하는데(실행시킬 다른 프로세서를 찾을 때) 이는 성능을 떨어뜨릴 수 있다. 또한 아무런 보정이 없다면, 캐시 친화성이 떨어질 수 있다. 이를 해결하기 위해서 같은 프로세서가 같은 프로세스를 실행하도록 유도해서 오버헤드를 줄이는 방법도 있다. 이같은 방식은 좋지만, 구현이 어렵다는 단점이 있다. 10.5 멀티 큐 스케줄링 멀티 큐 스케줄링(Multi Queue Scheduling)은 단일 큐 스케줄링의 단점을 보완한 방식이다. 이것도 개념자체는 어렵지 않아서 간단하게 요약하면, 각 프로세서에 큐를 할당하고, 각 큐에 프로세스를 할당하는 방식이다. A,B,C,D 네가지 작업이 있다면, A,B는 큐1에, C,D는 큐2에 할당하는 방식이다. 기본적으로 캐시친화적이고, 큐로 인한 락을 줄일 수 있다. 단 이 방식도 문제가 있는데, 워크로드가 불균형하다면, 한쪽 큐가 너무 많은 작업을 처리하게 된다. 이걸 해결하기 위한 방법은 이주 (migration)이다. 이주는 프로세스를 다른 큐로 이동시키는 것이고 이를 통해 불균형을 해결할 수 있다. 개인적으로 모든 스케줄링 방법의 한계는 작업을 정확히 예측 할 수 없다는 것에 있다고 생각하는데, 그러한 정보의 단절 속에서 사전적인 해결책을 찾는 것이 어렵다고 생각한다. 이주는 그러한 것들을 잘 극복한 사례라고 생각한다.\n","permalink":"http://localhost:1313/_wiki/mlfq-multiprocessor-schedule/","summary":"8.0 스케줄링 : 멀티 레벨 피드백 큐 MLFQ가 해결하려고 하는 기본적인 문제는 두 가지 이다. 짧은 작업을 먼저 실행시켜 반환 시간을 최적화 하는 것. 대화형 사용자에게 빠른 시스템이라는 느낌을 주기 위해서 응답 시간을 최적화 하는 것. 그러나 1번은 작업수행시간을 모르기에, 2번은 rr과 같은 방식은 반환시간이 최악이기에 어렵다. 그래서 핵심 질문 \u0026gt; 정보 없이 스케줄 하는 방법은 무엇인가?\n8.1 MLFQ: 기본 규칙 MLFQ는 여러개의 큐로 구성되며, 각각 다른 우선순위를 가진다. 실행 준비가 된 프로세스는 이 중 하나의 큐에 존재한다.","title":"Week-03 📚"},{"content":"1. 변수의 메모리 공간 [데이터 영역]\n초기화된 데이터를 저장하는 공간 전역 변수, 정적 변수, 상수 등이 저장된다. .data(미리 초기화 해 둔 경우), .rodata(읽기 전용 데이터), .bss(초기화 안해둔 경우) 섹션에 저장된다. [스택 영역]\n지역 변수, 매개변수, 리턴 값 등이 저장된다. 함수 호출 시 생성되고 함수 종료 시 소멸된다. 함수 호출 시 생성되는 프레임에 저장된다. [힙 영역]\n","permalink":"http://localhost:1313/_wiki/cpp-%EB%B3%80%EC%88%98%EC%9D%98-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B3%B5%EA%B0%84/","summary":"1. 변수의 메모리 공간 [데이터 영역]\n초기화된 데이터를 저장하는 공간 전역 변수, 정적 변수, 상수 등이 저장된다. .data(미리 초기화 해 둔 경우), .rodata(읽기 전용 데이터), .bss(초기화 안해둔 경우) 섹션에 저장된다. [스택 영역]\n지역 변수, 매개변수, 리턴 값 등이 저장된다. 함수 호출 시 생성되고 함수 종료 시 소멸된다. 함수 호출 시 생성되는 프레임에 저장된다. [힙 영역]","title":"Cpp 변수의 메모리 공간(작성중)"},{"content":"1. 어셈블러 어셈블러는 어셈블리어를 기계어로 변환해주는 프로그램이다.\nSection 구분이 있다.\n.data : 데이터를 저장하는 공간 변수의 선언 및 사용 초기화 된 데이터를 저장하는 공간 .text : 코드를 저장하는 공간 .bss : 초기화되지 않은 데이터를 저장하는 공간 #include \u0026lt;iostream\u0026gt; using namespace std; char str[] = {\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;}; // .data 영역에 저장 int main() { char str2[] = {\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;,\u0026#39;5\u0026#39;}; // stack 영역에 저장 cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; str2 \u0026lt;\u0026lt; endl; return 0; } 12345 12345�% str은 초기화된 데이터이기 때문에 .data 영역에 저장된다. str2는 stack 영역에 저장된 문자 배열이고 우연히 escape null을 찾을때까지 출력한다. 8비트 : 1바이트 16비트 : 2바이트: 1워드 32비트 : 4바이트: 1더블워드 64비트 : 8바이트: 1쿼드워드\n레지스터의 크기는 일반적으로 64비트 운영체제에서 64비트 레지스터를 사용한다.(8바이트) 종류는 총 16개이다. 64비트 레지스터 : RAX, RBX, RCX, RDX, RSI, RDI, RBP, RSP, R8, R9, R10, R11, R12, R13, R14, R15 32비트 레지스터 : EAX, EBX, ECX, EDX, ESI, EDI, EBP, ESP 16비트 레지스터 : AX, BX, CX, DX, SI, DI, BP, SP 8비트 레지스터 : AL, BL, CL, DL, SIL, DIL, BPL, SPL 1.1. 어셈블리어 명령어 어셈블리어 명령어는 기계어로 변환되는 명령어이다.\n어셈블리어 명령어는 기계어 명령어와 1:1 대응된다.\nmov : 레지스터에 값을 저장하는 명령어\nadd : 레지스터에 값을 더하는 명령어\nsub : 레지스터에 값을 빼는 명령어\nmul : 레지스터에 값을 곱하는 명령어\ndiv : 레지스터에 값을 나누는 명령어\ninc : 레지스터에 값을 1 증가시키는 명령어\ndec : 레지스터에 값을 1 감소시키는 명령어\ncmp : 레지스터에 값을 비교하는 명령어\njmp : 레지스터에 값을 비교하는 명령어\nje : 레지스터에 값을 비교하는 명령어\njne : 레지스터에 값을 비교하는 명령어\njg : 레지스터에 값을 비교하는 명령어\njge : 레지스터에 값을 비교하는 명령어\njl : 레지스터에 값을 비교하는 명령어\njle : 레지스터에 값을 비교하는 명령어\ncall : 함수를 호출하는 명령어\nret : 함수를 종료하는 명령어\npush : 스택에 값을 저장하는 명령어\npop : 스택에 값을 꺼내는 명령어\nlea : 주소를 저장하는 명령어\nand : 논리곱을 하는 명령어\nor : 논리합을 하는 명령어\nxor : 배타적 논리합을 하는 명령어\nnot : 논리부정을 하는 명령어\nshl : 왼쪽 시프트를 하는 명령어\nshr : 오른쪽 시프트를 하는 명령어\nnop : 아무것도 하지 않는 명령어\ndb: Define Byte - 바이트 단위의 데이터를 정의합니다. dw: Define Word - 워드(2바이트) 단위의 데이터를 정의합니다. dd: Define Doubleword - 더블워드(4바이트) 단위의 데이터를 정의합니다. dq: Define Quadword - 쿼드워드(8바이트) 단위의 데이터를 정의합니다.\n","permalink":"http://localhost:1313/_wiki/%EC%96%B4%EC%85%88%EB%B8%94%EB%A6%AC/","summary":"어셈블리 디버깅을 위한 간단한 cheat sheet","title":"어셈블리"},{"content":"cpp 비트 연산 비트 연산은 거의 모든 low한(상대적으로) 언어는 지원하는데, 실제로 사용할때는 코테 문제나, 시험보는 상황 외에는 거의 없었다. 게임업계는 진짜 사용하는 것 같아 간단히 예제를 정리해보았다.\n비트 연산자 \u0026amp; : AND 연산자 | : OR 연산자 ^ : XOR 연산자 ~ : NOT 연산자 \u0026lt;\u0026lt; : 왼쪽 시프트 연산자 \u0026gt;\u0026gt; : 오른쪽 시프트 연산자 비트 연산 예제 비트 플래그 사용 예제 비트 부호를 플래그로 사용하여, 게임내의 캐릭터 상태를 표현할 수 있다.\n0b0000 [무적][변이][스턴][공중부양]\n#include \u0026lt;iostream\u0026gt; using namespace std; unsigned char flag; // 부호 비트가 딸려오는건 엄청 헷갈리기 때문에 보통 unsigned로 선언한다. flag = (1 \u0026lt;\u0026lt; 3); // 무적 플래그를 켠다. flag |= (1 \u0026lt;\u0026lt; 2); // 변이 플래그를 켠다(무적 + 변이). // 무적인지 확인하고 싶다 : bitmask if (flag \u0026amp; (1 \u0026lt;\u0026lt; 3) != 0) { cout \u0026lt;\u0026lt; \u0026#34;무적 상태입니다.\u0026#34; \u0026lt;\u0026lt; endl; } // 무적이나 스턴 상태인지 확인하고 싶다 : bitmask bool mask = (1 \u0026lt;\u0026lt; 3) | (1 \u0026lt;\u0026lt; 2); if (flag \u0026amp; mask != 0) { cout \u0026lt;\u0026lt; \u0026#34;무적이나 스턴 상태입니다.\u0026#34; \u0026lt;\u0026lt; endl; } ","permalink":"http://localhost:1313/_wiki/%EB%B9%84%ED%8A%B8-%EC%97%B0%EC%82%B0/","summary":"거의 처음으로 실사용 하는 예제를 찾아서 정리하는 중","title":"비트 연산"},{"content":"C++ 기본 문법 정리 [[어셈블리]] [[비트-연산]] [[cpp-변수의-메모리-공간]] [[pointer-reference-헷갈릴때-팁]] [[pointer-array-헷갈릴때-팁]] [[pointer-지옥]] [[free는-어떻게-할당을-해제하는가]] [[타입-변환]] [[cpp-casting]] ","permalink":"http://localhost:1313/_wiki/cpp-basic/","summary":"결국 리마인드 강의를 보면서 Cheatsheet 형식정도로만 가볍게 정리","title":"Cpp-basic 🐋"},{"content":"로드맵 https://www.inflearn.com/roadmaps/375\n","permalink":"http://localhost:1313/_wiki/2024-05/","summary":"로드맵 https://www.inflearn.com/roadmaps/375","title":""},{"content":"05.0 막간 : 프로세스 API 거의 모든 소스코드와 강의자료는 아래 링크가 출처 입니다.\n강의 소스코드 : OSTEP 테스트 프로그램 : OSTEP Test Programs 역자 강의 자료 : 강의자료 개념적인 내용이 아닌 실제적인 측면에서 코드를 보는 장은 막간이라고 별도 표기한다.\n이번 절에서는, Unix 시스템의 프로세스 생성에 관해 배운다. Unix는 프로세스를 생성하는 시스템콜로 다음 두가지를 제공한다. fork() exec() 그리고 wait() 함수를 통해 자식 프로세스가 종료될 때까지 기다릴 수 있다. 핵심 질문 : 프로세스를 생성하고 제어하는 방법, 프로세스를 생성하고 제어하려면 운영체제가 어떤 인터페이스를 제공해야 하는가? 유용성, 편리성, 그리고 성능을 위해서는 어떻게 인터페이스를 설계해야 하는가?\n5.1 fork() 참고로 fork() 시스템콜은 가장 이해하기 힘들거나 적어도 가장 특이한 시스템콜 중 하나이다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main(int argc, char *argv[]) { printf(\u0026#34;hello world (pid:%d)\\n\u0026#34;, (int) getpid()); int rc = fork(); if (rc \u0026lt; 0) { fprintf(stderr, \u0026#34;fork failed\\n\u0026#34;); exit(1); } else if (rc == 0) { printf(\u0026#34;hello, I am child (pid:%d)\\n\u0026#34;, (int) getpid()); } else { printf(\u0026#34;hello, I am parent of %d (pid:%d)\\n\u0026#34;, rc, (int) getpid()); } return 0; } gcc -o c1 c1.c -Wall ./c1 hello world (pid:4605) hello, I am parent of 4607 (pid:4605) hello, I am child (pid:4607) \u0026lsquo;hello world\u0026rsquo;는 부모 프로세스가 출력하고 본인 pid를 출력했다. fork() 시스템콜 이후 if 분기를 자세히 볼 필요가 있다. 부모 프로세스 (pid 4605)는 else 분기로 가고 자식 프로세스 (pid 4607)는 else if 분기로 간다. fork() 시스템콜 이후에는 두 개의 똑같은(더 정확히 말하면 거의 똑같은) 프로세스가 생성된다는 것이다. 거의 동일한 프로세스의 복사본이 생성되고, 그 복사본은 스스로의 주소 공간, 레지스터, 자신의 pc값을 갖지만 매우 중요한 차이점이 있다. 부모 프로세스는 fork() 시스템콜 이후에 자식 프로세스의 pid를 반환하고, 자식 프로세스는 0을 반환한다는 것이다. 이것은 부모 프로세스와 자식 프로세스가 서로 다른 일을 할 수 있게 해준다. 여기서 자식 프로세스 혹은 부모 프로세스중 어느것이 먼저 실행된다는것은 매우 어렵고 비결정성을 띈다.\n5.2 wait() #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; int main(int argc, char *argv[]) { printf(\u0026#34;hello world (pid:%d)\\n\u0026#34;, (int) getpid()); int rc = fork(); if (rc \u0026lt; 0) { fprintf(stderr, \u0026#34;fork failed\\n\u0026#34;); exit(1); } else if (rc == 0) { printf(\u0026#34;hello, I am child (pid:%d)\\n\u0026#34;, (int) getpid()); } else { int wc = wait(NULL); printf(\u0026#34;hello, I am parent of %d (wc:%d) (pid:%d)\\n\u0026#34;, rc, wc, (int) getpid()); } return 0; } wait() 함수를 사용하면 부모 프로세스가 자식 프로세스가 종료될 때까지 기다릴 수 있다. 그래서 아래처럼 의도한 실행 순서를 보게 된다. hello world (pid:4605) hello, I am child (pid:4607) hello, I am parent of 4607 (pid:4605) 5.3 exec() exec() 시스템콜은 새로운 프로그램을 실행하는데 사용된다. p2.c 프로그램은 같은 프로그램의 카피를 실행할때만 유용하다. p3.c 프로그램은 exec() 시스템콜을 사용하여 wc 프로그램을 실행한다. wc는 unix 명령어로 파일의 줄, 단어, 문자 수를 세는 프로그램이다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; int main(int argc, char *argv[]) { printf(\u0026#34;hello world (pid:%d)\\n\u0026#34;, (int) getpid()); int rc = fork(); if (rc \u0026lt; 0) { // fork failed; exit fprintf(stderr, \u0026#34;fork failed\\n\u0026#34;); exit(1); } else if (rc == 0) { // child (new process) printf(\u0026#34;hello, I am child (pid:%d)\\n\u0026#34;, (int) getpid()); char *myargs[3]; myargs[0] = strdup(\u0026#34;wc\u0026#34;); // program: \u0026#34;wc\u0026#34; (word count) myargs[1] = strdup(\u0026#34;p3.c\u0026#34;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count printf(\u0026#34;this shouldn\u0026#39;t print out\u0026#34;); } else { // parent goes down this path (original process) int wc = wait(NULL); printf(\u0026#34;hello, I am parent of %d (wc:%d) (pid:%d)\\n\u0026#34;, rc, wc, (int) getpid()); } return 0; } 실행 결과\n❯ ./p3 hello world (pid:7119) hello, I am child (pid:7120) 30 120 896 p3.c hello, I am parent of 7120 (wc:7120) (pid:7119) ❯ wc p3.c 30 120 896 p3.c 참고 : wc 프로그램이 잘 동작하는지 보기 위해 쉘에서 별도로 한 번 더 실행했다. char *myargs[3]; myargs[0] = strdup(\u0026#34;wc\u0026#34;); // program: \u0026#34;wc\u0026#34; (word count) myargs[1] = strdup(\u0026#34;p3.c\u0026#34;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count execvp() 함수는 exec() 시스템콜을 호출하는데, p3.c파일을 인자로 준 wc 프로그램을 실행한다. 30 120 896 p3.c 그래서 위와 같이 p3.c 파일의 줄, 단어, 문자 수를 세는 결과를 출력한다. 해당 wc 프로그램이 끝나면, 자식 프로세스는 종료되고, // parent goes down this path (original process) int wc = wait(NULL); printf(\u0026#34;hello, I am parent of %d (wc:%d) (pid:%d)\\n\u0026#34;, rc, wc, (int) getpid()); wait() 함수를 통해 기다리고 있던부모 프로세스가 재실행되어 아래 문구를 출력한다. hello, I am parent of 7120 (wc:7120) (pid:7119) fork()역시 매우 독특하다. fork() 시스템콜은 실행할 프로그램(executable)과 몇개의 인자를 제공한다. fork() 시스템콜이 호출되면, 인자로 제공한 프로그램의 코드가 로드되고, 지금 코드의 세그먼트와 정적 데이터를 덮어쓴다. 또한 힙이나 세그먼트 같은 메모리 공간은 새로 초기화된다. 즉 새로운 프로세스를 실행시키는것이 아니라, 지금 프로세스를 새로운 프로그램으로 덮어쓰는 것이다. 그 증거로 exec() 시스템콜 이후의 기존 프로세스는 실행되지 않는다 (\u0026ldquo;this shouldn’t print out\u0026rdquo;). 즉 다른 program을 덮어씌워 실행시키는 것이다. PID는 변하지 않고, 말인 즉슨 새로운 프로세스를 실행시키는것은 아닌, 다른 프로그램을 실행시키는 것이다. Tip : Getting It Right Lamson은 \u0026ldquo;옳은 일을 하라\u0026rdquo; 그리고 그것은 어떠한 추상화나 단순화로도 대체될 수 없다고 말한다. 책에서는 다양한 프로세스의 생성 디자인이 있을 수 있지만, 정확히 해야 할 일 은 fork(), exec()과 같이 단순하고 올바른 방법이 이라며 강조했다.\n5.4 왜, 이런 API를? 프로세스를 생성하는 간단한 일에 왜이렇게 이상하고 복잡한 인터페이스를 제공하는 것일까? 밝혀진 바에 따르면, Unix의 Shell을 구현하려면 fork()와 exec()의 분리는 꼭 필요했다. 쉘은 코드를 fork() 이후, 그리고 exec()이전에 실행해야 했기 때문이다. 쉘은 기본적으로 단순한 유저 프로그램이다. 프롬프트를 보여주고, 입력을 기다린다. 만약 커맨드(일반적으로 실행 가능한 프로그램과 인자)를 입력받으면, (대부분의 경우에) 쉘은 해당 실행 가능한 프로그램이 파일시스템의 어디에 있는지 찾는다. 그리고 fork()를 호출하여 커맨드를 실행할 자식 프로세스를 생성한다. 그리고 exec()를 호출하여 그 프로그램을 실행한다. 마지막으로 wait()를 호출하여 자식 프로세스가 종료될 때까지 기다린다. 자식프로세스가 종료되었다면, 쉘은 wait()의 결과를 리턴하고 다시 프롬프트를 보여준다(다음 커맨드를 위해). fork()와 exec()의 분리는 이런 상태에서 다양한 유용한 것들을 쉽게 할 수 있도록 만들어준다. wc p3.c \u0026gt; newfile.txt 위의 예제어서, wc 프로그램의 출력은 newfile.txt 파일로 리다이렉트된다. 쉘이 이걸 해내는 방법은 매우 단순한데, 자식스포세스가 생성되면, 쉘은 standard output을 닫고, newfile.txt를 open한다. 그래서 wc 프로그램의 출력은 화면에 뿌려지는대신, newfile.txt로 들어가게 된다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;sys/wait.h\u0026gt; int main(int argc, char *argv[]) { int rc = fork(); if (rc \u0026lt; 0) { // fork failed; exit fprintf(stderr, \u0026#34;fork failed\\n\u0026#34;); exit(1); } else if (rc == 0) { // child: redirect standard output to a file close(STDOUT_FILENO); open(\u0026#34;./p4.output\u0026#34;, O_CREAT|O_WRONLY|O_TRUNC, S_IRWXU); // now exec \u0026#34;wc\u0026#34;... char *myargs[3]; myargs[0] = strdup(\u0026#34;wc\u0026#34;); // program: \u0026#34;wc\u0026#34; (word count) myargs[1] = strdup(\u0026#34;p4.c\u0026#34;); // argument: file to count myargs[2] = NULL; // marks end of array execvp(myargs[0], myargs); // runs word count } else { // parent goes down this path (original process) int wc = wait(NULL); assert(wc \u0026gt;= 0); } return 0; } 위의 작업을 보여주는 코드이다. fork()를 호출해서 자식 프로세스(기존의 프로세스의 복사본)를 생성한다. 자식 프로세스가 타게될 분기에서는 close(STDOUT_FILENO)로 표준 출력을 닫는다. 그리고 open()을 호출하여 p4.output 파일을 열고, 그 파일을 표준 출력으로 사용한다. 그리고 exec()의 실행으로 인해서 기존의 프로그램이 wc로 덮어씌워지고 그동안의 출력은 p4.output 파일로 리다이렉트된다. 유닉스의 파이프는 이와 같은 방식으로 동작한다. 더 정확히는 한 프로세스의 출력이 커널 내 파이프(큐)로 들어가고, 다른 프로세스는 그 파이프로부터 입력을 받는다. 이러한 방식으로 프로세스의 체인을 구현해뒀다. 추가적으로 찾아본 내용 : pipe() 시스템 호출은 파이프를 생성하는데 사용된다, pipe() 를 호출하면 커널 내부에 파이프라고 불리는 메모리 버퍼가 생성된다. 실제로 큐로 구현되어있어, 한쪽 끝에서 데이터가 쓰이고 다른 한 쪽 끝에서 데이터가 읽힌다. (읽기 쓰기용 디스크립터가 각각 있음)\n5.5 프로세스 제어와 사용자. 유닉스에는 fork(), exec(), wait()와 같은 프로세스 제어를 위한 api들 외에도 다양한 프로세스 제어를 위한 api들이 있다. 예를 들어, kill() 시스템콜은 다른 프로세스를 멈추거나 끝내기 위한 시그널 을 보내기 위해 사용된다. 시그널이라는 운영체제의 매커니즘은 외부 사건을 프로세서에 전달하는 토대이다. 실제로 signal() 시스템콜은 시그널을 받았을 때 어떻게 반응할지를 알려줄 수 있도록 되어있는 시스템 콜이다. 이러한 프로세스 제어를 위한 시스템콜을 알게된다면 자연스럽게 보안과 관련된 이슈들도 알게된다. 예를 들어, 누구나 다른 프로세스를 죽일 수 있는 권한을 가지고 있으면, 그것은 보안 이슈가 될 수 있다. 그래서 user와 같은 개념을 도입하였다. 간단하게만 알아보면 user는 인증과정을 거쳐 시스템에 로그인 할 수 있고, 하나 이상의 프로세스를 실행할 수 있는 권한을 가진다. 일반적으로 그 프로세스들에 대해서만 제어 권한을 가진다. 운영체제는 CPU, 메모리와 디스크 같은 자원을 각 사용자와 프로세스들에 할당하여 전체적인 시스템의 목적에 도달하도록 만드는 역할을 한다. 5.7 요약 이번 장에서는 프로세스를 다루는 API중 일부를 알아봤다! 각 프로세스는 이름이 있다. 대부분의 시스템에서 이름은 PID라는 번호이다. UNIX 시스템에서는 fork 시스템 콜을 사용하여 새로운 프로세스를 생성한다. 생성의 주체가 되는 프로세스는 부모 프로세스, 생성된 프로세스는 자식 프로세스라고 한다. wait() 시스템 콜을 사용하여 부모 프로세스가 자식 프로세스가 종료될 때까지 기다릴 수 있다. exec() 시스템 콜을 사용하여 자식 프로세스가 부모와의 연관성을 완전히 끊어서 새로운 프로그램을 실행할 수 있다. UNIX 쉘은 보통 fork, exec, wait를 사용하여 사용자의 명령을 시작한다. fork와 exec을 분리하였기에 실행 중인 프로그램을 조작하지 않고도 입/출력 재지정, 파이프, 그리고 다른 기능을 처리하는것이 가능하다. 프로세스 제어는 시그널이라는 형태로 제공되며, 이를 활용하여 작업을 멈추고, 재시작하거나, 종료할 수 있다. 누가 어떠한 프로세스를 제어 할 수 있는지는 사용자라는 개념속에 포함되어있다. 슈퍼사용자는 시스템의 모든 프로세스를 제어할 수 있지만, 일반 사용자는 자신의 프로세스만을 제어할 수 있다. 5.8 과제! https://github.com/SmallzooDev/OSTEP/tree/main/Chapter05\n6.0 제한적 직접 실행 원리 CPU를 가상화 하기 위해서 운영체제는 여러 작업들이 동시에 실행되는 것처럼 보이게 해야 한다. 기본적인 아이디어는 간단하다, 하나의 프로세스를 잠깐 실행하고 다른 프로세스를 실행하고, 그것을 반복하는 것이다. 그것을 위해서는 두가지 주요한 이슈를 해열해야 하는데, 첫 번째는 오버헤드이며, 두 번째는 제어문제이다. 오버헤드로 인한 성능 저하를 최소화하고, CPU의 통제를 잃지 않는 것이 주된 목표이다. 그중에서 이번장의 핵심 질문은 : 제어를 유지하면서 효과적으로 CPU를 가상화하는 방법은 무엇인가? 이다.\n6.1 기본 원리: 제한적 직접 실행(Limited Direct Execution) Limited Direct Execution에서 Direct Execution부분은 간단하다. CPU 상에서 프로그램을 직접 실행하는 것을 의미한다. 즉 운영체제가 프로그램을 실행하기 시작 할 때 프로세스 목록에 해당 프로세스 항목을 만들고, 메모리 할당하고, 코드를 디스크에 탑재하고, 진입점(main()함수 또는 다른 언어에서 그러한 역할을 하는 진입점)코드를 찾아 실행한다. 직접 실행의 예시를 들면 다음과 같다.\n운영체제 프로그램 프로세스 목록의 항목을 생성 메모리 할당 디스크에서 코드를 읽어 메모리에 탑재 argv, envp를 스택에 넣고, main()함수를 호출 레지스터 초기화 main()함수 실행 main에서 return 명령어 실행 프로세스 메모리 반환 프로세스 목록에서 항목 제거 이 방법은 (Direct Execution)은 간단하고 효율적이지만, 두가지 문제가 있다. 첫 번째 문제는, 만약 프로그램을 직접 실행시킨다면 프로그램이, 운영체제가 원치않는 일을 하지 않는다는 것을 어떻게 보장할 수 있는가? 이고 두 번째 문제는, 프로세스 실행 시 운영체제는 어떻게 프로그램의 실행을 중단하고 다른 프로세스로 전환시킬 수 있는가, 즉 CPU를 가상화하는 데 필요한 시분할(time sharing)을 어떻게 구현할 수 있는가? 이다. 프로그램 실행에 제한을 두지 않으면 운영체제는 어떠한것 도 제어 할 수 없는 단순한 라이브러일 뿐이다.\n사실 이부분이 책에서, 원서를 봐도 크게 와닿지 않아 역자의 강의를 보니 핀트가 아주 적절하게 맞춰졌다.\n2장에서 이야기 한 상황 (procedure call)을 수행하는 운영체제는 사실상 라이브러리와 다름 없다고 했다. DE를 수행하고 있는 시점이 정확히 그 상황이고, 문제에 맞닥뜨린다는 포인트를 짚은 것이다.\n강의에서는 매우 간단한 예제 두개로 핀트를 잘 맞춰준다.\n// user can do wrong things int *i; i = 0; *i = 1; 이 코드가 실제로 실행된다면, 메모리 \u0026lsquo;주소\u0026rsquo; 부분에 값을 넣으려고 하기 때문에, 다른 시스템 전부에 장애를 일으킬 수 있다. // getting control back from CPU is not easy int i = 0; while (i = 0) { do something but never touch i; } 이 코드는 무한 루프에 빠지게 되고, CPU는 이 루프를 빠져나오지 못하게 된다. 즉 이러한 상황이 DE, 즉 권한과 제어를 제한하지 않으면 발생할 수 있는 문제점이다. 마지막으로 역자는 두가지 포인트의 부재를 짚고 있다 첫 번째 코드에는 protect system이 부재하고, 두 번째 코드에는 control execution이 부재하다. 6.2 문제점 1: 제한된 연산 (첫 번째 이슈 해결하기) 핵심 질문, 어떻게 제한된 연산을 수행해야 하는가? 프로세스는 I/O 연산과 또 다른 restricted operation을 수행할 수 있어야 한다. 그러나 시스템에 대한 모든 권한을 주지 않은 상태에서 어떻게 그런 연산을 수행 할 수 있을까?\n(Direct Execution)의 가장 큰 장점은 빠르다는 것 이다 그러나 디스크 입출력 요청이나 CPU나 메모리 같은 시스템 자원의 추가할당 같은 특수한 연산을 수행 할 수 없다. 물론 프로세스가 이러한 연산을 직접 수행하도록 방치하는 방법도 있지만, 아래와 같은 문제점이 생긴다. 예를들어 프로세스가 입출력 권한을 직접 가지는 상황을 생각해보면, 파일을 직접 접근하기위해 접근권한등을 파일시스템에 구현해뒀는데, 해당 프로세스로 인해 무력화된다. 이 때문에 user mode와 같은 새로운 모드가 도입되었다, 이 모드에서 실행중인 프로세스에서 입출력요청을 직접 하게되면 프로세서는 예외를 발생시키고, 운영체제는 프로세스를 제거한다. 반대는 계속 언급된 kernel mode이다, 이 모드에서는 운영체제가 모든것을 제어할 수 있다. user mode와 kernel mode를 구분하는 것으로 특수한 연산에 대한 제어는 할 수 있게 되었다. 하지만 다른 이슈 하나가 더 있는데 바로 특권 명령 (privileged operation)이다. 디스크 읽기와 같은 실제 하드웨어 동작을 수행하기 위해서 필요한 일인데, 이것은 시스템콜 (system call)을 통해 수행된다. 거의 모든 현대의 하드웨어들은 시스템 콜을 지원하고 있고, 표준은 POSIX를 찾아보면 확인 할 수 있다. 시스템 콜을 사용하기 위해서 프로그램은 trap 명령어를 사용한다. trap 명령어를 사용하면, privileged level을 kernel모드로 격상시키고, 시스템 콜을 수행할 수 있다. 일련의 작업이 끝난 이후에는 return-from-trap 명령어를 사용하여 다시 user모드로 돌아온다. trap 명령어를 사용할 때는 매우 신중해야하는데, 호출한 프로세스의 레지스터를 충분히 저장하고, 그로 인해 return-from-trap 명령어를 사용했을 때 실제 호출 프로세스로 제대로 리턴 할 수 있어야 한다. 예를 들어 x86 아키텍처에서는, 프로그램 카운터, 플래그와 다른 몇 개의 레지스터를 각 프로세스의 커널 스택에 저장한다. 그리고 return-from-trap 명령어가 커널 스택에서 pop해서 다시 usermode의 프로그램 실행을 하게 된다. (거의 대부분의 아키텍처에서 실제 구현은 다를 수 있어도 개념적으로는 이와 비슷한 방식으로 동작한다.) 여기서 또 하나의 중요한 이슈는 어떻게 trap 이후에 OS 내부에서 어떠한 코드가 실행되어야 하는지를 알 수 있는가? 이다. 호출한 프로세서가 명시해주는것은 매우 나쁜 아이디어이다, 주소를 명시하는것은 커널 내부의 원하는 지점을 접근 할 수 있다는 것이고, 그렇게 두는게 매우 위험하기 때문이다. 대신에, 커널에 trap table을 두는 것으로 해결한다. trap table은 부팅중에 세팅된다, machine이 부팅 될 때는 커널 모드로 동작되기 때문에, 모든 하드웨어를 마음대로 사용할 수 있다. 그동안 운영체제가 하는 일은 하드웨어에게 특정한 이벤트가 발생 했을 때 어떤 코드를 실행해야 하는지를 알려주는 것이다. 예를들어, 하드디스크가 인터럽트가 발생했을 때, 키보드 인터럽트가 발생했을 때, 프로그램이 인터럽트를 발생했을 때 등 인터럽트가 발생했을 때 어떤 코드를 실행해야 하는지를 알려주는 것이다. 더 정확한 용어를 사용하면 trap handler라고 부르는데, 이것은 인터럽트가 발생했을 때 실행되어야 하는 코드를 가리킨다. trap handler를 하드웨어에게 알려주면, 하드웨어는 해당 위치를 기억하고 있다가 시스템 콜과 같은 예외적인 사건이 발생했을 때 하드웨어는 어떤 코드 분기를 실행해야 하는지 알 수 있게 된다. 시스템콜을 특정하기 위해 system-call number라는 것이 있으며, 사용자 프로그램은 원하는 시스템콜을 호출하기 위해서, 해당 시스템 콜 번호를 레지스터 또는 스택의 지정된 위치에 저장하고 trap을 호출한다. 그러면 운영체제는 트랩 핸들러 내부에서 시스템콜을 처리하는데, 이 번호를 확인하고 일치하는 코드를 실행한다. 즉 시스템 콜 번호를 통해서 시스템콜 주소를 찾아내고, 그 주소로 점프하여 시스템콜을 실행하는 방식의 간접적인 방식이 Protection을 제공한다. 또한 하드웨어에게 trap table의 위치를 알려주는것은 매우 강력한 기능이며, 당연히 privileged operation이다. 잠시 정리 프로세스가 모든 권한을 갖게 되면 두가지 이슈가 있는데 첫 번째는 protect system이 부재하고, 두 번째는 control execution이 부재하다. Limited Direct Execution은 프로세스가 특정한 연산을 수행할 수 있도록 하는데, 이것은 user mode와 kernel mode를 사용하여 구현되고 protect system을 해결하는 방법이다. 유저모드에서 할 수 없는 일들(system call, privileged instruction)등을 분리하고 커널에서만 실행이 가능하도록 했다. 커널의 진입은 trap 명령어를 사용한다. 커널에서 실제로 실행되는 코드를 직접 알게하면 위험하기 때문에 trap table을 사용한다. trap table은 trap handler의 주소를 가지는 테이블이다. trap table은 부팅시에 설정되며, 하드웨어에게 어떤 코드(= 트랩 핸들러에 있는 코드)를 실행해야 하는지 알려준다. 여기서 살짝 헷갈릴 수 있는 부분은 트랩 테이블에 있는 주소는 시스템콜의 주소가 아니라, 시스템콜이 필요할때 사용 할 수 있는 트랩 핸들러의 주소이다. #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/syscall.h\u0026gt; int main() { #define SYS_CUSTOM_SYSCALL 333 long result = syscall(SYS_CUSTOM_SYSCALL); if (result == 0) { printf(\u0026#34;System call was successful!\\n\u0026#34;); } else { printf(\u0026#34;System call failed!\\n\u0026#34;); } return 0; } 위의 코드에서 예를 들어보면, syscall() 함수를 사용하여 시스템 콜을 호출한다. 내부적으로 \u0026lsquo;시스템 콜에 대한 트랩 핸들러가 호출되고\u0026rsquo;, 해당 핸들로에서 시스템 콜 번호에 해당하는 코드를 실행한다. (이부분이 가장 헷갈림) 6.3 문제점 2: 두 프로세스 사이에 스위칭 하기 (두 번째 이슈 해결하기) 프로세스를 switch 하는 것은 매우 간단해 보인다, 하나를 멈추고 다른 하나를 시작하면 될 것 같다. 운영체제도 프로그램이라는것을 인지하면 문제가 tricky해진다. 하나의 프로세스가 실행중이란 이야기는 os라는 프로그램이 cpu에서 실행중이지 않는다는 이야기이다. \u0026lsquo;실행중\u0026rsquo;이지 않은 상태에서 어떻게 액션을 취할 수 있을까? 핵심 질문 : 어떻게 프로세스로부터 CPU 제어권을 다시 가져올 수 있을까?\n6.3 협동적인 접근 방법 : System Call을 기다리기 예전에 주로 채택되었던 해결책 중 하나는 cooperative 방식이다. OS는 프로세스가 합리적으로 동작할 것 이라고 신뢰하고, 프로세스 스스로 너무 오래 점유하거나 하면 운영체제로 제어권을 넘겨주는 방식이다. 대부분의 프로세스들은 기대한대로 동작했고, 운영체제로 제어권을 넘겨주는 system call을 잘 사용했다. 이러한 시스템에서는 yield()라는 시스템 콜을 사용하여 제어권을 넘겨주는 방식이 사용되었다. 그리고 의도치 않게 동작하는 상황에서도, 프로세스를 스스로 정리하려는 시도를 하게 된다. 이러한 협동 방식을 생각하면 다음과 같은 의심이 들기 시작한다. 너무 수동적인게 아닌가? 프로그램이 무한루프에 빠지면 어떻게 되는가? 6.4 비협동적인 접근 방법 : OS Takes Control 협동적인 방식의 문제점들이 대두되고 있었다, 특히 무한루프와 같은 경우에는 재부팅 밖에 방법이 없었다. 이러한 문제들은 아까 이야기한 해결책을 다시 찾도록 되돌리게 되었다 핵심 질문 : 어떻게 프로세스로부터 CPU 제어권을 다시 가져올 수 있을까?\n이러한 문제를 해결하기 위해 timer interrupt를 사용한다. timer interrupt는 정해진 시간이 지나면 발생하는 인터럽트이다. 이 인터럽트는 미리 설정된 interrupt handler를 실행하게 되는데, 이렇게 하는 것 만으로도 운영체제는 프로세스로부터 제어권을 다시 가져올 수 있다. 운영체제는 인터럽트에서 마찬가지로, 실행해야 할 코드의 주소를 기록해둬야 한다. (이것이 바로 interrupt handler이다.) 인터럽트가 발생하면, 운영체제는 해당 주소로 점프하여 코드를 실행한다. 즉 타이머 인터럽트가 발생하면, 운영체제는 현재 실행중인 프로세스를 멈추고, (아마도 일반적으로)다른 프로세스로 전환하는 코드를 실행한다. 6.5 Saving and Restoring Context OS가 제어권을 얻었을 때, (그게 인터럽트든, 협력적인 방식이든) 결정을 내려야 한다 : 지금 실행중인 프로세스를 실행할 것인가? 아니면 다른 프로세스로 전환할 것인가? 여기서 이 결정을 내려주는 시스템은 scheduler (스케줄러는 정책에 따라서 프로세스를 선택하는 역할을 하는데, 해당 정책은 다음 챕터에서!) 만약 switch로 결정이 내려진다면, 운영체제는 context switch라 불리는 low-level operation을 수행해야 한다. context switch는 현재 실행중인 프로세스의 상태를 저장하고, 다음 실행할 프로세스의 상태를 복원하는 것이다. (저장도 복원도 일반적으로는 커널 스택에서) 이러한 것들이 수행된 이후 OS는 return-from-trap 명령어 실행 이후에 다음 프로세스를 실행된다는 것을 알 수 있다. context switch가 발생했을 때 프로세스에서 저장해야 할 정보는 다음과 같다 레지스터 값 커널 스택 포인터 프로세스 상태 (running, ready, blocked) 등 context switch가 발생했을 때 저장/복원이 두 번 일어나는것을 이해해야 한다. 첫 번째는 현재 실행중인 프로세스의 상태를 저장하는 것이고, 두 번째는 커널 레지스터를 전환될 프로세스 구조체에 저장된다, 이것으로 인해 두번째 프로세스가 레지스터를 복원할 수 있다. 두 번째 복원 작업으로 인해, 1번 프로세스로 인해 커널로 진입했지만, 2번 프로세스 실행중에 커널로 트랩한것처럼 보이게 된다. 6.6 동시성이 걱정되시나요? 똑똑하다면 이제 concurrency에 대해 걱정할 수 있을 것이다. 만약 시스템 콜을 처리하는 중에 다른 시스템콜이 발생한다면 어떻게 될까? 반대로 인터럽트를 핸들링 하는 중에 다른 인터럽트가 발생한다면 어떻게 될까? 당장 다룰 주제는 아니고 가장 간단한 해법을 생각하면, 인터럽트를 disable하는 것이다. 인터럽트를 disable하면, 다른 인터럽트가 발생하지 않지만, 손실되는 인터럽트가 생기게 된다. 사실 실제로는 lock이라는 것을 사용하는데, 실제로 매우 복잡하게 구현되어 있어 운영체제의 복잡도를 높이게 된다. 7.0 스케줄링: 개요 운영체제 수업에서 가장 핵심 주제라 여러번 보는 내용이 스케줄링이다. 이 장은 스케줄링 정책에 대해서 다룬다. 스케줄링의 기원은 컴퓨터 등장 이전에도 존재했다. 예를 들어, 공장에서 작업을 할당하는 것(Operation Management)이 스케줄링의 예시이다. 핵심 질문: 스케줄링 정책은 어떻게 개발하는가\n7.1 워크로드에 대한 가정 먼저 프로세스 동작에 대한 몇가지 가정을 해야 한다, 프로세스가 동작하는 일련의 행위를 워크로드라 한다. 워크로드의 선정은 매우 중요한 일이다, 실제로는 매우 어려운 일이다, 다만 이번 장에서는 비현실적일 정도로 간단한 워크로드를 가정한다. 그리고 나중에 실제 워크로드를 다루는 방법에 대해서도 다룰 것이다. 각각의 프로세스는 동일한 시간 동안 실행된다. 모든 프로세스는 동일한 시간에 도착한다. 일단 시작되면, 각각의 프로세스는 완료된다. 프로세스는 CPU만 사용한다. 각각의 프로세스의 실행시간은 알려져 있다. 7.2 스케줄링의 평가 항목 스케줄링의 평가 항목은 다양하지만 대표적인 것들은 아래와 같다.\nturnaround time : 프로세스가 도착한 시간부터 완료될 때까지 걸리는 시간 turnaround time = completion time - arrival time fairness : 모든 프로세스가 얼마나 공평하게 CPU를 사용하는가 참고로 성능과 공정성은 trade-off 관계이다.\n7.3 FIFO 같은 시간 도착, 같은 작업 시간\n가장 간단한 스케줄링 정책은 FIFO이다. FIFO는 First In First Out의 약자로, 가장 먼저 도착한 프로세스가 가장 먼저 CPU를 사용하는 방식이다. FIFO는 매우 간단하고 구현하기 쉽다. A : 10, B : 10, C : 10 라는 프로세스가 있다고 가정하면, FIFO는 아래와 같이 동작한다. time 0 : A, B, C도착 time 10 : A 완료 time 20 : B 완료 time 30 : C 완료 turnaround time은 각각 10, 20, 30이다, 즉 평균 turnaround time은 20이다. 이제 1번의 가정을 변경해보자, A : 100, B : 10, C : 10이라는 프로세스가 있다고 가정하면, FIFO는 아래와 같이 동작한다. time 0 : A, B, C 도착 time 100 : A 완료 time 110 : B 완료 time 120 : C 완료 turnaround time은 각각 100, 110, 120이다, 즉 평균 turnaround time은 110이다. FIFO의 문제점은 convoy effect이다, convoy effect는 긴 프로세스가 먼저 도착하면, 뒤에 도착한 프로세스들이 기다려야 하는 현상을 말한다. 마트에서 나는 콜라 하나만 계산하려고 하는데, 내 앞에 카트 세개를 풀로 채운 사람이 계산하고 있다면\u0026hellip;?\n7.4 최단 작업 우선 (SJF) 같은 작업 시간 완화\nFIFO의 문제점을 해결하기 위한 방법 중 하나는 Shortest Job First이다. SJF는 가장 짧은 프로세스가 가장 먼저 CPU를 사용하는 방식이다. A : 100, B : 10, C : 10 시나리오를 다시 보자 time 0 : A, B, C 도착 time 10 : B 완료 time 20 : C 완료 time 120 : A 완료 turnaround time은 각각 100, 10, 20이다, 즉 평균 turnaround time은 43.3이다. 동일한 시간에 도착하는 프로세스의 경우, SJF는 최적의 성능을 보여준다. 인생은 쉽지 않으니 2번의 가정을 무력화 해보자, A : (100, 0), B : (10, 10), C : (10, 10) 시나리오를 다시 보자(첫 번째 숫자는 실행시간, 두 번째 숫자는 도착시간) time 0 : A 도착 time 10 : B, C 도착 time 100 : A 완료 time 110 : B 완료 time 120 : C 완료 turnaround time은 각각 100, 100, 110이다, 즉 평균 turnaround time은 103.3이다. (다시 convoy effect가 발생했다) 7.5 최소 잔여 시간 우선 (STCF) 작업이 중단되지 않는다는 제약을 해제\nSJF의 변형으로 Shortest Time-to-Completion First이다. STCF는 가장 짧은 남은 실행시간을 가진 프로세스가 가장 먼저 CPU를 사용하는 방식이다. STCF는 SJF와 비슷하지만, STCF는 프로세스가 도착할 때마다 스케줄링을 다시 수행한다. A : (100, 0), B : (10, 10), C : (10, 10) 시나리오를 다시 보자 time 0 : A 도착 time 10 : B, C 도착 time 10 : B 완료 time 20 : C 완료 time 120 : A 완료 turnaround time은 각각 120, 10, 20이다, 즉 평균 turnaround time은 50이다. STCF는 SJF보다 더 좋은 성능을 보여준다. 7.6 새로운 평가 기준 : Response Time Response Time은 프로세스가 처음으로 CPU를 사용하기까지 걸리는 시간을 말한다. (처음으로 스케줄 될 때까지의 시간) Response = first time - arrival time STCF를 비롯해서 비슷한 정책들은 응답시간이 짧다고 보장할 수 없다. 예를 들어, A : (100, 0), B : (1, 10) 시나리오를 보자 time 0 : A 도착 time 10 : B 도착 time 100 : A 완료 time 101 : B 완료 B는 10초 동안 기다려야 하지만, STCF는 A를 먼저 처리하기 때문에 B는 90초 동안 기다려야 한다. 이러한 문제를 해결하기 위해 Round Robin이라는 정책이 등장한다. 7.7 라운드 로빈 (Round Robin) Round Robin은 각 프로세스에게 동일한 시간을 할당하는 방식이다. RR은 작업이 끝날 때 까지 기다리지 않고, 다른 프로세스로 전환한다. 이 때 작업이 실행되는 시간을 time slice, 또는 scheduler quantum이라고 한다. RR은 타이머 인터럽트의 배수로 동작한다. A : 100, B : 10, C : 10 시나리오를 다시 보자 time 0 : A, B, C 도착 time 10 : A 실행, B, C 대기 time 20 : A 완료, B 실행, C 대기 time 30 : B 완료, C 실행 time 40 : C 완료 ... 타임 슬라이스의 시간이 짧아질수록, 성능의 기준이 응답시간일수록 RR은 좋은 성능을 보여준다. 하지만 타임 슬라이스가 너무 짧으면, context switch로 인한 오버헤드가 발생할 수 있다. context switch를 상쇄할 만큼 길어야하지만, 응답시간이 너무 길어지지 않도록 적절한 타임 슬라이스를 선택해야 한다. 반환 시간이 가장 중요한 경우에는 반대로 RR은 좋은 성능을 보여주지 못한다. 이것은 RR과 같이 공정한 정책(CPU를 공평하게 나눠쓰는 정책)은 반환 시간 기준으로는 성능이 좋지 않다는 것을 의미한다. 일단 응답시간, 반환시간을 기준으로 좋은 성능을 가지는 정책들을 알아봤다. 하지만 아직도 완화하지 않은 두가지 가정이 있다. (작업은 입출력을 하지 않는다, 각 작업의 실행시간을 알고 있다) 7.8 입출력 연산의 고려 프로세스는 입출력을 사용한다.\n가정 4를 완화해보자, 프로세스는 CPU만 사용하는 것이 아니라 입출력도 사용한다. 만약 지금 실행중인 프로세스가 입출력을 요청하면, 스케줄러는 다음에 어떤 작업을 실행할지 결정해야 한다. 현재 실행 중인 프로세스는 입출력이 끝날 때까지 기다려야 한다. 왜냐하면 입출력이 끝나기 전까지 작업을 대기해야 하기 때문이다. 반대로 입출력이 끝난 프로세스도 의사 결정을 해야한다. 입출력이 완료되면 인터럽트가 발생하고, 이때 스케줄러는 어떤 작업을 실행할지 결정해야 한다. 위의 그림은 입출력이 끝난 프로세스가 CPU를 사용하지 않는 시간을 보여준다. 반면 STCF 스케줄링 정책을 사용한 케이스 7.9 만병 통치약은 없다 (No More Oracle) 간단한 스케줄링 정책들을 살펴봤다, 각각 극단적인 장단점을 가지고 있다. 거기에 아직도 보호받는 가정이 있다, 실제로는 프로세스는 입출력을 하고, 실행시간을 알 수 없다. 아무런 사전지식 없이 SJF/STCF 처럼 행동하는 알고리즘은 없을까? 추가적으로 RR 스케줄러의 장점을 살리는 방법은 없을까? 7.10 다음 장에서\u0026hellip; (요약) 다음 장에서는 더 정확한 스케줄링에 필요한 것들을 살펴볼 것이다. 정확한 스케줄링을 위해서는 미래 동작을 예측할 수 있는 방법이 필요하다. 프로세서의 미래 동작을 예측함에 있어 과거 동작 이력을 반영하는 방법이 필요하다. 이 스케줄러를 멀티 레벨 피드백 큐라고 부르며 다음 장에서 다룰 예정이다. ","permalink":"http://localhost:1313/_wiki/lde-scheduling/","summary":"05.0 막간 : 프로세스 API 거의 모든 소스코드와 강의자료는 아래 링크가 출처 입니다.\n강의 소스코드 : OSTEP 테스트 프로그램 : OSTEP Test Programs 역자 강의 자료 : 강의자료 개념적인 내용이 아닌 실제적인 측면에서 코드를 보는 장은 막간이라고 별도 표기한다.\n이번 절에서는, Unix 시스템의 프로세스 생성에 관해 배운다. Unix는 프로세스를 생성하는 시스템콜로 다음 두가지를 제공한다. fork() exec() 그리고 wait() 함수를 통해 자식 프로세스가 종료될 때까지 기다릴 수 있다. 핵심 질문 : 프로세스를 생성하고 제어하는 방법, 프로세스를 생성하고 제어하려면 운영체제가 어떤 인터페이스를 제공해야 하는가?","title":"운영체제 아주 쉬운 세 가지 이야기 📚"},{"content":"01. 명확하고 가장 좋은 기준 1 - 어찌보면 가장 당연하게도, 가장 중요한 기준은 내가 가장 익숙한 언어이다.\n아무래도 기존에 사용하는 언어를 사용하면, std나 기본 라이브러리에 대한 이해도가 확실하고,\n문법적인 부분에서도 손이 바로 나갈 수 있다는 것이 가장 큰 장점이다.\n특히나 대부분의 코딩 테스트는 직군이 갈려 있기 때문에, 내가 자주 사용하는 언어를 내가 가고싶은 회사의 인터뷰에서 지원 할 확률이 높다.\n02. 명확하고 가장 좋은 기준 2 - 파이썬 모든 기준을 무시하고서라도 파이썬은 한 번쯤 고려해볼만한 언어이다\n간결하고 강력한 문법을 가지고 있다. 문법 간결한건 굳이 설명 안해도 되고, 어지간한 포매팅이나 정규식, 문자열 다루는 메서드 등은 기본 문법에 내장되어 있다.\n초 강력한 범용성 (코테에서 가장 중요한 요소 중 하나, 아직 파이썬을 지원 안하는 코테는 만나보지 못했다.)\n위와 같은 이유로 매우 익숙한 언어가 있어도 파이썬은 한 번쯤 고려해볼만한 언어이다.\n참고로 파이썬의 속도를 단점으로 지적하시는 분들도 계신데, PS대회급이 아닌 취업용 코테에서는 언어 자체의 성능으로 인해 달라지는 경우는 사실상 없다고 봐도 무방하다.\n03. 근데 난 왜 이렇게 고민을 많이 할까? 파이썬이 싫다 지금 회사에서 주로 사용하는 자바는 간혹 지원하지 않거나, 코테에서 언어 자체로 이점이 있다고 보긴 힘들다. 그렇다고 cpp를 선택하자니, cpp와 담을 쌓은지 너무 오래다.. 러스트는 아직 코테에서 지원 안하는 곳이 많다 (99%\u0026hellip;.) 파이썬이 싫은 이유 :\n파이썬이 안좋아서가 절대 아니다. 일단 코테에서 동적 타입언어를 쓰는게 뭔가 오히려 더 적응이 안되고 불편함. java 다음으로 ts를 많이 사용하는데, 뭔가 ts와 닮아있으면서 애매하게 다르니까 실수를 더 많이함 들여쓰기로 블록 구분되는게 진짜 정말 너무 심하게 헷갈림(개인적인 문제이지만, 이게 파이썬을 못쓰겠는 가장 큰 이유인듯) 결론은 본인 숙련도 이슈이다. 자바 안쓰는 이유 :\n빈도는 요즘은 매우 낮지만, 찾아본 20군데의 회사중에 3군데 정도 지원을 안하는 곳이 있었다. 자바를 못 쓸 때 파이썬을 쓰기 싫다.. 04. 결론 그러던 중 운영체제 스터디까지 시작하면서 결국 다시 c를 봐야 했고, 결론이 나버렸다. cpp 문법을 열심히 다시 보고 있다. ","permalink":"http://localhost:1313/_wiki/%EC%BD%94%EB%94%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%96%B8%EC%96%B4-%EC%A0%95%ED%95%98%EA%B8%B0/","summary":"놀랍게도 언어 정하는데도 시간이 많이 필요하다..","title":"코딩 테스트 언어 정하기"},{"content":"Vim Improve Sheet 🦅 Vim Improve Sheet 라고 작성했는데, 사실 안좋은 습관을 고치기 위한 시트라고 생각하면 더 좋을 것 같다. 뭔가 분명히 더 나은 방법이 있을 것 같은데, 당장 알아보기 귀찮아서 그냥 넘어가는 습관을 고치기 위한 시트이다.\n01. Vim으로 따옴표 씌우기 nvim-surround 플러그인을 이용한다 (\u0026ldquo;kylechui/nvim-surround\u0026rdquo;)\n별 표시된 부분이 커서의 위치를 나타낸다.\nOld text Command New text\nsurr*ound_words ysiw) (surround_words) *make strings ys$\u0026quot; \u0026quot;make strings\u0026quot; [delete ar*ound me!] ds] delete around me! remove \u0026lt;b\u0026gt;HTML t*ags\u0026lt;/b\u0026gt; dst remove HTML tags 'change quot*es' cs'\u0026quot; \u0026quot;change quotes\u0026quot; \u0026lt;b\u0026gt;or tag* types\u0026lt;/b\u0026gt; csth1\u0026lt;CR\u0026gt; \u0026lt;h1\u0026gt;or tag types\u0026lt;/h1\u0026gt; delete(functi*on calls) dsf function calls 02. [ ] 복사 붙여넣기 남들은 어떻게 편하게 하는지 확인하기 04. 주석 관련 커맨드 shift + v : 블록 선택 : + norm + i// : 블록 주석 처리 : + norm + x : 블록 주석 해제 (앞에 글자 삭제) 단축키 합치는중\nTelescope 파일 브라우저 sf - 현재 버퍼의 경로에서 파일 브라우저 열기 ;f - 현재 작업 디렉토리의 파일 찾기 (.gitignore 존중) fP - 플러그인 파일 찾기 파일 브라우저 내부 단축키 N - 새 파일 만들기\nh - 상위 디렉토리로 이동\n/ - 검색 모드 시작\n- 10개 항목 위로 이동\n- 10개 항목 아래로 이동\n- 미리보기 위로 스크롤\n- 미리보기 아래로 스크롤\n창 및 탭 관련 te - 새 탭 열기\n- 다음 탭으로 이동\n- 이전 탭으로 이동\nss - 수평 분할\nsv - 수직 분할\nsh - 왼쪽 창으로 이동\nsk - 위쪽 창으로 이동\nsj - 아래쪽 창으로 이동\nsl - 오른쪽 창으로 이동\n- 창 너비 줄이기\n- 창 너비 늘리기\n- 창 높이 늘리기\n- 창 높이 줄이기\n검색 관련 단축키 Telescope 검색 ;r - 현재 작업 디렉토리에서 문자열 실시간 검색 (ripgrep, .gitignore 존중) ;t - 도움말 태그 검색 ;; - 이전 텔레스코프 선택기 다시 시작 ;e - 모든 열린 버퍼 또는 특정 버퍼의 진단 목록 표시 ;s - Treesitter를 통한 함수명, 변수 등 검색 ;c - 커서 아래 단어에 대한 LSP 들어오는 호출 목록 \\ - 열린 버퍼 목록 보기 LSP 관련 gd - 정의로 이동 (Telescope 사용) - 다음 진단으로 이동 기타 단축키 th - 숨겨진 버퍼 닫기 tu - 이름 없는 버퍼 닫기 z - Zen 모드 토글 ","permalink":"http://localhost:1313/_wiki/vim-impove-sheet/","summary":"Vim Improve Sheet 🦅 Vim Improve Sheet 라고 작성했는데, 사실 안좋은 습관을 고치기 위한 시트라고 생각하면 더 좋을 것 같다. 뭔가 분명히 더 나은 방법이 있을 것 같은데, 당장 알아보기 귀찮아서 그냥 넘어가는 습관을 고치기 위한 시트이다.\n01. Vim으로 따옴표 씌우기 nvim-surround 플러그인을 이용한다 (\u0026ldquo;kylechui/nvim-surround\u0026rdquo;)\n별 표시된 부분이 커서의 위치를 나타낸다.\nOld text Command New text\nsurr*ound_words ysiw) (surround_words) *make strings ys$\u0026quot; \u0026quot;make strings\u0026quot; [delete ar*ound me!] ds] delete around me!","title":"Vim Improve Sheet 🦅"},{"content":"추석 민숙이와 함께하는 일본 여행 ❤️ 00. 참고 링크 📌 교토 주요 관광지 [[회화-정리-링크]] 교토 여행 코스 교토 오사카 여행 코스 일본 지하철 코드 오사카 주요 관광지 01. 여행 준비 체크리스트 🇯 pre-commit test\n여권 확인 환전 필요한 의류 준비 세면도구 준비 충전기 및 어댑터 준비 여행가방 준비 로밍 선물 챙기기 02. 여행 일정 😊 09월 13일 (금) 오전 : 출국 오후 : 호텔 체크인, 아라시야마 방문 저녁 : 시간 보고 근처에서 식사 하고 마무리 숙박 : 굿 네이처 호텔 교토 전화번호: +81-75-3526730 참고 : 사가노-토롯코 열차 참고 : 대나무숲 후기 참고 : 아라시야마 관련 가이드 JR 하루카 공항 특급열차 편도티켓 (시간 제한 없음) 09월 14일 (토) 오전 : 청수사, 니넨자카, 산넨자카(교통편 확인) 오후 : 은각사, 교토타워 저녁 : 기온 거리에서 저녁 식사 숙박 : 연박 참고 : 청수사 관련 가이드/교통편 09월 15일 (일) 오전 : 후시미 이나리 신사, 나고야 이동 오후 : 오아시스 21, 나고야 성 (가능하면) 저녁 : 나고야에서 저녁 식사(맛집 찾을 예정) 숙박 : 호텔 케이한 나고야 교토역에서 나고야역 이동 (차량번호 Nozomi 94) 13:45분 출발 09월 16일 (월) 오전 : 지브리 😍 오후 : 지브리 😍 저녁 : 지브리 😍 저녁 맛집을 박아넣을 예정 숙박 : 연박 09월 17일 (화) 오전 : 오사카 이동 오후 : 도톤보리, 오사카 성 (미정) 저녁 : 도톤보리에서 저녁 식사 (맛집 찾을 예정) 숙박 : 호텔 한큐 오사카 나고야역에서 오사카역 이동 (차량번호 Nozomi 21) 11:00 출발 09월 18일 (수) 오전 : 유니버셜 스튜디오 재팬 🎢 오후 : 유니버셜 스튜디오 재팬 🎢 저녁 : 유니버셜 스튜디오 재팬 🎢 숙박 : 연박 09월 19일 (목) 오전 : 귀국 준비 오사카 - 간사이 공항 리무진 버스 이용(시간 제한 없음) ","permalink":"http://localhost:1313/_wiki/2024-%EC%B6%94%EC%84%9D-%EC%9D%BC%EB%B3%B8%EC%97%AC%ED%96%89/","summary":"추석 민숙이와 함께하는 일본 여행 ❤️ 00. 참고 링크 📌 교토 주요 관광지 [[회화-정리-링크]] 교토 여행 코스 교토 오사카 여행 코스 일본 지하철 코드 오사카 주요 관광지 01. 여행 준비 체크리스트 🇯 pre-commit test\n여권 확인 환전 필요한 의류 준비 세면도구 준비 충전기 및 어댑터 준비 여행가방 준비 로밍 선물 챙기기 02. 여행 일정 😊 09월 13일 (금) 오전 : 출국 오후 : 호텔 체크인, 아라시야마 방문 저녁 : 시간 보고 근처에서 식사 하고 마무리 숙박 : 굿 네이처 호텔 교토 전화번호: +81-75-3526730 참고 : 사가노-토롯코 열차 참고 : 대나무숲 후기 참고 : 아라시야마 관련 가이드 JR 하루카 공항 특급열차 편도티켓 (시간 제한 없음) 09월 14일 (토) 오전 : 청수사, 니넨자카, 산넨자카(교통편 확인) 오후 : 은각사, 교토타워 저녁 : 기온 거리에서 저녁 식사 숙박 : 연박 참고 : 청수사 관련 가이드/교통편 09월 15일 (일) 오전 : 후시미 이나리 신사, 나고야 이동 오후 : 오아시스 21, 나고야 성 (가능하면) 저녁 : 나고야에서 저녁 식사(맛집 찾을 예정) 숙박 : 호텔 케이한 나고야 교토역에서 나고야역 이동 (차량번호 Nozomi 94) 13:45분 출발 09월 16일 (월) 오전 : 지브리 😍 오후 : 지브리 😍 저녁 : 지브리 😍 저녁 맛집을 박아넣을 예정 숙박 : 연박 09월 17일 (화) 오전 : 오사카 이동 오후 : 도톤보리, 오사카 성 (미정) 저녁 : 도톤보리에서 저녁 식사 (맛집 찾을 예정) 숙박 : 호텔 한큐 오사카 나고야역에서 오사카역 이동 (차량번호 Nozomi 21) 11:00 출발 09월 18일 (수) 오전 : 유니버셜 스튜디오 재팬 🎢 오후 : 유니버셜 스튜디오 재팬 🎢 저녁 : 유니버셜 스튜디오 재팬 🎢 숙박 : 연박 09월 19일 (목) 오전 : 귀국 준비 오사카 - 간사이 공항 리무진 버스 이용(시간 제한 없음) ","title":"추석 일본여행"},{"content":"source code : process-run.py link : https://github.com/remzi-arpacidusseau/ostep-homework/blob/master/cpu-intro/process-run.py\n#! /usr/bin/env python from __future__ import print_function import sys from optparse import OptionParser import random # to make Python2 and Python3 act the same -- how dumb def random_seed(seed): try: random.seed(seed, version=1) except: random.seed(seed) return # process switch behavior SCHED_SWITCH_ON_IO = \u0026#39;SWITCH_ON_IO\u0026#39; SCHED_SWITCH_ON_END = \u0026#39;SWITCH_ON_END\u0026#39; # io finished behavior IO_RUN_LATER = \u0026#39;IO_RUN_LATER\u0026#39; IO_RUN_IMMEDIATE = \u0026#39;IO_RUN_IMMEDIATE\u0026#39; # process states STATE_RUNNING = \u0026#39;RUNNING\u0026#39; STATE_READY = \u0026#39;READY\u0026#39; STATE_DONE = \u0026#39;DONE\u0026#39; STATE_WAIT = \u0026#39;BLOCKED\u0026#39; # members of process structure PROC_CODE = \u0026#39;code_\u0026#39; PROC_PC = \u0026#39;pc_\u0026#39; PROC_ID = \u0026#39;pid_\u0026#39; PROC_STATE = \u0026#39;proc_state_\u0026#39; # things a process can do DO_COMPUTE = \u0026#39;cpu\u0026#39; DO_IO = \u0026#39;io\u0026#39; DO_IO_DONE = \u0026#39;io_done\u0026#39; class scheduler: def __init__(self, process_switch_behavior, io_done_behavior, io_length): # keep set of instructions for each of the processes self.proc_info = {} self.process_switch_behavior = process_switch_behavior self.io_done_behavior = io_done_behavior self.io_length = io_length return def new_process(self): proc_id = len(self.proc_info) self.proc_info[proc_id] = {} self.proc_info[proc_id][PROC_PC] = 0 self.proc_info[proc_id][PROC_ID] = proc_id self.proc_info[proc_id][PROC_CODE] = [] self.proc_info[proc_id][PROC_STATE] = STATE_READY return proc_id # program looks like this: # c7,i,c1,i # which means # compute for 7, then i/o, then compute for 1, then i/o def load_program(self, program): proc_id = self.new_process() for line in program.split(\u0026#39;,\u0026#39;): opcode = line[0] if opcode == \u0026#39;c\u0026#39;: # compute num = int(line[1:]) for i in range(num): self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) elif opcode == \u0026#39;i\u0026#39;: self.proc_info[proc_id][PROC_CODE].append(DO_IO) # add one compute to HANDLE the I/O completion self.proc_info[proc_id][PROC_CODE].append(DO_IO_DONE) else: print(\u0026#39;bad opcode %s (should be c or i)\u0026#39; % opcode) exit(1) return def load(self, program_description): proc_id = self.new_process() tmp = program_description.split(\u0026#39;:\u0026#39;) if len(tmp) != 2: print(\u0026#39;Bad description (%s): Must be number \u0026lt;x:y\u0026gt;\u0026#39; % program_description) print(\u0026#39; where X is the number of instructions\u0026#39;) print(\u0026#39; and Y is the percent change that an instruction is CPU not IO\u0026#39;) exit(1) num_instructions, chance_cpu = int(tmp[0]), float(tmp[1])/100.0 for i in range(num_instructions): if random.random() \u0026lt; chance_cpu: self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) else: self.proc_info[proc_id][PROC_CODE].append(DO_IO) # add one compute to HANDLE the I/O completion self.proc_info[proc_id][PROC_CODE].append(DO_IO_DONE) return def move_to_ready(self, expected, pid=-1): if pid == -1: pid = self.curr_proc assert(self.proc_info[pid][PROC_STATE] == expected) self.proc_info[pid][PROC_STATE] = STATE_READY return def move_to_wait(self, expected): assert(self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_WAIT return def move_to_running(self, expected): assert(self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_RUNNING return def move_to_done(self, expected): assert(self.proc_info[self.curr_proc][PROC_STATE] == expected) self.proc_info[self.curr_proc][PROC_STATE] = STATE_DONE return def next_proc(self, pid=-1): if pid != -1: self.curr_proc = pid self.move_to_running(STATE_READY) return for pid in range(self.curr_proc + 1, len(self.proc_info)): if self.proc_info[pid][PROC_STATE] == STATE_READY: self.curr_proc = pid self.move_to_running(STATE_READY) return for pid in range(0, self.curr_proc + 1): if self.proc_info[pid][PROC_STATE] == STATE_READY: self.curr_proc = pid self.move_to_running(STATE_READY) return return def get_num_processes(self): return len(self.proc_info) def get_num_instructions(self, pid): return len(self.proc_info[pid][PROC_CODE]) def get_instruction(self, pid, index): return self.proc_info[pid][PROC_CODE][index] def get_num_active(self): num_active = 0 for pid in range(len(self.proc_info)): if self.proc_info[pid][PROC_STATE] != STATE_DONE: num_active += 1 return num_active def get_num_runnable(self): num_active = 0 for pid in range(len(self.proc_info)): if self.proc_info[pid][PROC_STATE] == STATE_READY or \\ self.proc_info[pid][PROC_STATE] == STATE_RUNNING: num_active += 1 return num_active def get_ios_in_flight(self, current_time): num_in_flight = 0 for pid in range(len(self.proc_info)): for t in self.io_finish_times[pid]: if t \u0026gt; current_time: num_in_flight += 1 return num_in_flight def check_for_switch(self): return def space(self, num_columns): for i in range(num_columns): print(\u0026#39;%10s\u0026#39; % \u0026#39; \u0026#39;, end=\u0026#39;\u0026#39;) def check_if_done(self): if len(self.proc_info[self.curr_proc][PROC_CODE]) == 0: if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING: self.move_to_done(STATE_RUNNING) self.next_proc() return def run(self): clock_tick = 0 if len(self.proc_info) == 0: return # track outstanding IOs, per process self.io_finish_times = {} for pid in range(len(self.proc_info)): self.io_finish_times[pid] = [] # make first one active self.curr_proc = 0 self.move_to_running(STATE_READY) # OUTPUT: headers for each column print(\u0026#39;%s\u0026#39; % \u0026#39;Time\u0026#39;, end=\u0026#39;\u0026#39;) for pid in range(len(self.proc_info)): print(\u0026#39;%14s\u0026#39; % (\u0026#39;PID:%2d\u0026#39; % (pid)), end=\u0026#39;\u0026#39;) print(\u0026#39;%14s\u0026#39; % \u0026#39;CPU\u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;%14s\u0026#39; % \u0026#39;IOs\u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;\u0026#39;) # init statistics io_busy = 0 cpu_busy = 0 while self.get_num_active() \u0026gt; 0: clock_tick += 1 # check for io finish io_done = False for pid in range(len(self.proc_info)): if clock_tick in self.io_finish_times[pid]: io_done = True self.move_to_ready(STATE_WAIT, pid) if self.io_done_behavior == IO_RUN_IMMEDIATE: # IO_RUN_IMMEDIATE if self.curr_proc != pid: if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING: self.move_to_ready(STATE_RUNNING) self.next_proc(pid) else: # IO_RUN_LATER if self.process_switch_behavior == SCHED_SWITCH_ON_END and self.get_num_runnable() \u0026gt; 1: # this means the process that issued the io should be run self.next_proc(pid) if self.get_num_runnable() == 1: # this is the only thing to run: so run it self.next_proc(pid) self.check_if_done() # if current proc is RUNNING and has an instruction, execute it instruction_to_execute = \u0026#39;\u0026#39; if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING and \\ len(self.proc_info[self.curr_proc][PROC_CODE]) \u0026gt; 0: instruction_to_execute = self.proc_info[self.curr_proc][PROC_CODE].pop(0) cpu_busy += 1 # OUTPUT: print what everyone is up to if io_done: print(\u0026#39;%3d*\u0026#39; % clock_tick, end=\u0026#39;\u0026#39;) else: print(\u0026#39;%3d \u0026#39; % clock_tick, end=\u0026#39;\u0026#39;) for pid in range(len(self.proc_info)): if pid == self.curr_proc and instruction_to_execute != \u0026#39;\u0026#39;: print(\u0026#39;%14s\u0026#39; % (\u0026#39;RUN:\u0026#39;+instruction_to_execute), end=\u0026#39;\u0026#39;) else: print(\u0026#39;%14s\u0026#39; % (self.proc_info[pid][PROC_STATE]), end=\u0026#39;\u0026#39;) # CPU output here: if no instruction executes, output a space, otherwise a 1 if instruction_to_execute == \u0026#39;\u0026#39;: print(\u0026#39;%14s\u0026#39; % \u0026#39; \u0026#39;, end=\u0026#39;\u0026#39;) else: print(\u0026#39;%14s\u0026#39; % \u0026#39;1\u0026#39;, end=\u0026#39;\u0026#39;) # IO output here: num_outstanding = self.get_ios_in_flight(clock_tick) if num_outstanding \u0026gt; 0: print(\u0026#39;%14s\u0026#39; % str(num_outstanding), end=\u0026#39;\u0026#39;) io_busy += 1 else: print(\u0026#39;%10s\u0026#39; % \u0026#39; \u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;\u0026#39;) # if this is an IO start instruction, switch to waiting state # and add an io completion in the future if instruction_to_execute == DO_IO: self.move_to_wait(STATE_RUNNING) self.io_finish_times[self.curr_proc].append(clock_tick + self.io_length + 1) if self.process_switch_behavior == SCHED_SWITCH_ON_IO: self.next_proc() # ENDCASE: check if currently running thing is out of instructions self.check_if_done() return (cpu_busy, io_busy, clock_tick) # # PARSE ARGUMENTS # parser = OptionParser() parser.add_option(\u0026#39;-s\u0026#39;, \u0026#39;--seed\u0026#39;, default=0, help=\u0026#39;the random seed\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;seed\u0026#39;) parser.add_option(\u0026#39;-P\u0026#39;, \u0026#39;--program\u0026#39;, default=\u0026#39;\u0026#39;, help=\u0026#39;more specific controls over programs\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;program\u0026#39;) parser.add_option(\u0026#39;-l\u0026#39;, \u0026#39;--processlist\u0026#39;, default=\u0026#39;\u0026#39;, help=\u0026#39;a comma-separated list of processes to run, in the form X1:Y1,X2:Y2,... where X is the number of instructions that process should run, and Y the chances (from 0 to 100) that an instruction will use the CPU or issue an IO (i.e., if Y is 100, a process will ONLY use the CPU and issue no I/Os; if Y is 0, a process will only issue I/Os)\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_list\u0026#39;) parser.add_option(\u0026#39;-L\u0026#39;, \u0026#39;--iolength\u0026#39;, default=5, help=\u0026#39;how long an IO takes\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;io_length\u0026#39;) parser.add_option(\u0026#39;-S\u0026#39;, \u0026#39;--switch\u0026#39;, default=\u0026#39;SWITCH_ON_IO\u0026#39;, help=\u0026#39;when to switch between processes: SWITCH_ON_IO, SWITCH_ON_END\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_switch_behavior\u0026#39;) parser.add_option(\u0026#39;-I\u0026#39;, \u0026#39;--iodone\u0026#39;, default=\u0026#39;IO_RUN_LATER\u0026#39;, help=\u0026#39;type of behavior when IO ends: IO_RUN_LATER, IO_RUN_IMMEDIATE\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;io_done_behavior\u0026#39;) parser.add_option(\u0026#39;-c\u0026#39;, help=\u0026#39;compute answers for me\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;solve\u0026#39;) parser.add_option(\u0026#39;-p\u0026#39;, \u0026#39;--printstats\u0026#39;, help=\u0026#39;print statistics at end; only useful with -c flag (otherwise stats are not printed)\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;print_stats\u0026#39;) (options, args) = parser.parse_args() random_seed(options.seed) assert(options.process_switch_behavior == SCHED_SWITCH_ON_IO or options.process_switch_behavior == SCHED_SWITCH_ON_END) assert(options.io_done_behavior == IO_RUN_IMMEDIATE or options.io_done_behavior == IO_RUN_LATER) s = scheduler(options.process_switch_behavior, options.io_done_behavior, options.io_length) if options.program != \u0026#39;\u0026#39;: for p in options.program.split(\u0026#39;:\u0026#39;): s.load_program(p) else: # example process description (10:100,10:100) for p in options.process_list.split(\u0026#39;,\u0026#39;): s.load(p) assert(options.io_length \u0026gt;= 0) if options.solve == False: print(\u0026#39;Produce a trace of what would happen when you run these processes:\u0026#39;) for pid in range(s.get_num_processes()): print(\u0026#39;Process %d\u0026#39; % pid) for inst in range(s.get_num_instructions(pid)): print(\u0026#39; %s\u0026#39; % s.get_instruction(pid, inst)) print(\u0026#39;\u0026#39;) print(\u0026#39;Important behaviors:\u0026#39;) print(\u0026#39; System will switch when \u0026#39;, end=\u0026#39;\u0026#39;) if options.process_switch_behavior == SCHED_SWITCH_ON_IO: print(\u0026#39;the current process is FINISHED or ISSUES AN IO\u0026#39;) else: print(\u0026#39;the current process is FINISHED\u0026#39;) print(\u0026#39; After IOs, the process issuing the IO will \u0026#39;, end=\u0026#39;\u0026#39;) if options.io_done_behavior == IO_RUN_IMMEDIATE: print(\u0026#39;run IMMEDIATELY\u0026#39;) else: print(\u0026#39;run LATER (when it is its turn)\u0026#39;) print(\u0026#39;\u0026#39;) exit(0) (cpu_busy, io_busy, clock_tick) = s.run() if options.print_stats: print(\u0026#39;\u0026#39;) print(\u0026#39;Stats: Total Time %d\u0026#39; % clock_tick) print(\u0026#39;Stats: CPU Busy %d (%.2f%%)\u0026#39; % (cpu_busy, 100.0 * float(cpu_busy)/clock_tick)) print(\u0026#39;Stats: IO Busy %d (%.2f%%)\u0026#39; % (io_busy, 100.0 * float(io_busy)/clock_tick)) print(\u0026#39;\u0026#39;) 소스코드 분석 # process switch behavior SCHED_SWITCH_ON_IO = \u0026#39;SWITCH_ON_IO\u0026#39; SCHED_SWITCH_ON_END = \u0026#39;SWITCH_ON_END\u0026#39; # io finished behavior IO_RUN_LATER = \u0026#39;IO_RUN_LATER\u0026#39; IO_RUN_IMMEDIATE = \u0026#39;IO_RUN_IMMEDIATE\u0026#39; # process states STATE_RUNNING = \u0026#39;RUNNING\u0026#39; STATE_READY = \u0026#39;READY\u0026#39; STATE_DONE = \u0026#39;DONE\u0026#39; STATE_WAIT = \u0026#39;BLOCKED\u0026#39; # members of process structure PROC_CODE = \u0026#39;code_\u0026#39; PROC_PC = \u0026#39;pc_\u0026#39; PROC_ID = \u0026#39;pid_\u0026#39; PROC_STATE = \u0026#39;proc_state_\u0026#39; # things a process can do DO_COMPUTE = \u0026#39;cpu\u0026#39; DO_IO = \u0026#39;io\u0026#39; DO_IO_DONE = \u0026#39;io_done\u0026#39; class scheduler: def __init__(self, process_switch_behavior, io_done_behavior, io_length): # keep set of instructions for each of the processes self.proc_info = {} self.process_switch_behavior = process_switch_behavior self.io_done_behavior = io_done_behavior self.io_length = io_length return def new_process(self): proc_id = len(self.proc_info) self.proc_info[proc_id] = {} self.proc_info[proc_id][PROC_PC] = 0 self.proc_info[proc_id][PROC_ID] = proc_id self.proc_info[proc_id][PROC_CODE] = [] self.proc_info[proc_id][PROC_STATE] = STATE_READY return proc_id def load_program(self, program): proc_id = self.new_process() for line in program.split(\u0026#39;,\u0026#39;): opcode = line[0] if opcode == \u0026#39;c\u0026#39;: # compute num = int(line[1:]) for i in range(num): self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) elif opcode == \u0026#39;i\u0026#39;: self.proc_info[proc_id][PROC_CODE].append(DO_IO) # add one compute to HANDLE the I/O completion self.proc_info[proc_id][PROC_CODE].append(DO_IO_DONE) else: print(\u0026#39;bad opcode %s (should be c or i)\u0026#39; % opcode) exit(1) return def load(self, program_description): proc_id = self.new_process() tmp = program_description.split(\u0026#39;:\u0026#39;) if len(tmp) != 2: print(\u0026#39;Bad description (%s): Must be number \u0026lt;x:y\u0026gt;\u0026#39; % program_description) print(\u0026#39; where X is the number of instructions\u0026#39;) print(\u0026#39; and Y is the percent change that an instruction is CPU not IO\u0026#39;) exit(1) num_instructions, chance_cpu = int(tmp[0]), float(tmp[1])/100.0 for i in range(num_instructions): if random.random() \u0026lt; chance_cpu: self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) else: self.proc_info[proc_id][PROC_CODE].append(DO_IO) # add one compute to HANDLE the I/O completion self.proc_info[proc_id][PROC_CODE].append(DO_IO_DONE) return def new_process(self): proc_id = len(self.proc_info) self.proc_info[proc_id] = {} self.proc_info[proc_id][PROC_PC] = 0 self.proc_info[proc_id][PROC_ID] = proc_id self.proc_info[proc_id][PROC_CODE] = [] self.proc_info[proc_id][PROC_STATE] = STATE_READY return proc_id def load_program(self, program): proc_id = self.new_process() for line in program.split(\u0026#39;,\u0026#39;): opcode = line[0] if opcode == \u0026#39;c\u0026#39;: num = int(line[1:]) for i in range(num): self.proc_info[proc_id][PROC_CODE].append(DO_COMPUTE) elif opcode == \u0026#39;i\u0026#39;: self.proc_info[proc_id][PROC_CODE].append(DO_IO) self.proc_info[proc_id][PROC_CODE].append(DO_IO_DONE) else: print(\u0026#39;bad opcode %s (should be c or i)\u0026#39; % opcode) exit(1) return def run(self): clock_tick = 0 if len(self.proc_info) == 0: return self.io_finish_times = {} for pid in range(len(self.proc_info)): self.io_finish_times[pid] = [] self.curr_proc = 0 self.move_to_running(STATE_READY) print(\u0026#39;%s\u0026#39; % \u0026#39;Time\u0026#39;, end=\u0026#39;\u0026#39;) for pid in range(len(self.proc_info)): print(\u0026#39;%14s\u0026#39; % (\u0026#39;PID:%2d\u0026#39; % (pid)), end=\u0026#39;\u0026#39;) print(\u0026#39;%14s\u0026#39; % \u0026#39;CPU\u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;%14s\u0026#39; % \u0026#39;IOs\u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;\u0026#39;) io_busy = 0 cpu_busy = 0 while self.get_num_active() \u0026gt; 0: clock_tick += 1 io_done = False for pid in range(len(self.proc_info)): if clock_tick in self.io_finish_times[pid]: io_done = True self.move_to_ready(STATE_WAIT, pid) if self.io_done_behavior == IO_RUN_IMMEDIATE: if self.curr_proc != pid: if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING: self.move_to_ready(STATE_RUNNING) self.next_proc(pid) else: if self.process_switch_behavior == SCHED_SWITCH_ON_END and self.get_num_runnable() \u0026gt; 1: self.next_proc(pid) if self.get_num_runnable() == 1: self.next_proc(pid) self.check_if_done() instruction_to_execute = \u0026#39;\u0026#39; if self.proc_info[self.curr_proc][PROC_STATE] == STATE_RUNNING and \\ len(self.proc_info[self.curr_proc][PROC_CODE]) \u0026gt; 0: instruction_to_execute = self.proc_info[self.curr_proc][PROC_CODE].pop(0) cpu_busy += 1 if io_done: print(\u0026#39;%3d*\u0026#39; % clock_tick, end=\u0026#39;\u0026#39;) else: print(\u0026#39;%3d \u0026#39; % clock_tick, end=\u0026#39;\u0026#39;) for pid in range(len(self.proc_info)): if pid == self.curr_proc and instruction_to_execute != \u0026#39;\u0026#39;: print(\u0026#39;%14s\u0026#39; % (\u0026#39;RUN:\u0026#39;+instruction_to_execute), end=\u0026#39;\u0026#39;) else: print(\u0026#39;%14s\u0026#39; % (self.proc_info[pid][PROC_STATE]), end=\u0026#39;\u0026#39;) if instruction_to_execute == \u0026#39;\u0026#39;: print(\u0026#39;%14s\u0026#39; % \u0026#39; \u0026#39;, end=\u0026#39;\u0026#39;) else: print(\u0026#39;%14s\u0026#39; % \u0026#39;1\u0026#39;, end=\u0026#39;\u0026#39;) num_outstanding = self.get_ios_in_flight(clock_tick) if num_outstanding \u0026gt; 0: print(\u0026#39;%14s\u0026#39; % str(num_outstanding), end=\u0026#39;\u0026#39;) io_busy += 1 else: print(\u0026#39;%10s\u0026#39; % \u0026#39; \u0026#39;, end=\u0026#39;\u0026#39;) print(\u0026#39;\u0026#39;) if instruction_to_execute == DO_IO: self.move_to_wait(STATE_RUNNING) self.io_finish_times[self.curr_proc].append(clock_tick + self.io_length + 1) if self.process_switch_behavior == SCHED_SWITCH_ON_IO: self.next_proc() self.check_if_done() return (cpu_busy, io_busy, clock_tick) # # PARSE ARGUMENTS # parser = OptionParser() parser.add_option(\u0026#39;-s\u0026#39;, \u0026#39;--seed\u0026#39;, default=0, help=\u0026#39;the random seed\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;seed\u0026#39;) parser.add_option(\u0026#39;-P\u0026#39;, \u0026#39;--program\u0026#39;, default=\u0026#39;\u0026#39;, help=\u0026#39;more specific controls over programs\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;program\u0026#39;) parser.add_option(\u0026#39;-l\u0026#39;, \u0026#39;--processlist\u0026#39;, default=\u0026#39;\u0026#39;, help=\u0026#39;a comma-separated list of processes to run, in the form X1:Y1,X2:Y2,... where X is the number of instructions that process should run, and Y the chances (from 0 to 100) that an instruction will use the CPU or issue an IO (i.e., if Y is 100, a process will ONLY use the CPU and issue no I/Os; if Y is 0, a process will only issue I/Os)\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_list\u0026#39;) parser.add_option(\u0026#39;-L\u0026#39;, \u0026#39;--iolength\u0026#39;, default=5, help=\u0026#39;how long an IO takes\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;int\u0026#39;, dest=\u0026#39;io_length\u0026#39;) parser.add_option(\u0026#39;-S\u0026#39;, \u0026#39;--switch\u0026#39;, default=\u0026#39;SWITCH_ON_IO\u0026#39;, help=\u0026#39;when to switch between processes: SWITCH_ON_IO, SWITCH_ON_END\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;process_switch_behavior\u0026#39;) parser.add_option(\u0026#39;-I\u0026#39;, \u0026#39;--iodone\u0026#39;, default=\u0026#39;IO_RUN_LATER\u0026#39;, help=\u0026#39;type of behavior when IO ends: IO_RUN_LATER, IO_RUN_IMMEDIATE\u0026#39;, action=\u0026#39;store\u0026#39;, type=\u0026#39;string\u0026#39;, dest=\u0026#39;io_done_behavior\u0026#39;) parser.add_option(\u0026#39;-c\u0026#39;, help=\u0026#39;compute answers for me\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;solve\u0026#39;) parser.add_option(\u0026#39;-p\u0026#39;, \u0026#39;--printstats\u0026#39;, help=\u0026#39;print statistics at end; only useful with -c flag (otherwise stats are not printed)\u0026#39;, action=\u0026#39;store_true\u0026#39;, default=False, dest=\u0026#39;print_stats\u0026#39;) (options, args) = parser.parse_args() random_seed(options.seed) assert(options.process_switch_behavior == SCHED_SWITCH_ON_IO or options.process_switch_behavior == SCHED_SWITCH_ON_END) assert(options.io_done_behavior == IO_RUN_IMMEDIATE or options.io_done_behavior == IO_RUN_LATER) s = scheduler(options.process_switch_behavior, options.io_done_behavior, options.io_length) if options.program != \u0026#39;\u0026#39;: for p in options.program.split(\u0026#39;:\u0026#39;): s.load_program(p) else: # example process description (10:100,10:100) for p in options.process_list.split(\u0026#39;,\u0026#39;): s.load(p) assert(options.io_length \u0026gt;= 0) if options.solve == False: print(\u0026#39;Produce a trace of what would happen when you run these processes:\u0026#39;) for pid in range(s.get_num_processes()): print(\u0026#39;Process %d\u0026#39; % pid) for inst in range(s.get_num_instructions(pid)): print(\u0026#39; %s\u0026#39; % s.get_instruction(pid, inst)) print(\u0026#39;\u0026#39;) print(\u0026#39;Important behaviors:\u0026#39;) print(\u0026#39; System will switch when \u0026#39;, end=\u0026#39;\u0026#39;) if options.process_switch_behavior == SCHED_SWITCH_ON_IO: print(\u0026#39;the current process is FINISHED or ISSUES AN IO\u0026#39;) else: print(\u0026#39;the current process is FINISHED\u0026#39;) print(\u0026#39; After IOs, the process issuing the IO will \u0026#39;, end=\u0026#39;\u0026#39;) if options.io_done_behavior == IO_RUN_IMMEDIATE: print(\u0026#39;run IMMEDIATELY\u0026#39;) else: print(\u0026#39;run LATER (when it is its turn)\u0026#39;) print(\u0026#39;\u0026#39;) exit(0) (cpu_busy, io_busy, clock_tick) = s.run() if options.print_stats: print(\u0026#39;\u0026#39;) print(\u0026#39;Stats: Total Time %d\u0026#39; % clock_tick) print(\u0026#39;Stats: CPU Busy %d (%.2f%%)\u0026#39; % (cpu_busy, 100.0 * float(cpu_busy)/clock_tick)) print(\u0026#39;Stats: IO Busy %d (%.2f%%)\u0026#39; % (io_busy, 100.0 * float(io_busy)/clock_tick)) print(\u0026#39;\u0026#39;) 문제 ","permalink":"http://localhost:1313/_wiki/chapter-04/","summary":"source code : process-run.py link : https://github.com/remzi-arpacidusseau/ostep-homework/blob/master/cpu-intro/process-run.py\n#! /usr/bin/env python from __future__ import print_function import sys from optparse import OptionParser import random # to make Python2 and Python3 act the same -- how dumb def random_seed(seed): try: random.seed(seed, version=1) except: random.seed(seed) return # process switch behavior SCHED_SWITCH_ON_IO = \u0026#39;SWITCH_ON_IO\u0026#39; SCHED_SWITCH_ON_END = \u0026#39;SWITCH_ON_END\u0026#39; # io finished behavior IO_RUN_LATER = \u0026#39;IO_RUN_LATER\u0026#39; IO_RUN_IMMEDIATE = \u0026#39;IO_RUN_IMMEDIATE\u0026#39; # process states STATE_RUNNING = \u0026#39;RUNNING\u0026#39; STATE_READY = \u0026#39;READY\u0026#39; STATE_DONE = \u0026#39;DONE\u0026#39; STATE_WAIT = \u0026#39;BLOCKED\u0026#39; # members of process structure PROC_CODE = \u0026#39;code_\u0026#39; PROC_PC = \u0026#39;pc_\u0026#39; PROC_ID = \u0026#39;pid_\u0026#39; PROC_STATE = \u0026#39;proc_state_\u0026#39; # things a process can do DO_COMPUTE = \u0026#39;cpu\u0026#39; DO_IO = \u0026#39;io\u0026#39; DO_IO_DONE = \u0026#39;io_done\u0026#39; class scheduler: def __init__(self, process_switch_behavior, io_done_behavior, io_length): # keep set of instructions for each of the processes self.","title":"프로세스 시뮬레이션 숙제 📚"},{"content":"","permalink":"http://localhost:1313/_wiki/ostep-week-01/","summary":"","title":"OSTEP-Week-01 질의 응답 📚"},{"content":"01 장 - 이 책에 대한 대화 아주 간단한 이 책에 대한 소개를 하는 챕터이다.\n두 장으로 이루어져 있고, 이 책에서 자주 나오게 되는 교수와 학생의 대화 형식으로 이루어져 있다.\n핵심적인 아이디어를 요약하면 다음과 같다.\n리처드 파인만의 물리학 아주 쉬운 6가지 이야기라는 강의 노트가 있다. 물리학이 6만큼 어려우면, 운영체제는 3만큼 어렵기 때문에, 이 책의 제목이 \u0026ldquo;운영체제 아주 쉬운 세 가지 이야기\u0026quot;이다. 이 책은 운영체제에 대한 이야기를 3가지로 나누어서 설명한다. 가상화, 병행성, 영속성 02 장 - 운영체제 개요 이 책에서 다루게 될 내용이지만 아주 간단하게 약식으로 설명하는 글이 있어 가져왔다. c/cpp를 공부할 때 이분의 블로그와 강의자료를 들었는데 상대적으로 최근에 업로드된 문서이다. 내가 c언어를 배우기 전에 알았다면 좋았을 것들\n프로그램은 명령어를 실행하는 아주 단순한 일을 한다. 프로세서는 명렁어를 반입(fetch)하고, 디코딩(decoding)하고, 실행(execute)하는 일을 한다. 그리고 프로그램을 쉽게 실행하고, 프로그램간의 메모리 공유를 가능케 하고, 장치와 상호작용을 가능케하고, 다양한 흥미로운 일을 할 수 있는 소프트웨어가 운영체제이다. 운영체제는 앞에서 언급한 일을 하기 위해서 Virtualization이라는 기법을 사용한다. 실제 프로세서, 메모리, 디스크 같은 물리적인 자원을 이용해서 일반적이고, 강력하고, 사용이 편리한 가상 형태의 자원을 생성한다. 그래서 운영체제를 가상머신이라고 하기도 한다. 가상화를 이용해서 실제 사용자들이 해당 자원을 접근 할 수 있는 API를 제공하며, Application이 사용 할 수 있는 시스템콜을 제공한다. 02.1 CPU 가상화 핵심 질문 : 자원을 어떻게 가상화 시키는가?\n운영체제가 자원을 가상화 시켜서 사용하면 편리한건 너무 당연하기 때문에, 이러한 문제는 질문이 될 수 없다. 이것을 어떻게, 어떠한 기법과 정책으로, 어떻게 효율적으로, 어떠한 하드웨어 지원이 필요한지 와 같은 질문이 중요하다. #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; void Spin(int howlong) { double t = GetTime(); while ((GetTime() - t) \u0026lt; (double)howlong) ; // do nothing in loop } int main(int argc, char *argv[]) { if (argc != 2) { printf(\u0026#34;Usage: CPU \u0026lt;string\u0026gt;\\n\u0026#34;); exit(-1); } char *str = argv[1]; while (1) { Spin(1); printf(\u0026#34;%s\\n\u0026#34;, str); } return 0; } 위 코드는 CPU를 사용하는 프로그램이다. 이 프로그램은 인자로 받은 문자열을 1초에 한 번 영원히 출력한다. $ gcc -o CPU CPU.c $ ./CPU A \u0026amp; ; ./CPU B \u0026amp; ; ./CPU C \u0026amp; ; 이렇게 실행시키면 마치 CPU가 세 개인 것 처럼 ABC가 번갈아가며 출력된다. 이렇게 CPU를 가상화 시키는 것은 유용하지만, 새로운 문제가 발생한다. 예를 들어 동일한 시점에 실행되어야 하는 프로그램이 많아지면, 어떠한 프로그램이 실행되어야 하는가 와 같은 이슈가 생긴다. 이러한 문제를 해결하기 위해서 필요한 정책 같은 것들이 있는데, 이번 장에서는 이러한 정책들을 다루게 된다.(즉 자원 관리자로서의 운영체제 역할에 대해 다룬다.) 02.2 메모리 가상화 #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; double GetTime() { struct timeval t; int rc = gettimeofday(\u0026amp;t, NULL); assert(rc == 0); return (double)t.tv_sec + (double)t.tv_usec / 1e6; } void Spin(int howlong) { double t = GetTime(); while ((GetTime() - t) \u0026lt; (double)howlong) ; // do nothing in loop } int main(int argc, char *argv[]) { int *p = malloc(sizeof(int)); // 메모리를 한당 받는다. assert(p != NULL); printf(\u0026#34;(%d) address pointed to by p: %p\\n\u0026#34;, getpid(), p); // process의 id를 출력한다. *p = 0; // 할당받은 메모리에 0을 넣는다. while (1) { Spin(1); *p = *p + 1; printf(\u0026#34;(%d) p: %d\\n\u0026#34;, getpid(), *p); // process의 id와 p의 값을 출력한다. } } 위 코드는 메모리를 사용하는 프로그램이다. 이 프로그램은 메모리를 할당 받고, 1초에 한 번씩 메모리에 있는 값을 1씩 증가시킨다.\n그러면서 주석에 있는 내용처럼 process의 id와 메모리 주소를 출력한다.\n다수의 프로그램을 동시에 실행시킨 결과는 다음과 같다.\n$ gcc -o MEM MEM.c $ ./MEM \u0026amp; ; ./MEM \u0026amp; ; ./MEM \u0026amp; ; [1] 7890 [2] 7891 [3] 7892 (7890) memory address of p: 0x200000000 (7891) memory address of p: 0x200000000 (7892) memory address of p: 0x200000000 (7890) p: 0 (7891) p: 0 (7892) p: 0 (7890) p: 1 (7891) p: 1 (7892) p: 1 (7890) p: 2 (7891) p: 2 (7892) p: 2 (7890) p: 3 (7891) p: 3 (7892) p: 3 ... 주목해야 할 결과값은 메모리 주소이다. 프로그램이 실행되는 메모리 주소는 모두 같다. 이 역시 메모리 가상화의 결과이다. 프로그램은 자신만의 메모리를 가지고 있다고 생각하지만, 실제로는 운영체제가 제공하는 가상 메모리를 사용하고 있다. 이와 같은 메모리의 가상화 역시 이 책에서 다루게 된다. 02.3 병행성 (Concurrency) 프로그램이 한 번에 많은 일을 하려 할 때 (동시에) 발생하는 문제를 다룬다. 사실 운영체제는 한 프로세스 실행, 다음 프로세스 실행, 다음 프로세스 실행, \u0026hellip; 이런식으로 프로세스를 번갈아가며 실행하는데 이 때 발생하는 문제들이 생긴다. #include \u0026lt;assert.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; volatile int counter = 0; int loops; // loop 횟수만큼 counter를 증가시키는 함수 void *worker(void *arg) { int i; for (i = 0; i \u0026lt; loops; i++) { counter++; } return NULL; } int main(int argc, char *argv[]) { if (argc != 2) { fprintf(stderr, \u0026#34;usage: threads \u0026lt;value\u0026gt;\\n\u0026#34;); exit(1); } loops = atoi(argv[1]); // 인자로 받은 값을 loops에 저장한다. pthread_t p1, p2; printf(\u0026#34;Initial value : %d\\n\u0026#34;, counter); double t1 = GetTime(); pthread_create(\u0026amp;p1, NULL, worker, NULL); // thread p1 worker 함수 실행 pthread_create(\u0026amp;p2, NULL, worker, NULL); // thread p2 worker 함수 실행 pthread_join(p1, NULL); pthread_join(p2, NULL); double t2 = GetTime(); printf(\u0026#34;Final value : %d\\n\u0026#34;, counter); printf(\u0026#34;Time : %f\\n\u0026#34;, t2 - t1); return 0; } 이 코드는 복잡해보이지만 전혀 그렇지 않다. thread 2개를 생성하고, 각각의 thread에서 worker 함수를 실행한다. worker 함수는 인자로 받은 loop 횟수만큼 counter를 증가시킨다. 실제 실행 결과는 다음과 같다. $ gcc -o THREAD THREAD.c -lpthread $ ./THREAD 1000 Initial value : 0 Final value : 2000 Time : 0.000000 일단 값이 2000이 나왔다. 이는 2개의 thread가 각각 1000번씩 counter를 증가시켰기 때문이다. 더 많은 횟수로 실행한 결과는 다음과 같다. $ ./THREAD 100000 Initial value : 0 Final value : 143012 Time : 0.000000 이번에는 143012가 나왔다. 인자 * 스레드의 개수 만큼 counter가 증가해야 하는데 그렇지 않은 이유는 아래와 같다.\n실제 카운터를 증가시키는 코드의 로직은 다음과 같다.\ncounter를 메모리에서 레지스터로 불러온다. 레지스터에 1을 더한다. 레지스터의 값을 메모리에 저장한다. 이 세가지 작업이 원자성을 가지지 않는다. 즉, 다른 스레드가 counter를 읽어가는 동안 다른 스레드가 counter를 증가시킬 수 있다.\n이러한 문제가 Concurrency 문제이며, 이러한 문제를 해결하기 위한 방법들을 이 책에서 다룬다.\n병행성의 핵심 질문 : 올바르게 동작하는 병행 프로그램은 어떻게 작성해야 하는가 같은 메모리 공간에 다수의 쓰레드가 동시에 실행단다고 할 때, 올바르게 동작하는 프로그램을 어떻게 잘성 할 수 있는가? 운영체제는 어떠한 기본 기법을 제공하는가, 하드웨어는 어떠한 지원을 제공하는가? 병행성 문제를 해결하기 위해 기본 기법들과 하드웨어 기능을을 어떻게 사용할 수 있는가?\n02.4 영속성 (Persistence) RAM은 읽고 쓰기가 레지스터, 캐시에 비해서는 느리지만, 그래도 충분히 빠르다. 작업 시간 (현실 시간으로 환산) CPU 사이클 1초 L1 캐시 접근 2초 L2 캐시 접근 7초 L3 캐시 접근 1분 RAM 접근 4분 NVMe SSD 접근 17시간 일반 SSD 접근 1.5일 ~ 4일 일반 하드디스크 접근 1 ~ 9달 서울 - 샌프란시스코 패킷 전송 시간 14년 출처 : 내가 c언어를 배우기 전에 알았다면 좋았을 것들 그러나 RAM은 전원이 꺼지면 모든 데이터가 사라진다. 그래서 우리는 데이터를 영구적으로 저장할 수 있는 영속성을 구현하기 위해 하드웨어와 소프트웨어가 필요하다. 많이들 알고 있겠지만, 하드웨어는 I/O 장치 형태로 제공되며, 요즘은 주로 SSD를 사용한다. 디스크를 관리하는 운영체제 소프트웨어는 파일 시스템이라고 한다. (파일시스템은 사용자가 생성한 파일을 시스템의 디스크에 안전하고 효율적으로 저장할 책임이 있다.) 영속성과 관련한 핵심 질문은 다음과 같다. 영속성의 핵심 질문 : 데이터를 영속적으로 저장하는 방법은 무엇인가 파일 시스템은 데이터를 여속적으로 관리하는 운영체제의 일부분인다. 올바르게 동작하기 위해서는 어떤 기법이 필요할까? 이러한 작업 성능을 높이기 위해서 어떤 기법과 정책이 필요할까? 하드웨어와 소프트웨어가 실패하더라도 올바르게 동작하려면 어떻게 해야 할까?\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;assert.h\u0026gt; #include \u0026lt;fcnt1.h\u0026gt; #include \u0026lt;sys/file.h\u0026gt; int main(int argc, char *argv[]) { int fd = open(\u0026#34;tmp/file\u0026#34;, O_WRONLY | O_CREAT | O_TRUNC, S_IRWXU); // 프로그램의 운영체제 첫 번째 호출(call) assert(fd \u0026gt; -1); int rc = write(fd, \u0026#34;hello world\\n\u0026#34;, 13); // 프로그램의 운영체제 두 번째 호출(call) close(fd); // 프로그램의 운영체제 세 번째 호출(call) assert(rc == 13); /** * 이 처럼 파일 시스템의 시스템 콜을 사용한다. */ return 0; } 이 코드는 파일 시스템을 사용하는 프로그램이다. 파일을 열고, 쓰고, 닫는 작업을 한다. 디스크를 접근해서 파일시스템으로 관리하고 시스템콜을 통해 파일을 생성하고, 쓰고, 닫아왔었다. 이러한 시스템콜은 표준화 되어있어서 마치 언어의 STL로 제공받는 것처럼 편리하지만, 실제로 내부에서 일어나는 일은 매우 복잡하다. 에를 들어 쓰기 지연시간동안 정전이 되었거나 고장이 났을 때, 기록 순서가 뒤바뀔 수 있고, 쓰려고 모였던 데이터는 이미 쓰였을 수도 있다. 이런 것들을 해결하기 위해 운영체제는 journaling, copy-on-write, checksums 등의 기법을 사용하는데, 이러한 것들도 같이 다루게 된다. 02.5 설계 목표 설계 목표라고 되어 있어서 흐름상 애매하지만, 위의 소주제에서 세가지를 보면서(가상화, 병행성, 영속성) 운영체제가 해야하는, 하고있는, 해야할 일을 알게 되었으니, 그것들을 어떻게 잘 수행할 수 있을지에 대한 설계 목표를 다룬다고 생각하면 될 것 같다.\n첫 번째로, 가장 기본적인 목표는 시스템을 편리하고 사용하기 쉽게 만드는 데 필요한 개념들을 정의하는 것 즉 추상화이다.\n이 추상화는 컴퓨터 과학에 있어서 모든 일에 대한 근간이다. 추상화로 개념을 정의해가며 큰 프로그램을 이해하기 쉬운 작은 여러가지로 나눌 수 있다. 예를 들어 논리 게이트를 몰라도 어셈블리어로 프로그램을 작성 할 수 잇고, 어셈블리어를 몰라도 C와 같은 high level 언어로 프로그램을 작성할 수 있다. 두 번째로, 운영체제의 가장 중요한 목표는 성능이다. (minimize the overhead)\noverhead는 시스템의 성능을 떨어뜨리는 요소이며, 시간(더 많은 명령어)과 공간(더 많은 메모리)적인 요소로 나뉜다. 이 시간과 공간의 낭비를 최소화 하면서도, 절충할 부분은 절충하면서, 성능을 최대화 하는 것이 운영체제의 목표이다. 세 번째로, 보호이다.\n운영체제와 프로그램, 프로그램간의 보호를 제공하는 것이다. 한 프로그램의 악의적인 또는 의도치 않은 행동이 다른 프로그램이나 운영체제에 영향을 미치지 않도록 하는 것이 필요하다. 보호는 운영체제의 원칙 중 하나인 isolation 원칙의 핵심이다. 마지막으로 신뢰성이다.\n운영체제는 항상, 지속적으로 실행되고 있어야 한다. 운영체제가 실패하면, 그 위에서 돌아가는 프로그램들도 실패하게 된다. 이러한 종속성 때문에 운영체제는 매우 높은 신뢰성을 요구받는다. 이러한 목표들은 운영체제의 설계와 구현에 있어서 중요한 요소이며, 이 책에서는 이러한 목표들을 달성하기 위한 기법과 정책들을 다룬다.\n추가적으로 에너지 효율성과 보안, 이식성등을 언급하지만, 이 책에에서 직접적으로 다루진 않고, 실제로도 위의 네가지가 조금 더 운영체제의 핵심 목표이다.\n02.6 배경 소개 (라고 되어있지만 사실 그냥 운영체제의 역사) 초창기 운영체제: 단순 라이브러리 초창기에는 운영체제가 많은 일을 하지 않았다, 자주 사용되는 저수준의 입출력 처리 코드를 함수화 하여 모아놓은 라이브러리 정도였다. 작업을 모아놓고 일괄적으로 처리하는 것은 batch processing이라고 하는데, 이러한 작업은 컴퓨터 관리자가 수동으로 처리했다. 라이브러리를 넘어 : 보호 운영체제는 단순한 라이브러리를 넘어 컴퓨터 \u0026lsquo;관리\u0026rsquo; 측면에서 중요한 역할을 하기 시작했다. 운영체제가 실행하는 코드는 일반적인 응용 프로그램의 코드와는 다르게, 실제 하드웨어 장치의 제어를 담당하고 있기에, 다르게 취급되어야 한다는 필요성이 대두되었다. 예를들어 모든 응용 프로그램이 하드디스크에 접근하면, 응용 프로그램끼리 서로의 데이터를 읽고 쓸 수 있게 되어 보안상 문제가 발생한다. 결론적으로 예를들 file system과 같은 것들을 일반 라이브러리처럼 제공하고 운영하면, 자료의 기록과 보호라는 원래 의도한 역할을 수행할 수 없게 된다. 여기서 Atlas Computing System에 의해 System Call이라는 아이디어가 발명되었다. 기본적으로 Atlas Computing System의 아이디어는 OS routine을 라이브러리 형식으로 제공하는 대신, OS를 더 공식적이고 제어된 프로세스로 전환하기위해 하드웨어 명령어와 하드웨어 상태라는 특별한 페어를 추가하는 아이디어이다. System Call과 Procedure Call의 차이점은 System Call에서는 OS로 제어권이 넘어가는 시점에 하드웨어 제어 권한(정확히 번역은 하드웨어 특권 수준 : Hardware Privilege level 으로 되어있다)을 격상시키는 것이다. 일단 일반적인 응용프로그램은 user mode에서 실행되는데, 이때는 하드웨어에 대한 접근이 제한된다. 하지만 System Call을 호출하면, OS로 제어권이 넘어가고, OS는 kernel mode에서 실행되며, 이때는 하드웨어에 대한 접근이 허용된다. 구체적으로는 trap이라는 명령어를 사용하여 System Call을 호출하고, 이때 trap은 kernel mode로 전환하는 역할을 한다. 또한 하드웨어는 trap으로 인해 System Call이 호출되었을 때, 미리 지정된 trap handler 함수에게 제어권을 넘긴다. 이 상태에서는 모든 하드웨어에 대한 접근이 허용되며, 이를 통해 OS는 필요한 요청을 처리하고, 제어권을 다시 user에게 넘겨준다. 이러한 System Call을 통해 OS는 하드웨어에 대한 접근을 제어하고, 이를 통해 보호와 다른 기능들을 수행할 수 있게 되었다. 참고: System call과 Procedure call의 차이점\n권한 수준 (Privilege Level):\n프로시저 호출: 프로시저 호출은 일반적으로 동일한 권한 수준(예: 사용자 모드)에서 발생합니다. 호출된 프로시저는 호출한 프로그램과 동일한 권한 수준에서 실행됩니다. 시스템 호출: 시스템 호출은 권한 수준을 변경하여 실행됩니다. 시스템 호출은 일반적으로 사용자 모드에서 이루어지며, 호출된 OS 코드는 권한이 더 높은 커널 모드에서 실행됩니다. 이로써 OS는 보다 높은 권한 수준에서 하드웨어와 상호 작용하여 특권 명령을 실행할 수 있습니다. 하드웨어 접근 및 보안:\n프로시저 호출: 프로시저 호출은 호출된 프로시저가 호출한 프로그램의 메모리 공간과 동일한 접근 권한을 가집니다. 이는 호출된 프로시저가 호출한 프로그램의 데이터에 자유롭게 접근할 수 있다는 것을 의미할 수 있습니다. 시스템 호출: 시스템 호출은 권한 수준을 변경하므로, 호출된 OS 코드는 호출한 프로그램의 메모리 공간에 직접 액세스할 수 없습니다. 이는 시스템 호출을 통해 호출된 OS가 사용자 프로그램의 데이터에 무단으로 접근하는 것을 방지합니다. 운영 체제와의 상호 작용:\n프로시저 호출: 프로시저 호출은 일반적으로 동일한 응용 프로그램 내에서 다른 함수 또는 프로시저를 호출하는 데 사용됩니다. 시스템 호출: 시스템 호출은 주로 운영 체제와 상호 작용하기 위해 사용됩니다. 예를 들어, 파일 시스템 접근, 네트워크 통신, 시스템 자원 할당 등과 같은 운영 체제 서비스에 접근하기 위해 사용됩니다. 멀티 프로그래밍 시대 미니 컴퓨터 시대에 이루어 졌다고 한다. 회사마다 하나의 컴퓨터를 사용하는 정도로 보급되었다고 한다. 이때부터 운영체제는 multiprogramming이라는 개념을 도입하게 된다. 왜냐하면 한대의 컴퓨터에서 여러개의 프로그램을 실행하면서, CPU가 놀지 않도록 일을 시킬 수 있기 때문이다. 그래서 인터럽트를 통한 context switch라는 아이디어가 등장했는데, 운영체제 역사에서 혁신이라 부를 만 한 아이디어이다. 물론 이러한 상황에서 메모리 보호, 병행성에 대한 처리도 필요해졌다. 그 외에 역사적으로는 UNIX 운영체제가 등장했고, 이 역시 가장 중요한 사건 중 하나로 꼽힌다. 현대 (개인용 컴퓨터 시대) 이제는 개인용 컴퓨터가 보급되었고, 이에 따라 운영체제도 변화하게 된다. 놀랍게도 저자는 퇴보를 언급한다, 미니 컴퓨터 시대가 운영체제의 전성기였으며 초창기 pc들의 os들은 그 시대의 아이디어나 기술을 사용하지 않거나 심지어는 잘 몰랐다고 한다. 예시로 DOS는 메모리 보호를 전혀 생각하지 않고 디자인 되었고, MacOS는 잘못된 스케줄링을 채택하여, 쓰레드 하나가 무한루프에 빠지면, 전체 시스템이 멈추는 버그가 있었다. 이 당시가 암흑기라고 하며 1980년대가 지나가면서 다시 운영체제는 1970년대 미니컴퓨터 시대의 아이디어와 기술을 찾아가기 시작했다고 한다. 03장 - 가상화에 대한 대화 가상화에 대한 대화를 통해 가상화에 대한 기본적인 개념을 이해한다.\n가상화를 복숭아에 비유하여 설명한다.\n복숭아를 먹고 싶은 사람이 여럿 있고 복숭아는 단 하나라고 이야기한다.\n먼저 가상 복숭아를 먹고싶은 모두에게 나눠준다.\n사실 그 사람들은 매 시간 복숭아를 먹고 있는게 아니라, 대부분의 시간을 낮잠을 자거나 휴식을 취하고 있다.\n그래서 실제로 복숭아를 사용하고 있지 않을 때, 다른 사람에게 실제 복숭아를 가져다 준다는 것이다.\n이 비유에서 복숭아는 자원이고, 사람들은 프로세스이다.\n그리고 그 복숭아를 옮기는 사람은 운영체제이다.\n복숭아를 CPU로 바꾸면 CPU 가상화가 되고, 복숭아를 메모리로 바꾸면 메모리 가상화가 된다.\n04장 - 프로세스 프로세스는 일반적으로 실행중인 프로그램이라고 정의한다. 프로그램은 디스크 상에 존재하는 실행을 위한 명령어와 정적 데이터의 묶음이다. 핵심 질문 : CPU가 여러 개 존재한다는 환상을 어떻게 제공하는가?\n운영체제는 CPU를 가상화하여 여러 개의 프로세스가 동시에 실행되는 것처럼 보이게 한다. 하나의 프로세스를 실행하고, 다른 프로세스를 실행하고, 다시 다른 프로세스를 실행하는 것을 반복한다. 이러한 기법은 time sharing 이라고 불리는데, 원하는 수 만큼의 프로세스를 동시에 실행 할 수 있다.(물론 CPU를 공유하기 때문에 각 프로세스의 성능은 떨어진다.) CPU 가상화를 효율적으로 구현하기 위해서는 도구(mechanism)와 지능(policy)이 필요하다. 여기서의 도구는 context switch와 interrupt이며, 지능은 scheduler인데 지금부터 이것들을 다룬다. 04.1 프로세스의 개념(프로세스 추상화) 프로세스 인스턴스를 요약하려면, 프로세스가 실행간에 접근했거나 영향을 미친 것들에 대한 목록을 통해 알아볼 수 있다.\n이러한 관점으로 프로세스를 알아보기 위해서 일단 하드웨어 상태(machine state)에 대해서 이해를 해야 한다.\nmachine state는 프로그램이 실행되는 동안 읽거나 쓸 수 있는 모든 것을 의미한다.\nmachine state의 가장 중요한 컴포넌트는 memory이다. 명령어와 읽고 쓰는 데이터 모두 메모리에 저장되어 있고, 프로세스가 접근 할 수 있는 메모리(주소공간)는 프로세스의 machine state의 일부이다.\n두 번 째 컴포넌트로 레지스터가 있는데, 레지스터는 CPU에 있는 작은 메모리 공간이다. 레지스터는 CPU가 명령어를 실행하는 동안 사용되며, 프로세스의 machine state의 일부이다.\n레지스터중 하나로 program counter가 있는데, 프로그램의 어느 명령어가 실행 중 인지를 알려주는 컴포넌트이다.(명령어 포인터 : Intruction Pointer 로도 불린다.)\n또한 stack pointer와 frame pointer가 있는데, 이것들은 프로세스의 실행 중에 사용되는 메모리 공간을 가리키는 포인터이다.\n그리고 영구 저장장소에 접근하기 위한 것들도 있다.\n요약하자면, 프로세스는 실행중인 프로그램이며, 프로세스를 이해하기 위해서는 프로세스의 machine state를 이해해야 하는데, machine state는 메모리, 레지스터, 프로그램 카운터, 스택 포인터, 프레임 포인터 등이 있다.\n04.2 프로세스 API 실제 프로세스 API는 다음장에서 나오지만, 운영체제가 반드시 API로 제공해야하는 기능들은 다음과 같다. 생성(Create) : 운영체제는 프로세스를 생성 할 수 있는 방법을 제공해야 한다. 제거(Destory) : 운영체제는 프로세스를 강제로 제거 할 수 있는 방법을 제공해야 한다. 대기(Wait) : 운영체제는 프로세스가 다른 프로세스의 종료를 기다릴 수 있는 방법을 제공해야 한다. 각종 제어(Miscellaneous Control) : 프로세스의 우선순위를 변경하거나, 프로세스의 상태를 변경하는 등의 제어를 제공해야 한다. 상태 (Status) : 프로세스의 상태를 확인할 수 있는 방법을 제공해야 한다. 04.3 프로세스 생성: 조금 더 자세히 프로세스의 생성의 첫 단계는 디스크에 있는 프로그램을 메모리에 로드하는 것이다. 현대의 운영체제는 이 과정에서 paging과 swapping같은 기능을 활용하여 실제 지금 필요한 부분만 메모리에 로드하는데 지금 주제와 관련이 없으므로 언급만 한다. 탑재 이후 프로세스를 실행시키기 전에 운영체제가 해야할 일이 있다. 바로 특정한 만큼의 메모리를 Stack, Heap 용도로 나눠서 할당하는 것이다. 또한 입출력과 관련된 것들도 초기화 해야 한다. 그 다음에 main() 함수를 실행시키는 것이다. 04.4 프로세스 상태 프로세스 상태를 단순화 하면 다음 세가지로 구분 할 수 있다. 실행중(Running) : 프로세스가 CPU를 사용하고 있는 상태이다.(명령어를 실행하고 있는 상태) 대기중(Ready) : 프로세스가 CPU를 사용하고 있지 않지만, 언제든지 사용할 수 있는 상태이다. 대기중(Blocked) : 프로세스가 CPU를 사용하고 있지 않고, 어떤 이벤트를 기다리고 있는 상태이다. 프로세스는 운영체제의 스케쥴링 정책에 따라 스케줄이 되면, 준비상태에서 실행상태로 바뀌게 된다. 프로세스가 입출력등의 완료 이벤트가 필요한 경우, 대기상태로 바뀌게 된다. 그리고 이렇게 입출력을 포함한 두 프로세스가 CPU를 사용하는 것은 아래의 표와 같이 나타낼 수 있다. 시간 프로세스0 프로세스1 비고 1 준비 실행 2 실행 준비 3 실행 준비 Process0이 입출력을 시작 4 대기 실행 Process0 대기 상태 5 대기 실행 Process1 실행 6 대기 실행 7 준비 실행 Process0 입출력 종료 8 준비 실행 Process1 종료 9 실행 10 실행 Process0 종료 이러한 방식 (1 프로세스가 실행중이고, 0 프로세스가 대기상태일 때 1을 마무리한게 효율적이었나?) 등을 고민하는건 운영체제의 스케줄러가 담당하고 이부분은 다음장에서 다룬다. 04.5 자료 구조 운영체제도 프로그램이고 프로세스는 운영체제가 관리해야 하는 정보다. 그래서 프로세스를 관리하기 위한 자료구조가 필요하다.\n예를 들어 프로세스의 상태를 저장하는 자료구조가 필요고, 프로세스 리스트와 같은 자료구조를 사용한다. 또한 현제 실행중인 프로세스를 저장하는 자료구조도 필요하다. 이러한 예시로 책에서는 register context를 보여준다. // 프로세스를 중단하고 이후에 다시 시작할 수 있는 정보를 저장하는 구조체 struct context { int eax; int ebx; int ecx; int edx; int esi; int edi; int eip; int esp; int ebp; }; enum proc_state { UNUSED, USED, ZOMBIE, SLEEPING, RUNNABLE, RUNNING }; struct proc { char *mem; // 프로세스의 메모리 주소 struct context context; // 프로세스의 레지스터 상태 enum proc_state state; // 프로세스의 상태 char *kstack; // 커널 스택바닥주소 int pid; // 프로세스의 고유 식별자 struct proc *parent; // 부모 프로세스 struct proc *children; // 자식 프로세스 void *chan // 0이 아닌 경우, 프로세스가 대기중인 이벤트 int killed; // 0이 아닌 경우, 프로세스가 종료되었음을 나타냄 struct file *ofile[NOFILE]; // 열린 파일 struct inode *cwd; // 현재 디렉토리 }; register context : 프로세스가 중단되었을 때 해당 프로세스의 레지스터 값을 저장 (나중에 이 값을 복원하여 재개 -\u0026gt; 그걸 context switch) 프로세스 리스트는 태스크 리스트라고도 불리며, 단순한 자려구조이다. 다수의 프로그램을 \u0026lsquo;동시에\u0026rsquo; 실행시키는 모든 운영체제는 이와 유사한 자료구조를 가지고 있고, 이 자료구조를 이용하여 시스템에서 실행중인 프로그램을 관리한다. 프로세스의 관리를 위한 정보를 저장하는 자료구조를 PCB (Process Control Block)이라고 한다.\n","permalink":"http://localhost:1313/_wiki/os-overview-process/","summary":"01 장 - 이 책에 대한 대화 아주 간단한 이 책에 대한 소개를 하는 챕터이다.\n두 장으로 이루어져 있고, 이 책에서 자주 나오게 되는 교수와 학생의 대화 형식으로 이루어져 있다.\n핵심적인 아이디어를 요약하면 다음과 같다.\n리처드 파인만의 물리학 아주 쉬운 6가지 이야기라는 강의 노트가 있다. 물리학이 6만큼 어려우면, 운영체제는 3만큼 어렵기 때문에, 이 책의 제목이 \u0026ldquo;운영체제 아주 쉬운 세 가지 이야기\u0026quot;이다. 이 책은 운영체제에 대한 이야기를 3가지로 나누어서 설명한다. 가상화, 병행성, 영속성 02 장 - 운영체제 개요 이 책에서 다루게 될 내용이지만 아주 간단하게 약식으로 설명하는 글이 있어 가져왔다.","title":"Week-01 📚"},{"content":"00. Introduction 운영체제 아주 쉬운 세가지 이야기 (Operating Systems: Three Easy Pieces) 01. Appendix 강의 소스코드 : OSTEP 테스트 프로그램 : OSTEP Test Programs 역자 강의 자료 : 강의자료 02. Contents Virtualization CPU [[Os-Overview-Process]] [[LDE-Scheduling]] [[MLFQ-Multiprocessor-Schedule]] Memory [[Memory-Virtual-Intro]] [[Memory-Virtualization]] [[Segmentation-Paging]] [[Paging-TLB]] Concurrency [[Concurrency-Intro]] 03. Homeworks 과제-레포\n[[Chapter-04]]\n","permalink":"http://localhost:1313/_wiki/ostep/","summary":"OSTEP 스터디","title":"운영체제 아주 쉬운 세 가지 이야기 📚"},{"content":"1일 1커맨드 정리 ^ + b, f : 한 페이지씩 스크롤 zz : 현재 커서가 있는 줄을 화면 중앙으로 이동 yi( : 괄호 안에 있는 내용 복사 vap : 비주얼모드 한 문단 블록 씌우기 이동 관련 brace 관련 커맨드를 조금 더 잘쓰면 좋겠다는 생각을 한다.\n개인적으로 vim을 더 잘쓰기 위해서 정리를 잘 해둬야 할 것 같다.\n^ + b, f: 한 페이지씩 스크롤 ^ + d, u: 반 페이지씩 스크롤 e, E: 다음 단어의 끝으로, 문자 단위 이동 w, W: 다음 단어의 처음으로, 문자 단위 이동 $: 줄의 마지막으로 이동 0: 줄의 처음으로 이동 ^: 줄의 처음으로 이동 (공백이 아닌 처음 시작되는 문자) Shift + g: 문서의 마지막으로 이동 gg, 1g: 문서의 처음으로 이동 (숫자 라인으로 이동) ), (: 다음, 이전 문장의 처음으로 이동 }, {: 다음, 이전 문단의 처음으로 이동 ]], [[: 다음, 이전 구절의 처음으로 이동 안녕하세요 Vimwiki 관련 커맨드 Tab – Find next wiki link Shift + Tab – Find previous wiki link Split 관련 커맨드 \u0026lt;leader\u0026gt;sv: 창 수직 분할 \u0026lt;leader\u0026gt;sh: 창 수평 분할 \u0026lt;leader\u0026gt;se: 창 확장 \u0026lt;leader\u0026gt;sx: 창 닫기 lsp 관련 커맨드 \u0026lt;leader\u0026gt;gd: 정의로 이동 키 바인딩 \u0026lt;leader\u0026gt;gR: LSP 참조 표시 \u0026lt;leader\u0026gt;gD: 선언으로 이동 \u0026lt;leader\u0026gt;gd: LSP 정의 표시 \u0026lt;leader\u0026gt;gi: LSP 구현 표시 \u0026lt;leader\u0026gt;gt: LSP 유형 정의 표시 \u0026lt;leader\u0026gt;ca: 사용 가능한 코드 액션 표시 \u0026lt;leader\u0026gt;rn: 스마트 리네임 \u0026lt;leader\u0026gt;D: 버퍼 진단 표시 \u0026lt;leader\u0026gt;d: 줄 진단 표시 \u0026lt;leader\u0026gt;[d: 이전 진단으로 이동 \u0026lt;leader\u0026gt;]d: 다음 진단으로 이동 \u0026lt;leader\u0026gt;K: 커서 아래 항목에 대한 문서 표시 \u0026lt;leader\u0026gt;rs: LSP 재시작 nvim-surround 따옴표 추가\n비주얼 모드에서 텍스트를 선택한 후 S\u0026quot;를 누르면 선택한 텍스트가 큰따옴표로 감싸집니다. 괄호 변경\n예를 들어, ()로 감싸진 텍스트를 {}로 변경하려면 커서를 괄호 안에 두고 cs({를 누르면 됩니다. ","permalink":"http://localhost:1313/_wiki/lsp-cheat-sheet/","summary":"1일 1커맨드 정리 ^ + b, f : 한 페이지씩 스크롤 zz : 현재 커서가 있는 줄을 화면 중앙으로 이동 yi( : 괄호 안에 있는 내용 복사 vap : 비주얼모드 한 문단 블록 씌우기 이동 관련 brace 관련 커맨드를 조금 더 잘쓰면 좋겠다는 생각을 한다.\n개인적으로 vim을 더 잘쓰기 위해서 정리를 잘 해둬야 할 것 같다.\n^ + b, f: 한 페이지씩 스크롤 ^ + d, u: 반 페이지씩 스크롤 e, E: 다음 단어의 끝으로, 문자 단위 이동 w, W: 다음 단어의 처음으로, 문자 단위 이동 $: 줄의 마지막으로 이동 0: 줄의 처음으로 이동 ^: 줄의 처음으로 이동 (공백이 아닌 처음 시작되는 문자) Shift + g: 문서의 마지막으로 이동 gg, 1g: 문서의 처음으로 이동 (숫자 라인으로 이동) ), (: 다음, 이전 문장의 처음으로 이동 }, {: 다음, 이전 문단의 처음으로 이동 ]], [[: 다음, 이전 구절의 처음으로 이동 안녕하세요 Vimwiki 관련 커맨드 Tab – Find next wiki link Shift + Tab – Find previous wiki link Split 관련 커맨드 \u0026lt;leader\u0026gt;sv: 창 수직 분할 \u0026lt;leader\u0026gt;sh: 창 수평 분할 \u0026lt;leader\u0026gt;se: 창 확장 \u0026lt;leader\u0026gt;sx: 창 닫기 lsp 관련 커맨드 \u0026lt;leader\u0026gt;gd: 정의로 이동 키 바인딩 \u0026lt;leader\u0026gt;gR: LSP 참조 표시 \u0026lt;leader\u0026gt;gD: 선언으로 이동 \u0026lt;leader\u0026gt;gd: LSP 정의 표시 \u0026lt;leader\u0026gt;gi: LSP 구현 표시 \u0026lt;leader\u0026gt;gt: LSP 유형 정의 표시 \u0026lt;leader\u0026gt;ca: 사용 가능한 코드 액션 표시 \u0026lt;leader\u0026gt;rn: 스마트 리네임 \u0026lt;leader\u0026gt;D: 버퍼 진단 표시 \u0026lt;leader\u0026gt;d: 줄 진단 표시 \u0026lt;leader\u0026gt;[d: 이전 진단으로 이동 \u0026lt;leader\u0026gt;]d: 다음 진단으로 이동 \u0026lt;leader\u0026gt;K: 커서 아래 항목에 대한 문서 표시 \u0026lt;leader\u0026gt;rs: LSP 재시작 nvim-surround 따옴표 추가","title":"nvim cheat sheet"},{"content":"Cheat Sheet 📜 코틀린 Cheat Sheet : 코틀린을 배워놓고 안써먹다보니 까먹는 부분이 많아 찾아온 Cheat Sheet Coding Test 🧩 cpp-문법-정리 : 코테용 C++ 문법 정리 cpp-문자열 : 문자열 처리 팁 cpp-코테 : 코테 관련 자주 나오는 패턴들 ShortCuts 🚀 [[LSP-Cheat-Sheet]] : Neovim Language Server Cheat Sheet Vim-Cheat-Sheet : Vim Cheat Sheet [[AeroSpace-macOS]] : 윈도우 관리 툴 ","permalink":"http://localhost:1313/_wiki/cheat-sheet/","summary":"Cheat Sheet 📜 코틀린 Cheat Sheet : 코틀린을 배워놓고 안써먹다보니 까먹는 부분이 많아 찾아온 Cheat Sheet Coding Test 🧩 cpp-문법-정리 : 코테용 C++ 문법 정리 cpp-문자열 : 문자열 처리 팁 cpp-코테 : 코테 관련 자주 나오는 패턴들 ShortCuts 🚀 [[LSP-Cheat-Sheet]] : Neovim Language Server Cheat Sheet Vim-Cheat-Sheet : Vim Cheat Sheet [[AeroSpace-macOS]] : 윈도우 관리 툴 ","title":"개발 관련 Cheat Sheet"},{"content":"8.0.0 Common Collections 러스트의 std::collections 모듈은 여러 유용한 자료구조인 컬렉션을 제공한다.\nheap에 저장되는 컬렉션들은 컴파일 시점에 크기를 알 수 없고 늘어나거나 줄어들거나 한다.\n이번 장에서는 Vec\u0026lt;T\u0026gt;, String, HashMap\u0026lt;K, V\u0026gt;에 대해 알아본다.\n8.1.0 Storing Lists of Values with Vectors Vec\u0026lt;T\u0026gt;는 가변 길이의 리스트를 저장할 수 있는 컬렉션이다.\nVec\u0026lt;T\u0026gt;는 동일한 타입의 여러 값을 저장할 수 있고, 다음 자료를 메모리 옆칸에 연속적으로 저장하는 선형 자료구조이다. (배열)\n8.1.1 Creating a New Vector Vec\u0026lt;T\u0026gt;를 생성하는 방법은 두 가지가 있다.\nVec::new(): 빈 벡터를 생성한다. let v: Vec\u0026lt;i32\u0026gt; = Vec::new(); 와 같이 타입을 명시해야 한다.\nvec!: 매크로를 사용하여 초기값을 가진 벡터를 생성한다. let v = vec![1, 2, 3]; 이처럼 초기화까지 한번에 하면 타입을 명시하지 않아도 된다.\n8.1.2 Updating a Vector Vec\u0026lt;T\u0026gt;에 값을 추가하는 방법은 두 가지가 있다.\npush: push 메서드를 사용하여 값을 추가한다. let mut v = Vec::new(); v.push(5); 이처럼 사용한다.\nappend: append 메서드를 사용하여 다른 벡터를 추가한다. let mut v = vec![1, 2, 3]; v.append(\u0026amp;mut vec![4, 5, 6]); 이처럼 사용한다.\n8.1.3 Reading Elements of Vectors Vec\u0026lt;T\u0026gt;의 요소에 접근하는 방법은 두 가지가 있다.\n\u0026amp;v[i]: 인덱스를 사용하여 값을 참조한다. let v = vec![1, 2, 3]; let third: \u0026amp;i32 = \u0026amp;v[2]; 이처럼 사용한다.\nget: get 메서드를 사용하여 값을 참조한다. let v = vec![1, 2, 3]; let third: Option\u0026lt;\u0026amp;i32\u0026gt; = v.get(2); 이처럼 사용한다.\nlet v = vec![1, 2, 3, 4, 5]; let third: \u0026amp;i32 = \u0026amp;v[2]; println!(\u0026#34;The third element is {third}\u0026#34;); let third: Option\u0026lt;\u0026amp;i32\u0026gt; = v.get(2); match third { Some(third) =\u0026gt; println!(\u0026#34;The third element is {third}\u0026#34;), None =\u0026gt; println!(\u0026#34;There is no third element.\u0026#34;), } 당연하지만 포인트는 get 메서드는 Option\u0026lt;T\u0026gt;를 반환한다는 것이다. 인덱스가 범위를 벗어나면 None을 반환한다.\n\u0026amp;v[i]는 인덱스가 범위를 벗어나면 패닉을 일으킨다.\n두 가지 방법 중 어떤 것을 사용할지는 상황에 따라 다르다. 인덱스가 범위를 벗어나는 경우가 없다면 \u0026amp;v[i]를 사용해서 수상한 시도를 painc으로 몰아 낼 수 있다.\n반대로 인덱스가 범위를 벗어나는 경우가 있을 수 있다면 get 메서드를 사용하여 Option\u0026lt;T\u0026gt;를 반환하게 해서 일어날 법 한 상황에 유연하게 대처하면 된다.\n일단 올바른 인덱스를 건낸다면, borrow checker는 소유권과 borrow 규칙을 따르게 해서 이 참조와 벡터 내용에 대한 다른 참조가 유효하도록 한다.\n// error[E0502]: cannot borrow `v` as mutable because it is also borrowed as immutable let mut v = vec![1, 2, 3, 4, 5]; let first = \u0026amp;v[0]; v.push(6); println!(\u0026#34;The first element is: {}\u0026#34;, first); 언뜻 보기에는 컴파일 되어야 할 것 같지만, first가 v의 불변 참조를 가지고 있기 때문에 v를 변경할 수 없다.\n또 더 언뜻 보기에는 첫번째 참조와 마지막 원소의 참조와는 아무런 관계가 없어 보이지만, 벡터가 메모리에 저장되는 방식 때문에 이런 제약이 생긴다.\n벡터가 메모리에 저장되는 방식은 다음과 같다.\n벡터는 capacity와 length를 가진다.\ncapacity는 벡터가 메모리에 할당된 공간의 크기를 나타낸다.\nlength는 벡터에 실제로 저장된 요소의 개수를 나타낸다.\n벡터가 메모리에 저장되는 방식은 capacity가 늘어나면 새로운 메모리에 복사하고, length가 늘어나면 새로운 요소를 추가한다.\n여기서 새로은 메모리에 복사되면 첫 번째 참조가 있는 상태에서 새로운 메모리에 복사되면서 첫 번째 참조가 해제된 메모리를 가리키게 되기 때문에 용납하지 않는다.\n8.1.4 Iterating over the Values in a Vector 벡터의 각각의 모든 요소에 접근하려면, 한번에 하나의 인덱스 사용하는 대신, 모든 요소를 순회하면서 접근하는 방법이 있다.\ni32 값의 벡터에서 각 요소에 대한 불변 참조를 얻어 그 값을 출력하는 예제\nlet v = vec![100, 32, 57]; for i in \u0026amp;v { println!(\u0026#34;{}\u0026#34;, i); } i32 값의 벡터에서 각 요소에 대한 가변 참조를 얻어 그 값을 변경하는 예제 let mut v = vec![100, 32, 57]; for i in \u0026amp;mut v { *i += 50; } for 루프를 사용하여 벡터의 요소에 접근할 때, \u0026amp;를 사용하여 불변 참조를 얻거나, \u0026amp;mut를 사용하여 가변 참조를 얻을 수 있다.\n가변 참조가 참조하는 값을 변경하려면 * 연산자를 사용하여 참조를 역참조해야 한다.\nborrow checker 덕에 이러한 행동은 안전하다, (위에서와 동일한 논리로, 벡터에 대한 참조는 전체 벡터의 동시 수정을 방지한다)\n8.1.5 Using an Enum to Store Multiple Types 벡터는 동일한 타입의 값만 저장할 수 있다. 하지만, 열거형을 사용하면 다른 타입의 값들을 저장할 수 있다. enum SpreadsheetCell { Int(i32), Float(f64), Text(String), } let row = vec![ SpreadsheetCell::Int(3), SpreadsheetCell::Text(String::from(\u0026#34;blue\u0026#34;)), SpreadsheetCell::Float(10.12), ]; 참고로 이넘의 variant를 식별해야 몇칸씩 읽어야 하는지 알 수 있기 때문에, 이넘을 사용한다면 태그 또는 디스크리미네이터를 메모리의 해당 위치에 저장한다.\n8.1.4 Dropping a Vector Drops Its Elements 벡터가 스코프를 벗어나면, 벡터와 그 안의 요소들이 모두 해제된다. ㅂㅂ 8.2.0 Storing UTF-8 Encoded Text with Strings String은 가변 길이의 텍스트를 저장할 수 있는 컬렉션이다.\nRustcean들이 String을 사용할 때, 아래의 세가지 이유로 막힌다고 한다.\nString은 가능한 에러를 노출시키는 경향이 있다. String은 생각보다 복잡한 자료구조이다. UTF-8\u0026hellip; 결론적으로 이 장에서는 문자열을 컬렉션의 맥락으로 논의한다.\n왜냐하면 실제로 String은 바이트의 컬렉션이며, 텍스트로 해설될 때 유용한 기능을 제공하는 메서드가 추가되었다고 보면 적절하기 때문이다.\nCollection의 맥락에서 CRUD를 논의한다.\n8.2.1 What is a String? 러스트의 String을 먼저 정리해야 한다. 기본적으로는 표준 라이브러리에서 제공하는 가변적이고, 소유권이 있으며, 확장 가능한, UTF-8 인코딩된 문자열 타입니다. 물론 일반적으로 String이라고 하면 해당 String과 str을 모두 포함한다.\n8.2.2 Creating a New String Vec\u0026lt;T\u0026gt;에서 가능한 많은 연산들은 String에서도 가능하다. 그 이유는 String이 Vec\u0026lt;u8\u0026gt;을 래핑하여 추가적인 구현(몇가지 guarantees, restrictions, capabilities 등)되어 있기 때문이다.\n예를들어 생성도 벡터와 똑같이 new를 이용해서 할 수 있다.\nlet mut s = String::new(); 또한 Display 트레이트를 구현한 타입에 대해서 to_string 메서드를 사용할 수 있다.\nlet data = \u0026#34;initial contents\u0026#34;; let s = data.to_string(); let s = \u0026#34;initial contents\u0026#34;.to_string(); let s = String::from(\u0026#34;initial contents\u0026#34;); 8.2.3 Updating a String 기본적으로 벡터와 같이 값을 추가/변경 할 수 있다. 심지어는 + 연산자를 사용하거나, format! 매크로를 사용하여 문자열을 결합 수정 할 수 있다.\nlet mut s = String::from(\u0026#34;foo\u0026#34;); s.push_str(\u0026#34;bar\u0026#34;); s.push(\u0026#39;l\u0026#39;); s += \u0026#34;bar\u0026#34;; s = s + \u0026#34;bar\u0026#34;; s = format!(\u0026#34;{}-{}\u0026#34;, s, \u0026#34;bar\u0026#34;); fn add(self, s: \u0026amp;str) -\u0026gt; String { 참고로 + 연산자는 add 메서드를 호출한다.\n그리고 메서드 정의는 위와 같은데, 여기서 두가지를 알아 볼 수 있다.\nlet s1 = String::from(\u0026#34;Hello, \u0026#34;); let s2 = String::from(\u0026#34;world!\u0026#34;); let s3 = s1 + \u0026amp;s2; 이렇게 사용하면 s1은 더이상 사용할 수 없다. (self를 직접 사용하며 소유권을 가져가기 때문에) 두 번째로 \u0026amp;String은 \u0026amp;str로 강제 변환이 가능하다.\n8.2.4 Indexing into Strings String은 Vec\u0026lt;u8\u0026gt;을 래핑하고 있다고 하기도 했고, 많은 다른 언어에서 문자열을 인덱스로 접근하는게 일반적이라 당연하 가능할 것 같은 아래의 코드는\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let h = s1[0]; 컴파일 에러가 발생한다.\nerror[E0277]: the type `str` cannot be indexed by `{integer}` 간단히 이유를 요약하자면, 메모리에 나열되어있는 바이트들이 UTF-8로 인코딩 되어있기 때문에, 각각의 문자가 다른 바이트 수를 가지고 있는 상황에서 정수 인덱스로 접근하는 것은 불가능하기 때문이다.\n8.2.5 Slicing Strings \u0026ldquo;문자열\u0026quot;을 슬라이싱 하는 것 자체는 나쁜 아이디어 일 수 있지만 정 필요하면 range를 주는 방식으로 사용 할수는 있다.\nlet hello = \u0026#34;안녕하세요\u0026#34;; let s = \u0026amp;hello[0..3]; 하지만 이것도 마찬가지로 UTF-8로 인코딩 되어있기 때문에, 문자열의 일부를 슬라이싱 하는 것은 위험하다.\n8.2.6 Methods for Iterating Over Strings 진짜 결론적으로 실질적으로 문자를 다루고 싶다면 chars 메서드를 사용하면 된다.\nfor c in \u0026#34;안녕하세요\u0026#34;.chars() { println!(\u0026#34;{}\u0026#34;, c); } 8.3.0 Storing Keys with Associated Values in Hash Maps HashMap은 딱히 다른게 없다..\n8.3.1 Creating a New Hash Map \u0026amp; Accessing Values in a Hash Map use std::collections::HashMap; let mut scores = HashMap::new(); scores.insert(String::from(\u0026#34;Blue\u0026#34;), 10); scores.insert(String::from(\u0026#34;Yellow\u0026#34;), 50); let team_name = String::from(\u0026#34;Blue\u0026#34;); let score = scores.get(\u0026amp;team_name).copied().unwrap_or(0); HashMap은 Option\u0026lt;\u0026amp;T\u0026gt;를 반환하기 때문에 코드는 조금 더 예뻐질 수 있다. (copied로 Option\u0026lt;\u0026amp;T\u0026gt;를 Option\u0026lt;T\u0026gt;로 받고, unwrap_or로 기본값을 설정한다.)\n8.3.2 Hash Maps and Ownership let field_name = String::from(\u0026#34;Favorite color\u0026#34;); let field_value = String::from(\u0026#34;Blue\u0026#34;); let mut map = HashMap::new(); map.insert(field_name, field_value); Ownership 자체는 동일하게 동작한다. Copy 트레이트를 구현한 타입은 복사되어 저장되고, 그렇지 않은 타입은 소유권이 이전된다. (정확히는 insert method로 이동 후 drop)\n8.3.3 Updating a Hash Map let mut scores = HashMap::new(); scores.insert(String::from(\u0026#34;Blue\u0026#34;), 10); scores.insert(String::from(\u0026#34;Yellow\u0026#34;), 50); scores.entry(String::from(\u0026#34;Blue\u0026#34;)).or_insert(50); 8.3.4 Overwriting a Value let mut scores = HashMap::new(); scores.insert(String::from(\u0026#34;Blue\u0026#34;), 10); scores.insert(String::from(\u0026#34;Blue\u0026#34;), 25); 8.3.5 Only Inserting a Value If the Key Has No Value let mut scores = HashMap::new(); scores.insert(String::from(\u0026#34;Blue\u0026#34;), 10); scores.entry(String::from(\u0026#34;Yellow\u0026#34;)).or_insert(50); scores.entry(String::from(\u0026#34;Blue\u0026#34;)).or_insert(50); 8.3.6 Updating a Value Based on the Old Value let text = \u0026#34;hello world wonderful world\u0026#34;; let mut map = HashMap::new(); for word in text.split_whitespace() { let count = map.entry(word).or_insert(0); *count += 1; } ","permalink":"http://localhost:1313/_wiki/common-collections/","summary":"8.0.0 Common Collections 러스트의 std::collections 모듈은 여러 유용한 자료구조인 컬렉션을 제공한다.\nheap에 저장되는 컬렉션들은 컴파일 시점에 크기를 알 수 없고 늘어나거나 줄어들거나 한다.\n이번 장에서는 Vec\u0026lt;T\u0026gt;, String, HashMap\u0026lt;K, V\u0026gt;에 대해 알아본다.\n8.1.0 Storing Lists of Values with Vectors Vec\u0026lt;T\u0026gt;는 가변 길이의 리스트를 저장할 수 있는 컬렉션이다.\nVec\u0026lt;T\u0026gt;는 동일한 타입의 여러 값을 저장할 수 있고, 다음 자료를 메모리 옆칸에 연속적으로 저장하는 선형 자료구조이다. (배열)\n8.1.1 Creating a New Vector Vec\u0026lt;T\u0026gt;를 생성하는 방법은 두 가지가 있다.","title":"러스트의 컬렉션 모아보기"},{"content":"7.0 패키지, 크래이트, 모듈을 이용해 커지는 프로젝트를 관리하기 프로젝트가 커지면서 코드를 관리하는 것이 중요해진다, 기능을 단위로 모듈화하고 나눠야 관리하는것이 편리하다.\n이 챕터는 그러한 것들을 하는 방법을 다룬다.\n높은 레벨에서의 코드 재사용성을 위해 encaptulating, implementing등 달성하는 방법을 다룬다.\n실제 구현을 알지 못해도 사용할 수 있는 인터페이스로 추상화를 제공하는 방법을 다룬다.\nscope와 namespace를 이용해 코드를 구조화하는 방법을 다룬다.\n위에 내용들을 아우르는 러스트의 모듈화 시스템은 아래와 같다.\npackage : 크레이트를 빌드하고 공유하는 단위 crate : 라이브러리나 실행파일을 빌드하는 단위 module : 코드를 그룹화하고 namespace를 제공하는 단위 path : 모듈을 참조하는 방법 7.1 Package and Crates crate는 러스트의 컴파일러가 한번에 고려 할 수 있는 가장 최소의 코드 단위이다.\ncargo 가 아닌 rustc로 컴파일을 하는 경우에, 하나의 소스코드파일만 컴파일 하더라도, 컴파일러는 그 하나의 파일을 하나의 크레이트로 취급한다.\ncrate는 모듈을 포함 할 수 있는데, 해당 모듈은 crate로 컴파일된 다른 모듈에 정의 된 것을 사용할 수 있다.\ncrate는 두가지 형태로 나뉜다.\nbinary crate : 실행파일을 만드는 크레이트, cli 프로그램이나 서버 프로그램처럼, 또한 main함수를 꼭 ㅎ포함해야한다. library crate : 라이브러리를 만드는 크레이트, main함수를 포함하지 않으며, 실행 가능한 바이너리를 만들지 않는다. crate root는 컴파일러가 크레이트를 시작하는 파일을 가리킨다. 이 파일은 crate의 루트 모듈을 정의한다.\npackage는 하나 이상의 크레이트들을 포함하는(bundle) 단위이다.\npackage는 Cargo.toml파일을 가지며, 이 파일은 package의 메타데이터를 정의해서 package 내부의 해당 크레이트들을 어떻게 빌드 해야 하는지 알려준다.\npackage는 하나의 크레이트만 포함 할 수도 있고, 여러개의 크레이트를 포함 할 수도 있다.\n다수의 binary crate를 가질 수 있으나, 하나의 library crate만 가질 수 있다.\nsrc/main.rs와 src/lib.rs는 각각 binary crate와 library crate의 crate root이다.\n7.2 Defining Modules to Control Scope and Privacy 이 챕터에서는 모듈과 모듈 시스템에 대해 다룬다. 주요 키워드들은 다음과 같다\nmodule : 코드를 그룹화하고 namespace를 제공하는 단위 use : 모듈을 다른 스코프로 가져오는 키워드 as : 가져온 모듈을 다른 이름으로 사용하는 키워드 pub : 모듈을 공개하는 키워드 7.2.1 Modules Cheetsheet 러스트의 모듈 시스템이 따르는 규칙과 동작하는 방법은 아래와 같다.\nStart from the crate root : 크레이트를 컴파일 할 때, 컴파일러는 컴파일 할 코드를 찾기 위해 crate root를 찾는다. (src/main.rs와 src/lib.rs).\nDeclaring modules : crate root에서 새로운 모듈들을 선언 할 수 있따. 모듈은 mod 키워드와 선언한다. 예를들어 mod garden;과 같이 선언하면 컴파일러는 모듈의 코드를 아래와 같은 위치에서 찾는다\nDefining modules in other files : 모듈을 다른 파일에 정의 할 수 있다. 이때 파일의 이름은 모듈의 이름과 같아야 한다. 예를들어 mod garden;이라고 선언하면, garden.rs나 garden/mod.rs파일을 찾는다.\nInline : mod garden { ... } 와 같이 중괄호와 세미콜론으로 정의된 모듈이 있는지 인라인에서 찾는다. File : src/garden.rs나 src/garden/mod.rs파일을 찾는다. Declaring subomodules : 모듈 내부에 또 다른 모듈을 선언 할 수 있다(crate root에는 안된다). 이때도 mod 키워드를 사용한다. 이번에는 mod vegetables;를 mod garden;안에 선언하면 아래와 같은 순서로 찾는다.\nInline : mod vegetables { ... } 와 같이 중괄호와 세미콜론으로 정의된 모듈이 있는지 인라인에서 찾는다.\nFile : src/garden/vegetables.rs나 src/garden/vegetables/mod.rs파일을 찾는다.\nPaths to code in modules : 모듈이 크레이트에 일부가 된다면, 해당 모듈의 코드를 크레이트의 어디에서든 참조할 수 있다. 만약 pricacy 규칙에 어긋나지 않는다면 Asparagus모듈의 type을 호출하려면 crate::garden::vegetables::Asparagus와 같이 호출 할 수 있다.\nPrivate vs public : 모듈 내부의 코드는 기본적으로 private이다. pub 키워드를 사용해 모듈을 공개 할 수 있다. 모듈을 공개하면, 다른 크레이트에서 해당 모듈을 사용 할 수 있다.\nUse : use 키워드를 사용해 모듈을 가져올 수 있다. use 키워드는 모듈을 현재 스코프로 가져온다.\n// binary crate name backyard backyard ├── Cargo.lock ├── Cargo.toml └── src ├── garden │ └── vegetables.rs ├── garden.rs └── main.rs File : src/main.rs\nuse crate::garden::vegetables::Asparagus; pub mod garden; fn main() { let plant = Asparagus {}; println!(\u0026#34;I\u0026#39;m growing {:?}!\u0026#34;, plant); } File : src/garden.rs\npub mod vegetables; File : src/garden/vegetables.rs\npub struct Asparagus { pub name: String, } 7.2.2 Grouping Related Code in Modules 모듈은 크레이트 내부의 코드를 조직화햇해서 읽기 쉽고 재사용 가능한 코드를 만들 수 있게 해준다.\n또한 private과 public으로 코드의 접근성을 제어할 수 있다.\n기본적으로 private으로 캡슐화 하기 때문에, 다른 코드에서 해당 구현을 알거나 사용할 수 없다.\n실제로 사용하거나 의존해야 할 코드들만 public으로 만들면 된다.\n아래는 모듈을 사용해 레스토랑을 만드는 예제이다.\nFilename : src/lib.rs\nmod front_of_house { mod hosting { fn add_to_waitlist() {} fn seat_at_table() {} } mod serving { fn take_order() {} fn serve_order() {} fn take_payment() {} } } 이런식으로 모듈을 사용하고, 그룹화해두면 왜 관련되어 있는지를 알 수 있고, 그러한 코드들을 쉽게 찾을 수 있다.\n마찬가지로 이 모듈에 코드를 추가/수정 할 때도, 그러기 위한 가이드라인을 제공해 줄 수 있다.\nmodule tree\ncrate └── front_of_house ├── hosting │ ├── add_to_waitlist │ └── seat_at_table └── serving ├── take_order ├── serve_order └── take_payment 참고로 src/main.rs나 src/lib.rs는 crate root인 이유는, 이 두 파일중 하나가 크레이트의 모듈구조 루트인 모듈 crate를 선언하기 때문이다.\n그리고 그 아래에 마치 파일시스템처럼 모듈이 구조화 될 수 있다.\n7.3 Paths for Referring to an Item in the Module Tree 위에 살짝 언급한 것처럼 우리가 러스트에서 모듈의 아이템을 찾기 위해서는 파일시스템처럼 path를 기반으로 찾아나가게 된다.\npath는 두가지 형태가 있다.\nabsolute path : 크레이트의 루트에서 시작하는 경로, 루트는 crate나 mod 키워드로 선언된 모듈이다. relative path : 현재 모듈에서 시작하는 경로, self, super, 혹은 아이템의 이름으로 시작한다. 두 경로 모두, 하나 이상의 식별자와 :: 로 구분된다.\n아래는 crate의 루트 모듈에서 front_of_house모듈의 hosting모듈의 add_to_waitlist함수를 호출하는 예제이다.\nmod front_of_house { mod hosting { fn add_to_waitlist() {} } } pub fn eat_at_restaurant() { // Absolute path crate::front_of_house::hosting::add_to_waitlist(); // Relative path front_of_house::hosting::add_to_waitlist(); } 첫 번째 호출은 crate의 루트 모듈에서 시작하는 absolute path이다.\n두 번째 호출은 현재 모듈에서 시작하는 relative path이다.\n가능하면 상대경로 대신 절대경로를 지정하는 것이 낫다고 이야기한다. 당연히 일장일단은 있지만, 코드 수정이나 리팩토링을 할 때, 수정이 얼마나 적어질지가 가장 주요한 기준이라고 했을 때, 코드 정의와 호출을 서로 독립적으로 이동하려는 경우가 더 많이 때문이라고 이야기한다. 호출하는 부분이 정의된 부분에 대한 상대경로를 사용하면, 정의된 부분이 다른곳으로 옮겨졌을 때, 호출하는 부분의 변경이 생기는 상황이 더 자주 발생한다.\n무튼 위의 코드는 동작하지 않는다. 왜냐하면 add_to_waitlist함수는 private이기 때문이다.\n이를 해결하기 위해서는 pub키워드를 사용해야 한다.\nmod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } 7.4.1 Starting Relative Paths with super super 키워드를 사용해 상위 모듈로 이동할 수 있다.\nfile system에서 ..과 같은 역할을 한다.\n부모 모듈과 자식 모듈이 연관되어 있을 때, rearrange를 할 때 유용하다.\nFilename : src/lib.rs\nfn deliver_order() {} mod back_of_house { fn fix_incorrect_order() { cook_order(); super::deliver_order(); } fn cook_order() {} } 이러한 기능을 제공하는 이유는, 모듈의 구조를 변경할 때, 코드를 수정하지 않고도 모듈의 위치를 변경할 수 있게 해주기 때문이다. 7.3.2 Making Structs and Enums Public 구조체와 열거형에서도 pub키워드를 사용해 접근성을 제어 할 수 있지만, 추가적으로 알아야 할 것이 있다.\n구조체가 public이라고 해서 그 구조체의 필드가 public이 되는 것은 아니다.\n구조체의 필드를 public으로 만들려면, 구조체의 필드를 public으로 만들어야 한다.\nmod back_of_house { pub struct Breakfast { pub toast: String, seasonal_fruit: String, } impl Breakfast { pub fn summer(toast: \u0026amp;str) -\u0026gt; Breakfast { Breakfast { toast: String::from(toast), seasonal_fruit: String::from(\u0026#34;peaches\u0026#34;), } } } } pub fn eat_at_restaurant() { // Order a breakfast in the summer with Rye toast let mut meal = back_of_house::Breakfast::summer(\u0026#34;Rye\u0026#34;); // Change our mind about what bread we\u0026#39;d like meal.toast = String::from(\u0026#34;Wheat\u0026#34;); println!(\u0026#34;I\u0026#39;d like {} toast please\u0026#34;, meal.toast); // The next line won\u0026#39;t compile if we uncomment it; we\u0026#39;re not allowed // to see or modify the seasonal fruit that comes with the meal // meal.seasonal_fruit = String::from(\u0026#34;blueberries\u0026#34;); } 위의 코드는 private으로 선언된 seasonal_fruit필드가 있어 해당 필드를 접근하려고 하면 컴파일 에러가 발생한다.\n심지어 해당 struct의 인스턴스를 생성할 때도, 해당 필드를 초기화 할 수 없기 때문에, summer와 같은 생성자를 만들어서 사용해야 한다.\n패키지와 클래스의 의의가 상대적으로 불분명했던 자바와 달리, 러스트는 패키지와 크레이트의 경계가 명확하고, 어떠한 의미에서는 캡슐화에 대한 더 다양한 제어를 제공한다.\n반대로 enum은 그 자체로 public이면, 그 안에 있는 모든 variant들도 public이다.\nmod back_of_house { pub enum Appetizer { Soup, Salad, } } pub fn eat_at_restaurant() { let order1 = back_of_house::Appetizer::Soup; let order2 = back_of_house::Appetizer::Salad; } 7.4 Bringing Paths into Scope with the use Keyword use 키워드를 사용하면, 모듈의 아이템을 현재 스코프로 가져올 수 있다.\nuse 키워드는 ::를 사용해 접근해야 하는 아이템을 간단하게 사용할 수 있게 해준다.\nmod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } use crate::front_of_house::hosting; pub fn eat_at_restaurant() { hosting::add_to_waitlist(); } use 키워드를 사용하면, symbolic link를 만드는 것과 같다.\nuse 는 use를 선언한 스코프에서만 유효하다.\nmod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } pub fn eat_at_restaurant() { use crate::front_of_house::hosting; hosting::add_to_waitlist(); } fn seat_at_table() { hosting::add_to_waitlist(); // 컴파일 에러 } 7.4.2 Creating Idiomatic use Paths use 키워드를 사용해서 함수를 특정해서 가져오는것이 아니라 모듈을 가져오는 것이 의아 할 수 있다. mod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } use crate::front_of_house::hosting::add_to_waitlist; pub fn eat_at_restaurant() { add_to_waitlist(); } 물론 결과는 같다.\n이렇게 부모 모듈까지 불러오면, 실제로 사용 할 때는 hosting::add_to_waitlist와 같이 사용해야 하고, 이렇게 하면서 이 함수가 로컬에 정의되어 있지 않다는 것을 알리면서 최소한의 경로를 사용 할 수 있게 해준다.\n반대로 use 키워드를 사용해 함수를 가져오면 해당 함수가 어디에 정의되어있는지 헷갈릴 수 있다.\n반대로 struct나 enum을 가져올 때는, 전체 경로를 명시하는것이 관용적이다.\nuse std::collections::HashMap; fn main() { let mut map = HashMap::new(); map.insert(1, 2); } 딱히 이유는 없고, 그냥 관용적인 방법이다.\n또한 use 키워드를 사용해 여러개의 아이템을 가져올 때 같은 이름을 가진 아이템을 가져올 수 없다.\nuse std::fmt; use std::io; fn function1() -\u0026gt; fmt::Result { // --snip-- } fn function2() -\u0026gt; io::Result\u0026lt;()\u0026gt; { // --snip-- } 만약 아래와 같이 사용하면 컴파일 에러가 발생한다.\nuse std::fmt::Result; use std::io::Result; fn function1() -\u0026gt; Result { // --snip-- } fn function2() -\u0026gt; Result\u0026lt;()\u0026gt; { // --snip-- } 이런 경우에는 as 키워드를 사용해 다른 이름으로 가져올 수 있다. use std::fmt::Result; use std::io::Result as IoResult; fn function1() -\u0026gt; Result { // --snip-- } fn function2() -\u0026gt; IoResult\u0026lt;()\u0026gt; { // --snip-- } 7.4.3 Re-exporting Names with pub use 기본적으로 use 키워드로 가져온 아이템은 private이다.\n만약 가져온 아이템을 public으로 만들고 싶다면, pub use 키워드를 사용하면 된다.\nmod front_of_house { pub mod hosting { pub fn add_to_waitlist() {} } } pub use crate::front_of_house::hosting; pub fn eat_at_restaurant() { hosting::add_to_waitlist(); } 이렇게 하면 hosting모듈은 public이 되고, add_to_waitlist함수도 public이 된다.\nrestaurant::front_of_house::hosting::add_to_waitlist와 같이 사용해야 하는 것을.\nrestaurant::hosting::add_to_waitlist와 같이 사용할 수 있다.\n이러한 기능은, 코드의 내부 구조가 이 코드를 사용하려는 프로그래머에게 노출되지 않도록 할 수 있다. (노출되지 않으므로 변경되어도 영향을 받지 않고, 도메인에 대한 생각을 하지 않을 수 있다.)\n7.4.4 Using External Packages 외부 패키지를 사용할 때는, Cargo.toml에 의존성을 추가하고, use 키워드를 사용해 가져올 수 있다.\nuse 키워드를 사용해 가져올 때는, 패키지의 이름을 사용해야 한다.\n[dependencies] rand = \u0026#34;0.8.3\u0026#34; use rand::Rng; fn main() { let secret_number = rand::thread_rng().gen_range(1..101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); } 이렇게 하면 rand패키지의 Rng trait을 가져올 수 있다.\nRng trait의 스코프에 있는 thread_rng함수를 호출하고, gen_range함수를 호출 할 수 있다.\n7.5 Separating Modules into Different Files 파일시스템과 이름을 조금 생각해두면 딱히 어려운건 없기에 생략~ ","permalink":"http://localhost:1313/_wiki/managing-growing-projects-with-packages-crates-and-modules/","summary":"7.0 패키지, 크래이트, 모듈을 이용해 커지는 프로젝트를 관리하기 프로젝트가 커지면서 코드를 관리하는 것이 중요해진다, 기능을 단위로 모듈화하고 나눠야 관리하는것이 편리하다.\n이 챕터는 그러한 것들을 하는 방법을 다룬다.\n높은 레벨에서의 코드 재사용성을 위해 encaptulating, implementing등 달성하는 방법을 다룬다.\n실제 구현을 알지 못해도 사용할 수 있는 인터페이스로 추상화를 제공하는 방법을 다룬다.\nscope와 namespace를 이용해 코드를 구조화하는 방법을 다룬다.\n위에 내용들을 아우르는 러스트의 모듈화 시스템은 아래와 같다.\npackage : 크레이트를 빌드하고 공유하는 단위 crate : 라이브러리나 실행파일을 빌드하는 단위 module : 코드를 그룹화하고 namespace를 제공하는 단위 path : 모듈을 참조하는 방법 7.","title":"Package, Crates, Modules"},{"content":"0. 요즘 드는 생각과 걱정은 보통 AI와 관련된 것.. 물론 피상적으로 AI가 나를 대체하지 않을까? 와 같은 걱정을 하는 것은 아니다.\n그렇게 되지 않을 자신도 있다.\n다만 나의 시장 가치를 고민 할 때, 어떠한 방식으로 발전해야 AI가 만들어갈 앞으로의 환경에서 가치가 높은 사람이 될 수 있을지에 대한 고민이 많았다.\n사람들이 이야기 하는 부분은 주로 아래와 같이 두 부류로 나뉘는 것 같다.\n특정 지점 이하의 기술적인 지식은 AI가 대체할 수 있을 것이고, 사람은 문제를 만들어가고, AI라는 도구를 이용해 문제를 해결해야 한다 라는 관점 젠슨 황이 이야기하는 관점인 것 같다. 프로그래밍을 하지 않아도 사람들이 프로그램을 만들 수 있게 된다고 말하며, 결국 그것을 잘 이용하는 능력 + 도메인의 지식등 문제를 만들고 설계하는 능력이 중요하다고 이야기하는 것 같다. 실제로 본인이 대학시절로 돌아간다면 생명공학을 전공할 것이라고 이야기한다.(그 쪽이 해결해야 할 문제가 많다고 생각하기 때문이라고 한다.) 오히려 기본적인 지식을 (1번의 관점에서는 ai가 대체해줘야 할, 블랙박스가 되어야 할 지점)을 강조하는 입장. 물론 칩 설계 분야에 대한 이야기 였지만, ai가 발생시킬 생산성을 정확히 이해하고 이용하려면 본질적인 지식이 필요하다는 것을 강조하는 것 같다. 도메인에 대한 특정성이 있지만, 적어도 논리적인 부분에서는 1번의 관점과 정확히 배치되는 이야기이다. AI가 너무 꽃밭인 관계로 이러한 관점에서 이야기 하는 사람이 반가워서 아래의 인터뷰 내용을 정리하려고 한다. 1.짐 켈러의 인터뷰 이 인터뷰는 AI 뿐 아니라 요즘 내가 가장 많이 하고 있는 고민들과 많이 맞닿아 있었다.\n주로 시간을 어디에 써야 하는지에 대해서 내가 가장 많이 고민하는 부분은 아래와 같다.\n해결해야 할 문제를 해결하는데만 집중해서 흘러가는 방식. 더 많은 문제해결이 더 많은 성장을 야기한다는 관점이다. 조금 더 시간을 쓰더라도, 정확한 내용을 이해하고, 본질을 파악하는데 집중하는 방식. 이렇게 되면 문제해결에는 돌아가게 된다. 단적으로 예를 들면, 극단적인 이야기지만, 스프링 웹 백엔드 서버를 만들어야 한다고 할 때,\n1번의 관점에서는, 일단 가장 빠른 설정을 진행하고, 컨트롤러쪽에 로직을 작성하려고 할 것이다. 아마도 서비스 로직이 복잡해질 때, 영속성 데이터가 필요해질 때, 필요한 부분을 추가하게 될 것이며\n필요에 의해 도입한 새로운 기술이기에 빠르게 공부가 되고, 빠르게 적용이 될 수 있을 것이다.\n2번의 관점이라면, 먼저 톰캣이 어쩌고, 서블릿이 어쩌고, 스레드가 어쩌고, bean과 의존성 주입등이 어쩌고 저쩌고를 먼저 이해하려고 할 것이며, 코드 한 줄 짜지 않은 상태에서 이러한 부분을\n이해하려고 하는 것, 심지어는 해당 기술 등장 이전의 불편함을 인지하는등의 컨텍스트 없이 기술을 이해하려면 시간이 많이 걸리고 비효율적일 것이다,\n묘하게 내 글을 내가 읽어도 후자를 더 진중하고 우호적으로 생각하는 느낌이 들지만, 실제로는 매우 첨예할 정도로 엄대엄인 문제라고 생각한다.\n이러한 관점에서 짐 켈러의 이야기는 매우 흥미로웠다. (모두에게 첨예할 문제일 것이라 생각했고, 사회자도 그렇게 생각했기에 질문을 던졌을 것이지만, 짐켈러는 명확한 입장을 가지고 있었다)\n결론적으로 짐 켈러는 2번의 관점을 강조했다.\n사실 2번을 강조하기만 했다면 포스팅을 하지는 않았을 것이다. 하지만, 사회자의 질문에 응대하면서 나온 이야기들은 어떻게 균형을 찾아가야 하는지에 대한 매우 좋은 답변이었다.\n먼저 짐켈러는 레시피에 대한 이야기를 한다. 사람들은 레시피를 따라서 요리를 한다고 한다. 그러나, 요리를 이해하고 요리를 한다는 것은 다르다고 한다.\n레시피를 따라서 빵을 만드는 방법\n밀가루를 넣는다. 물을 넣는다. 이스트를 넣어 반죽과 섞는다. 부풀도록 놔둔다. 접시에 넣고 오븐에 넣는다. 빵 한덩이를 이해한다는 것\n발효의 생물학적 원리를 이해한다. 재료 유통 방식을 이해한다. 물리학, 열역학, 화학적 원리를 이해한다. 이런 관점으로 나누면 레시피에는 한계가 존재한다.\n레시피를 통해 빵을 만든 사람은 오믈렛을 만들 수 없다는 것이다.\n레시피를 이해하는 사람은 다른 요리도 만들 수 있다.\n더 자세히 나눠서 보면, 레시피는 수많은 블랙박스와 그로인한 가설로 이루어져 있다.\n이스트를 넣어 반죽과 섞을 때, 이스트가 물과 밀가루를 어떻게 변화시키는지를 알지 못하고 그 부분을 블랙박스로 둔다면, 뭔가 맛있게 만들어준다는 가설을 믿고 행동하는 것이다.\n여기까지는 명확한 입장 표명이고, 근거가 필요한데 사회자가 그런 부분을 잘 짚어주었다.\n2. 사회자의 질문 Q. \u0026lsquo;그럼 좋은 제품을 개발하려면 모든 지식을 100% 이해 해야 하나요?\u0026rsquo;\nA. 그 사이의 균형을 잘 유지해야죠. 예술가인 동시에 과학자가 되어야 합니다. 이미 정해진 레시피를 따르지 않고, 모든 것을 이해하려고만 한다면 아무것도 만들지 못할 겁니다.\nA. 그러나, 레시피를 따르기만 한다면, 언젠가는 잘못된 제품을 만들 겁니다.\nQ. 그렇다면 대체 얼마나 깊게 이해해야 하나요? 컴퓨터를 만드는 기술자라면 컴퓨터의 정확한 정의부터 시작해서 기술자로서 어떤 목적을 가져야 하는지, 어떤 태도를 갖고 컴퓨터를 만들어야 하는지, 복잡ㅂ한 컴퓨터 공학과 물리학 이론 등등.. 이런 것들을 전부 알아야 할까요?\nA. 아니요, 쉽게 생각해보죠, 만약 여러분에게 일을 맡긴 의뢰인이 컴퓨터 성능을 10% 높이고 싶다면, 메모리 용량을 늘리거나 부품을 추가하겠죠,\n아니면 컴퓨터 설정을 만져서 효율을 최대치로 끌어올릴 겁니다. 하지만 부품을 추가하고 설정을 바꿀 수록 구조도 복잡해지고 관리도 어렵죠,\n언젠가는 벽에 부딪힐 겁니다. 아무리 부품을 덕지덕지 붙여도 성능이 높아지지 않을 겁니다. 그럴 때 누군가는 \u0026lsquo;어쩔 수 없어요. 이게 한계입니다\u0026rsquo; 라고 말할 겁니다.\n하지만, 누군가는 \u0026lsquo;지금의 구조는 더이상 한계야 뭘 새롭게 추가한다고 바뀔건 없어 새로운 구조를 다시 짜보자.\u0026rsquo; 라고 말할 겁니다. 그렇게 기존 구조를 뜯어보고 난 후에\n사람들은 비로소 알게 됩니다. 아예 처음부터 새로운 구조를 만드는 것이 훨씬 빠르고 간단한 방법이에요.\n이 부분에 대해서는 좋은 가이드라인을 제시해 줬다고 생각한다. 처음부터 모든 것을 이해하려고 하지 않고, 처음부터 모든 것들을 이해하는 것을 상정하지 않았기 때문이다. 인용한 비유에서는, 레시피를 따르다 한계에 부딪히면, 구조를 뜯어보고 새로운 구조를 만들어내야 한다는 이야기를 한다. 즉 우리에게는 레시피를 통해 한계에 도달할 시간이 있고, 심지어 그 이후에도 구조를 뜯어볼 시간이 있다는 것이다. 다만 그 시간 이후에는 본질에대한 이해만이 다음 스텝으로 나아갈 수 있는 힘을 줄 것이다.\n3. 내가 느낀 점 다시 돌아와 1번의 관점에서 지향해야 할 것 은, 수많은 블랙박스와 기술부채를 남기더라도 앞으로 나아가는 것이다.\nAI도구들은 훨씬 더 많은 문제를 해결해주는 댓가로 정말 수많은 블랙박스와 가설 기술부채를 남길 것이다.\n더 많은 레시피를 통해 훨씬 빠르고 효율적으로 많은 문제를 해결해주는 도구라고 생각한다.\n내가 얻은 것은, 지향해야 할 것에 대한 관점이다.\n단순히 더 많은 요구와 더 많은 해결을 통해 나아가는 것만이 유리하다고 말하는 상황에서, 더 많은 이해와 본질을 통해 나아가는 것이 더 중요하다고 이야기 하는 사람을 만나게 되었다.\n애초에 이분법적이고 한쪽을 배제한 관점과 그에대한 이야기가 아니라, 지향점에 대해서 이해나 본질을 덮어두지 않아도 된다고 이야기 하는 사람을 만나서 반가웠다\n","permalink":"http://localhost:1313/_wiki/interview-from-jim-keller/","summary":"0. 요즘 드는 생각과 걱정은 보통 AI와 관련된 것.. 물론 피상적으로 AI가 나를 대체하지 않을까? 와 같은 걱정을 하는 것은 아니다.\n그렇게 되지 않을 자신도 있다.\n다만 나의 시장 가치를 고민 할 때, 어떠한 방식으로 발전해야 AI가 만들어갈 앞으로의 환경에서 가치가 높은 사람이 될 수 있을지에 대한 고민이 많았다.\n사람들이 이야기 하는 부분은 주로 아래와 같이 두 부류로 나뉘는 것 같다.\n특정 지점 이하의 기술적인 지식은 AI가 대체할 수 있을 것이고, 사람은 문제를 만들어가고, AI라는 도구를 이용해 문제를 해결해야 한다 라는 관점 젠슨 황이 이야기하는 관점인 것 같다.","title":"짐켈러의 인터뷰를 보고 든 생각"},{"content":"블로그를 만드는데 시간을 쏟고, 글을 쓰면서 들던 생각들 3월과 4월간 가장 많은 시간을 쏟은건 블로그와 neovim인 것 같다. 원하는 만큼의 공부 진도가 아니라 아쉬운 와중에, 블로그등에 뭔가 개인 시간을 지나치게 많이 썼나 싶어서 드는 생각을 써보려고 한다.\n블로그를 만들게 된 계기 시작은 당연히 이직과 관련된 이유였다. 생각보다 회사 일에 대한 개발 내용을 이력서에 정리하기는 쉽지 않았고, 포트폴리오를 내기에도, 금전적으로 엮인게 많아 올릴 수 없어 블로그를 만들게 되었다.\n적어도 내 취향에 보기 좋게 블로그를 만들고, 기계적으로 정리를 하다 보면 내가 무엇을 했는지, 어떤 공부를 했는지, 어떤 프로젝트를 했는지 정리가 되어 경력기술서의 역할을 대신할 수 있을 것이라 생각했다.\n블로그를 만들고 나서 느낀 점 사실 이 부분 때문에 해당 포스팅을 작성하고 있다. 좋은 인사이트를 얻고, 삶에 유의미한 변화가 있게 된 것 같다.\nAS-IS 원래도 private wiki를 vimwiki를 이용해서 작성하고 있지만, 사실상은 cmd + f 용도로만 사용하고 있었다. (내가 기계적으로 암기해야하는 것들을 대충 때려넣고 필요할때 검색하는 정도)\n내 생활에 무의미한 루틴이 많았었다. 예를들어 아침에 일어나서 비몽사몽 한 채로 처음 하는 일이 변기에 앉아 주로 방문하는 커뮤니티 사이트나, 유튜브 리스트를 보는 것이었다.\n물론 무의미하다는 것은 지나치게 비관적인 표현일 수 있는게, 생각보다 커뮤니티 사이트들이나 유튜브에서도 많은 것들을 배우거나 알게되고 심지어 좋은 인사이트를 얻은 적도 많다.\n문제는 그러한 생각과 알게된 것들, 인사이트들이 매우 휘발성이 높다는 것이다. 그리고 그것들을 나중에 다시 찾아보거나, 다시 생각해보기가 어렵다.\n그렇게 얻은 것들을 아이폰의 Reminder에 적어놓기는 하지만, 그것들이 장기적인 생각이나 지식으로 가는 경우는 극히 일부였다.\n그나마도 그러한 인사이트로 발전되는 경우는 일부였고, 금새 다른 소모적인 것들 (축구, 게임)과 같이 쉽고 생각을 안하게 되는 쪽으로 빠지는 경우가 많았다.\nTO-BE TO-BE로 옮겨 적기에 아래의 일들이 전부 실제로 일어난 것은 아니다.\n블로그를 작성하면서, 생각보다 비몽사몽 한 채로 변기에 앉아서 키는 사이트의 비중이 블로그로 많이 옮겨졌다.\n개인 위키쪽에 기록해둔 영상들도 보게 되는 것 같다. 내 생각으로 다시 정리를 한 글에서는 더 많은 인사이트를 얻거나 더 많은 것을 얻을 수 있도록 노력하는 시간이 조금 더 길어지는 것 같다.\n사실 이러한 일들은 극히 일부에서만 일어났는데, 러스트 기본 문법을 정리한 페이지들을 다시금 열어보면서 뭔가 들었던 생각을 되짚는 일이 많아진 것 같았고, 실제로 블로그의 수정도 많이 했다.\n그러던 과정 중에 진짜 인사이트를 얻었는데, 블로그를 작성하면서 기록을 이어가두면 좋은 인사이트들을 이어갈 수 있다는 생각이 들었다.\n원래는 공개된 공간에 글을 쓰는게 두려워서, 내가 정확히 알고 있는 것들에 대한 것들만 작성을 하려고 하고, 애매하게 아는 것들에 대한 검증을 하느라 글을 쓰는게 매우 demanding한 일이었는데,\n앞으로는 조금 더 그냥 내가 보겠다는 생각으로, 적어도 private쪽 공간에는 글을 편하게 쓰기로 했다.\n결론은 내 생각이나 인사이트를 연속성, 지속성 있게 가져가기 위한 도구로 활용해보려고 한다.\n그래서 누가 볼지 몰라서 utterance라도 달아야 하나 하는 생각을 하고 있다. 적어도 너무 잘못된 글은 댓글로 알려주면 수정하겠다는 마음으로.\n","permalink":"http://localhost:1313/_wiki/blog%EC%97%90-%EB%8C%80%ED%95%9C-%EC%83%9D%EA%B0%81/","summary":"블로그를 만드는데 시간을 쏟고, 글을 쓰면서 들던 생각들 3월과 4월간 가장 많은 시간을 쏟은건 블로그와 neovim인 것 같다. 원하는 만큼의 공부 진도가 아니라 아쉬운 와중에, 블로그등에 뭔가 개인 시간을 지나치게 많이 썼나 싶어서 드는 생각을 써보려고 한다.\n블로그를 만들게 된 계기 시작은 당연히 이직과 관련된 이유였다. 생각보다 회사 일에 대한 개발 내용을 이력서에 정리하기는 쉽지 않았고, 포트폴리오를 내기에도, 금전적으로 엮인게 많아 올릴 수 없어 블로그를 만들게 되었다.\n적어도 내 취향에 보기 좋게 블로그를 만들고, 기계적으로 정리를 하다 보면 내가 무엇을 했는지, 어떤 공부를 했는지, 어떤 프로젝트를 했는지 정리가 되어 경력기술서의 역할을 대신할 수 있을 것이라 생각했다.","title":"Blog에 대한 생각 정리 글"},{"content":"6 Enum and Pattern Matching In this chapter, we’ll look at enumerations, also referred to as enums. Enums allow you to define a type by enumerating its possible variants 가능한 상태의 목록을 열거하여 타입을 정의한다는 정의가 마음에 든다. 보통 상대적으로 새로운 언어들이 명시적이면서 경제적이면서 예쁜 문법을 제공하는데 러스트의 enum이 특히 그런 느낌이다.\n6.1 Defining an Enum 구조체가 데이터를 그룹화 하는 방법을 제공한다면, enum은 특정한 값이 가질수 있는 모든 가능한 값을 정의한다. 이런 류의 정의가 좋은 것 같다. 처음 Generic을 배울 때 처음에 복잡하고 읽기 어려운 문법과 사용 방법에 포커스를 하고 공부하니 이해가 안됐었는데, 똑같은 로직을 여러번 작성하지 않기 위해 사용하는 문법이라고 c++ primer plus 책에서 설명을 해줘서 해당 관점으로 이해하려 하니 이해가 잘 되었었던 기억이 난다.\n공식 가이드에서는 IP 주소를 다루는 예제를 들고 있다. IP주소라는 개념을 코드로 \u0026lsquo;표현\u0026rsquo;한다면\n4개의 8비트 숫자로 구성된 IPv4 주소를 다루는 경우 8개의 16비트 숫자로 구성된 IPv6 주소를 다루는 경우 이렇게 두가지 상태만 존재하고, 모든 IP의 버전은 두가지 중 하나에 속하게 된다.\nIP 주소이면서 저 두가지의 상태가 아닌 다른 상태에 속할 수 없고, 둘 다에 속할 수 없으며, 이런 경우에 enum을 이용해서 표현할 수 있다.\n버전 4와 버전 6 주소 모두 근본적으로는 IP 주소이므로, 코드가 어떤 종류의 IP 주소에도 적용되는 상황을 처리할 때 동일한 타입으로 취급되어야 한다.\n즉 모든, 고유한, 가능한 상태의 열거이므로 일정 정도의 추상화의 역할을 한다.\nenum IpAddrKind { V4, V6, } let four = IpAddrKind::V4; let six = IpAddrKind::V6; fn route(ip_kind: IpAddrKind) {} route(IpAddrKind::V4); route(IpAddrKind::V6); 문법은 enum 키워드로 시작하고, 각 상태는 중괄호로 묶인 목록으로 정의된다.\n각 상태는 그 자체로 유효한 값이다. 이 값은 enum의 이름을 통해 접근할 수 있다.\nenum의 이름과 상태의 이름은 같은 이름 공간에 있으므로, enum의 이름을 통해 상태를 참조할 수 있다.\nenum에 값을 저장할 수도 있다.\nenum IpAddr { V4(String), V6(String), } let home = IpAddr::V4(String::from(\u0026#34;127.0.0.1\u0026#34;)); let loopback = IpAddr::V6(String::from(\u0026#34;::1\u0026#34;)); 이렇게 하면 각 상태가 다른 타입의 데이터를 가질 수 있다. 단순히 열거형에 String을 매핑하는 정도가 아니라 아래와 같은 것들도 가능하다. enum IpAddr { V4(u8, u8, u8, u8), V6(String), } let home = IpAddr::V4(127, 0, 0, 1); let loopback = IpAddr::V6(String::from(\u0026#34;::1\u0026#34;)); 이렇게 하면 각 상태가 다른 타입의 데이터를 가질 수 있다. struct Ipv4Addr { // --snip-- } struct Ipv6Addr { // --snip-- } enum IpAddr { V4(Ipv4Addr), V6(Ipv6Addr), } 이렇게 하면 각 상태가 다른 구조체를 가질 수 있다. enum Message { Quit, Move { x: i32, y: i32 }, Write(String), ChangeColor(i32, i32, i32), } 다양한 것들을 매핑하되, 하나의 enumerate variants에 같은 타입이 아닌 것들을 매핑할 수 있다. struct QuitMessage; // unit struct struct MoveMessage { x: i32, y: i32, } struct WriteMessage(String); // tuple struct struct ChangeColorMessage(i32, i32, i32); // tuple struct impl Message { fn call(\u0026amp;self) { // method body would be defined here } } let m = Message::Write(String::from(\u0026#34;hello\u0026#34;)); m.call(); impl로 메소드를 정의할 수 있다. 6.1.1 The Option Enum and Its Advantages Over Null Values Option\u0026lt;T\u0026gt;는 표준 라이브러리에 정의된 enum이다.\nOption\u0026lt;T\u0026gt;는 Some(T)와 None 두가지 상태를 가진다.\nOption\u0026lt;T\u0026gt;는 null 값의 대안으로 사용할 수 있다.\nJava의 Optional과 비슷한 개념이다.\n값이 있는 경우, 그렇지 않은 경우(그 모든 variant) 가 있고, 그 모든케이스를 다뤄야하는데, Option을 사용하면 정확히 모든 케이스를 핸들링 했는지, 컴파일러가 체크해준다.\n우리는 언어를 배울때, 해당 언어가 어떠한 기능을 포함(include)하고 있는지에는 충분히 주목하면서, 어떠한 기능을 배제(exclude)하고 있는지에는 충분히 주목하지 않는다.\n기능의 배제 또한 언어의 특징이라는 점을 서적에서 강조하고 있다.\n결론적으로 Rust는 null을 제공하지 않는다. null이라는 기능을 제공하는 언어의 모든 값은 두가지 variant를 가진다. (null, not null)\nTony Hoare가 null을 발명했는데, 후에 이것이 \u0026lsquo;my billion dollar mistake\u0026rsquo;라고 말했다.\n공식 가이드 문서에서 해당 내용과 관련한 인터뷰 기사를 인용하고 있는데, 이게 대충 60년만의 사과라고 한다. 해당 기사의 배스트 댓글에는, \u0026ldquo;Bjarne Stroustrup의 사과까지는 14년이 더 남았네\u0026rdquo; 라는 댓글이 달려 있어 검색해봤는데, 1979년은 cpp의 탄생년 이었다.\n무튼 실제 구현은 아래와 같다. enum Option\u0026lt;T\u0026gt; { None, Some(T), } prelude에는 Option이 포함되어 있어서(그만큼 유용하고 자주 사용해야 하기에) 따로 include할 필요가 없고, Option을 사용할 때는 Option::을 사용하지 않아도 된다.\nSome\u0026lt;T\u0026gt; 는 제네릭으로 특정 타입을 가질 수 있다.\nlet some_number = Some(5); let some_string = Some(\u0026#34;a string\u0026#34;); let absent_number: Option\u0026lt;i32\u0026gt; = None; some_number의 타입은 Option\u0026lt;i32\u0026gt;이다.\nsome_string의 타입은 Option\u0026lt;\u0026amp;str\u0026gt;이다.\nabsent_number의 타입은 Option\u0026lt;i32\u0026gt;이다.\n무튼 결론적으로 Some value는 값이 있는 경우를 나타내고, None value는 값이 없는 경우를 나타낸다.\nNone variant는 사실상 null과 같은 의미를 지니는데, 굳이 이렇게 하는 이유는 뭘까? (왜 null보다 None을 사용하는가?)\n짧게 요약하면, Option\u0026lt;T\u0026gt;와 T는 다른 타입이기 때문에 컴파일러는 Option\u0026lt;T\u0026gt;를 사용 할 때, 무조건적으로 valid value라고 상정하지 않기 때문이다.\nlet x: i8 = 5; let y: Option\u0026lt;i8\u0026gt; = Some(5); let sum = x + y; 위 코드는 컴파일 되지 않는다. Option\u0026lt;i8\u0026gt;와 i8은 다른 타입이기 때문이다.\n당연하게도 i8과 i8이 아닌 무엇인가의 값을 더하는 방법을 알지 못한다.\n컴파일러가 이해 할 수 있는 코드를 작성하기 위해서는, Option\u0026lt;i8\u0026gt;를 그냥 사용하는것이 아닌 무엇인가의 처리를 해야한다.\n여기서 무엇인가의 처리란 바로 Option의 variants를 다뤄야 하는 것이고, 그러한 과정 이후에 null(None) 에 대한 대응을 진행하게된다.\n6.2 The match Control Flow Construct match는 다른 언어의 switch와 비슷한 역할을 한다.\nPattern은 literal value, variable, wild card, tuple, destructured structure, enum 등을 포함할 수 있다.\nmatch는 컴파일러로 하여금 모든 케이스를 다루는지 확인하게 한다.\n동전 자판기처럼 처음으로 일치하는 패턴을 만나면 해당 블록을 실행하고, 나머지는 무시한다.\nenum Coin { Penny, Nickel, Dime, Quarter, } fn value_in_cents(coin: Coin) -\u0026gt; u8 { match coin { Coin::Penny =\u0026gt; 1, Coin::Nickel =\u0026gt; 5, Coin::Dime =\u0026gt; 10, Coin::Quarter =\u0026gt; 25, } } if 문과 다른 점은 굳이 boolean을 사용하지 않아도 된다는 점이다.\nmatch의 arm이란 =\u0026gt;과 ,로 구분된 패턴과 실행 코드 블록이다. 패턴과 코드 블록으로 이루어져 있다.\n각각의 arm에 연관되어있는 코드 블록은 표현식이며, 이 표현식의 결과는 match 표현식의 결과가 된다.\n한 줄을 넘는 코드를 작성할 때는 {}를 사용해야 한다.\n6.2.1 Patterns That Bind to Values match의 또 다른 유용한 기능은 패턴에 매칭되는 값을 바인딩 할 수 있다는 것이고, enumd variants 의 값을 추출할 수 있다. #[derive(Debug)] enum UsState { Alabama, Alaska, // --snip-- } enum Coin { Penny, Nickel, Dime, Quarter(UsState), } Quarter variant는 UsState를 가지고 있다. fn value_in_cents(coin: Coin) -\u0026gt; u8 { match coin { Coin::Penny =\u0026gt; 1, Coin::Nickel =\u0026gt; 5, Coin::Dime =\u0026gt; 10, Coin::Quarter(state) =\u0026gt; { println!(\u0026#34;State quarter from {:?}!\u0026#34;, state); 25 }, } } Coin::Quarter(state)에서 state는 UsState 타입이 된다.\\\n이렇게 하면 UsState를 추출할 수 있다.\n6.2.2 Matching with Option Option\u0026lt;T\u0026gt;를 사용할 때도 match를 사용하는 예제. fn plus_one(x: Option\u0026lt;i32\u0026gt;) -\u0026gt; Option\u0026lt;i32\u0026gt; { match x { None =\u0026gt; None, Some(i) =\u0026gt; Some(i + 1), } } let five = Some(5); let six = plus_one(five); let none = plus_one(None); match rust의 유연한 enum과 함께 사용할 때 매우 강력한 도구가 된다.\nmatch 의 variable binding 기능 덕에 코드가 깔끔하게 떨어지는 경우가 많고, 실제로 코드를 작성하면서도 이점을 느낄 수 있다.\n6.3.3 Mathches Are Exhaustive match는 모든 경우를 다루지 않으면 컴파일 되지 않는다. fn plus_one(x: Option\u0026lt;i32\u0026gt;) -\u0026gt; Option\u0026lt;i32\u0026gt; { match x { Some(i) =\u0026gt; Some(i + 1), } } 위 코드는 컴파일 되지 않는다. None에 대한 처리가 없기 때문이다.\n이처럼 러스트의 match는 철저하기 때문에 일어날 수 있는 실수를 방지해준다.\nbillion dollor mistake는 애초에 러스트에서 가능하지 않다고 한 번 더 비꼰다 ㅋㅋ\n6.3.4 Catch-all Patterns and The _ Placeholder enum과 match를 사용할 때, 특정 값에 대해서만 특별한 처리를 하고, 나머지에 대해서는 아예 처리를 하지 않을 때가 있다. let dice_roll = 9; match dice_roll { 3 =\u0026gt; add_fancy_hat(), 7 =\u0026gt; remove_fancy_hat(), other =\u0026gt; move_player(other), } fn add_fancy_hat() {} fn remove_fancy_hat() {} fn move_player(num_spaces: u8) {} 이러한 경우 3,7이 아닌 모든 경우는 other에 매칭되어 처리된다.\n참고로 다른 언어의 switch에서와 같이 other을 위에 쓰면 그 아래 arm들은 비교조차 안하기 때문에 주의가 필요하다.\n비슷하게 catch-all 하면서도, 해당 값에 대해서는 아무것도 하지 않을 때는 _를 사용한다.\nlet dice_roll = 9; match dice_roll { 3 =\u0026gt; add_fancy_hat(), 7 =\u0026gt; remove_fancy_hat(), _ =\u0026gt; (), // or another actions for now do nothing } fn add_fancy_hat() {} fn remove_fancy_hat() {} 6.4 Concise Control Flow with if let if let을 사용하면, 하나의 값ㅂ에 대해서만 매칭을 하고, 나머지를 무시하는 경우에 match를 사용하는 것보다 간결하게 코드를 작성할 수 있다. let some_u8_value = Some(0u8); match some_u8_value { Some(3) =\u0026gt; println!(\u0026#34;three\u0026#34;), _ =\u0026gt; (), } if let Some(3) = some_u8_value { println!(\u0026#34;three\u0026#34;); } 두 코드 모두 정확히 같은 동작을 한다.\nif let은 보일러 플레이트도, verbose한 코드도, 굳이 필요없는 들여쓰기도 없애주지만, match의 exhaustive checking을 제공하지 않는다.\n결론적으로 syntax sugar이다.\nelse를 사용할 수도 있다.\nlet mut count = 0; if let Coin::Quarter(state) = coin { println!(\u0026#34;State quarter from {:?}!\u0026#34;, state); } else { count += 1; } 6.5 Summary 다양한 match 사용 예제\n// 1. 트래픽 라이트 시뮬레이터 enum TrafficLight { Red, Yellow, Green, } fn simulate_traffic_light(light: TrafficLight) { match light { TrafficLight::Red =\u0026gt; println!(\u0026#34;Stop\u0026#34;), TrafficLight::Yellow =\u0026gt; println!(\u0026#34;Caution\u0026#34;), TrafficLight::Green =\u0026gt; println!(\u0026#34;Go\u0026#34;), } } // 2. 파일 읽기 함수 use std::fs; fn read_file(file_path: \u0026amp;str) -\u0026gt; Result\u0026lt;String, String\u0026gt; { match fs::read_to_string(file_path) { Ok(contents) =\u0026gt; Ok(contents), Err(_) =\u0026gt; Err(String::from(\u0026#34;Failed to read the file.\u0026#34;)), } } // 3. 동물의 소리 출력 enum Animal { Dog, Cat, Bird, } fn make_sound(animal: Animal) { match animal { Animal::Dog =\u0026gt; println!(\u0026#34;Woof!\u0026#34;), Animal::Cat =\u0026gt; println!(\u0026#34;Meow!\u0026#34;), Animal::Bird =\u0026gt; println!(\u0026#34;Tweet!\u0026#34;), } } // 4. 모양의 면적 계산 enum Shape { Circle(f64), Triangle(f64, f64), Rectangle(f64, f64), } fn calculate_area(shape: Shape) -\u0026gt; f64 { match shape { Shape::Circle(radius) =\u0026gt; std::f64::consts::PI * radius * radius, Shape::Triangle(base, height) =\u0026gt; 0.5 * base * height, Shape::Rectangle(width, height) =\u0026gt; width * height, } } // 5. 주소 정보 출력 enum Address { City(String), State(String), Country(String), } struct Location { city: String, state: String, country: String, } fn print_city_address(address: Address) { match address { Address::City(city) =\u0026gt; println!(\u0026#34;City: {}\u0026#34;, city), _ =\u0026gt; (), } } // 6. 두 옵션 처리 enum OptionEnum\u0026lt;T\u0026gt; { Some(T), None, } fn process_option(option1: OptionEnum\u0026lt;i32\u0026gt;, option2: OptionEnum\u0026lt;i32\u0026gt;) { match (option1, option2) { (OptionEnum::Some(val1), OptionEnum::Some(val2)) =\u0026gt; println!(\u0026#34;Both options have values: {}, {}\u0026#34;, val1, val2), _ =\u0026gt; println!(\u0026#34;At least one option is None.\u0026#34;), } } // 7. 사칙연산 함수 fn calculate_operation(op: \u0026amp;str, num1: f64, num2: f64) -\u0026gt; Result\u0026lt;f64, String\u0026gt; { match op { \u0026#34;+\u0026#34; =\u0026gt; Ok(num1 + num2), \u0026#34;-\u0026#34; =\u0026gt; Ok(num1 - num2), \u0026#34;*\u0026#34; =\u0026gt; Ok(num1 * num2), \u0026#34;/\u0026#34; =\u0026gt; { if num2 == 0.0 { Err(String::from(\u0026#34;Division by zero is not allowed.\u0026#34;)) } else { Ok(num1 / num2) } }, _ =\u0026gt; Err(String::from(\u0026#34;Invalid operation.\u0026#34;)), } } // 8. 계절 출력 enum Season { Spring, Summer, Autumn, Winter, } fn print_season_message(season: Season) { match season { Season::Spring =\u0026gt; println!(\u0026#34;It\u0026#39;s spring!\u0026#34;), Season::Summer =\u0026gt; println!(\u0026#34;It\u0026#39;s summer!\u0026#34;), Season::Autumn =\u0026gt; println!(\u0026#34;It\u0026#39;s autumn!\u0026#34;), Season::Winter =\u0026gt; println!(\u0026#34;It\u0026#39;s winter!\u0026#34;), } } // 9. 로그인 함수 fn login(username: \u0026amp;str, password: \u0026amp;str) -\u0026gt; Result\u0026lt;(), String\u0026gt; { if password == \u0026#34;correctpassword\u0026#34; { Ok(()) } else { Err(String::from(\u0026#34;Incorrect password.\u0026#34;)) } } // 10. 주문 상태 출력 enum OrderStatus { Pending, Completed, } fn print_order_status(status: OrderStatus) { match status { OrderStatus::Pending =\u0026gt; println!(\u0026#34;Your order is pending.\u0026#34;), OrderStatus::Completed =\u0026gt; println!(\u0026#34;Your order is completed.\u0026#34;), } } ","permalink":"http://localhost:1313/_wiki/enums-and-pattern-matching/","summary":"6 Enum and Pattern Matching In this chapter, we’ll look at enumerations, also referred to as enums. Enums allow you to define a type by enumerating its possible variants 가능한 상태의 목록을 열거하여 타입을 정의한다는 정의가 마음에 든다. 보통 상대적으로 새로운 언어들이 명시적이면서 경제적이면서 예쁜 문법을 제공하는데 러스트의 enum이 특히 그런 느낌이다.\n6.1 Defining an Enum 구조체가 데이터를 그룹화 하는 방법을 제공한다면, enum은 특정한 값이 가질수 있는 모든 가능한 값을 정의한다.","title":"Enums and Pattern Matching in Rust"},{"content":"5.0 Defining and Instantiating Structs struct User { username: String, email: String, sign_in_count: u64, active: bool, } 기본적으로 튜플과 비슷하게 데이터를 묶어주는 역할을 한다. 튜플보다 더 많은 유연성을 제공한다. cpp의 구조체와 거의 동일하다. ts의 인터페이스와 유사하다. struct 키워드를 사용하여 정의한다. fn main() { let user1 = User { email: String::from(\u0026#34;some@example.com\u0026#34;), username: String::from(\u0026#34;someusername\u0026#34;), active: true, sign_in_count: 1, } .을 사용하여 필드에 접근할 수 있다. 만약 instance가 mutable하다면 필드의 값을 변경할 수 있다. 필드의 일부는 mutable이고 일부는 immutable일 수 없다. fn build_user(email: String, username: String) -\u0026gt; User { User { email: email, username: username, active: true, sign_in_count: 1, } } fn build_user2(email: String, username: String) -\u0026gt; User { User { email, username, active: true, sign_in_count: 1, } } 표현식 형태로 함수의 반환값으로 사용할 수 있다. 필드의 이름과 변수의 이름이 같다면 email: email을 email로 축약할 수 있다. 5.1.1 Creating Instances From Other Instances With Struct Update Syntax fn main() { // --snip-- let user2 = User { email: String::from(\u0026#34;another@example.com\u0026#34;), active: user1.active, sign_in_count: user1.sign_in_count, username: user1.username, }; let user3 = User { email: String::from(\u0026#34;another@example.com\u0026#34;), ..user1 }; } ..을 사용하여 다른 인스턴스를 복사할 수 있다. 디스럭쳐링과 비슷한 문법이지만, 구조체가 기본적으로 iterable trait를 구현하고 있지는 않는다고 한다. 어떻게 구현되어있는지 궁금하다. (알아보기) 소유권 이전은 동일한 논리로 일어나기 때문에, 만약 stack only data가 아닌 필드를 가지고 있다면, 업데이트 이후 기존 인스턴스를 사용할 수 없게 된다. 5.1.2 Using Tuple Structs without Named Fields to Create Different Types struct Color(i32, i32, i32); struct Point(i32, i32, i32); fn main() { let black = Color(0, 0, 0); let origin = Point(0, 0, 0); } 필드의 이름이 없는 튜플 구조체를 사용할 수 있다.\n필드의 이름을 붙이지 않는 구조체라고 생각하면 된다.\n한번 타입을 정의하면, 그 필드들이 같아도 다른 타입으로 인식한다.\nblack과 origin은 서로 다른 타입이기에, 함수 파라미터등으로 반대를 넣어주면 컴파일 에러가 발생한다.\n5.1.3 Unit-Like Structs Without Any Fields struct UnitLikeStruct; fn main() { let unit_like_struct = UnitLikeStruct; } 필드가 없는 구조체를 사용할 수 있다. 이런 구조체는 유닛 타입과 비슷하다. 데이터필드가 없는 trait를 구현할 때 유용하게 사용할 수 있다. 타입 파라미터나 테스트용 mock 객체를 만들 때 유용하게 사용할 수 있다. 5.2 An Example Program Using Structs 구조체를 사용하지 않고 작성한 코드를 구조체를 사용하여 리팩토링하는 간단한 예제.\nfn main() { let width1 = 30; let height1 = 50; println!( \u0026#34;The area of the rectangle is {} square pixels.\u0026#34;, area(width1, height1) ); } 파라미터가 두개이며, 해당 값들이 어떤 값인지에 대한 인지가 필요해서 별로라고 한다. 5.2.1 Refactoring with Tuples fn main() { let rect1 = (30, 50); println!( \u0026#34;The area of the rectangle is {} square pixels.\u0026#34;, area(rect1) ); } fn area(dimensions: (u32, u32)) -\u0026gt; u32 { dimensions.0 * dimensions.1 } 조금 더 낫긴 하지만, 의미적으로 dimensions.0과 dimensions.1이 width와 height라는 것을 알 수 없다. 5.2.2 Refactoring with Structs: Adding More Meaning fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!( \u0026#34;The area of the rectangle is {} square pixels.\u0026#34;, area(\u0026amp;rect1) ); } fn area(rectangle: \u0026amp;Rectangle) -\u0026gt; u32 { rectangle.width * rectangle.height } 구조체를 사용하여 가독성을 높일 수 있다. ownership을 넘기지 않고 참조를 넘기는 것이 좋다. 5.2.3 Adding Useful Functionality with Derived Traits struct Rectangle { width: u32, height: u32, } fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\u0026#34;rect1 is {}\u0026#34;, rect1); } println! 매크로는 Display trait를 구현한 타입만 사용할 수 있다, 관련된 컴파일 에러를 확인 할 수 있다. = help: the trait `std::fmt::Display` is not implemented for `Rectangle` = note: in format strings you may be able to use `{:?}` (or {:#?} for pretty-print) instead 친절한 컴파일러의 조언을 따라 {:?}를 사용해서 출력하는 예제. fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\u0026#34;rect1 is {:?}\u0026#34;, rect1); } 또 다른 에러가 발생한다. = note: `Rectangle` cannot be formatted using `{:?}` because it doesn\u0026#39;t implement `std::fmt::Debug` Debug trait를 구현해야 한다는 에러이다. #[derive(Debug)]를 사용하여 Debug trait를 구현할 수 있다. 이는 #[derive(Debug)]를 사용하여 컴파일러가 자동으로 구현하도록 할 수 있다. #[derive(Debug)] struct Rectangle { width: u32, height: u32, } 이제 {:?}를 사용하여 출력할 수 있다. {:?}는 Debug trait를 구현한 타입을 출력할 수 있다. fn main() { let rect1 = Rectangle { width: 30, height: 50 }; println!(\u0026#34;rect1 is {:?}\u0026#34;, rect1); } Debug format을 사용해서 출력하는 다른 방법은 dbg! 매크로를 사용하는 것이다. dbg! 매크로는 println! 매크로와 비슷하지만, dbg! 매크로는 값을 반환하고, ownership을 가져갔다 반환해준다 (println!은 참조만 가져간다.) #[derive(Debug)] struct Rectangle { width: u32, height: u32, } fn main() { let scale = 2; let rect1 = Rectangle { width: dbg!(30 * scale), height: 50, }; dbg!(\u0026amp;rect1); } $ cargo run Compiling rectangles v0.1.0 (file:///projects/rectangles) Finished dev [unoptimized + debuginfo] target(s) in 0.61s Running `target/debug/rectangles` [src/main.rs:10] 30 * scale = 60 [src/main.rs:14] \u0026amp;rect1 = Rectangle { width: 60, height: 50, } 5.3 Method Syntax 구조체에 메서드를 추가할 수 있다. 메서드는 함수와 비슷하지만, 구조체의 인스턴스에 대해 호출된다는 점이 다르다. 메서드는 self 파라미터를 가지고 있어야 한다. self 파라미터는 메서드를 호출한 인스턴스를 가리킨다. 5.3.1 Defining Methods #[derive(Debug)] struct Rectangle { width: u32, height: u32, } impl Rectangle { fn area(\u0026amp;self) -\u0026gt; u32 { self.width * self.height } } fn main() { let rect1 = Rectangle { width: 30, height: 50, }; println!( \u0026#34;The area of the rectangle is {} square pixels.\u0026#34;, rect1.area() ); } impl 블록을 사용하여 메서드를 정의할 수 있다.\nimpl 블록은 구조체의 이름과 메서드를 구현할 구조체의 이름을 가지고 있다.\nself 파라미터를 사용하여 메서드를 호출한 인스턴스를 가리킬 수 있다.\nself 파라미터는 self: \u0026amp;self의 약어이다.\nSelf 타입은 impl 블록이 적용되는 타입의 별칭이다. (alias)\nrectangle: \u0026amp;Rectangle 에서처럼, 이 메소드가 Self 인스턴스를 빌린다는 것을 나타내기 위해 self 약어 앞에 \u0026amp;를 사용해야 한다.\n메소드는 다른 매개변수처럼 self의 소유권을 가질 수도 있고, 여기처럼 self를 불변으로 빌릴 수도 있으며, 혹은 self를 가변으로 빌릴 수도 있다.\n반대로 \u0026amp;mut self로 선언하면, 해당 인스턴스를 가변으로 빌릴 수 있다.\n특정한 인스턴스를 변화시키고, 기존의 인스턴스를 사용할 수 없게 하고 싶다면, \u0026amp;mut self를 사용하면 된다.\nstruct Circle { radius: f64, } impl Circle { // Circle의 면적을 계산하는 메서드 fn area(\u0026amp;self) -\u0026gt; f64 { 3.14159 * self.radius * self.radius } // Circle의 반지름을 주어진 배율로 조정하는 메서드 fn scale(\u0026amp;mut self, factor: f64) { self.radius *= factor; } } fn main() { let mut circle = Circle { radius: 5.0 }; println!(\u0026#34;원래 면적: {}\u0026#34;, circle.area()); // circle의 반지름을 2배로 조정 circle.scale(2.0); println!(\u0026#34;조정된 면적: {}\u0026#34;, circle.area()); } impl Circle { // Circle을 Square로 변환하는 메서드 fn into_square(self) -\u0026gt; Square { Square { side: self.radius * 2.0 } } } struct Square { side: f64, } fn main() { let circle = Circle { radius: 5.0 }; let square = circle.into_square(); // 여기서 circle의 소유권이 이동됨 // println!(\u0026#34;원의 반지름: {}\u0026#34;, circle.radius); // 오류: `circle`은 더 이상 유효하지 않음 println!(\u0026#34;정사각형의 변 길이: {}\u0026#34;, square.side); } fn main() { let circle = Circle { radius: 5.0 }; // circle.scale(2.0); // 오류: `circle`은 불변 참조이며, `scale`은 가변 참조를 요구함 } 함수 대신 메서드를 사용하는 이유는 단지 구조체에서 타입을 매번 쓰지 않기 위해서가 아니라, 해당 타입에 대한 method를 조직화 하기 때문이다. (organization)\n메서드를 사용하면, 해당 타입에 대한 모든 기능을 한 곳에 모아둘 수 있다.\n필드의 이름과 메서드의 이름이 같게 할 수 있다.\ngetter와 같은것들도 구현하는데, 이건 나중에..\n5.3.2 Where\u0026rsquo;s the -\u0026gt; Operator? (c/cpp 에서) -\u0026gt; 연산자는 포인터의 메서드를 호출할 때 사용한다. 객체에서 직접 호출하는 경우는 . 역참조를 해서 호출할 필요가 있기 때문인데, object 가 포인터라면, object-\u0026gt;method()는 (*object).method()와 비슷하다. 러스트에서는 이러한 과정이 자동화 되어있다 (automatic referencing and dereferencing). object.method() 와 같이 메서드를 호출하면, 러스트는 자동으로 \u0026amp;, \u0026amp;mut, *를 추가하여 호출한다. // same p1.distance(\u0026amp;p2); (\u0026amp;p1).distance(\u0026amp;p2); 짐작할수 있듯이 self라는 명확한 수신자를 사용하기 때문에 가능하다\n리시버가 \u0026amp;self, \u0026amp;mut self, self로 정의되어 있기 때문에, 읽기 수정 소비에 대한 부분을 명확하게 파악 할 수 있다.\n예를 들어, 어떤 객체 obj가 있고 이 객체에 대한 메서드 method()가 정의되어 있을 때,\nRust는 obj.method() 호출을 적절하게 처리한다.\n이 메서드가 \u0026amp;self를 요구한다면, Rust는 자동으로 \u0026amp;obj.method()를 호출한다.\n만약 메서드가 \u0026amp;mut self를 요구한다면, Rust는 \u0026amp;mut obj.method()로 처리한다.\n객체가 값으로 메서드를 호출해야 한다면, Rust는 필요에 따라 (*obj).method()처럼 역참조를 자동으로 처리한다.\n5.3.3 Methods with More Parameters 메서드는 추가적인 파라미터를 가질 수 있다. fn main() { let rect1 = Rectangle { width: 30, height: 50, }; let rect2 = Rectangle { width: 10, height: 40, }; let rect3 = Rectangle { width: 60, height: 45, }; println!(\u0026#34;Can rect1 hold rect2? {}\u0026#34;, rect1.can_hold(\u0026amp;rect2)); println!(\u0026#34;Can rect1 hold rect3? {}\u0026#34;, rect1.can_hold(\u0026amp;rect3)); } impl Rectangle { fn can_hold(\u0026amp;self, other: \u0026amp;Rectangle) -\u0026gt; bool { self.width \u0026gt; other.width \u0026amp;\u0026amp; self.height \u0026gt; other.height } } self reciever 이후는 그냥 일반적인 함수와 동일하다. 5.3.4 Associated Functions self 파라미터를 가지지 않는 함수를 impl 블록 내에 정의할 수 있다.\nself 파라미터가 없기 때문에, 메서드는 아니고 associated function이라고 한다.\nassociated function은 주로 구조체의 인스턴스를 생성하는데 사용된다.\nimpl Rectangle { fn square(size: u32) -\u0026gt; Self { Self { width: size, height: size, } } } 마지막으로 impl블록을 여러개 둘 수 있는데, 큰 의미는 없는 것 같다 ","permalink":"http://localhost:1313/_wiki/using-structs-to-structure-related-data/","summary":"5.0 Defining and Instantiating Structs struct User { username: String, email: String, sign_in_count: u64, active: bool, } 기본적으로 튜플과 비슷하게 데이터를 묶어주는 역할을 한다. 튜플보다 더 많은 유연성을 제공한다. cpp의 구조체와 거의 동일하다. ts의 인터페이스와 유사하다. struct 키워드를 사용하여 정의한다. fn main() { let user1 = User { email: String::from(\u0026#34;some@example.com\u0026#34;), username: String::from(\u0026#34;someusername\u0026#34;), active: true, sign_in_count: 1, } .을 사용하여 필드에 접근할 수 있다. 만약 instance가 mutable하다면 필드의 값을 변경할 수 있다.","title":"Using Structs to Structure Related Data"},{"content":"4.0 Ownership 소유권은 러스트의 가장 특징적인 개념이다, 러스트를 이해하기 위해서, 또는 러스트가 왜 다른 언어들보다 주목받는지 이해하기 위해서 가장 중요한 장이라고 생각한다.\n4.1.1 What is Ownership? Ownership은 러스트가 메모리를 관리하는 규칙이다.\n모든 프로그래밍 언어는 메모리를 관리하는 방법이 있다.\n가장 대표적인 두 갈래는 GC(Garbage Collection)와 수동 메모리 관리로 볼 수있다.\nGC는 프로그램이 실행되는동안, 더 이상 사용하지 않는 메모리를 찾아내고 해체하는 방법이다.\n수동 메모리 관리는 프로그래머가 메모리를 직접 관리하는 방법이다.\n당연히 GC가 편리하고 안전하지만, 성능이 떨어진다는 단점이 있다.\n러스트는 세번째 방법인 Ownership을 사용한다.\n개인적으로 Ownership에서 가장 중요한 포인트는 \u0026lsquo;규칙\u0026rsquo;이라고 생각한다.\n소유권이 적용되는 규칙을 요약하면 다음과 같다.\n각각의 값은 소유자(owner)가 있다.\n한번에 하나의 소유자만 존재할 수 있다.\n소유자가 스코프를 벗어나면, 값은 해제된다.\n사실 완전히 새로운 방식은 아니다. C++의 RAII(Resource Acquisition Is Initialization)와 비슷한 개념이다.\nRAII는 객체가 생성될 때, 자원을 할당하고, 소멸될 때 자원을 해제하는 방식이다.\n객체의 생성과 소멸을 자원의 할당과 해제로 연결짓는다. 참조가 없으면(스코프를 나가면) 자동으로 해제된다는 점에서는 GC와 비슷하다.\nGC를 아주 무식하게 요약하면 참조가 없어진 매모리를 체크하고 회수한다고 할 수 있다. Rust는\u0026rsquo;규칙\u0026rsquo;에 기반한 소유권을 사용하여 메모리를 관리한다, 반대로 생각하면, 메모리를 낭비하거나 위험에 빠뜨리지 않는 \u0026lsquo;규칙을\u0026rsquo; 구현한 것에 더 큰 의의가 있다.\n그에 대한 댓가로 Rust는 컴파일타임에 메모리 안정성을 검증 할 수 있고, GC와 같이 런타임에 추가적인 비용이 발생하지 않는다.\n결론적으로 프로그래머는 Rust의 Ownership이라는 규칙을 따르며 프로그래밍을 하는 것은 어렵지만, 그 댓가로 안전하면서도 빠른 프로그램을 만들 수 있다.\n4.1.2 Stack and Heap Stack과 Heap은 우리의 코드가 런타임에 사용 할 수 있는 메모리이다. 스택은 자료구조 스택의 개념을 따른다. LIFO는 굳이 설명 안해도 괜찮지만, 특정한 메모리 공간에 일렬로 늘어서 있는 선형 자료구조임은 인지해야 한다. 왜냐면 힙은 스택과 다르게 메모리의 어느 곳에든 할당하고, 첫칸의 포인터를 반환받기 때문인다. 보통 스택은 빠르고, 힙은 느리다고 알려져 있다. 그 이유는 스택은 LIFO로 데이터를 저장하고, 힙은 데이터를 저장하고 찾기 위해 추가적인 작업이 필요하기 때문이다. 실제로는 주로 혼용해서 사용하는데, 스택에 힙의 포인터를 저장하고, 실제 참조가 필요할 때 힙을 참조하는 방식으로 사용한다.\n이 레퍼런스가 의미있는 이유를 잘 생각해 봐야 한다.\nRust는 Stack과 Heap을 사용하여 메모리를 관리한다.\n예를들어 함수가 호출 될 때 마다, 함수의 지역변수와 매개변수가 스택에 저장된다(힙 데이터 포함). 그리고 사용이 끝나면 스택에서 제거된다.\n결론적으로 우리가 관리해야하는 데이터는 사실상 힙에 할당된 데이터이다.\nStack은 스코프 또는 사용 시점에 따라 자동으로 관리되지만, 힙은 프로그래머가 직접 관리해야 한다.\n책에서는 Stack과 Heap을 생각하면서 프로그래밍 해야 할 필요는 없지만, Ownership 시스템이 뭘 어떻게 하는지, 그리고 왜 그렇게 하는지 이해하는데 도움이 된다고 한다.\n4.1.3 Ownership Rules 다시 Ownership의 규칙을 살펴보면, 다음과 같다.\n각각의 값은 소유자(owner)가 있다. 한번에 하나의 소유자만 존재할 수 있다. 소유자가 스코프를 벗어나면, 값은 해제된다. 이부분을 이해하기 위해서는 러스트의 변수 바인딩방식, 스코프를 이해해야 한다.\n4.1.4 Variable Scope ** 문자열 리터럴 에서**\nfn main() { // s is not valid here, it\u0026#39;s not yet declared let s = \u0026#34;hello\u0026#34;; // s is valid from this point forward } // this scope is now over, and s is no longer valid 위의 코드에 가장 중요한 포인트 변수 s는 선언된 블록 내에서만 유효하다. 블록이 끝나면 변수 s는 소멸된다. 아직까지 다른 언어와 크게 다르지 않다. 4.1.5 The String Type String 타입에서\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); // do stuff with s } // this scope is now over, and s is no longer valid String 타입도 별반 다르지 않은 것 같은데..? 4.1.6 Memory and Allocation 문자 리터럴의 경우, 컴파일 타임에 컨텐츠를 알 수 있기 때문에, 해당 컨텐츠가 하드코딩되어 바이너리에 포함된다. 그래서 빠르고 효율적이지만, 변경이 불가능하다.\n반면 String 타입은 컴파일 타임에 크기를 알 수 없고, 런타임에 크기가 결정되어 할당될 공간을 찾아 힙에 저장되어야 한다.\n이 시점에 가장 중요한 포인트는 다음과 같다.\n런타임에 메모리 할당을 요청해서 할당해야한다.\n그로인해 이 메모리를 해제하고 반환해하는 방법이 필요하다.\n첫 번째는 String::from 함수를 통해 이루어졌다 (쉽다 쉬워).\n그런데 두 번째는 프로그래머들의 아주 오래된 고민중에 하나이다. (GC가 없는 언어에서는)\n메모리를 할당하고 해제하는 것은 프로그래머의 몫이다. 근데 그게 잘 되겠냐고, 사람은 실수를 하기 마련인데\u0026hellip; 일단 해제를 안하면 메모리 누수가 발생해서 프로그램이 느려지고, 더 심하면 프로그램이 죽을 수 있다. 해제를 두번하면, 프로그램이 죽을 수 있다. 해제를 너무 일찍하면, 프로그램이 죽을 수 있다. 결론적으로 메모리 관리는 어렵다. Rust는 Ownership 규칙을 통해 이 문제를 해결한다.\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); // do stuff with s } // this scope is now over, and s is no longer valid 위의 코드에서 s는 스코프를 벗어나면 해제된다. (쉽고 편리하고 안전해보이지!, 안전한건 맞는데 쉽고 편할까?)\n무튼 이것이 Ownership의 규칙이다.\n참고로 실제 구현은 drop이라는 함수를 통해 이루어진다.\n스코프의 기준이 되는 닫힌 중괄호가 실행되면, 내부적으로는 drop 함수가 호출되어 메모리가 해제된다.\n4.1.7 Ways Variables and Data Interact : Move let x = 5; let y = x; 여기서는 x의 값을 복사해서 y에 넣고 실제로 x와 y인 5는 스택에 각각 푸시된다. let s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; 여기는 다르다! String의 데이터는 세 부분으로 나뉘어져 있다 (포인터, 길이, 용량)\n포인터는 힙에 저장된 데이터를 가리키는 주소 길이는 데이터의 길이 용량은 할당된 메모리의 크기 일단 이 데이터 (참조와 뭐 대충 메타데이터)는 스택에 저장된다.\n출처 : The Rust Programming Language\n그리고 s1을 s2에 할당하면 어떻게 될까?\n결론은 s1의 데이터중 스택에 저장된 데이터는 s2로 복사되고, 힙에 저장된 데이터는 복사되지 않는다.\n그런데 문제는 여기서 발생한다. s1과 s2가 모두 힙의 데이터를 가리키고 있으면, 두 변수가 스코프를 벗어나면 두 변수가 동시에 메모리를 해제하려고 할 것이다.\n메모리를 두번 해제해\u0026hellip;? \u0026ldquo;죽을게\u0026rdquo;\n가 아니고 Rust는 이런 상황을 방지하기 위해 장치를 마련해뒀다.\n내용을 먼저 보면\nlet s2 = s1 코드 이후의 시점에, s1을 더이상 유효하지 않다고 간주한다.\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1; println!(\u0026#34;{}, world!\u0026#34;, s1); $ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0382]: borrow of moved value: `s1` --\u0026gt; src/main.rs:5:28 | 2 | let s1 = String::from(\u0026#34;hello\u0026#34;); | -- move occurs because `s1` has type `String`, which does not implement the `Copy` trait 3 | let s2 = s1; | -- value moved here 4 | 5 | println!(\u0026#34;{}, world!\u0026#34;, s1); | ^^ value borrowed here after move | = note: this error originates in the macro `$crate::format_args_nl` which comes from the expansion of the macro `println` (in Nightly builds, run with -Z macro-backtrace for more info) help: consider cloning the value if the performance cost is acceptable | 3 | let s2 = s1.clone(); | ++++++++ For more information about this error, try `rustc --explain E0382`. error: could not compile `ownership` due to previous error 실제로 이런 에러가 발생한다.\n얕은 복사 나도 알아 라고 입이 근질근질하셨던분들은 고려해야 할 게 하나 더 늘은 샘이다.\nRust는 얕은 복사를 하지 않고, move라는 개념을 사용한다.\n출처 : The Rust Programming Language\n결론적으로 스코프를 나갈때마다 메모리를 해제하면 되는데 왜 그렇게 안했지? 와 같은 생각에는 다음과 같은 이유가 있었고(중복 해제) 러스트는 이러한 부분들에 대한 규칙을 지정하며 해결하고 있는 것이다.\n참고로 깊은 복사를 하고 싶다면 clone 함수를 사용하면 된다.\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;{}, world!\u0026#34;, s1); 이렇게 하면 s1과 s2는 서로 다른 데이터를 가리키게 된다. 4.1.8 Copy Trait 앞에서 분류한 Stack only 타입들은 굳이 move를 하지 않아도 된다.\n이런 타입들은 Copy 트레이트를 구현하고 있다.\nCopy 트레이트는 다음과 같은 특징을 가진다.\n스택에 저장되는 타입들은 Copy 트레이트를 구현하고 있다.\nCopy 트레이트를 구현하고 있는 타입들은 move 대신 복사가 이루어진다.\nCopy 트레이트를 구현하고 있는 타입들은 스코프를 벗어나도 메모리가 해제되지 않는다.\nCopy 트레이트를 구현하고 있는 타입들은 다음과 같다.\n- i32 - bool - f64 - char - Tuple (단, 모든 요소가 Copy 트레이트를 구현하고 있어야 한다.) 이외에는 drop trait를 구현하고 있어 Copy 트레이트를 구현할 수 없다.\n4.1.9 Ownership and Functions 함수의 인자로 값을 넘기는 것은 변수를 할당하는 것과 의미론적으로 비슷하다.\n함수의 인자로 값을 넘기면, 해당 값은 함수의 스코프로 이동한다.\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); // s comes into scope takes_ownership(s); // s\u0026#39;s value moves into the function... // ... and so is no longer valid here let x = 5; // x comes into scope makes_copy(x); // x would move into the function, // but i32 is Copy, so it\u0026#39;s okay to still // use x afterward } // Here, x goes out of scope, then s. But because s\u0026#39;s value was moved, nothing // special happens. fn takes_ownership(some_string: String) { // some_string comes into scope println!(\u0026#34;{}\u0026#34;, some_string); } // Here, some_string goes out of scope and `drop` is called. The backing // memory is freed. fn makes_copy(some_integer: i32) { // some_integer comes into scope println!(\u0026#34;{}\u0026#34;, some_integer); } // Here, some_integer goes out of scope. Nothing special happens. 함수의 반환값 역시 마찬가지로 move가 이루어진다. fn main() { let s1 = gives_ownership(); // gives_ownership moves its return // value into s1 let s2 = String::from(\u0026#34;hello\u0026#34;); // s2 comes into scope let s3 = takes_and_gives_back(s2); // s2 is moved into // takes_and_gives_back, which also // moves its return value into s3 } // Here, s3 goes out of scope and is dropped. s2 was moved, so nothing // happens. s1 goes out of scope and is dropped. fn gives_ownership() -\u0026gt; String { // gives_ownership will move its // return value into the function // that calls it let some_string = String::from(\u0026#34;yours\u0026#34;); // some_string comes into scope some_string // some_string is returned and // moves out to the calling // function } // This function takes a String and returns one fn takes_and_gives_back(a_string: String) -\u0026gt; String { // a_string comes into // scope a_string // a_string is returned and moves out to the calling function } 납득이 안가는 예제는 없는 것 같다.\n다만 모든 함수가 소유권을 가져갔다가 반환하는것은 지루하기 때문에 러스트는 참조를 사용한다.\n4.2 References and Borrowing fn main() { let s1 = String::from(\u0026#34;hello\u0026#34;); let len = calculate_length(\u0026amp;s1); println!(\u0026#34;The length of \u0026#39;{}\u0026#39; is {}.\u0026#34;, s1, len); } fn calculate_length(s: \u0026amp;String) -\u0026gt; usize { // s is a reference to a String s.len() } 러스트에서 참조는 변수를 빌려오는 것이다. 참고로 reference의 반대는 dereference이며 * 연산자를 사용한다.\n참조를 사용하면 소유권을 넘기지 않으므로, drop 함수가 호출되지 않는다.\n참조는 기본적으로 immutable하다.\nfn main() { let s = String::from(\u0026#34;hello\u0026#34;); change(\u0026amp;s); } fn change(some_string: \u0026amp;String) { some_string.push_str(\u0026#34;, world\u0026#34;); } 위의 코드는 에러가 발생한다. $ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0596]: cannot borrow `*some_string` as mutable, as it is behind a `\u0026amp;` reference --\u0026gt; src/main.rs:8:5 | 7 | fn change(some_string: \u0026amp;String) { | ------- help: consider changing this to be a mutable reference: `\u0026amp;mut String` 8 | some_string.push_str(\u0026#34;, world\u0026#34;); | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `some_string` is a `\u0026amp;` reference, so the data it refers to cannot be borrowed as mutable For more information about this error, try `rustc --explain E0596`. error: could not compile `ownership` due to previous error 참조를 mutable로 사용하려면 \u0026amp;mut을 사용해야 한다. fn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); change(\u0026amp;mut s); } fn change(some_string: \u0026amp;mut String) { some_string.push_str(\u0026#34;, world\u0026#34;); } 참조를 사용하면 소유권을 넘기지 않으므로, 여러 참조를 사용할 수 있다. fn main() { let mut s = String:: from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;mut s; let r2 = \u0026amp;mut s; println!(\u0026#34;{}, {}\u0026#34;, r1, r2); } $ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0499]: cannot borrow `s` as mutable more than once at a time --\u0026gt; src/main.rs:5:17 | 4 | let r1 = \u0026amp;mut s; 5 | let r2 = \u0026amp;mut s; | ^^^^ mutable borrow starts here in previous iteration of loop 6 | 7 | println!(\u0026#34;{}, {}\u0026#34;, r1, r2); | -- borrow later used here | = note: this error originates in a macro outside of the current crate (in Nightly builds, run with -Z external-macro-backtrace for more info) error: aborting due to previous error For more information about this error, try `rustc --explain E0499`. error: could not compile `ownership` due to previous error 실제 코드를 작성하는데 가장 힘들게 느껴지는 제약사항 중 하나이다.\n러스트는 이러한 제약사항을 통해 메모리 안정성을 보장한다.\n정확히는 러스트는 데이터 레이스를 방지하기 위해 이러한 제약사항을 두고 있다.\n데이터 레이스는 두개 이상의 스레드가 동시에 같은 데이터에 접근할 때 발생하는 문제이다.\n동시에 같은 데이터에 접근하면서, 적어도 하나의 접근이 쓰기일 때, 동시성 로직이 없는 경우에 발생한다. 러스트는 이러한 문제를 방지하기 위해 컴파일 타임에 이러한 문제를 방지한다.\nfn main() { let mut s = String::(\u0026#34;hello\u0026#34;); { let r1 = \u0026amp;mut s; } // r1 goes out of scope here, so we can make a new reference with no problems. let r2 = \u0026amp;mut s; 다수의 참조가 필요 할 때, 위와 같이 블록을 사용하여 스코프를 나누어 사용하면 된다.\n참조의 범위를 제한함으로써, 데이터 레이스를 방지할 수 있다.\n또 하나의 제약사항은 불변 참조와 가변 참조를 동시에 사용할 수 없다는 것이다.\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; let r2 = \u0026amp;s; let r3 = \u0026amp;mut s; // error } 불변 참조값이 있는 동안에는 가변 참조로 인해서 데이터가 변경되는것을 원하지 않기 때문에 막아둔 것이다.\n추가적으로 러스트는 컴파일 시점에 불변 참조의 마지막 사용 위치 이후에는 가변 참조를 사용할 수 있도록 해준다.\nfn main() { let mut s = String::from(\u0026#34;hello\u0026#34;); let r1 = \u0026amp;s; let r2 = \u0026amp;s; println!(\u0026#34;{} and {}\u0026#34;, r1, r2); // r1 and r2 are no longer used after this point let r3 = \u0026amp;mut s; } 4.2.1 Dangling References Dangling References는 참조가 가리키는 메모리가 해제된 경우를 말한다.\n메모리 해제 후에도 참조가 존재하는 경우, 범위 밖 참조가 일어나는 경우, 복사된 포인터가 일으키는 경우 등이 있다. 러스트는 참조가 유효한 동안에는 반드시 데이터가 스코프 내에 있도록 보장한다.\n즉, 데이터가 참조보다 먼저 스코프 밖으로 벗어나서는 안 되며, 이를 통해 댕글링 참조가 생성되는 것을 컴파일 시점에 방지한다.\n예를들어 함수가 로컬 변수의 참조를 반환하는 경우, 러스트는 컴파일 에러를 발생시킨다.\nfn main() { let reference_to_nothing = dangle(); } fn dangle() -\u0026gt; \u0026amp;String { let s = String::from(\u0026#34;hello\u0026#34;); \u0026amp;s } 4.3 The Slice Type 슬라이드는 참조의 일종으로, 오너쉽을 가지지 않는다.\n예시 : 문자열에서 첫 단어를 찾는 함수 만들어보기 (공백을 기준으로)\nfn first_word(s: \u0026amp;String) -\u0026gt; ? 이 함수는 문자열의 참조를 받는데, 무엇을 반환해야 할까? fn first_word(s: \u0026amp;String) -\u0026gt; usize { let bytes = s.as_bytes(); for (i, \u0026amp;item) in bytes.iter().enumerate() { if item == b\u0026#39; \u0026#39; { return i; } } s.len() } let bytes = s.as_bytes(); // as_bytes() 메소드는 문자열을 바이트 배열로 변환한다. for (i, \u0026amp;item) in bytes.iter().enumerate() // iter() 메소드는 컬렉션을 반복하는 반복자를 생성한다, enumerate() 메소드는 반복자를 튜플로 변환한다. 문자열의 인덱스를 반환하는 방식으로 구현했다, fn main() { let mut s = String::from(\u0026#34;hello world\u0026#34;); let word = first_word(\u0026amp;s); // word will get the value 5 s.clear(); // this empties the String, making it equal to \u0026#34;\u0026#34; // word still has the value 5 here, but there\u0026#39;s no more string that // we could meaningfully use the value 5 with. word is now totally invalid! } 4.3.1 String Slices\n슬라이스는 문자열의 일부분을 참조하는 방법이고 이렇게 생겼다. let s = String::from(\u0026#34;hello world\u0026#34;); let hello = \u0026amp;s[0..5]; let world = \u0026amp;s[6..11]; Rather than a reference to the entire String, hello is a reference to a portion of the String, specified in the extra [0..5] bit. We create slices using a range within brackets by specifying [starting_index..ending_index], where starting_index is the first position in the slice and ending_index is one more than the last position in the slice. Internally, the slice data structure stores the starting position and the length of the slice, which corresponds to ending_index minus starting_index. So, in the case of let world = \u0026amp;s[6..11];, world would be a slice that contains a pointer to the byte at index 6 of s with a length value of 5.\nlet s = String::from(\u0026#34;hello\u0026#34;); let slice = \u0026amp;s[0..2]; let slice = \u0026amp;s[..2]; let len = s.len(); let slice = \u0026amp;s[3..len]; let slice = \u0026amp;s[3..]; let slice = \u0026amp;s[0..len]; let slice = \u0026amp;s[..]; fn first_word(s: \u0026amp;String) -\u0026gt; \u0026amp;str { let bytes = s.as_bytes(); for (i, \u0026amp;item) in bytes.iter().enumerate() { if item == b\u0026#39; \u0026#39; { return \u0026amp;s[0..i]; } } \u0026amp;s[..] } 똑같이 개념적으로는 인덱스를 통해 문자열을 찾는 방식이지만, 참조를 엮어두면 훨씬 더 안전하게 사용 할 수 있다.\n스트링이 유효한 동안에 슬라이스도 유효하다.\nfn main() { let mut s = String::from(\u0026#34;hello world\u0026#34;); let word = first_word(\u0026amp;s); s.clear(); // error! println!(\u0026#34;the first word is: {}\u0026#34;, word); } $ cargo run Compiling ownership v0.1.0 (file:///projects/ownership) error[E0502]: cannot borrow `s` as mutable because it is also borrowed as immutable --\u0026gt; src/main.rs:18:5 | 16 | let word = first_word(\u0026amp;s); | -- immutable borrow occurs here 17 | 18 | s.clear(); // error! | ^^^^^^^^^ mutable borrow occurs here 19 | 20 | println!(\u0026#34;the first word is: {}\u0026#34;, word); | ---- immutable borrow later used here For more information about this error, try `rustc --explain E0502`. error: could not compile `ownership` due to previous error String의 내용을 지우기 위해서는 해당 String에 대한 가변 참조가 필요한데, 만약 이미 불변 참조가 존재한다면\nclear 메소드를 호출하여 String의 내용을 변경하려고 할 때 컴파일 오류가 발생한다.\n이는 println! 매크로가 word에서 불변 참조를 사용하려고 하기 때문에 발생한다.\n따라서, clear 함수가 가변 참조를 요구하는 동안 word의 불변 참조가 여전히 활성화되어 있어야 한다.\n러스트는 가변 참조와 불변 참조가 동시에 존재하는 것을 허용하지 않기 때문에 컴파일이 실패한다.\n결론적으로 String Literal은 바이너리를 참조하는 것이다.\n위 코드에서 s의 타입은 \u0026amp;str입니다. 이는 특정 이진 파일 내의 위치를 가리키는 슬라이스로, 문자열 리터럴이 어떻게 처리되는지를 명확히 이해할 수 있게 해줍니다. 문자열 리터럴이 불변인 이유도 여기에 있습니다 \u0026amp;str은 불변 참조이기 때문입니다.따라서, 문자열 리터럴은 프로그램의 이진 파일 내에 직접 저장되며, 이를 통해 생성된 \u0026amp;str 타입의 변수는 이진 파일 내 해당 문자열의 위치를 가리키는 불변의 슬라이스가 됩니다. 이러한 특성은 문자열 리터럴이 왜 변경할 수 없는지(immutable)를 설명해 줍니다.\nlet s = \u0026#34;Hello, world!\u0026#34;; 참고로 경험 많은 개발자들은 다음과 같이 시그니처를 유연하게 만들어서 사용한다고 한다. fn first_word(s: \u0026amp;str) -\u0026gt; \u0026amp;str 위처럼 s 매개변수의 타입으로 문자열 슬라이스를 사용하게 만든다.\n이를 통해 문자열 슬라이스를 직접 전달할 수 있고, String이 있을 경우 String의 슬라이스나 String에 대한 참조를 전달할 수 있게 된다.\n이러한 유연성은 역참조 강제 변환(deref coercions)이라는 기능을 활용하는 것으로 나중에\u0026hellip;\nfn main() { let my_string = String::from(\u0026#34;hello world\u0026#34;); // `first_word` works on slices of `String`s, whether partial or whole let word = first_word(\u0026amp;my_string[0..6]); let word = first_word(\u0026amp;my_string[..]); // `first_word` also works on references to `String`s, which are equivalent // to whole slices of `String`s let word = first_word(\u0026amp;my_string); let my_string_literal = \u0026#34;hello world\u0026#34;; // `first_word` works on slices of string literals, whether partial or whole let word = first_word(\u0026amp;my_string_literal[0..6]); let word = first_word(\u0026amp;my_string_literal[..]); // Because string literals *are* string slices already, // this works too, without the slice syntax! let word = first_word(my_string_literal); } ","permalink":"http://localhost:1313/_wiki/understanding-ownership/","summary":"4.0 Ownership 소유권은 러스트의 가장 특징적인 개념이다, 러스트를 이해하기 위해서, 또는 러스트가 왜 다른 언어들보다 주목받는지 이해하기 위해서 가장 중요한 장이라고 생각한다.\n4.1.1 What is Ownership? Ownership은 러스트가 메모리를 관리하는 규칙이다.\n모든 프로그래밍 언어는 메모리를 관리하는 방법이 있다.\n가장 대표적인 두 갈래는 GC(Garbage Collection)와 수동 메모리 관리로 볼 수있다.\nGC는 프로그램이 실행되는동안, 더 이상 사용하지 않는 메모리를 찾아내고 해체하는 방법이다.\n수동 메모리 관리는 프로그래머가 메모리를 직접 관리하는 방법이다.\n당연히 GC가 편리하고 안전하지만, 성능이 떨어진다는 단점이 있다.","title":"Understanding the Ownership of the Rust Programming Language"},{"content":" 01. 왜 마이그레이션을 하게 되었을까? 사실 마이그레이션을 하려고 하지는 않았고, 기존 Neovim 설정에서 마음에 안드는 부분들이 조금 있어서 그부분만 수정하려고 했다. 그러다 지난번 설정을 따라했었던 유튜버가 2024년 설정이라는 영상으로 기존 Neovim 설정 가이드 영상을 리뉴얼했다. packer나 lsp-saga와 같이 기존에 불편하던 부분들을 귀신같이 뺀 영상임을 확인하고 바로 마이그레이션을 하게 되었다.\n마이그레이션이라고 하기는 사실 애매하고 완전 새롭게 설정을 하고, 기존 설정을 새로운 설정에 덧붙였다고 보는게 맞을 것 같다. 해당 설정을 다시 하면서 추가된 내용에 대한 약간의 내용정리와, 간단한 설명을 덧붙여 포스팅을 해보려고 한다. 02. 기존에 불편했던 것들 packer, lsp-saga packer는 아주 약간 아쉬운점이 있었다.\n콘솔이 훨씬 덜 직관적이다. 상대적으로 무거운 플러그인들도 사실상 무조건 로드되어야 한다.(Lazy Loading이 안되는 것으로 알고 있다) 플러그인을 추가하거나 삭제할때마다 :PackerSync를 해줘야 하는데, Lazy처럼 접근성 좋은 대시보드를 제공하지는 않아서 불편했다. 사실 Mason과 비슷하게 믓찌게 생긴 Lazy.vim 대시보드를 사용하고 싶었다. lsp-saga는 아주 약간 많이 아쉬운점이 있었다.\n업데이트나 플러그인을 추가 할 때 마다 에러가 발생했다. Neovim이 버전업되면, 혹은 아주 오래 쉬다가 새로운 lsp-saga release가 나오면, 에러에 시달려서 내려놨던 경우가 많았다. 현실적으로 lsp와 그 친구들이 neovim으로 넘어와서 애매한 프로젝트가 되어있는게 보였다. 03. Josean의 2024 Neovim 설정 기본적으로 위의 블로그와 유튜브 영상을 참고하면 누구나 쉽게 설정을 할 수 있다. 유튜브와 포스팅의 코드들을 보면서 설정을 하면 거의 영상의 러닝타임 내로 설정을 마칠 수 있다.\n다만 포스팅만 보거나 해당 소스코드를 그냥 pull 받는 것 보다는 영상을 시청하면서 따라하는것을 추천한다.\n플러그인을 설정하는 것에 더해서, 플러그인들의 기본적인 사용법과 꿀팁들을 설명하고 보여주기 때문이다.\n개인적으로는 lazyvim이나 lunarvim같은 distro를 사용하는 것 보다 위의 영상을 보고 직접 설정하는게 훨씬 재미있으면서도, 실제 사용법을 알 수 있어 좋다고 생각한다.\n무엇보다 매우 재미있다.\n04. 위 영상을 보기 전에 알면 좋은 내용들. lua 언어에 대한 기본적인 지식이 필요하다. lua는 neovim의 설정파일을 작성할 때 사용되는 스크립트 언어이다. lua의 기본적인 문법과, neovim에서 사용되는 lua의 특수한 문법들을 알면 좋다.(간단한 스크립트 언어로 lua cheet sheet 정도만 찾아봐도 위의 영상을 따라하는데는 충분하다.) neovim의 기본적인 설정파일에 대한 이해가 필요하다. 먼저 init.lua는 모든 설정파일의 시작점이자 끝점이다.\n기본적으로 init.lua에 모든 설정을 작성해도 되지만 lua의 특성상 모듈화를 해서 init.lua에 init하는 방식으로 설정한다.\n-- 실제 내 설정파일의 init.lua 의 예시 require(\u0026#34;smallzooDev.core\u0026#34;) require(\u0026#34;smallzooDev.lazy\u0026#34;) 위와 같이 require를 사용해서 모듈화를 하고, init.lua에서 require를 통해 모듈을 불러온다.\n실제 프로젝트의 구조는 아래와 같다. packer, lazy.vim들과 같은 플러그인들로, 외부 레포에서 플러그인들을 가져오고, 모듈화를 해서 init.lua에서 불러오는 방식이다.\n즉 나의 프로젝트를 기준으로 설명하면, smallzooDev.core(모듈화 한 코어설정)와 smallzooDev.lazy(외부 플러그인 모듈화 해둔 설정)을 불러오는 방식이다.\nlazy.vim은 플러그인 매니저이고, 외부 저장소에서 플러그인을 가져오고 관리해준다. 위와 같이 플러그인들을 불러오고 관리해주는 플러그인 매니저이다.\nvim이라고는 믿기지않은 멋진 대시보드를 제공해준다.\n실제 플러그인 설정은 아래와 같은 방식으로 작성된다. \u0026ldquo;gooloard/alpha-vim\u0026quot;과 같이 레포명을 적고 그와 관련된 설정을 작성한다. 플러그인에 대한 참조를 변수에 저장해서 위와 같이 프로퍼티등을 수정할수 있고 해당 스크립트에는 vim의 전역변수를 사용할 수 있어서, g:alpha_scroll과 같이 전역변수를 사용해서 설정을 할 수 있다. 05. 내가 추가한 플러그인, 설정들 Vimwiki Vimwiki는 마크다운 문법을 사용해서 간단한 노트를 작성할 수 있는 플러그인이며 이 블로그도 Vimwiki로 작성하고 있다. 아래는 간단한 설정 참고 copilot 설명은 딱히.. color-schemes, key-mappings등 개인화된 설정들 이정도만 해도 나는 충분했던 것 같다 (설정 유튜브에 충분히 많은 플러그인들을 init한다)\n06. 마무리 마이그레이션을 하면서, 기존 설정에서 불편했던 부분들을 해결하고, 새로운 플러그인들을 추가하면서 더욱 편리하게 사용할 수 있게 되었다. 결론적으로 파일탐색, 플러그인관리, 언어서버, 린팅, 포맷팅, 자동완성, 인덴트, 검색 등 ide의 기능에 하나도 빠지지 않는 neovim을 만들게 되었다. 마지막으로 나처럼 초보자일수록 꼭 distro를 사용하지 않고, 직접 설정을 해보는 것을 추천한다. 그것이 더욱 더 재미있고, 실제 사용법을 알 수 있기 때문이다. ","permalink":"http://localhost:1313/_wiki/neovim-migration-%ED%95%98%EA%B8%B0/","summary":"01. 왜 마이그레이션을 하게 되었을까? 사실 마이그레이션을 하려고 하지는 않았고, 기존 Neovim 설정에서 마음에 안드는 부분들이 조금 있어서 그부분만 수정하려고 했다. 그러다 지난번 설정을 따라했었던 유튜버가 2024년 설정이라는 영상으로 기존 Neovim 설정 가이드 영상을 리뉴얼했다. packer나 lsp-saga와 같이 기존에 불편하던 부분들을 귀신같이 뺀 영상임을 확인하고 바로 마이그레이션을 하게 되었다.\n마이그레이션이라고 하기는 사실 애매하고 완전 새롭게 설정을 하고, 기존 설정을 새로운 설정에 덧붙였다고 보는게 맞을 것 같다. 해당 설정을 다시 하면서 추가된 내용에 대한 약간의 내용정리와, 간단한 설명을 덧붙여 포스팅을 해보려고 한다.","title":"Neovim 마이그레이션(?) 하기"},{"content":" 기본적으로 이직이다\n4월 중순 내일배움캠프 튜터링이 시작되어 그 전까지 좀 공부를 당겨놓고 싶다.\n지금은 굵직하게 4가지 목표를 잡고 있다.\nDB 공부 - Real MySql 8.0 두 권 다 읽기 Network 공부 - 정말 필요한 만큼만, 항상 네트워크는 지루해\u0026hellip; 운영체제등의 공부 - 원래는 운영체제 아주 쉬운 세가지 이야기를 읽으려고 했는데, 그래도 약간의 보상이 필요 할 것 같아서, 상대적으로 재미있는 러스트를 공부하면서 마주하는 개념들을 조금 더 자세하게 정리하는 것으로 하려고 한다. 코테 공부 - 아무래도 만 3년차이다보니 코테를 요구하는 회사들이 더 많아서 눈여겨본 유데미 강의를 볼까 한다. 이중에서 4월 내로 러스트 기본 문법 빠르게 훑고, 러스트인액션과같이 구현에 들어가는것, 그리고 Mysql 8.0 2권 (2권부터 읽으려 한다) 읽기를 목표로 잡았다.\n월간 회고를 결국 쓸거니까 이번달에는 꼭 범위를 타이트하게 지켜봐야지\n아 그리고 이번달 쓰고 싶은 포스팅 주제는 비동기 프로그래밍이다, Nest.js, Webflux, Armereia 같이 요즘은 비동기 프로그래밍과 같은 키워드가 많이 나와 조사해보려고 한다.\n또 두번째 주제는 지금 하고 있는 업무에 대한 회고이다. 이렇게 두개는 꼭 써야지\n0407 ~ 0414\nmysql remind 완료 rust 기본 문법 ~14장까지 완료 0415 ~ 0421\nrust 15장 ~ 20장까지 완료 os lecture part 1 0422 ~ 0428\nrust in action 시작 os lecture part 2 코테 공부 시작 0429 ~ 0505\nos lecture part 3 rust in action 코테 공부 0506 ~ 0512\nos lecture part 4 rust in action 코테 공부 0513 ~ 0519\nrust in action 완료 코테 공부 현실적으로 이 이후부터 mySql 8.0 시작 (이직 일정에 따라 필요하면 중간부터 읽고 크게는 5월까지 끝내는 것으로) ","permalink":"http://localhost:1313/_wiki/2024-04/","summary":"기본적으로 이직이다\n4월 중순 내일배움캠프 튜터링이 시작되어 그 전까지 좀 공부를 당겨놓고 싶다.\n지금은 굵직하게 4가지 목표를 잡고 있다.\nDB 공부 - Real MySql 8.0 두 권 다 읽기 Network 공부 - 정말 필요한 만큼만, 항상 네트워크는 지루해\u0026hellip; 운영체제등의 공부 - 원래는 운영체제 아주 쉬운 세가지 이야기를 읽으려고 했는데, 그래도 약간의 보상이 필요 할 것 같아서, 상대적으로 재미있는 러스트를 공부하면서 마주하는 개념들을 조금 더 자세하게 정리하는 것으로 하려고 한다. 코테 공부 - 아무래도 만 3년차이다보니 코테를 요구하는 회사들이 더 많아서 눈여겨본 유데미 강의를 볼까 한다.","title":"2024년 4월의 목표"},{"content":"3 Common Programming Concepts 이번 장에서는 러스트의 기본적인 프로그래밍 개념들을 다룬다, 가장 특징적인 부분이라면 다른 언어를 대비해서 러스트가 어떤 부분이 다른지 위주로 설명하는 가장 크게 두드러진다는 것이다.\nmz한 언어답게 예약어가 예약되어 있다고 한다 ㅋㅋ(아직 예약어로써 기능하지는 않지만, 미래의 예약어가 될 수 있어 예약해둔 keword)\n3.1 Variables and Mutability 변수는 기본적으로 불변이며, 이렇게 된게 러스트의 nudge라고 한다. src/main.rs\nfn main() { let x = 5; println!(\u0026#34;The value of x is: {}\u0026#34;, x); x = 6; println!(\u0026#34;The value of x is: {}\u0026#34;, x); } $ cargo run Compiling variables v0.1.0 (file:///projects/variables) error[E0384]: cannot assign twice to immutable variable `x` --\u0026gt; src/main.rs:4:5 | 2 | let x = 5; | - | | | first assignment to `x` | help: consider making this binding mutable: `mut x` 3 | println!(\u0026#34;The value of x is: {x}\u0026#34;); 4 | x = 6; | ^^^^^ cannot assign twice to immutable variable For more information about this error, try `rustc --explain E0384`. error: could not compile `variables` due to previous error 친절한 컴파일에러.. 무튼 변수를 변경하려면 mut 키워드를 사용해야 한다, 이렇게 하면 일단 변수를 선언하고, 고심한 이후에 mut 키워드를 붙이는 습관이 들 수 있다.\nConstants 상수는 const 키워드를 사용하며, 타입을 명시해야 한다.\n전역을 포함한 어느 스코프에서도 선언이 가능하다.\n런타임에 계산되는 값은 상수로 선언할 수 없고, 오직 상수 표현식(컴파일 타임에 계산되는 값)만 가능하다.\nconst THREE_HOURS_IN_SECONDS: u32 = 60 * 60 * 3; Shadowing 변수를 재선언하는 것을 shadowing이라고 한다. fn main() { let x = 5; let x = x + 1; { let x = x * 2; println!(\u0026#34;The value of x in the inner scope is: {x}\u0026#34;); } println!(\u0026#34;The value of x is: {x}\u0026#34;); } 결과는\nThe value of x in the inner scope is: 12 The value of x is: 6 변수 재 선언과는 다르고, 특히 스코프를 벗어나면 이전 변수가 다시 보이게 된다는게 특징이다.\n그리고 타입을 변경하여도 shadowing이 가능하다.\nlet spaces = \u0026#34; \u0026#34;; let spaces = spaces.len(); 이렇게 하면 spaces는 문자열이었다가 숫자로 바뀌게 된다, space_len 같은 변수를 만들 필요가 없다.\n실제로 저장하고 싶은 데이터는 공백의 갯수이기 때문에 특정한 상황에서 효율적일 수 있다.\n뭔가 스코프에 따라 Shadowing이 영향을 받기도 해서 위험해 보이고, 처음에는 표현식.타입의메셔드() 이런 방법보다 더 나은가 싶긴 했는데, 러스트의 문법적 특징과 잘 어울리게 쓰면 멋진 코드가 나오는 것 같다.\n3.2 Data Types 러스트는 정적 타입 언어이다.\n컴파일 타임에 모든 타입이 알려져야 한다.\nlet guess: u32 = \u0026#34;42\u0026#34;.parse().expect(\u0026#34;Not a number!\u0026#34;); 컴파일 시점에 다양한 가능성이 있는 경우라면 타입을 명시해야 컴파일 에러가 나지 않는다.\n그리고 러스트에는 스칼라 타입과 컴파운드 타입이 있다.\nScalar Types 기본적으로 하나로 표현되는 값이다. (다른 언어의원시 타입)\n러스트의 스칼라 타입은 정수형, 부동소수점, 불리언, 문자로 구성된다.\nInteger Types 정수형은 unsigned인지만 구분하고, 크기에 따라 8, 16, 32, 64, 128비트로 나뉜다.\ni8 -\u0026gt; 8비트 signed integer\nu64 -\u0026gt; 64비트 unsigned integer\nisize, usize는 운영체제에 따라 32, 64비트로 결정된다. (64비트 운영체제에서는 64비트) (포인터 사이즈)\n디폴트값은 i32이다.\n추가적으로 정수 오버플로우는 검사하지 않고, 2의 보수 래핑을 한다. 11111 -\u0026gt; 00000\n이를 방지하기 위해서 보통은 충분히 큰 타입을 사용하라고,,,,할수는 없으니 (BigDecimal.java)\nstd의 Wrapping을 사용하면 된다.\nuse std::num::Wrapping; fn main() { let x = Wrapping(0u8); let y = Wrapping(1u8); let z = x - y; println!(\u0026#34;{:?}\u0026#34;, z); } Floating-Point Types 부동소수점은 f32, f64로 나뉜다.\nf64가 디폴트이다.\nIEEE-754 표준을 따른다고 한다\nNumeric Operations 산술연산자는 간단하게..\nfn main() { let sum = 5 + 10; let difference = 95.5 - 4.3; let product = 4 * 30; let quotient = 56.7 / 32.2; let remainder = 43 % 5; } The Boolean Type 생략 The Character Type 러스트의 char는 유니코드 스칼라 값이다. 크기는 4바이트이다. 유니코드 스칼라 값은 0x0000과 0xD7FF, 0xE000과 0x10FFFF 사이의 값을 가진다. 0부터 55295까지의 범위는 기본 다국어 평면, 57344부터 1114111까지의 범위는 보조 다국어 평면이다. fn main() { let heart_eyed_cat = \u0026#39;😻\u0026#39;; // 가능! } Compound Types 여러 값을 하나로 묶어서 저장하는 타입이다. 튜플과 배열이 있다. 튜플은 고정된 길이를 가지고 각 요소의 타입은 달라도 된다. 러스트는 배열의 길이를 컴파일 시점에 알아야 한다. fn main() { let tup: (i32, f64, u8) = (500, 6.4, 1); } fn main() { let tup = (500, 6.4, 1); let (x, y, z) = tup; // 디스트럭처링 가능 println!(\u0026#34;The value of y is: {y}\u0026#34;); } fn main() { let x: (i32, f64, u8) = (500, 6.4, 1); let five_hundred = x.0; // 인덱스로 접근가능 let six_point_four = x.1; let one = x.2; } Array\nfn main() { let a = [1, 2, 3, 4, 5]; } 배열은 고정된 길이를 가지고, 모든 요소의 타입은 같아야 한다. 배열의 길이는 타입의 일부이다. 배열의 요소에 접근할 때는 인덱스를 사용한다. 배열은 데이터를 힙(heap) 대신 스택(stack)에 할당하려는 경우에 유용하다. 스택에 할당하면 데이터를 빠르게 할당하고 접근할 수 있지만, 데이터가 컴파일 시점에 정해진 크기만큼만 스택에 할당될 수 있기 때문에 유연하지 않다. 힙에 할당하면 컴파일 시점에 크기가 정해지지 않아서 런타임에 크기를 늘릴 수 있지만, 느리다.\n보통 공식 가이드에서는 명확한 이유가 없다면 벡터를 사용하라고 권한다. 벡터는 힙에 할당되고, 컴파일 시점에 크기가 정해지지 않아서 런타임에 크기를 늘릴 수 있다.\n나중에 훨씬 더 자세하게 거론된다 fn main() { let a = [1, 2, 3, 4, 5]; let a = [3; 5]; // [3, 3, 3, 3, 3] let first = a[0]; let second = a[1]; } 저수준의 언어임에도 OOI 에러를 패닉으로 잡아내준다. 3.3 Functions fn main() { println!(\u0026#34;Hello, world!\u0026#34;); another_function(); } fn another_function() { println!(\u0026#34;Another function.\u0026#34;); } ```rust fn main() { another_function(5, 6); } fn another_function(x: i32, y: i32) { println!(\u0026#34;The value of x is: {x}\u0026#34;); println!(\u0026#34;The value of y is: {y}\u0026#34;); } 함수 선언의 위치는 중요하지 않다. 파라미터는 타입을 명시해야 한다. Statements and Expressions Function bodies are made up of a series of statements optionally ending in an expression. So far, the functions we’ve covered haven’t included an ending expression, but you have seen an expression as part of a statement. Because Rust is an expression-based language, this is an important distinction to understand. Other languages don’t have the same distinctions, so let’s look at what statements and expressions are and how their differences affect the bodies of functions\n이 장에서 가장 중요한 부분이라고 생각한다.\n먼저 함수를 일련의 \u0026lsquo;문(statement)\u0026lsquo;로 구성되어 있고, 이 문들은 선택적으로 \u0026lsquo;표현식(expression)\u0026lsquo;으로 끝난다 고 정의하고있다.\n또한 러스트는 표현식 기반 언어라고 정의한다.\n문(statement)는 어떤 작업을 수행하고 값을 반환하지 않는다.\n표현식(expression)은 값을 반환한다.\n예를 들어, let x = 5; 는 문이고, 5 + 6;은 표현식이다.\nlet x = 5; 는 변수에 값을 할당하고, 그 자체로 평가될 값이 없다.\n반면 5 + 6;은 두 값을 더한 결과를 반환하고, 반환한 값으로 평가된다.\n참고로 {} 블록은 표현식이며, 블록 내부의 마지막 표현식이 블록 전체의 값이 된다.\n함수를 호출하는 것, 매크로를 호출하는것 것은 표현식이다.\n표현식의 끝에는 세미콜론을 붙이지 않는다.\n결론적으로 return 키워드는 함수를 일찍 종료시킬 때 사용되며, 일반적으로는 문들의 나열 이후에 마지막 표현식으로 값을 반환한다!\n3.4 Comments 생략..?\n3.5 Control Flow 러스트의 if문은 특징적인 내용은 별로 없다.\n조건식은 반드시 bool 타입이어야 한다. (거의 대부분의 강타입 언어가 그렇듯이)\n분기가 많은 경우 match 키워드를 사용하는 것이 좋다.\n러스트의 if는 표현식이기 때문에 다음과 같이 3항 연산자를 대체할 수 있다.\nfn main() { let number = 3; if number \u0026lt; 5 { println!(\u0026#34;condition was true\u0026#34;); } else { println!(\u0026#34;condition was false\u0026#34;); } let condition = true; let number = if condition { 5 } else { 6 }; println!(\u0026#34;The value of number is: {number}\u0026#34;); } 반복문은 loop, while, for가 있다.\nloop는 조건 검사를 전적으로 프로그래머에게 맡기는 반복문이다.\n내가 배운 언어에서는 없었던 것 같다.\n종료 조건을 잘 생각하고 코드를 작성해야 한다.\n종료 keyword인 break 뒤에 값을 반환할 수 있다 (표현식으로 사용 가능)\nfn main() { let mut counter = 0; let result = loop { counter += 1; if counter == 10 { break counter * 2; } }; println!(\u0026#34;The result is {result}\u0026#34;); } 루프에 레이블을 붙일 수 있다. \u0026#39;outer: loop { println!(\u0026#34;Entered the outer loop\u0026#34;); \u0026#39;inner: loop { println!(\u0026#34;Entered the inner loop\u0026#34;); break \u0026#39;outer; } println!(\u0026#34;This point will never be reached\u0026#34;); } 독특한 기능인 것 같다. 당연히 레이블을 붙이지 않아도 되고, 그런 경우 loop 제어 키워드들은 가장 가까운 루프를 기준으로 동작한다.\n루프 레이블과 루프의 값 반환을 함께 사용하는 예제\nfn main() { let mut counter = 0; let result = \u0026#39;outer: loop { println!(\u0026#34;Entered the outer loop\u0026#34;); \u0026#39;inner: loop { println!(\u0026#34;Entered the inner loop\u0026#34;); counter += 1; if counter == 10 { break \u0026#39;outer counter * 2; } } }; println!(\u0026#34;The result is {result}\u0026#34;); } while은 조건이 참인 동안 반복한다 (특징적이지 않다) fn main() { let mut number = 3; while number != 0 { println!(\u0026#34;{number}\u0026#34;); number -= 1; } println!(\u0026#34;LIFTOFF!!!\u0026#34;); } for는 컬렉션을 순회한다.\n먼저 while 기반의 인덱스 순회 방법을 소개한다.\nfn main() { let a = [10, 20, 30, 40, 50]; let mut index = 0; while index \u0026lt; 5 { println!(\u0026#34;{a[index]}\u0026#34;); index += 1; } } 이런 방법은 러스트의 인덱스 오버플로우를 방지하기 위해 좋지 않으며, 느리다고 언급한다.\n느린 이유는 루프의 매 반복마다 OOI를 체크하기위한 런타임 코드를 추가하기 때문이라고 한다.\n일단 for문은 이렇게 생겼다.\nfn main() { let a = [10, 20, 30, 40, 50]; for element in a.iter() { println!(\u0026#34;{element}\u0026#34;); } } 지정한 횟수만큼의 반복을 원한다면, range()를 사용하면 된다. fn main() { for number in (1..4).rev() { // .rev()는 역순으로 순회한다. println!(\u0026#34;{number}\u0026#34;); } println!(\u0026#34;LIFTOFF!!!\u0026#34;); } 러스트의 순회는 어떻게 구현되어있을까? 먼저Java와 같은 언어에서는 Iterable 인터페이스를 구현하고, Iterator를 반환하는 메서드를 구현한다.\n그리고 Iterator는 대충 아래와 같이 생겼다.\npublic interface Iterator\u0026lt;T\u0026gt; { boolean hasNext(); T next(); } 그래서 Iterator를 구현한 클래스는 hasNext()와 next()를 구현해야 한다.\n이러한 경우 인덱스를 카운트 하지 않고 Iterator의 구현체를 순회 할 수 있다.\nIterator의 구현체와 사용 예시 (for 문)\npublic class MyIterator\u0026lt;T\u0026gt; implements Iterator\u0026lt;T\u0026gt;, Iterable\u0026lt;T\u0026gt; { private T[] elements; private int index = 0; public MyIterator(T[] elements) { this.elements = elements; } @Override public boolean hasNext() { return index \u0026lt; elements.length; } @Override public T next() { return elements[index++]; } @Override public Iterator\u0026lt;T\u0026gt; iterator() { return this; } } public class Main { public static void main(String[] args) { Integer[] elements = {1, 2, 3, 4, 5}; MyIterator\u0026lt;Integer\u0026gt; iterator = new MyIterator\u0026lt;\u0026gt;(elements); for (Integer element : iterator) { System.out.println(element); } } } 이런경우 축약된 for문은 Iterator를 구현한 클래스에 대해서만 사용할 수 있다.\n축약된 for문에서는 Iterator의 hasNext()와 next()를 호출하며, hasNext()가 false를 반환할 때까지 next()를 호출한다.\n즉 길이와 인덱스를 몰라도 순회가 가능하다.\nJavascript에서는 이터러블과 이터레이터를 사용한다. (이터러블 프로토콜과 이터레이터 프로토콜)\n이터러블 프로토콜은 Symbol.iterator 메서드를 구현하고, 이터레이터를 반환하는 것이다.\n이터레이터 프로토콜은 next() 메서드를 구현하고, value와 done을 반환하는 것이다.\n마찬가지로 예시는 아래와 같다\n생긴건 자바와 조금 다르지만 원리는 같다 (다음원소가 있는지 확인하고, 다음 원소를 반환한다)\nfunction MyIterator(elements) { this.elements = elements; this.index = 0; } MyIterator.prototype.next = function() { return this.elements[this.index++]; } MyIterator.prototype.hasNext = function() { return this.index \u0026lt; this.elements.length; } MyIterator.prototype[Symbol.iterator] = function() { return this; } const elements = [1, 2, 3, 4, 5]; const iterator = new MyIterator(elements); for (const element of iterator) { console.log(element); } 프로토타입 기반 언어라서 그렇다고 한다. 이 객체가 특정한 추상화의 구현체인지를 따지는것 (자바, c++)과, 이 객체와 다른 언어의 유사점(프로토콜 구현 등)을 기반으로 따지는것 (자바스크립트)의 차이라고 한다.\n무튼 마지막으로 러스트는 트레이트를 사용한다.\n트레이트를 배우고 Iterator를 다뤄야지!\nSummary \u0026amp; Impression 러스트는 표현식 기반 언어이다. ","permalink":"http://localhost:1313/_wiki/common-programming-concepts/","summary":"3 Common Programming Concepts 이번 장에서는 러스트의 기본적인 프로그래밍 개념들을 다룬다, 가장 특징적인 부분이라면 다른 언어를 대비해서 러스트가 어떤 부분이 다른지 위주로 설명하는 가장 크게 두드러진다는 것이다.\nmz한 언어답게 예약어가 예약되어 있다고 한다 ㅋㅋ(아직 예약어로써 기능하지는 않지만, 미래의 예약어가 될 수 있어 예약해둔 keword)\n3.1 Variables and Mutability 변수는 기본적으로 불변이며, 이렇게 된게 러스트의 nudge라고 한다. src/main.rs\nfn main() { let x = 5; println!(\u0026#34;The value of x is: {}\u0026#34;, x); x = 6; println!","title":"러스트 공식 가이드 3장 정리"},{"content":" :profile start profile.log :profile func * :profile file * \u0026#34; At this point do slow actions :profile pause :noautocmd qall! 출처 : stackoverflow\n이렇게 하면 profile.log 파일이 생성된다.\n나의 경우는 copilot 관련 로그가 많아 회사 컴퓨터에서는 브랜치를 새로 파서,\n회사에서는 copilot을 disable 시켜서 해결했다.\n집가서 로그를 자세히 봐야겠다\n","permalink":"http://localhost:1313/_wiki/vim-profile-log-debugging/","summary":":profile start profile.log :profile func * :profile file * \u0026#34; At this point do slow actions :profile pause :noautocmd qall! 출처 : stackoverflow\n이렇게 하면 profile.log 파일이 생성된다.\n나의 경우는 copilot 관련 로그가 많아 회사 컴퓨터에서는 브랜치를 새로 파서,\n회사에서는 copilot을 disable 시켜서 해결했다.\n집가서 로그를 자세히 봐야겠다","title":"Vim이 느린 경우 Trouble Shootings"},{"content":"Hello World!\n","permalink":"http://localhost:1313/_wiki/%ED%9A%8C%EC%82%AC%EC%BB%B4-%EC%84%B8%ED%8C%85/","summary":"Hello World!","title":"회사 컴퓨터 세팅 관련"},{"content":"2. Programming a Guessing Game 간단한 숫자 맞추는 게임을 통해 러스트의 기본적인 문법과 기능을 익히는 예제, 처음 문법을 배우는 입장에서 생각보다 다룰 내용이 많았었던 기억이 난다.\nSetting Up a New Project 프로젝트 생성\n$ cargo new guessing_game $ cd guessing_game Processing a Guess src/main.rs\nuse std::io; // io 라이브러리를 가져온다. fn main() { println!(\u0026#34;Guess the number!\u0026#34;); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); // 빈 문자열을 생성한다. io::stdin().read_line(\u0026amp;mut guess) // 사용자 입력을 받아 guess 변수에 저장한다. .expect(\u0026#34;Failed to read line\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); // 사용자 입력을 출력한다. } Storing Values with Variables let mut guess = String::new(); // 빈 문자열을 생성한다. let : 변수를 생성하는 키워드. mut : mutable한 변수를 생성한다. (변경 가능한 변수, 기본적으로는 immutable) 개인적인 소감이지만 이러한 부분에서 러스트의 언어 디자인이 마음에 들었다, 다른 언어는 기본적으로 가변 변수를 선언하거나 키워드를 다르게 두는데 러스트는 let 키워드로 변수를 선언하고 mut 키워드로 가변 변수를 선언해서 가변 변수를 선언하는 부분을 사용자가 명시적으로 표현하게끔 했다.\n결론적으로 가변으로 선언한 guess라는 변수에, String::new() 표현식의 \u0026lsquo;값\u0026rsquo;을 할당한다. 참고로 러스트의 String은 표준 라이브러리의 String 타입이며, 힙에 할당된 UTF-8 인코딩된 텍스트를 가리키는 포인터이다(growable : 크기가 가변적이다).\n:: : 연산자는 특정 타입의 연관 함수를 호출한다. Receives User Input io::stdin().read_line(\u0026amp;mut guess) // 사용자 입력을 받아 guess 변수에 저장한다. io::stdin() : io 모듈의 stdin 함수를 호출한다. read_line(\u0026amp;mut guess) : Stdin 타입의 read_line 메서드를 호출한다. 이 메서드는 사용자 입력을 받아들이고, 그 값을 문자열에 저장한다(정확히는 추가한다). \u0026amp; : 참조 연산자, 정확히는 이 값이 참조를 가리킨다는 의미이다, 참고로 \u0026amp;은 immutable 하기에 \u0026amp;mut을 사용해서 가변 참조를 만들어야 한다. Handling Potential Failure with the Result .expect(\u0026#34;Failed to read line\u0026#34;); read_line 메서드는 input으로 받은 String에 유저로부터 받은 값을 추가해주고, 그 결과로 Result 타입을 반환한다. Result : 러스트의 표준 라이브러리에 정의된 열거형이다. 이 열거형은 Ok와 Err 두 가지의 variant를 가지고 있다. 이 가이드에서 enum에 대한 좋은 정의를 제공한다. \u0026ldquo;열거형은 여러 가능한 상태 중 하나로 존재할 수 있는 타입을 나타내는데, 이때 각각의 가능한 상태를 variant라고 부릅니다.\u0026rdquo;\nResult의 variant는 다음과 같다.\nOk : 연산이 성공적으로 완료되었음을 나타낸다.\nErr : 연산이 실패했음을 나타낸다.\nResult 타입의 값은 (다른 타입들처럼) method를 가질 수 있다. (뭔가 객체지향 프로그래밍의 인스턴스와 메서드를 연상시킨다. 러스트는 객체지향이 아니지만..)\n무튼 Result 타입의 expect 메서드를 요약하면, Result 값이 Err variant를 가지고 있다면, 프로그램을 강제 종료하고, 인자로 받은 메시지를 출력한다.\n뭔가 파라미터로 받아서 처리해야 하는 것 같은데, 체이닝을 통해 이어지는 것 같다! 이러면 어디에 구현을 해뒀을까 생각해보면 나중에 trait를 배울 때 더 이해가 잘 될 것 같다.\n반대로 Result 값이 Ok variant를 가지고 있다면, expect 메서드는 Ok variant가 가지고 있는 값을 반환한다. Optional\n참고로 Result 타입의 값에 expect 메서드를 호출하지 않으면 컴파일러는 경고를 발생시킨다(컴파일은 된다).\nexpect 메서드는 프로그램을 강제 종료시키기 때문에, 이 메서드를 사용할 때는 주의해야 한다.\nPrinting Values with println! println!(\u0026#34;You guessed: {}\u0026#34;, guess); // 사용자 입력을 출력한다. 난 모든언어에서 포매팅이 항상 지루하더라..\n러스트의 포매팅은 중괄호 {}를 사용한다. 중괄호는 문자열에 포매팅할 값의 위치를 나타낸다. 중괄호 안에는 값을 넣을 수 있다. 여러 개의 중괄호를 사용할 수도 있다.\n예시 :\nlet x = 5; let y = 10; println!(\u0026#34;x = {} and y = {}\u0026#34;, x, y); Generating a Secret Number 러스트에는 랜덤 숫자를 생성하는 기능이 내장되어 있지 않다. 따라서 외부 라이브러리(by Rust team)를 사용해야 한다. rand 라이브러리를 사용한다. Cargo.toml 파일에 의존성을 추가한다. [dependencies] rand = \u0026#34;0.8.4\u0026#34; Generating a Random Number use rand::Rng; use std::io; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin().read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); } Rng 는 랜덤 숫자를 제공하는 메서드를 정의한 트레이트이다. 이 트레이트는 rand 라이브러리에 정의되어 있다. trait란 뒤에서 아주 자세히 다루겠지만, 간단히 말하면 트레이트는 메서드의 집합을 정의한다. 스레드 로컬한 랜덤 숫자 생성기를 생성하고, 1부터 100까지의 랜덤 숫자를 생성한다.\n정리하자면 rand::thread_rng().gen_range(1..101) 는 rand 라이브러리의 thread_rng 함수를 호출하고, 이 함수는 Rng 트레이트를 구현한 객체를 반환한다. 이 객체는 gen_range 메서드를 호출할 수 있고, 이 메서드는 1부터 100까지의 랜덤 숫자를 반환한다. gen_range 메서드는 range를 인자로 받는다. range는 .. 연산자로 표현되며, 이 연산자는 첫 번째 숫자부터 두 번째 숫자까지의 범위를 나타낸다. 이때 두 번째 숫자는 범위에 포함되지 않는다.\nComparing the Guess to the Secret Number use rand::Rng; use std::cmp::Ordering; use std::io; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin().read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: u32 = guess.trim().parse() .expect(\u0026#34;Please type a number!\u0026#34;); println!(\u0026#34;You guessed: {}\u0026#34;, guess); // cmp 메서드는 Ordering 열거형을 반환한다. match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; println!(\u0026#34;You win!\u0026#34;), } } 위 코드에서는 Ordering 열거형을 스코프에 가져와서 사용한다. 이 열거형은 Less, Greater, Equal 세 가지 variant를 가지고 있다. match 표현식은 guess.cmp(\u0026amp;secret_number)의 결과를 패턴 매칭한다. 이 결과는 Ordering 열거형의 variant 중 하나이다.\n열거형으로 타입의 값을 매칭하는 방식과, 그 타입 내부의 메서드를 호출하는 방식이 러스트의 특징 중 하나라고 생각한다. 이러한 방식은 러스트의 타입 시스템을 이해하는데 도움이 된다. 러스트의 타입 시스템은 다른 언어와는 다르게, 타입의 값과 타입의 메서드를 분리해서 생각하게끔 한다. 표현식과 문의 차이점을 잘 생각하면서 코드를 보면 이해가 조금 더 쉬운 것 같다.\nrust arm 이라는 표현이 나왔는데, arm은 패턴 매칭을 위한 키워드인 것 같다. 이 키워드는 match 표현식에서 사용된다. 참고로 위의 코드는 아래의 컴파일 에러를 발생시킨다.\n$ cargo build Compiling libc v0.2.86 Compiling getrandom v0.2.2 Compiling cfg-if v1.0.0 Compiling ppv-lite86 v0.2.10 Compiling rand_core v0.6.2 Compiling rand_chacha v0.3.0 Compiling rand v0.8.5 Compiling guessing_game v0.1.0 (file:///projects/guessing_game) error[E0308]: mismatched types --\u0026gt; src/main.rs:22:21 | 22 | match guess.cmp(\u0026amp;secret_number) { | --- ^^^^^^^^^^^^^^ expected struct `String`, found integer | | | arguments to this function are incorrect | = note: expected reference `\u0026amp;String` found reference `\u0026amp;{integer}` note: associated function defined here --\u0026gt; /rustc/d5a82bbd26e1ad8b7401f6a718a9c57c96905483/library/core/src/cmp.rs:783:8 For more information about this error, try `rustc --explain E0308`. error: could not compile `guessing_game` due to previous error 이 컴파일 에러는 guess 변수의 타입이 String인데, cmp 메서드의 인자로 \u0026amp;secret_number를 넘겨주고 있기 때문에 발생한다. 모두가 알고 있듯이 러스트는 강타입 언어이고 아래와 같이 수정을 해야한다.\nlet guess: u32 = guess.trim().parse() .expect(\u0026#34;Please type a number!\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: u32 = guess.trim().parse().expect(\u0026#34;Please type a number!\u0026#34;); println!(\u0026#34;You guessed: {guess}\u0026#34;); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; println!(\u0026#34;You win!\u0026#34;), } guess를 재선언했네\u0026hellip;?\nrust에는 Shadowing이라는 개념이 있다. 이는 같은 이름의 변수를 여러 번 선언할 수 있다는 것이다. 이때, 이전에 선언한 변수는 가려진다.\n나중에 더 보겠지만, 이전에 선언한 변수는 더 이상 사용할 수 없다. 이는 변수의 타입을 변경할 때 유용하다.\n나머지는 이전에 다룬 내용과 동일하다.\nAllowing Multiple Guesses with Looping use rand::Rng; use std::cmp::Ordering; use std::io; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..101); println!(\u0026#34;The secret number is: {}\u0026#34;, secret_number); loop { println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: u32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; continue, }; println!(\u0026#34;You guessed: {}\u0026#34;, guess); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; { println!(\u0026#34;You win!\u0026#34;); break; } } } } 크 깔끔..\n개인적으로 변화도 많고 슈가신택스로 떡칠된 부분이 반복문이라고 생각한다. 타입 매칭과 break, continue같은 반복문 키워드만으로 깔끔한 코드를 작성할 수 있다. 왜 굳이 처음부터 이렇게 하지 않았는지 궁금하지만, 게임 종료하기 use rand::Rng; use std::cmp::Ordering; use std::io; fn main() { println!(\u0026#34;Guess the number!\u0026#34;); let secret_number = rand::thread_rng().gen_range(1..=100); loop { println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); io::stdin() .read_line(\u0026amp;mut guess) .expect(\u0026#34;Failed to read line\u0026#34;); let guess: u32 = match guess.trim().parse() { Ok(num) =\u0026gt; num, Err(_) =\u0026gt; continue, }; println!(\u0026#34;You guessed: {guess}\u0026#34;); match guess.cmp(\u0026amp;secret_number) { Ordering::Less =\u0026gt; println!(\u0026#34;Too small!\u0026#34;), Ordering::Greater =\u0026gt; println!(\u0026#34;Too big!\u0026#34;), Ordering::Equal =\u0026gt; { println!(\u0026#34;You win!\u0026#34;); break; } } } } Conclusion \u0026amp; Impression 러스트의 기본 문법과 기능을 익히기에 좋은 예제였다. 러스트의 타입 시스템과 패턴 매칭을 이해하는데 도움이 되었다. 러스트의 표준 라이브러리에 대한 이해를 높일 수 있었다. 러스트의 문법이나 기능을 배울 때, 러스트의 특징을 잘 드러내는 예제라고 생각한다. 뭔가 아쉬운점은 공식 문서의 내용 그대로를 가져온 느낌인데 앞으로는 내생각을 조금 더 작성해야지! ","permalink":"http://localhost:1313/_wiki/programming-a-guessing-game/","summary":"2. Programming a Guessing Game 간단한 숫자 맞추는 게임을 통해 러스트의 기본적인 문법과 기능을 익히는 예제, 처음 문법을 배우는 입장에서 생각보다 다룰 내용이 많았었던 기억이 난다.\nSetting Up a New Project 프로젝트 생성\n$ cargo new guessing_game $ cd guessing_game Processing a Guess src/main.rs\nuse std::io; // io 라이브러리를 가져온다. fn main() { println!(\u0026#34;Guess the number!\u0026#34;); println!(\u0026#34;Please input your guess.\u0026#34;); let mut guess = String::new(); // 빈 문자열을 생성한다. io::stdin().read_line(\u0026amp;mut guess) // 사용자 입력을 받아 guess 변수에 저장한다.","title":"러스트 공식 가이드 2장 정리"},{"content":"1.1. Installation 러스트 설치에 대한 아주 간단한 가이드.\n간단한 내용이라 딱히 정리할 내용은 없다. 1.2. Hello, World! 러스트로 Hello, World! 출력하기.\n특징적인 내용은 아래와 같다.\n공식 가이드의 Helloworld 섹션 첫줄에 다른 언어에 대한 이해도를 전제하고 있다. 실제로 공식 가이드 문서 내내 러스트의 특징을 다른 언어의 특징과 거울처럼 대비하며 설명한다. 파일명 컨벤션은 스네이크 케이스를 사용한다. (그리고 그걸 첫장에 설명한다.) rustc와 같은 컴파일 커맨드도 첫장에 알려준다. fn main() { println!(\u0026#34;Hello, World!\u0026#34;); } 다양한 언어를 배워오면서 느끼는건, Hello, World!를 출력하려고 할 때 언어의 특징을 알 수 있다는 것이다. Public static void main(String[] args) \u0026hellip;. 러스트는 println! 매크로를 사용한다. (매크로는 러스트의 특징 중 하나이다, 나중에 자세히 정리가 나온지만 간단하게 설명하면 러스트의 매크로는 러스트의 문법을 확장할 수 있는 기능이다.) Hello World Anatomy fn : 함수를 선언할 때 사용하는 키워드. 러스트의에서 main함수의 의미 : 프로그램의 시작점을 나타낸다.(The main function is special: it is always the first code that runs in every executable Rust program.) {} : 블록을 나타낸다. 블록은 코드의 범위를 나타낸다. (블록은 러스트의 다른 부분과 마찬가지로 중괄호로 둘러싸여 있다.) println! : 매크로를 호출하는 방법. (매크로는 러스트의 문법을 확장할 수 있는 기능이다.) ; : 문장의 끝을 나타낸다. (러스트는 문장의 끝에 세미콜론을 붙여야 한다, 식의 끝에 세미콜론을 붙이는 것은 문장의 끝을 나타낸다. 이 가이드에서도 문과 식을 구분하는 것이 중요하다.) 러스트의 들여쓰기는 4칸을 권장한다. (공식 가이드에서는 4칸을 권장하는데.. 왜..?) 그 외에는 간단한 컴파일 관련 설명이다.\n1.3. Hello, Cargo! MZ한 언어답게 트랜디한 공식 빌드 시스템이자 패키지 매니저인 Cargo에 대한 간단한 가이드.\nCargo는 러스트의 빌드 시스템이자 패키지 매니저이다. [package] name = \u0026#34;hello_cargo\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] 보통은 이렇게 생겼다. (Cargo.toml 파일) cargo new hello_cargo : 새로운 프로젝트를 생성한다. cargo build : 프로젝트를 빌드한다. 기본적으로 러스트는 디버그 모드로 빌드한다. 그래서 빌드된 실행 파일(바이너리)은 target/debug/${my_project_name}에 위치한다. cargo run : 프로젝트를 실행한다. cargo check : 프로젝트를 빌드하지 않고 컴파일을 실행한다. cargo build --release : 프로젝트를 릴리즈 모드로 빌드한다. cargo update : 프로젝트의 의존성을 업데이트한다. 의존성을 체크하는 lock 파일이 있다. (Cargo.lock) 빌드할 때 알아서 변경을 감지하고 빌드한다. (즉, 변경사항이 없으면 빌드하지 않는다.) cargo check으로 컴파일만 하는 이휴는 빠르기 때문이다, 프로젝트 중간중간 컴파일체크만 하고 싶을 때 사용한다고 한다. --release 플래그로 릴리즈 모드로 빌드할 수 있다. (릴리즈 모드는 최적화가 적용된다.) 컨벤션은 아래와 같다.\n$ git clone example.org/someproject $ cd someproject $ cargo build Conculusion \u0026amp; Impression 패키지매니저를 공식적으로 가지고 있고, 빌드 시스템이 강력하다. 기본적으로 간단한 문법의 언어이다. 매크로가 있다. ","permalink":"http://localhost:1313/_wiki/getting-started/","summary":"1.1. Installation 러스트 설치에 대한 아주 간단한 가이드.\n간단한 내용이라 딱히 정리할 내용은 없다. 1.2. Hello, World! 러스트로 Hello, World! 출력하기.\n특징적인 내용은 아래와 같다.\n공식 가이드의 Helloworld 섹션 첫줄에 다른 언어에 대한 이해도를 전제하고 있다. 실제로 공식 가이드 문서 내내 러스트의 특징을 다른 언어의 특징과 거울처럼 대비하며 설명한다. 파일명 컨벤션은 스네이크 케이스를 사용한다. (그리고 그걸 첫장에 설명한다.) rustc와 같은 컴파일 커맨드도 첫장에 알려준다. fn main() { println!(\u0026#34;Hello, World!\u0026#34;); } 다양한 언어를 배워오면서 느끼는건, Hello, World!","title":"러스트 공식 가이드 1장 정리"},{"content":"러스트 공식 가이드 문서 정리 The Rust Programming Language 위의 러스트 공식 가이드 문서를 보고 정리한 내용입니다, 복습을 위해 공식 가이드를 한 번 다시 정리하고 시작하려고 합니다. 집합인가 [[Getting-Started]] : 러스트 설치 및 프로젝트 생성에 대한 가이드 [[Programming-a-Guessing-Game]] : 간단한 숫자 맞추기 게임을 만들어보며 러스트 프로그래밍 기초 문법 및 개념 익히기 [[Common-Programming-Concepts]] : 러스트 프로그래밍 기초 문법 및 개념 [[Understanding-Ownership]] : 러스트의 소유권 시스템에 대한 이해 [[burrow-checker]] : rust-in-action 내용 [[Using-Structs-to-Structure-Related-Data]] : 구조체를 사용하여 관련 데이터 구조화하기 [[Enums-and-Pattern-Matching]] : 열거형과 패턴 매칭 [[Managing-Growing-Projects-with-Packages-Crates-and-Modules]] : 패키지, 크레이트, 모듈을 사용하여 프로젝트 확장하기 [[Common-Collections]] : 컬렉션 사용하기 [[Error-Handling]] : 에러 처리하기 [[Funcional-Langauges-Features]] : Iterators and Closures 변수의 수명은 컴파일 시점에서 스코프 내에서 더이상 사용이 되지 않는걸 확인 가능한 마지막 줄까지 이걸 악용해서 여러개의 가변 참조를 가지는게 약간 안티패턴 같다. ","permalink":"http://localhost:1313/_wiki/the-rust-programming-language/","summary":"러스트 공식 가이드 문서 정리 The Rust Programming Language 위의 러스트 공식 가이드 문서를 보고 정리한 내용입니다, 복습을 위해 공식 가이드를 한 번 다시 정리하고 시작하려고 합니다. 집합인가 [[Getting-Started]] : 러스트 설치 및 프로젝트 생성에 대한 가이드 [[Programming-a-Guessing-Game]] : 간단한 숫자 맞추기 게임을 만들어보며 러스트 프로그래밍 기초 문법 및 개념 익히기 [[Common-Programming-Concepts]] : 러스트 프로그래밍 기초 문법 및 개념 [[Understanding-Ownership]] : 러스트의 소유권 시스템에 대한 이해 [[burrow-checker]] : rust-in-action 내용 [[Using-Structs-to-Structure-Related-Data]] : 구조체를 사용하여 관련 데이터 구조화하기 [[Enums-and-Pattern-Matching]] : 열거형과 패턴 매칭 [[Managing-Growing-Projects-with-Packages-Crates-and-Modules]] : 패키지, 크레이트, 모듈을 사용하여 프로젝트 확장하기 [[Common-Collections]] : 컬렉션 사용하기 [[Error-Handling]] : 에러 처리하기 [[Funcional-Langauges-Features]] : Iterators and Closures 변수의 수명은 컴파일 시점에서 스코프 내에서 더이상 사용이 되지 않는걸 확인 가능한 마지막 줄까지 이걸 악용해서 여러개의 가변 참조를 가지는게 약간 안티패턴 같다.","title":"The Rust Programming Language"},{"content":"Neovim Copilot 관련 설정 이슈 Copilot을 import하고 잘 쓰고 있는데, Vimwiki와 Tab키 충돌이 발생한다. Tab키를 누르면, Copilot이 자동완성을 제공하는데, Vimwiki에서는 Tab키를 사용하여 들여쓰기를 한다. 뭔가 Vimwiki의 탭이 Copilot의 탭보다 우선순위가 높은 것 같다. 처음에는 Copilot의 설정을 변경하여 해결하려고 했지만 Vimwiki의 설정을 변경하는 것이 더 편할 것 같다. 해결 다행히도 Vimwiki Repository에 이슈가 올라와 있었다. Vimwiki Issue return { \u0026#39;vimwiki/vimwiki\u0026#39;, init = function() -- .. end, config = function() vim.g.vimwiki_key_mappings = { table_mappings = 0, } vim.keymap.set(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;nl\u0026#39;, \u0026#39;\u0026lt;Plug\u0026gt;VimwikiNextLink\u0026#39;, { silent = true }) -- For Tab vim.keymap.set(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;pl\u0026#39;, \u0026#39;\u0026lt;Plug\u0026gt;VimwikiPrevLink\u0026#39;, { silent = true }) -- For STab end } 위와 같이 설정을 변경하면, Tab키를 누르면 들여쓰기가 되고, \u0026lt;leader\u0026gt;nl을 누르면 다음 링크로 이동한다. 내 생각으로는 vimwiki_key_mappings 설정만 변경해도 괜찮았어야 하는데, 저부분만 변경시 제대로 동작하지 않았다. 물론 Tab으로 페이지 내의 링크를 이동하는걸 잘 쓰고 있었지만, \u0026lt;leader\u0026gt;nl을 쓰는 것도 나쁘지 않아서 적용해봤는데 제대로 동작한다. 실제 코드 변경 nvimConfig repo commit hash - 921de26 use({ \u0026#34;vimwiki/vimwiki\u0026#34;, config = function() vim.g.vimwiki_conceallevel = 0 vim.g.vimwiki_global_ext = 0 vim.g.vimwiki_key_mappings = { table_mappings = 0, } vim.keymap.set(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;nl\u0026#39;, \u0026#39;\u0026lt;Plug\u0026gt;VimwikiNextLink\u0026#39;, { silent = true }) -- For Tab vim.keymap.set(\u0026#39;n\u0026#39;, \u0026#39;\u0026lt;leader\u0026gt;pl\u0026#39;, \u0026#39;\u0026lt;Plug\u0026gt;VimwikiPrevLink\u0026#39;, { silent = true }) -- For STab vim.g.vimwiki_list = { { path = \u0026#39;/Users/joonkyu_kang/wiki/SmallzooDevWiki/content/_wiki\u0026#39;, ext = \u0026#39;.md\u0026#39;, styntax = \u0026#39;markdown\u0026#39;, index = \u0026#39;home\u0026#39; }, { path = \u0026#39;/Users/joonkyu_kang/wiki/private_wiki\u0026#39;, ext = \u0026#39;.md\u0026#39;, }, } end }) 위와 같이 변경하였다, vimwiki 설정도 plugin 파일로 빼야하는데 귀찮\u0026hellip; ","permalink":"http://localhost:1313/_wiki/neovim-copilot-config/","summary":"Neovim Copilot 관련 설정 이슈 Copilot을 import하고 잘 쓰고 있는데, Vimwiki와 Tab키 충돌이 발생한다. Tab키를 누르면, Copilot이 자동완성을 제공하는데, Vimwiki에서는 Tab키를 사용하여 들여쓰기를 한다. 뭔가 Vimwiki의 탭이 Copilot의 탭보다 우선순위가 높은 것 같다. 처음에는 Copilot의 설정을 변경하여 해결하려고 했지만 Vimwiki의 설정을 변경하는 것이 더 편할 것 같다. 해결 다행히도 Vimwiki Repository에 이슈가 올라와 있었다. Vimwiki Issue return { \u0026#39;vimwiki/vimwiki\u0026#39;, init = function() -- .. end, config = function() vim.g.vimwiki_key_mappings = { table_mappings = 0, } vim.","title":"Neovim Copilot 관련 설정 이슈"},{"content":" 이미지 호스팅 알아보기 구글 검색 노출 관련 검색, 테스팅 징행하기 [v] 빔을 통해서 괄호를 편하게 작성하는 방법에 대한 포스팅 작성하기 회고 문서 작성하기 ","permalink":"http://localhost:1313/_wiki/todolist/","summary":" 이미지 호스팅 알아보기 구글 검색 노출 관련 검색, 테스팅 징행하기 [v] 빔을 통해서 괄호를 편하게 작성하는 방법에 대한 포스팅 작성하기 회고 문서 작성하기 ","title":"ToDoList✅"},{"content":"모니터🖥️ Lg 듀얼업 모니터 : 꼭 사고싶은 모니터, 최종적인 조합은 이것과 피벗용 27인치 모니터로 마무리 하고 싶다. 키보드⌨️ HHKB 키보드 : 미니배열이 좋으면서도 백틱이 걱정되긴한다. 키 커스텀이 어느정도인지 확인하고 구매할 것 같다 ","permalink":"http://localhost:1313/_wiki/%EC%82%AC%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EC%9E%A5%EB%B9%84/","summary":"모니터🖥️ Lg 듀얼업 모니터 : 꼭 사고싶은 모니터, 최종적인 조합은 이것과 피벗용 27인치 모니터로 마무리 하고 싶다. 키보드⌨️ HHKB 키보드 : 미니배열이 좋으면서도 백틱이 걱정되긴한다. 키 커스텀이 어느정도인지 확인하고 구매할 것 같다 ","title":"사고싶은 장비 List"},{"content":"Inbox 💭 [[Blog에-대한-생각]] [[Interview-From-Jim-Keller]] [[블로그-작성-가이드라인]] Monthly goal 🚀 [[2024-04]] [[2024-05]] ToDoList ✅ [[ToDoList]] Travel 🌍 About Machines 🧊 [[사고-싶은-장비]] About Settings 🧊 [[회사컴-세팅]] [[New-Vimwiki-Test]] Chore 🧹 [[이사]] ","permalink":"http://localhost:1313/_wiki/private-wiki/","summary":"Inbox 💭 [[Blog에-대한-생각]] [[Interview-From-Jim-Keller]] [[블로그-작성-가이드라인]] Monthly goal 🚀 [[2024-04]] [[2024-05]] ToDoList ✅ [[ToDoList]] Travel 🌍 About Machines 🧊 [[사고-싶은-장비]] About Settings 🧊 [[회사컴-세팅]] [[New-Vimwiki-Test]] Chore 🧹 [[이사]] ","title":"개인적인 이야기를 작성할 예정입니다."},{"content":"1일 1커맨드 정리 ^ + b, f : 한 페이지씩 스크롤 zz : 현재 커서가 있는 줄을 화면 중앙으로 이동 yi( : 괄호 안에 있는 내용 복사 vap : 비주얼모드 한 문단 블록 씌우기 이동 관련 brace 관련 커맨드를 조금 더 잘쓰면 좋겠다는 생각을 한다.\n개인적으로 vim을 더 잘쓰기 위해서 정리를 잘 해둬야 할 것 같다.\n^ + b, f: 한 페이지씩 스크롤 ^ + d, u: 반 페이지씩 스크롤 e, E: 다음 단어의 끝으로, 문자 단위 이동 w, W: 다음 단어의 처음으로, 문자 단위 이동 $: 줄의 마지막으로 이동 0: 줄의 처음으로 이동 ^: 줄의 처음으로 이동 (공백이 아닌 처음 시작되는 문자) Shift + g: 문서의 마지막으로 이동 gg, 1g: 문서의 처음으로 이동 (숫자 라인으로 이동) ), (: 다음, 이전 문장의 처음으로 이동 }, {: 다음, 이전 문단의 처음으로 이동 ]], [[: 다음, 이전 구절의 처음으로 이동 안녕하세요 Vimwiki 관련 커맨드 Tab – Find next wiki link Shift + Tab – Find previous wiki link Split 관련 커맨드 \u0026lt;leader\u0026gt;sv: 창 수직 분할 \u0026lt;leader\u0026gt;sh: 창 수평 분할 \u0026lt;leader\u0026gt;se: 창 확장 \u0026lt;leader\u0026gt;sx: 창 닫기 lsp 관련 커맨드 \u0026lt;leader\u0026gt;gd: 정의로 이동 ","permalink":"http://localhost:1313/_wiki/%EC%9E%90%EC%A3%BC-%EA%B9%8C%EB%A8%B9%EB%8A%94-%EC%BB%A4%EB%A7%A8%EB%93%9C-%EC%A0%95%EB%A6%AC/","summary":"1일 1커맨드 정리 ^ + b, f : 한 페이지씩 스크롤 zz : 현재 커서가 있는 줄을 화면 중앙으로 이동 yi( : 괄호 안에 있는 내용 복사 vap : 비주얼모드 한 문단 블록 씌우기 이동 관련 brace 관련 커맨드를 조금 더 잘쓰면 좋겠다는 생각을 한다.\n개인적으로 vim을 더 잘쓰기 위해서 정리를 잘 해둬야 할 것 같다.\n^ + b, f: 한 페이지씩 스크롤 ^ + d, u: 반 페이지씩 스크롤 e, E: 다음 단어의 끝으로, 문자 단위 이동 w, W: 다음 단어의 처음으로, 문자 단위 이동 $: 줄의 마지막으로 이동 0: 줄의 처음으로 이동 ^: 줄의 처음으로 이동 (공백이 아닌 처음 시작되는 문자) Shift + g: 문서의 마지막으로 이동 gg, 1g: 문서의 처음으로 이동 (숫자 라인으로 이동) ), (: 다음, 이전 문장의 처음으로 이동 }, {: 다음, 이전 문단의 처음으로 이동 ]], [[: 다음, 이전 구절의 처음으로 이동 안녕하세요 Vimwiki 관련 커맨드 Tab – Find next wiki link Shift + Tab – Find previous wiki link Split 관련 커맨드 \u0026lt;leader\u0026gt;sv: 창 수직 분할 \u0026lt;leader\u0026gt;sh: 창 수평 분할 \u0026lt;leader\u0026gt;se: 창 확장 \u0026lt;leader\u0026gt;sx: 창 닫기 lsp 관련 커맨드 \u0026lt;leader\u0026gt;gd: 정의로 이동 ","title":"Vim 자주 깜빡하는 커맨드"},{"content":"생활 관련 링크 Archive 목 디스크 스트레칭 : 언젠가는 하겠지\u0026hellip;?\n게임음악 모음\n지브리 오케스트라\nobsidian to 1 (a)\nraycast to opt opt\nchrome to w\nsystem window cycle to hyper + c ;\n","permalink":"http://localhost:1313/_wiki/life-archive-2025/","summary":"생활 관련 링크 Archive 목 디스크 스트레칭 : 언젠가는 하겠지\u0026hellip;?\n게임음악 모음\n지브리 오케스트라\nobsidian to 1 (a)\nraycast to opt opt\nchrome to w\nsystem window cycle to hyper + c ;","title":"생활 관련 링크 Archive"},{"content":"개발 관련 링크 Archive 나이들어가는 프로그래머 : 63세의 나이에도 더 일을 하고싶은 마음이 부러워서, 나도 그러고 싶은 사람으로써 이미 그런사람을 보는 기분 업계에서 10년 있은 뒤, 마음이 바뀐 소프트웨어 개발 토픽들 shunpo : directory 북마크 cli app, yazi와는 다른 맥락으로 유용할듯 modern unix : 유용한 modern unix cli tool을 소개하는 레포, 주기적으로 업데이트 된다. 2024년 가장 조회수 높은 소프트 엔지니어링 발표들 : 재미있는 내용들이 많은 것 같다. ","permalink":"http://localhost:1313/_wiki/dev-archive-2025/","summary":"개발 관련 링크 Archive 나이들어가는 프로그래머 : 63세의 나이에도 더 일을 하고싶은 마음이 부러워서, 나도 그러고 싶은 사람으로써 이미 그런사람을 보는 기분 업계에서 10년 있은 뒤, 마음이 바뀐 소프트웨어 개발 토픽들 shunpo : directory 북마크 cli app, yazi와는 다른 맥락으로 유용할듯 modern unix : 유용한 modern unix cli tool을 소개하는 레포, 주기적으로 업데이트 된다. 2024년 가장 조회수 높은 소프트 엔지니어링 발표들 : 재미있는 내용들이 많은 것 같다. ","title":"개발 관련 링크 Archive"},{"content":"01. Intro - 블로그를 다시 시작하려고 보니.. 👋🏼 올해 초 이직에 대한 열망이 매우 차오를 때 부터 블로그를 다시 시작해야지 하는 생각이 계속 들어왔다. 누구나 그렇겠지만, 회사와 퇴근 후에 진행하는 멘토링/튜터링이 바빴기 때문에.. 튜터링 혹은 멘토링을 하는 내내 블로그와 TIL을 권해놓고 나는 정작 이력서를 쓰면서 나에 대한소개나 포트 폴리오를 쓰기도 참 애매하구나 싶었다. 그래서 내가 일하면서 해왔던 트러블슈팅들이나, 자라났던 생각들을 잘 기록해 놓고 싶어졌다. 지금까지의 기록은 계획을 가지지 않고 해왔기 때문에살리는건 시작도 전에 포기했다! Vimwiki Private 디렉토리에 우후죽순으로 작성되어 있고. 아마 해당 기록을 올리면 높은 확률로 고소를 당할 것 같다 구상권 무튼 늦었지만 다시 시작해보려고 마음을 먹었다, 지나간일은 회고가 되고 하고있는 것들이나 배우는 것들은 TIL 비슷한 뭔가가 되겠지 그래서 블로그를 시작하기로 마음먹고 최근 2주동안 겪은 시행착오에 대해서 이야기 해보려고 한다. 02. Wannabe - Johngrib과 수많은 위키형 블로그🚀 앞서 이야기 한 것처럼 원래 Johngrib님의 블로그를 보고 나의 NeoVim config에 나름 적당히 잘 세팅해놓은 Vimwiki를 사용하고 있었다.\n그리고Johngrib님의 레포를 fork해서 jekyll로 깃허브 블로그도 띄웠었다.\n사실 그러고 나서는 거의 private 위키만을 이용해 왔었다. 왜냐하면 퇴근하고 하는 일도 있다보니 개인컴을 사용하지 않기도 하고, 회사맥에는 주로 업무를 위한 메모가 많았어서 분류할 겨를이 없었다.\n그리고 다시 블로그를 띄우려고 하다보니.. 여러가지 설정들도 까먹고, 다시 시작하기 손에 안잡혔다.\n그렇지만 위키의 형식을 갖추지 않고 글을 써갈 자신은 없고, 포스팅을 위해 추가적인 시간을 쓰기는 여전히 싫었다.\n결론적으로는 새로 블로그를 파면서 위키를 세팅하는 시간을 가져기로 했고 나름의 대장정이 시작됐다\n03. 블로그를 시작하며 영감을 줬던 것들 당연히 Johngrib님의 블로그 저런 윈도우 98같은 감성부터 세세한 기능들과 pre-hook까지 내가 했던 해왔던 고민들이랑 많이 일치한다는 생각을 했다. 다양한 TIL 레포들 이렇게 죽어라 긴 TIL을 보며 참 부러웠던 것 같다. 04. Hugo, Gatsby, Jekyll - 뭐가 더 좋고 적합할까🤔 사실 제목은 위와 같이 작성했지만, Jekyll은 딱히 고민하지 않았다, Jekyll을 사용해서는 Johngrib님의 위키보다 좋은 위키를 만들 자신이 없었다.\n결론적으로는 Hugo, Gatsby 였는데 이 고민을 해결하는데 가장 시간이 오래 걸렸던 것 같다.\n대표적인 특징이라기 보다는 내가 느낀 장단점은 아래와 같다\nGatsby 장점 너무 좋은 예시가 있었다. 바로 PadosumWiki 딱 저렇게 만들고 싶었었다. 심지어 해당 위키를 실행시키는 starter도 찾았었다. 싫다 싫다 하면서 개발해온 React와 Graphql 짬밥이 있어 커스텀에 자신이 있었다. 사실 커스텀보다 디버깅에 자신이 있었다. Gatsby 단점 npm 싫다\u0026hellip; yarn 도 그냥 그렇다.. pnpm은 왜 안되는지 모르겠지만 굳이 공부하기는 싫었다. 마찬가지로 퇴근하고 React도 싫었다.. 회사에서와 달리 내가 뷰를 만지는게 불가능한 시점부터 유의미한 커스텀이 가능할까 싶어지기도 했다 핑계 Hugo 장점 Go를 사용해서 만들어 졌다. (커스텀 하기 위해 공부를 해야 한다면 차라리 이쪽을\u0026hellip;) 빠르다 (대표적인 장점이지만, 실제로 Netlify에 호스팅을 시작하고 뭔가 크게 다가왔다) 나름 Jekyll을 써본 적이 있다고 익숙한 정적 사이트 생성기의 문법 (이생각은 큰 후회를 불러온다) 가볍고 미니멀해서 마음에 드는 테마가 있었다. 영어라면 레퍼런스는 충분히 많고, 포럼도 나름 활발하다. 너무 많이 든든한 레퍼런스를 찾았다, 이친구의 가이드 만 있으면 걱정이 없을 정도.. Hugo 단점 Jekyll을 쓸 때 기억이 안났나 보다, 사실상 Go로 뭔가를 할 일은 극히 드물다, 아무래도 블로그 영업글? 등에서 Go로 되어있는 부분을 지나치게 강조하시는 것 같다. (물론 이부분은 생각이 많이 달라질 수 있다.) 특유의 SSR 템플릿 문법 (이건 위와 같은 맥락인데 쓰고 수정하는 내내 Thymeleaf, Handlebars 와 같은 문법에 시달렸다) 테마의 편집이 생각보다 신경 쓸 부분이 있긴하다. (서브모듈로 관리해야하는게 또 하나의 관리포인트가 될 것 같다, 심지어 조금 찝찝해서 테마 서브모듈을 포크를 따서 수정중이다) 05. Hugo Blog - 세팅기💭 기본 설정 기본 세팅 : 너무 쉽고 간편한 편이다. Hugo 공식 가이드도 잘 되어있고, 이 친구의 가이드와 함께면 더 간단하게 세팅 할 수 있다. 추가 커스텀 세팅 : 공식 가이드와 위 친구의 가이드를 참고해서 따라하다보면 눈치껏 커스텀이 가능하다. toc와 코드블럭과 같은 세팅들을 주로 했다. Nord Theme으로 무드잡기🧊 : Papermod는css관리가 잘되어 있어서 GPT에게 부탁하면 Nord처럼 유명한 Color Scheme은 바로 해준다. Theme/${테마명} 의 asset에 보면 보통 잘되어 있는 테마들은 주요 색상값에 대한 관리가 되어 있다. 테마 관리 : 결국 이런식의 커스텀은 테마쪽에서 이루어 질 수 밖에 없어서 결국 테마를 포크딴 레포를 서브모듈로 지정했다. (아마 테마 커스텀에 생각이 없거나, 더 정확하게 커스텀할 실력이 있다면 원본 레포를 서브모듈로 추가해 사후관리를 받는게 더 좋은 선택지 일 것 같다) Vimwiki 관련 설정 Vimwiki의 링크를 html 링크로 수정하기\n\u0026lt;script\u0026gt; ;(function() { var content = document.querySelector(\u0026#39;article.post-single\u0026#39;); content.innerHTML = content.innerHTML.replace(/\\[\\[(.+?)\\]\\]\\{(.+?)\\}/g, \u0026#39;\u0026lt;a href=\u0026#34;../$1\u0026#34;\u0026gt;$2\u0026lt;/a\u0026gt;\u0026#39;); content.innerHTML = content.innerHTML.replace(/\\[\\[(.+?)\\]\\]/g, \u0026#39;\u0026lt;a href=\u0026#34;../$1\u0026#34;\u0026gt;$1\u0026lt;/a\u0026gt;\u0026#39;); })(); \u0026lt;/script\u0026gt; vimwiki는 [[Link]]와 같은 형식의 링크를 생성하고, 마크다운은 [link](pathToLinkResource)와 같은 형식의 링크를 작성해줘야 한다 \u0026ldquo;./theme/Papermod/layouts/_default/single.html\u0026rdquo; (마크다운 렌더 탬플릿) Johngrib님의 스크립트와 거의 같다.\nnvim config의 vimwiki관련 lua 스크립트 수정하기\nuse({ \u0026#34;vimwiki/vimwiki\u0026#34;, config = function() vim.g.vimwiki_conceallevel = 0 vim.g.vimwiki_list = { { path = \u0026#39;/Users/joonkyu_kang/wiki/SmallzooDevWiki/content/_wiki\u0026#39;, -- hugo 블로그 위치로 수정한다. ext = \u0026#39;.md\u0026#39;, styntax = \u0026#39;markdown\u0026#39;, index = \u0026#39;home\u0026#39; -- 인덱스파일의 이름을 바꿔줘야 한다. }, { path = \u0026#39;/Users/joonkyu_kang/wiki/private_wiki\u0026#39;, -- private wiki 설정 ext = \u0026#39;.md\u0026#39;, }, } end }) 별거 아닌데, 여기서 은근히 시간을 많이 잡아먹었다, index.md를 사용해야 하는데, 휴고는 index.md를 uri path 설정중 문법으로 사용한다. Vimwiki가 생각보다 설정이 되는걸 빨리 알았다면 시간을 아꼈을 것 같다. 처음에는 심지어 Git commit pre-hook에 스크립트를 둬서 해결하려고 했었다. vim.cmd [[ let g:md_modify_disabled = 0 function! NewTemplate () let l:wiki_directory = v:false for wiki in g:vimwiki_list if expand(\u0026#39;%:p:h\u0026#39;) =~ expand(wiki.path) let l:wiki_directory= v:true break endif endfor if !l:wiki_directory echom \u0026#39;first debugging point \u0026gt;\u0026gt; called this return statement\u0026#39; return endif if line(\u0026#34;$\u0026#34;) \u0026gt; 1 return endif let l:template = [] call add(l:template, \u0026#39;---\u0026#39;) call add(l:template, \u0026#39;title: \u0026#39;) call add(l:template, \u0026#39;summary: \u0026#39;) call add(l:template, \u0026#39;date: \u0026#39; . strftime(\u0026#39;%Y-%m-%d %H:%M:%S +0900\u0026#39;)) call add(l:template, \u0026#39;lastmod: \u0026#39; . strftime(\u0026#39;%Y-%m-%d %H:%M:%S +0900\u0026#39;)) call add(l:template, \u0026#39;tags: \u0026#39;) call add(l:template, \u0026#39;categories: \u0026#39;) call add(l:template, \u0026#39;public: true\u0026#39;) call add(l:template, \u0026#39;parent: \u0026#39;) call add(l:template, \u0026#39;description: \u0026#39;) call add(l:template, \u0026#39;showToc: true\u0026#39;) call add(l:template, \u0026#39;---\u0026#39;) call add(l:template, \u0026#39;\u0026#39;) call add(l:template, \u0026#39;# \u0026#39;) call setline(1, l:template) execute \u0026#39;normal! G\u0026#39; execute \u0026#39;normal! $\u0026#39; echom \u0026#39;new wiki page has created\u0026#39; endfunction function! LastModified() if g:md_modify_disabled return endif if \u0026amp;modified \u0026#34; echo(\u0026#39;markdown updated time modified\u0026#39;) let save_cursor = getpos(\u0026#34;.\u0026#34;) let n = min([10, line(\u0026#34;$\u0026#34;)]) keepjumps exe \u0026#39;1,\u0026#39; . n . \u0026#39;s#^\\(.\\{,10}updated\\s*: \\).*#\\1\u0026#39; . \\ strftime(\u0026#39;%Y-%m-%d %H:%M:%S +0900\u0026#39;) . \u0026#39;#e\u0026#39; call histdel(\u0026#39;search\u0026#39;, -1) call setpos(\u0026#39;.\u0026#39;, save_cursor) endif endfun augroup wimwikiauto autocmd BufWritePre *wiki/*.md call LastModified() autocmd BufRead,BufNewFile *wiki/*.md call NewTemplate() augroup END ]] vimwiki를 위한 설정파일도 vimwiki-command.lua에 수정해뒀다. 사실 기존에 사용하던 스크립트에 frontmatter만 hugo에 맞게 수정했다. 06. 배포하기 - Netlify ✈️ 배포는 역시 Github pages나 Netlify를 고민했다.\n둘 다 일정 사용량까지는 무료이며 확인해봤을때 특정 사이트가 빠르거나 하지는 않은 것 같다.\n그래도 Netlify가 배포관련 설정들이 훨씬 더 상세하고, 에러나 로그도 잘 관리되고 있다.\n나중에 비용이 발생 할 수 있다는 것 때문에 조금 더 고민했는데, 그정도로 블로그를 많이 봐주신다면 기꺼이 낼 만 한 금액이기도 했다.\n연동도 github pages와 비견될 정도로 간단하다.\n일단 Netlify에 접속해서 github로 연동하고 물어보는걸 답하면 바로 배포까지 해준다.\n다만 바로 잘되진 않았는데, 처음 사용해보는 만큼 약간의 트러블슈팅을 했다.\n사실 당연히 체크 했어야 하는데, 요즘 서비스들은 너무 잘 래핑되어있고, 휴고정도라면 알아서 해줄줄 알고 생각을 안했던 것 같다.\n빌드 스크립트를 작성해줘야 한다. 당연한 이야기이긴 하지만, 뭔가 휴고인거 알고 알아서 하려나 싶고 안했다가 빌드가 안됐다. 휴고 레포를 연동하고 Deploy 관련 설정을 하다보면 설정하는곳이 나온다. 거기에 \u0026ldquo;huho\u0026quot;라고 기입하면 된다. 배포 디렉토리를 설정해줘야 한다. 마찬가지의 맥락. pulic 디렉토리를 설정해줘야 한다. 마지막으로 빌드 버전을 설정해줘야 한다. 로컬에서 빌드가 잘되는데, 문법에러가 발생한다면 이부분을 체크해보자 이게 다 싫다면 아래와 같은 설정파일을 프로젝트 루트에 netlify.toml이라는 이름으로 두면 알아서 해준다.\n[build] publish = \u0026#34;public\u0026#34; # Or the directory where your Hugo site generates the static files command = \u0026#34;hugo\u0026#34; # This is the default build command for Hugo [build.environment] HUGO_VERSION = \u0026#34;0.123.8\u0026#34; 07. 결과\u0026amp; Left Todo 🤔 Netlify와 Hugo로 설정을 해두니 Vimwiki private을 사용할때와 차이는 정말 커밋 푸시 한번으로 끝났다. 나도 내 생활에 큰 도구가 되어주기를 바라고 있다. 거의 대부분의 설정이 마무리가 잘 되었지만, 아직 남은 일들이 있다.\n이미지관련 플러그인을 조금 더 알아보고, 가능하면 이미지 호스팅 서비스를 찾아내려고 한다. (로컬로 관리하기는 귀찮고, Netlify는 가격을 깐깐하게 매기는 느낌이다) 아직 검색 노출이 잘 되는지 확인해보지 않았는데, 아마도 헤더쪽 설정을 조금 더 해야할 것 같다. 태그와 카테고리 검색과 같은 설정들은 아직 테마의 기본 상태인데 찾아봐야할 것 같다.(다만 메인 위키의 길게 늘어진 링크들을 만들고 싶어서 바로 보지는 않을 것 같다.) 코드 테마를 바꾸고 싶다 이제까지 나만 보려고 써왔던 나의 마크다운 문서 작성능력에 회의가 왔기 때문에 마크다운 문서 공부.. 08. Link (감사합니다\u0026hellip;.) 🙇 Johngrib 님 어느 휴고를 잘쓰는 중국 친구 ","permalink":"http://localhost:1313/_wiki/%EC%83%88%EB%A1%9C%EC%9A%B4-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EC%A0%95%EC%B0%A9%ED%95%98%EA%B8%B0/","summary":"01. Intro - 블로그를 다시 시작하려고 보니.. 👋🏼 올해 초 이직에 대한 열망이 매우 차오를 때 부터 블로그를 다시 시작해야지 하는 생각이 계속 들어왔다. 누구나 그렇겠지만, 회사와 퇴근 후에 진행하는 멘토링/튜터링이 바빴기 때문에.. 튜터링 혹은 멘토링을 하는 내내 블로그와 TIL을 권해놓고 나는 정작 이력서를 쓰면서 나에 대한소개나 포트 폴리오를 쓰기도 참 애매하구나 싶었다. 그래서 내가 일하면서 해왔던 트러블슈팅들이나, 자라났던 생각들을 잘 기록해 놓고 싶어졌다. 지금까지의 기록은 계획을 가지지 않고 해왔기 때문에살리는건 시작도 전에 포기했다!","title":"Hugo, Vimwiki로 블로그 정착하기"},{"content":" Contact : Email 📧 Github : SmallzooDev 🐦‍⬛ Postings Tag의 글은 조금 더 읽기 쉽게 작성하려고 노력하고 있습니다 : #Postings 🗞️ This wiki inspired by : 기계인간 Johngrib 💭 큰 문제를 작은 문제 여러개로 볼 수 있는 지혜와, 가장 작은 문제 하나를 시작할 만큼의 실행력을 갖기를\nMain 🏠 [[Daily-Log-2024]] : 저에 대해 궁금하시다면 이 문서를 참고해주세요(데일리 아님 주의 🙉) [[Daily-Log-2025]] : 2025 시작! Archive 📘 [[Dev-Archive-2025]] : 개발관련 유용한 정보, 링크 모음 [[Life-Archive-2025]] : 개발 외적인 유용한 정보, 링크 모음 [[Cheat-Sheet]] : 개발 관련 Cheat Sheet 모음 Rust 🦀 [[Rust-Main]] [[The-Rust-Programming-Language]] [[Effective-Rust]] [[Build-Redis-With-Rust]] Java/Kotlin 🏝️ [[코틀린-완벽-가이드-1장-6장]] : 코틀린관련 책, 강의, 스터디 내용정리 [[코틀린-완벽-가이드-7장-12장]] : 위의 2편! [[Kotlin-Algorithms]] [[Kotlin-Functional]] [[Java-Jvm]] Cpp 🐋 [[Cpp-basic]] : C++ 기본 문법 정리 PS ⚠️ [[cpp-ps-basic]] Backend 💰 [[헥사고날-아키텍처]] [[스프링부트]] [[System-Design-Interview]] DataBase 🗄️ [[데이터-중심-애플리케이션-설계]] : 해당 도서에 대한 스터디 내용정리 문서 [[Interview-Queries]] : sql50, advanced sql 50을 하루에 다섯개씩 풀 예정, 정리는 필요한것만 할 것 같다. [[Real-My-SQL]] Computer Science 🦉 [[OSTEP]] : 운영체제 아주 쉬운 세 가지 이야기 [[Network]] : TCP/IP Illustrated Vim 🦅 [[Neovim-Copilot-Config]] [[Vim-Profile-Log-Debugging]] [[Vim-Impove-Sheet]] Postings 🌳 [[새로운-블로그-정착하기]] : 블로그 개발기 [[Neovim-Migration-하기]] [[Interview-From-Jim-Keller]] : ai와 관련된 고민중에 보게된 인터뷰 (ai와 관련은 별로 없다) [[튜터링-질의-응답-모음]] [[redis-handshake-for-replicas]] : 레플리카(슬레이브) 등록을 위한 HandShake중 클라이언트를 식별하는 이슈 [[Redis-Stream-Issue]] [[rust-mpsc]] : rust tokio의 mpsc 기능 이해하기 [[난개발된-레디스를-이벤트루프-기반으로-리팩토링하기]] : 레디스 클론코딩중 발생한 이슈 트러블슈팅 [[Learners-High]] : 토스 러너스 하이 1기를 진행하면서 겪은 이야기들 [[vimwiki-obsidian-같이-사용하기]] : 빔위키로 관리하던 블로그를 옵시디언 볼트로도 관리하도록 설정하기 [[전시영역-백엔드-테스트코드-도입기]] : 전시영역 백엔드 레거시 프로젝트에 테스트코드를 도입하면서 했던 고민들 정리 [[레거시-프로젝트의-로깅-개선하기]] : 레거시 프로젝트의 로깅 개선하기 [[카프카를-헥사고날하게-클론코딩-해보기]] : 러스트로 카프카를 헥사고날하게 클론코딩 해보기 [[결제-서비스-리뉴얼하기]] : 10몇년된 서비스의 결제 전면 리뉴얼 [[신규-프로젝트에서-본인인증-연동-구현하기]]: postMessage를 이용해서 조금더 정돈된 방식으로 인증창 관리하기 ETC 👻 [[Settings]] ","permalink":"http://localhost:1313/_wiki/home/","summary":"Contact : Email 📧 Github : SmallzooDev 🐦‍⬛ Postings Tag의 글은 조금 더 읽기 쉽게 작성하려고 노력하고 있습니다 : #Postings 🗞️ This wiki inspired by : 기계인간 Johngrib 💭 큰 문제를 작은 문제 여러개로 볼 수 있는 지혜와, 가장 작은 문제 하나를 시작할 만큼의 실행력을 갖기를\nMain 🏠 [[Daily-Log-2024]] : 저에 대해 궁금하시다면 이 문서를 참고해주세요(데일리 아님 주의 🙉) [[Daily-Log-2025]] : 2025 시작! Archive 📘 [[Dev-Archive-2025]] : 개발관련 유용한 정보, 링크 모음 [[Life-Archive-2025]] : 개발 외적인 유용한 정보, 링크 모음 [[Cheat-Sheet]] : 개발 관련 Cheat Sheet 모음 Rust 🦀 [[Rust-Main]] [[The-Rust-Programming-Language]] [[Effective-Rust]] [[Build-Redis-With-Rust]] Java/Kotlin 🏝️ [[코틀린-완벽-가이드-1장-6장]] : 코틀린관련 책, 강의, 스터디 내용정리 [[코틀린-완벽-가이드-7장-12장]] : 위의 2편!","title":"Index 🧊️"},{"content":"","permalink":"http://localhost:1313/_wiki/kotlin%EC%9D%B4-%EC%A2%8B%EC%A7%80%EB%A7%8E%EC%9D%80-%EC%95%8A%EC%9D%80-%EC%9D%B4%EC%9C%A0/","summary":"","title":""},{"content":" Contact: Email 📧 안녕하세요! 지금은 웹 백엔드 개발자로 일하고 있는 [SmallzooDev 🐦‍⬛] 입니다! 언젠가는 레거시가 되지 않는 무언가를 개발해보고 싶습니다. 알고 계시겠지만, [Nord Theme 🧊]을 좋아합니다, Catppuccin-Mocha도 나쁘지 않네요. Vim을 좋아합니다. [Neovim ⌨️]은 더 좋아합니다. 지금은 [이런 설정 🚀]으로 네오빔에 눌러앉았습니다. 지금은 Rust를 가장 열심히 공부하고 있습니다. [기계인간 Johngrib 💭]님의 위키에 영감을 받아 위키 형식으로 운영해보려고 합니다! 파란색을 좋아합니다, 하늘색, 남색, 바다색 전부 좋아합니다. 좋은 기회에 열려있습니다! ","permalink":"http://localhost:1313/about/","summary":"백엔드 개발자로 일하고 있는 강준규 입니다!","title":"About Me🧊️"}]